
=== [main.py::train] PYTORCH TRAINING DEBUG ===
[main.py::train] Arguments: Namespace(input_size='128x256', batch_size=4, local_rank=0, epochs=2, train=True, test=False, yaml_file='utils/args_bionano.yaml', save_path='./results/rect_256x128_v5_pytoch', dataset_dir='./Dataset/bionano_cellv2', img_size=(128, 256), world_size=1)
[main.py::train] Image size: (128, 256)
[main.py::train] Batch size: 4
[main.py::train] Epochs: 2
[main.py::train] Local rank: 0
[main.py::train] World size: 1
[main.py::train] Parameters: {'lr0': 0.01, 'lrf': 0.01, 'momentum': 0.937, 'weight_decay': 0.0005, 'warmup_epochs': 3.0, 'warmup_momentum': 0.8, 'warmup_bias_lr': 0.1, 'box': 7.5, 'cls': 0.5, 'dfl': 1.5, 'hsv_h': 0.015, 'hsv_s': 0.7, 'hsv_v': 0.4, 'degrees': 0.0, 'translate': 0.1, 'scale': 0.5, 'shear': 0.0, 'flip_ud': 0.0, 'flip_lr': 0.5, 'mosaic': 1.0, 'mix_up': 0.0, 'names': {0: 'cell'}}
[main.py::train] Number of classes: 1
[main.py::train] Model created with input size: (128, 256)
[main.py::train] Model architecture: YOLO(
  (net): DarkNet(
    (backbone): ModuleList(
      (0): Conv(
        (conv): Conv2d(3, 4, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (norm): BatchNorm2d(4, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (1): Conv(
        (conv): Conv2d(4, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (norm): BatchNorm2d(8, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Conv(
        (conv): Conv2d(8, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (norm): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Conv(
        (conv): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (norm): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
  )
  (head): Head(
    (conv): Conv(
      (conv): Conv2d(64, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (norm): BatchNorm2d(24, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (dfl): DFL(
      (conv): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
    (cls): Conv2d(24, 1, kernel_size=(1, 1), stride=(1, 1))
    (box): Conv2d(24, 64, kernel_size=(1, 1), stride=(1, 1))
  )
)
Model summary saved to ./results/rect_256x128_v5_pytoch/model_summary.txt
Successfully logged model summary from ./results/rect_256x128_v5_pytoch/model_summary.txt
Accumulate steps: 16
Weight decay: 0.0005 -> 0.0005

--- [utils/util.py::ComputeLoss.__init__] PYTORCH INITIALIZATION DEBUG ---
[utils/util.py::ComputeLoss.__init__] Model head stride: tensor([8.])
[utils/util.py::ComputeLoss.__init__] Number of classes: 1
[utils/util.py::ComputeLoss.__init__] Output channels (no): 65
[utils/util.py::ComputeLoss.__init__] DFL channels: 16
[utils/util.py::ComputeLoss.__init__] Task aligned assigner params - top_k: 10, alpha: 0.5, beta: 6.0
[utils/util.py::ComputeLoss.__init__] Loss weights - cls: 0.5, box: 7.5, dfl: 1.5

     epoch    memory      loss

--- PYTORCH BATCH 0 DEBUG ---
Samples shape: torch.Size([4, 3, 128, 256])
Samples dtype: torch.uint8
Samples min/max: 0.000/255.000
Targets shape: torch.Size([6, 6])
Targets dtype: torch.float32
Number of targets: 6
Target sample: tensor([0.0000, 0.0000, 0.4033, 0.3785, 0.1124, 0.2293])
Unique image indices: tensor([0., 1., 2., 3.])
Shapes: [None, None, None, None]
After normalization - samples min/max: 0.000/1.000

--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([4, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: True
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([4, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - box shape: torch.Size([4, 64, 16, 32]), cls shape: torch.Size([4, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - final concat shape: torch.Size([4, 65, 16, 32])

--- PYTORCH MODEL OUTPUT DEBUG ---
Number of output tensors: 1
Output 0 shape: torch.Size([4, 65, 16, 32])
Output 0 min/max: -8.679688/7.613281
Output 0 mean/std: 0.891113/1.105469

--- [utils/util.py::ComputeLoss.__call__] PYTORCH LOSS COMPUTATION DEBUG ---
[utils/util.py::ComputeLoss.__call__] Outputs type: <class 'list'>
[utils/util.py::ComputeLoss.__call__] x type: <class 'list'>, len: 1
[utils/util.py::ComputeLoss.__call__] x[0] shape: torch.Size([4, 65, 16, 32])
[utils/util.py::ComputeLoss.__call__] Concatenated output shape: torch.Size([4, 65, 512])
[utils/util.py::ComputeLoss.__call__] self.no: 65, self.dfl_ch: 16, self.nc: 1
[utils/util.py::ComputeLoss.__call__] pred_output shape: torch.Size([4, 64, 512])
[utils/util.py::ComputeLoss.__call__] pred_scores shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.__call__] After permute - pred_output shape: torch.Size([4, 512, 64])
[utils/util.py::ComputeLoss.__call__] After permute - pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Size tensor: tensor([128., 256.], device='cuda:0', dtype=torch.float16)
[utils/util.py::ComputeLoss.__call__] Stride: tensor([8.])
[utils/util.py::ComputeLoss.__call__] Anchor points shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.__call__] Stride tensor shape: torch.Size([512, 1])

--- [utils/util.py::ComputeLoss.__call__] TARGET PROCESSING ---
[utils/util.py::ComputeLoss.__call__] Targets shape: torch.Size([6, 6])
[utils/util.py::ComputeLoss.__call__] Targets dtype: torch.float32
[utils/util.py::ComputeLoss.__call__] First few targets: tensor([[0.0000, 0.0000, 0.4033, 0.3785, 0.1124, 0.2293],
        [0.0000, 0.0000, 0.9594, 0.4695, 0.0811, 0.2151],
        [1.0000, 0.0000, 0.4436, 0.3686, 0.0543, 0.1159],
        [1.0000, 0.0000, 0.9184, 0.2683, 0.0411, 0.0928],
        [2.0000, 0.0000, 0.2233, 0.5476, 0.0637, 0.1254]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Image indices: tensor([0., 0., 1., 1., 2., 3.], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Counts per image: tensor([2, 2, 1, 1], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT tensor shape: torch.Size([4, 2, 5])
[utils/util.py::ComputeLoss.__call__] Image 0: 2 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 1: 2 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 2: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 3: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] GT before coordinate conversion: tensor([[[0.0000, 0.4033, 0.3785, 0.1124, 0.2293],
         [0.0000, 0.9594, 0.4695, 0.0811, 0.2151]],

        [[0.0000, 0.4436, 0.3686, 0.0543, 0.1159],
         [0.0000, 0.9184, 0.2683, 0.0411, 0.0928]],

        [[0.0000, 0.2233, 0.5476, 0.0637, 0.1254],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.3477, 0.6266, 0.1303, 0.2389],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT after coordinate conversion: tensor([[[  0.0000,  88.8507,  33.7716, 117.6140,  63.1211],
         [  0.0000, 235.2372,  46.3320, 255.9990,  73.8603]],

        [[  0.0000, 106.6271,  39.7590, 120.5178,  54.5947],
         [  0.0000, 229.8518,  28.4011, 240.3757,  40.2780]],

        [[  0.0000,  48.9989,  62.0648,  65.3166,  78.1198],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000,  72.3236,  64.9187, 105.6767,  95.4924],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT labels shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.__call__] GT bboxes shape: torch.Size([4, 2, 4])
[utils/util.py::ComputeLoss.__call__] GT mask shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.__call__] Pred output dimensions - b: 4, a: 512, c: 64
[utils/util.py::ComputeLoss.__call__] Pred bboxes after softmax shape: torch.Size([4, 512, 4, 16])
[utils/util.py::ComputeLoss.__call__] Pred bboxes after matmul shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Final pred bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.__call__] ASSIGNMENT PHASE ---

--- [utils/util.py::ComputeLoss.assign] PYTORCH ASSIGNMENT DEBUG ---
[utils/util.py::ComputeLoss.assign] pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] true_labels shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 2, 4])
[utils/util.py::ComputeLoss.assign] true_mask shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.assign] anchors shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.assign] Batch size: 4, Max boxes: 2
[utils/util.py::ComputeLoss.assign] Created indices tensor with shape: torch.Size([2, 4, 2])

--- [utils/util.py::ComputeLoss.assign] IOUs DEBUG ---
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 2, 4])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([4, 2, 1, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([4, 1, 512, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([4, 2, 1, 1]), h: torch.Size([4, 2, 1, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([4, 1, 512, 1]), h: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.000000, max: 0.076794
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: -0.651453, max: 0.071171
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.assign] overlaps shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] overlaps min: 0.0, max: 0.07117093354463577
[utils/util.py::ComputeLoss.assign] align_metric shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] align_metric min: 0.0, max: 3.323610053840298e-09
[utils/util.py::ComputeLoss.assign] mask_in_gts shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] mask_in_gts sum: 50.0
[utils/util.py::ComputeLoss.assign] metrics shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] top_k_mask shape: torch.Size([4, 2, 10])
[utils/util.py::ComputeLoss.assign] top_k_metrics shape: torch.Size([4, 2, 10])
[utils/util.py::ComputeLoss.assign] top_k_indices shape: torch.Size([4, 2, 10])
[utils/util.py::ComputeLoss.assign] is_in_top_k shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] mask_top_k shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] mask_pos shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] fg_mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] fg_mask sum: 38.0
[utils/util.py::ComputeLoss.assign] target_gt_idx shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_labels shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] Normalized target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] target_scores sum: 0.687991738319397
--- [utils/util.py::ComputeLoss.assign] END PYTORCH ASSIGNMENT DEBUG ---

[utils/util.py::ComputeLoss.__call__] Target bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Target scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] FG mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.__call__] Target scores sum: 0.687992
[utils/util.py::ComputeLoss.__call__] Classification loss computed: 7.755816
[utils/util.py::ComputeLoss.__call__] Foreground count: 38
[utils/util.py::ComputeLoss.__call__] Weight shape: torch.Size([38, 1])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([38, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([38, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([38, 1]), h: torch.Size([38, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([38, 1]), h: torch.Size([38, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([38, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([38, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([38, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.010041, max: 0.074065
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([38, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([38, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([38, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([38, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: 0.009759, max: 0.071207
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.__call__] IoU values shape: torch.Size([38, 1])
[utils/util.py::ComputeLoss.__call__] Box loss computed: 0.936732
[utils/util.py::ComputeLoss.__call__] Target LT-RB shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.df_loss] PYTORCH DFL LOSS DEBUG ---
[utils/util.py::ComputeLoss.df_loss] pred_dist shape: torch.Size([152, 16])
[utils/util.py::ComputeLoss.df_loss] target shape: torch.Size([38, 4])
[utils/util.py::ComputeLoss.df_loss] DFL loss shape: torch.Size([38, 1])
[utils/util.py::ComputeLoss.df_loss] DFL loss mean: 2.786175
--- [utils/util.py::ComputeLoss.df_loss] END PYTORCH DFL LOSS DEBUG ---

[utils/util.py::ComputeLoss.__call__] DFL loss before weighting: 2.786175
[utils/util.py::ComputeLoss.__call__] DFL loss computed: 2.796428

--- [utils/util.py::ComputeLoss.__call__] LOSS COMPONENTS DEBUG ---
[utils/util.py::ComputeLoss.__call__] Raw loss_cls: 7.755816
[utils/util.py::ComputeLoss.__call__] Raw loss_box: 0.936732
[utils/util.py::ComputeLoss.__call__] Raw loss_dfl: 2.796428
[utils/util.py::ComputeLoss.__call__] Loss weights - cls: 0.5, box: 7.5, dfl: 1.5
[utils/util.py::ComputeLoss.__call__] target_scores_sum: 0.687992
[utils/util.py::ComputeLoss.__call__] fg_mask sum: 38
[utils/util.py::ComputeLoss.__call__] Weighted loss_cls: 3.877908
[utils/util.py::ComputeLoss.__call__] Weighted loss_box: 7.025493
[utils/util.py::ComputeLoss.__call__] Weighted loss_dfl: 4.194642
[utils/util.py::ComputeLoss.__call__] Total loss: 15.098042
--- [utils/util.py::ComputeLoss.__call__] END PYTORCH LOSS COMPUTATION DEBUG ---


--- PYTORCH LOSS DEBUG ---
Loss value: 15.098042
Loss dtype: torch.float32
Loss requires_grad: True

--- PYTORCH BATCH 1 DEBUG ---
Samples shape: torch.Size([4, 3, 128, 256])
Samples dtype: torch.uint8
Samples min/max: 0.000/171.000
Targets shape: torch.Size([7, 6])
Targets dtype: torch.float32
Number of targets: 7
Target sample: tensor([0.0000, 0.0000, 0.2949, 0.2557, 0.1340, 0.2519])
Unique image indices: tensor([0., 2., 3.])
Shapes: [None, None, None, None]
After normalization - samples min/max: 0.000/0.671

--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([4, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: True
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([4, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - box shape: torch.Size([4, 64, 16, 32]), cls shape: torch.Size([4, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - final concat shape: torch.Size([4, 65, 16, 32])

--- PYTORCH MODEL OUTPUT DEBUG ---
Number of output tensors: 1
Output 0 shape: torch.Size([4, 65, 16, 32])
Output 0 min/max: -10.453125/7.917969
Output 0 mean/std: 0.888184/1.108398

--- [utils/util.py::ComputeLoss.__call__] PYTORCH LOSS COMPUTATION DEBUG ---
[utils/util.py::ComputeLoss.__call__] Outputs type: <class 'list'>
[utils/util.py::ComputeLoss.__call__] x type: <class 'list'>, len: 1
[utils/util.py::ComputeLoss.__call__] x[0] shape: torch.Size([4, 65, 16, 32])
[utils/util.py::ComputeLoss.__call__] Concatenated output shape: torch.Size([4, 65, 512])
[utils/util.py::ComputeLoss.__call__] self.no: 65, self.dfl_ch: 16, self.nc: 1
[utils/util.py::ComputeLoss.__call__] pred_output shape: torch.Size([4, 64, 512])
[utils/util.py::ComputeLoss.__call__] pred_scores shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.__call__] After permute - pred_output shape: torch.Size([4, 512, 64])
[utils/util.py::ComputeLoss.__call__] After permute - pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Size tensor: tensor([128., 256.], device='cuda:0', dtype=torch.float16)
[utils/util.py::ComputeLoss.__call__] Stride: tensor([8.])
[utils/util.py::ComputeLoss.__call__] Anchor points shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.__call__] Stride tensor shape: torch.Size([512, 1])

--- [utils/util.py::ComputeLoss.__call__] TARGET PROCESSING ---
[utils/util.py::ComputeLoss.__call__] Targets shape: torch.Size([7, 6])
[utils/util.py::ComputeLoss.__call__] Targets dtype: torch.float32
[utils/util.py::ComputeLoss.__call__] First few targets: tensor([[0.0000, 0.0000, 0.2949, 0.2557, 0.1340, 0.2519],
        [2.0000, 0.0000, 0.0076, 0.0636, 0.0152, 0.1263],
        [2.0000, 0.0000, 0.3472, 0.1123, 0.0586, 0.1168],
        [2.0000, 0.0000, 0.7665, 0.9063, 0.0755, 0.1537],
        [3.0000, 0.0000, 0.5379, 0.0239, 0.0503, 0.0478]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Image indices: tensor([0., 2., 2., 2., 3., 3., 3.], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Counts per image: tensor([1, 3, 3], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT tensor shape: torch.Size([4, 3, 5])
[utils/util.py::ComputeLoss.__call__] Image 0: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 2: 3 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 3: 3 targets assigned
[utils/util.py::ComputeLoss.__call__] GT before coordinate conversion: tensor([[[0.0000, 0.2949, 0.2557, 0.1340, 0.2519],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.0076, 0.0636, 0.0152, 0.1263],
         [0.0000, 0.3472, 0.1123, 0.0586, 0.1168],
         [0.0000, 0.7665, 0.9063, 0.0755, 0.1537]],

        [[0.0000, 0.5379, 0.0239, 0.0503, 0.0478],
         [0.0000, 0.0631, 0.5327, 0.0501, 0.0984],
         [0.0000, 0.6078, 0.5306, 0.0501, 0.1027]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT after coordinate conversion: tensor([[[0.0000e+00, 5.8355e+01, 1.6605e+01, 9.2650e+01, 4.8853e+01],
         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],

        [[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],

        [[0.0000e+00, 0.0000e+00, 6.4396e-02, 3.8784e+00, 1.6226e+01],
         [0.0000e+00, 8.1386e+01, 6.8946e+00, 9.6381e+01, 2.1848e+01],
         [0.0000e+00, 1.8657e+02, 1.0617e+02, 2.0590e+02, 1.2584e+02]],

        [[0.0000e+00, 1.3127e+02, 0.0000e+00, 1.4415e+02, 6.1192e+00],
         [0.0000e+00, 9.7356e+00, 6.1894e+01, 2.2564e+01, 7.4488e+01],
         [0.0000e+00, 1.4917e+02, 6.1342e+01, 1.6200e+02, 7.4494e+01]]],
       device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT labels shape: torch.Size([4, 3, 1])
[utils/util.py::ComputeLoss.__call__] GT bboxes shape: torch.Size([4, 3, 4])
[utils/util.py::ComputeLoss.__call__] GT mask shape: torch.Size([4, 3, 1])
[utils/util.py::ComputeLoss.__call__] Pred output dimensions - b: 4, a: 512, c: 64
[utils/util.py::ComputeLoss.__call__] Pred bboxes after softmax shape: torch.Size([4, 512, 4, 16])
[utils/util.py::ComputeLoss.__call__] Pred bboxes after matmul shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Final pred bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.__call__] ASSIGNMENT PHASE ---

--- [utils/util.py::ComputeLoss.assign] PYTORCH ASSIGNMENT DEBUG ---
[utils/util.py::ComputeLoss.assign] pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] true_labels shape: torch.Size([4, 3, 1])
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 3, 4])
[utils/util.py::ComputeLoss.assign] true_mask shape: torch.Size([4, 3, 1])
[utils/util.py::ComputeLoss.assign] anchors shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.assign] Batch size: 4, Max boxes: 3
[utils/util.py::ComputeLoss.assign] Created indices tensor with shape: torch.Size([2, 4, 3])

--- [utils/util.py::ComputeLoss.assign] IOUs DEBUG ---
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 3, 4])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([4, 3, 1, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([4, 1, 512, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([4, 3, 1, 1]), h: torch.Size([4, 3, 1, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([4, 1, 512, 1]), h: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.000000, max: 0.112536
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: -0.656264, max: 0.080218
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.assign] overlaps shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] overlaps min: 0.0, max: 0.08021760731935501
[utils/util.py::ComputeLoss.assign] align_metric shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] align_metric min: 0.0, max: 9.343042783882538e-09
[utils/util.py::ComputeLoss.assign] mask_in_gts shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] mask_in_gts sum: 38.0
[utils/util.py::ComputeLoss.assign] metrics shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] top_k_mask shape: torch.Size([4, 3, 10])
[utils/util.py::ComputeLoss.assign] top_k_metrics shape: torch.Size([4, 3, 10])
[utils/util.py::ComputeLoss.assign] top_k_indices shape: torch.Size([4, 3, 10])
[utils/util.py::ComputeLoss.assign] is_in_top_k shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] mask_top_k shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] mask_pos shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] fg_mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] fg_mask sum: 28.0
[utils/util.py::ComputeLoss.assign] target_gt_idx shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_labels shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] Normalized target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] target_scores sum: 0.36853349208831787
--- [utils/util.py::ComputeLoss.assign] END PYTORCH ASSIGNMENT DEBUG ---

[utils/util.py::ComputeLoss.__call__] Target bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Target scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] FG mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.__call__] Target scores sum: 0.368533
[utils/util.py::ComputeLoss.__call__] Classification loss computed: 7.933683
[utils/util.py::ComputeLoss.__call__] Foreground count: 28
[utils/util.py::ComputeLoss.__call__] Weight shape: torch.Size([28, 1])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([28, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([28, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([28, 1]), h: torch.Size([28, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([28, 1]), h: torch.Size([28, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([28, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([28, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([28, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.005629, max: 0.081368
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([28, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([28, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([28, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([28, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: 0.002178, max: 0.080203
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.__call__] IoU values shape: torch.Size([28, 1])
[utils/util.py::ComputeLoss.__call__] Box loss computed: 0.925664
[utils/util.py::ComputeLoss.__call__] Target LT-RB shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.df_loss] PYTORCH DFL LOSS DEBUG ---
[utils/util.py::ComputeLoss.df_loss] pred_dist shape: torch.Size([112, 16])
[utils/util.py::ComputeLoss.df_loss] target shape: torch.Size([28, 4])
[utils/util.py::ComputeLoss.df_loss] DFL loss shape: torch.Size([28, 1])
[utils/util.py::ComputeLoss.df_loss] DFL loss mean: 2.775710
--- [utils/util.py::ComputeLoss.df_loss] END PYTORCH DFL LOSS DEBUG ---

[utils/util.py::ComputeLoss.__call__] DFL loss before weighting: 2.775710
[utils/util.py::ComputeLoss.__call__] DFL loss computed: 2.785924

--- [utils/util.py::ComputeLoss.__call__] LOSS COMPONENTS DEBUG ---
[utils/util.py::ComputeLoss.__call__] Raw loss_cls: 7.933683
[utils/util.py::ComputeLoss.__call__] Raw loss_box: 0.925664
[utils/util.py::ComputeLoss.__call__] Raw loss_dfl: 2.785924
[utils/util.py::ComputeLoss.__call__] Loss weights - cls: 0.5, box: 7.5, dfl: 1.5
[utils/util.py::ComputeLoss.__call__] target_scores_sum: 0.368533
[utils/util.py::ComputeLoss.__call__] fg_mask sum: 28
[utils/util.py::ComputeLoss.__call__] Weighted loss_cls: 3.966842
[utils/util.py::ComputeLoss.__call__] Weighted loss_box: 6.942479
[utils/util.py::ComputeLoss.__call__] Weighted loss_dfl: 4.178886
[utils/util.py::ComputeLoss.__call__] Total loss: 15.088207
--- [utils/util.py::ComputeLoss.__call__] END PYTORCH LOSS COMPUTATION DEBUG ---


--- PYTORCH LOSS DEBUG ---
Loss value: 15.088207
Loss dtype: torch.float32
Loss requires_grad: True

--- PYTORCH BATCH 2 DEBUG ---
Samples shape: torch.Size([4, 3, 128, 256])
Samples dtype: torch.uint8
Samples min/max: 0.000/255.000
Targets shape: torch.Size([3, 6])
Targets dtype: torch.float32
Number of targets: 3
Target sample: tensor([0.0000, 0.0000, 0.2008, 0.7835, 0.1054, 0.2187])
Unique image indices: tensor([0., 1., 3.])
Shapes: [None, None, None, None]
After normalization - samples min/max: 0.000/1.000

--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([4, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: True
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([4, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - box shape: torch.Size([4, 64, 16, 32]), cls shape: torch.Size([4, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - final concat shape: torch.Size([4, 65, 16, 32])

--- PYTORCH MODEL OUTPUT DEBUG ---
Number of output tensors: 1
Output 0 shape: torch.Size([4, 65, 16, 32])
Output 0 min/max: -8.781250/5.363281
Output 0 mean/std: 0.891113/1.111328

--- [utils/util.py::ComputeLoss.__call__] PYTORCH LOSS COMPUTATION DEBUG ---
[utils/util.py::ComputeLoss.__call__] Outputs type: <class 'list'>
[utils/util.py::ComputeLoss.__call__] x type: <class 'list'>, len: 1
[utils/util.py::ComputeLoss.__call__] x[0] shape: torch.Size([4, 65, 16, 32])
[utils/util.py::ComputeLoss.__call__] Concatenated output shape: torch.Size([4, 65, 512])
[utils/util.py::ComputeLoss.__call__] self.no: 65, self.dfl_ch: 16, self.nc: 1
[utils/util.py::ComputeLoss.__call__] pred_output shape: torch.Size([4, 64, 512])
[utils/util.py::ComputeLoss.__call__] pred_scores shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.__call__] After permute - pred_output shape: torch.Size([4, 512, 64])
[utils/util.py::ComputeLoss.__call__] After permute - pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Size tensor: tensor([128., 256.], device='cuda:0', dtype=torch.float16)
[utils/util.py::ComputeLoss.__call__] Stride: tensor([8.])
[utils/util.py::ComputeLoss.__call__] Anchor points shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.__call__] Stride tensor shape: torch.Size([512, 1])

--- [utils/util.py::ComputeLoss.__call__] TARGET PROCESSING ---
[utils/util.py::ComputeLoss.__call__] Targets shape: torch.Size([3, 6])
[utils/util.py::ComputeLoss.__call__] Targets dtype: torch.float32
[utils/util.py::ComputeLoss.__call__] First few targets: tensor([[0.0000, 0.0000, 0.2008, 0.7835, 0.1054, 0.2187],
        [1.0000, 0.0000, 0.3009, 0.3063, 0.1269, 0.2712],
        [3.0000, 0.0000, 0.3860, 0.3718, 0.0610, 0.1087]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Image indices: tensor([0., 1., 3.], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Counts per image: tensor([1, 1, 1], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT tensor shape: torch.Size([4, 1, 5])
[utils/util.py::ComputeLoss.__call__] Image 0: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 1: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 3: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] GT before coordinate conversion: tensor([[[0.0000, 0.2008, 0.7835, 0.1054, 0.2187]],

        [[0.0000, 0.3009, 0.3063, 0.1269, 0.2712]],

        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.3860, 0.3718, 0.0610, 0.1087]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT after coordinate conversion: tensor([[[  0.0000,  37.9209,  86.2892,  64.9120, 114.2773]],

        [[  0.0000,  60.7733,  21.8466,  93.2709,  56.5551]],

        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000,  91.0076,  40.6313, 106.6339,  54.5452]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT labels shape: torch.Size([4, 1, 1])
[utils/util.py::ComputeLoss.__call__] GT bboxes shape: torch.Size([4, 1, 4])
[utils/util.py::ComputeLoss.__call__] GT mask shape: torch.Size([4, 1, 1])
[utils/util.py::ComputeLoss.__call__] Pred output dimensions - b: 4, a: 512, c: 64
[utils/util.py::ComputeLoss.__call__] Pred bboxes after softmax shape: torch.Size([4, 512, 4, 16])
[utils/util.py::ComputeLoss.__call__] Pred bboxes after matmul shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Final pred bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.__call__] ASSIGNMENT PHASE ---

--- [utils/util.py::ComputeLoss.assign] PYTORCH ASSIGNMENT DEBUG ---
[utils/util.py::ComputeLoss.assign] pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] true_labels shape: torch.Size([4, 1, 1])
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 1, 4])
[utils/util.py::ComputeLoss.assign] true_mask shape: torch.Size([4, 1, 1])
[utils/util.py::ComputeLoss.assign] anchors shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.assign] Batch size: 4, Max boxes: 1
[utils/util.py::ComputeLoss.assign] Created indices tensor with shape: torch.Size([2, 4, 1])

--- [utils/util.py::ComputeLoss.assign] IOUs DEBUG ---
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 1, 4])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([4, 1, 1, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([4, 1, 512, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([4, 1, 1, 1]), h: torch.Size([4, 1, 1, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([4, 1, 512, 1]), h: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.000000, max: 0.090413
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: -0.653734, max: 0.080237
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.assign] overlaps shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.assign] overlaps min: 0.0, max: 0.08023735135793686
[utils/util.py::ComputeLoss.assign] align_metric shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.assign] align_metric min: 0.0, max: 6.882846292910472e-09
[utils/util.py::ComputeLoss.assign] mask_in_gts shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.assign] mask_in_gts sum: 29.0
[utils/util.py::ComputeLoss.assign] metrics shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.assign] top_k_mask shape: torch.Size([4, 1, 10])
[utils/util.py::ComputeLoss.assign] top_k_metrics shape: torch.Size([4, 1, 10])
[utils/util.py::ComputeLoss.assign] top_k_indices shape: torch.Size([4, 1, 10])
[utils/util.py::ComputeLoss.assign] is_in_top_k shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.assign] mask_top_k shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.assign] mask_pos shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.assign] fg_mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] fg_mask sum: 23.0
[utils/util.py::ComputeLoss.assign] target_gt_idx shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_labels shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] Normalized target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] target_scores sum: 0.6832846403121948
--- [utils/util.py::ComputeLoss.assign] END PYTORCH ASSIGNMENT DEBUG ---

[utils/util.py::ComputeLoss.__call__] Target bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Target scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] FG mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.__call__] Target scores sum: 0.683285
[utils/util.py::ComputeLoss.__call__] Classification loss computed: 7.809246
[utils/util.py::ComputeLoss.__call__] Foreground count: 23
[utils/util.py::ComputeLoss.__call__] Weight shape: torch.Size([23, 1])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([23, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([23, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([23, 1]), h: torch.Size([23, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([23, 1]), h: torch.Size([23, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([23, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([23, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([23, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.014835, max: 0.083182
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([23, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([23, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([23, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([23, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: 0.010975, max: 0.080245
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.__call__] IoU values shape: torch.Size([23, 1])
[utils/util.py::ComputeLoss.__call__] Box loss computed: 0.928400
[utils/util.py::ComputeLoss.__call__] Target LT-RB shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.df_loss] PYTORCH DFL LOSS DEBUG ---
[utils/util.py::ComputeLoss.df_loss] pred_dist shape: torch.Size([92, 16])
[utils/util.py::ComputeLoss.df_loss] target shape: torch.Size([23, 4])
[utils/util.py::ComputeLoss.df_loss] DFL loss shape: torch.Size([23, 1])
[utils/util.py::ComputeLoss.df_loss] DFL loss mean: 2.822641
--- [utils/util.py::ComputeLoss.df_loss] END PYTORCH DFL LOSS DEBUG ---

[utils/util.py::ComputeLoss.__call__] DFL loss before weighting: 2.822641
[utils/util.py::ComputeLoss.__call__] DFL loss computed: 2.839220

--- [utils/util.py::ComputeLoss.__call__] LOSS COMPONENTS DEBUG ---
[utils/util.py::ComputeLoss.__call__] Raw loss_cls: 7.809246
[utils/util.py::ComputeLoss.__call__] Raw loss_box: 0.928400
[utils/util.py::ComputeLoss.__call__] Raw loss_dfl: 2.839220
[utils/util.py::ComputeLoss.__call__] Loss weights - cls: 0.5, box: 7.5, dfl: 1.5
[utils/util.py::ComputeLoss.__call__] target_scores_sum: 0.683285
[utils/util.py::ComputeLoss.__call__] fg_mask sum: 23
[utils/util.py::ComputeLoss.__call__] Weighted loss_cls: 3.904623
[utils/util.py::ComputeLoss.__call__] Weighted loss_box: 6.962999
[utils/util.py::ComputeLoss.__call__] Weighted loss_dfl: 4.258829
[utils/util.py::ComputeLoss.__call__] Total loss: 15.126451
--- [utils/util.py::ComputeLoss.__call__] END PYTORCH LOSS COMPUTATION DEBUG ---


--- PYTORCH LOSS DEBUG ---
Loss value: 15.126451
Loss dtype: torch.float32
Loss requires_grad: True

--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([4, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: True
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([4, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - box shape: torch.Size([4, 64, 16, 32]), cls shape: torch.Size([4, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - final concat shape: torch.Size([4, 65, 16, 32])

--- [utils/util.py::ComputeLoss.__call__] PYTORCH LOSS COMPUTATION DEBUG ---
[utils/util.py::ComputeLoss.__call__] Outputs type: <class 'list'>
[utils/util.py::ComputeLoss.__call__] x type: <class 'list'>, len: 1
[utils/util.py::ComputeLoss.__call__] x[0] shape: torch.Size([4, 65, 16, 32])
[utils/util.py::ComputeLoss.__call__] Concatenated output shape: torch.Size([4, 65, 512])
[utils/util.py::ComputeLoss.__call__] self.no: 65, self.dfl_ch: 16, self.nc: 1
[utils/util.py::ComputeLoss.__call__] pred_output shape: torch.Size([4, 64, 512])
[utils/util.py::ComputeLoss.__call__] pred_scores shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.__call__] After permute - pred_output shape: torch.Size([4, 512, 64])
[utils/util.py::ComputeLoss.__call__] After permute - pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Size tensor: tensor([128., 256.], device='cuda:0', dtype=torch.float16)
[utils/util.py::ComputeLoss.__call__] Stride: tensor([8.])
[utils/util.py::ComputeLoss.__call__] Anchor points shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.__call__] Stride tensor shape: torch.Size([512, 1])

--- [utils/util.py::ComputeLoss.__call__] TARGET PROCESSING ---
[utils/util.py::ComputeLoss.__call__] Targets shape: torch.Size([5, 6])
[utils/util.py::ComputeLoss.__call__] Targets dtype: torch.float32
[utils/util.py::ComputeLoss.__call__] First few targets: tensor([[0.0000, 0.0000, 0.6542, 0.6084, 0.1094, 0.2053],
        [1.0000, 0.0000, 0.6498, 0.7621, 0.1564, 0.2980],
        [3.0000, 0.0000, 0.4192, 0.0193, 0.0600, 0.0387],
        [3.0000, 0.0000, 0.0295, 0.4823, 0.0493, 0.0968],
        [3.0000, 0.0000, 0.5301, 0.3984, 0.0483, 0.0967]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Image indices: tensor([0., 1., 3., 3., 3.], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Counts per image: tensor([1, 1, 3], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT tensor shape: torch.Size([4, 3, 5])
[utils/util.py::ComputeLoss.__call__] Image 0: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 1: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 3: 3 targets assigned
[utils/util.py::ComputeLoss.__call__] GT before coordinate conversion: tensor([[[0.0000, 0.6542, 0.6084, 0.1094, 0.2053],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.6498, 0.7621, 0.1564, 0.2980],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.4192, 0.0193, 0.0600, 0.0387],
         [0.0000, 0.0295, 0.4823, 0.0493, 0.0968],
         [0.0000, 0.5301, 0.3984, 0.0483, 0.0967]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT after coordinate conversion: tensor([[[  0.0000, 153.4732,  64.7339, 181.4915,  91.0137],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000, 146.3367,  78.4752, 186.3669, 116.6176],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000,  99.6281,   0.0000, 114.9873,   4.9513],
         [  0.0000,   1.2324,  55.5425,  13.8479,  67.9375],
         [  0.0000, 129.5099,  44.8046, 141.8833,  57.1780]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT labels shape: torch.Size([4, 3, 1])
[utils/util.py::ComputeLoss.__call__] GT bboxes shape: torch.Size([4, 3, 4])
[utils/util.py::ComputeLoss.__call__] GT mask shape: torch.Size([4, 3, 1])
[utils/util.py::ComputeLoss.__call__] Pred output dimensions - b: 4, a: 512, c: 64
[utils/util.py::ComputeLoss.__call__] Pred bboxes after softmax shape: torch.Size([4, 512, 4, 16])
[utils/util.py::ComputeLoss.__call__] Pred bboxes after matmul shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Final pred bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.__call__] ASSIGNMENT PHASE ---

--- [utils/util.py::ComputeLoss.assign] PYTORCH ASSIGNMENT DEBUG ---
[utils/util.py::ComputeLoss.assign] pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] true_labels shape: torch.Size([4, 3, 1])
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 3, 4])
[utils/util.py::ComputeLoss.assign] true_mask shape: torch.Size([4, 3, 1])
[utils/util.py::ComputeLoss.assign] anchors shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.assign] Batch size: 4, Max boxes: 3
[utils/util.py::ComputeLoss.assign] Created indices tensor with shape: torch.Size([2, 4, 3])

--- [utils/util.py::ComputeLoss.assign] IOUs DEBUG ---
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 3, 4])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([4, 3, 1, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([4, 1, 512, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([4, 3, 1, 1]), h: torch.Size([4, 3, 1, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([4, 1, 512, 1]), h: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.000000, max: 0.127949
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: -0.667676, max: 0.115788
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.assign] overlaps shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] overlaps min: 0.0, max: 0.11578837037086487
[utils/util.py::ComputeLoss.assign] align_metric shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] align_metric min: 0.0, max: 6.574830990757619e-08
[utils/util.py::ComputeLoss.assign] mask_in_gts shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] mask_in_gts sum: 43.0
[utils/util.py::ComputeLoss.assign] metrics shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] top_k_mask shape: torch.Size([4, 3, 10])
[utils/util.py::ComputeLoss.assign] top_k_metrics shape: torch.Size([4, 3, 10])
[utils/util.py::ComputeLoss.assign] top_k_indices shape: torch.Size([4, 3, 10])
[utils/util.py::ComputeLoss.assign] is_in_top_k shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] mask_top_k shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] mask_pos shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] fg_mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] fg_mask sum: 25.0
[utils/util.py::ComputeLoss.assign] target_gt_idx shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_labels shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] Normalized target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] target_scores sum: 0.8375644087791443
--- [utils/util.py::ComputeLoss.assign] END PYTORCH ASSIGNMENT DEBUG ---

[utils/util.py::ComputeLoss.__call__] Target bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Target scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] FG mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.__call__] Target scores sum: 0.837564
[utils/util.py::ComputeLoss.__call__] Classification loss computed: 7.797908
[utils/util.py::ComputeLoss.__call__] Foreground count: 25
[utils/util.py::ComputeLoss.__call__] Weight shape: torch.Size([25, 1])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([25, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([25, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([25, 1]), h: torch.Size([25, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([25, 1]), h: torch.Size([25, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([25, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([25, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([25, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.006105, max: 0.119584
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([25, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([25, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([25, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([25, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: 0.001306, max: 0.115759
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.__call__] IoU values shape: torch.Size([25, 1])
[utils/util.py::ComputeLoss.__call__] Box loss computed: 0.897419
[utils/util.py::ComputeLoss.__call__] Target LT-RB shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.df_loss] PYTORCH DFL LOSS DEBUG ---
[utils/util.py::ComputeLoss.df_loss] pred_dist shape: torch.Size([100, 16])
[utils/util.py::ComputeLoss.df_loss] target shape: torch.Size([25, 4])
[utils/util.py::ComputeLoss.df_loss] DFL loss shape: torch.Size([25, 1])
[utils/util.py::ComputeLoss.df_loss] DFL loss mean: 2.805776
--- [utils/util.py::ComputeLoss.df_loss] END PYTORCH DFL LOSS DEBUG ---

[utils/util.py::ComputeLoss.__call__] DFL loss before weighting: 2.805776
[utils/util.py::ComputeLoss.__call__] DFL loss computed: 2.846103

--- [utils/util.py::ComputeLoss.__call__] LOSS COMPONENTS DEBUG ---
[utils/util.py::ComputeLoss.__call__] Raw loss_cls: 7.797908
[utils/util.py::ComputeLoss.__call__] Raw loss_box: 0.897419
[utils/util.py::ComputeLoss.__call__] Raw loss_dfl: 2.846103
[utils/util.py::ComputeLoss.__call__] Loss weights - cls: 0.5, box: 7.5, dfl: 1.5
[utils/util.py::ComputeLoss.__call__] target_scores_sum: 0.837564
[utils/util.py::ComputeLoss.__call__] fg_mask sum: 25
[utils/util.py::ComputeLoss.__call__] Weighted loss_cls: 3.898954
[utils/util.py::ComputeLoss.__call__] Weighted loss_box: 6.730639
[utils/util.py::ComputeLoss.__call__] Weighted loss_dfl: 4.269155
[utils/util.py::ComputeLoss.__call__] Total loss: 14.898747
--- [utils/util.py::ComputeLoss.__call__] END PYTORCH LOSS COMPUTATION DEBUG ---


--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([4, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: True
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([4, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - box shape: torch.Size([4, 64, 16, 32]), cls shape: torch.Size([4, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - final concat shape: torch.Size([4, 65, 16, 32])

--- [utils/util.py::ComputeLoss.__call__] PYTORCH LOSS COMPUTATION DEBUG ---
[utils/util.py::ComputeLoss.__call__] Outputs type: <class 'list'>
[utils/util.py::ComputeLoss.__call__] x type: <class 'list'>, len: 1
[utils/util.py::ComputeLoss.__call__] x[0] shape: torch.Size([4, 65, 16, 32])
[utils/util.py::ComputeLoss.__call__] Concatenated output shape: torch.Size([4, 65, 512])
[utils/util.py::ComputeLoss.__call__] self.no: 65, self.dfl_ch: 16, self.nc: 1
[utils/util.py::ComputeLoss.__call__] pred_output shape: torch.Size([4, 64, 512])
[utils/util.py::ComputeLoss.__call__] pred_scores shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.__call__] After permute - pred_output shape: torch.Size([4, 512, 64])
[utils/util.py::ComputeLoss.__call__] After permute - pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Size tensor: tensor([128., 256.], device='cuda:0', dtype=torch.float16)
[utils/util.py::ComputeLoss.__call__] Stride: tensor([8.])
[utils/util.py::ComputeLoss.__call__] Anchor points shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.__call__] Stride tensor shape: torch.Size([512, 1])

--- [utils/util.py::ComputeLoss.__call__] TARGET PROCESSING ---
[utils/util.py::ComputeLoss.__call__] Targets shape: torch.Size([6, 6])
[utils/util.py::ComputeLoss.__call__] Targets dtype: torch.float32
[utils/util.py::ComputeLoss.__call__] First few targets: tensor([[0.0000, 0.0000, 0.8176, 0.1538, 0.0518, 0.1079],
        [0.0000, 0.0000, 0.2473, 0.0446, 0.0522, 0.0891],
        [0.0000, 0.0000, 0.8453, 0.6751, 0.0521, 0.1107],
        [0.0000, 0.0000, 0.4022, 0.6787, 0.0568, 0.1132],
        [1.0000, 0.0000, 0.2839, 0.0503, 0.0906, 0.1007]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Image indices: tensor([0., 0., 0., 0., 1., 3.], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Counts per image: tensor([4, 1, 1], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT tensor shape: torch.Size([4, 4, 5])
[utils/util.py::ComputeLoss.__call__] Image 0: 4 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 1: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 3: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] GT before coordinate conversion: tensor([[[0.0000, 0.8176, 0.1538, 0.0518, 0.1079],
         [0.0000, 0.2473, 0.0446, 0.0522, 0.0891],
         [0.0000, 0.8453, 0.6751, 0.0521, 0.1107],
         [0.0000, 0.4022, 0.6787, 0.0568, 0.1132]],

        [[0.0000, 0.2839, 0.0503, 0.0906, 0.1007],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.2656, 0.8183, 0.1335, 0.2670],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT after coordinate conversion: tensor([[[  0.0000, 202.6702,  12.7830, 215.9402,  26.5886],
         [  0.0000,  56.6157,   0.0000,  69.9801,  11.4063],
         [  0.0000, 209.7336,  79.3313, 223.0792,  93.4960],
         [  0.0000,  95.6883,  79.6338, 110.2373,  94.1261]],

        [[  0.0000,  61.0919,   0.0000,  84.2886,  12.8843],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000,  50.9007,  87.6598,  85.0779, 121.8370],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT labels shape: torch.Size([4, 4, 1])
[utils/util.py::ComputeLoss.__call__] GT bboxes shape: torch.Size([4, 4, 4])
[utils/util.py::ComputeLoss.__call__] GT mask shape: torch.Size([4, 4, 1])
[utils/util.py::ComputeLoss.__call__] Pred output dimensions - b: 4, a: 512, c: 64
[utils/util.py::ComputeLoss.__call__] Pred bboxes after softmax shape: torch.Size([4, 512, 4, 16])
[utils/util.py::ComputeLoss.__call__] Pred bboxes after matmul shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Final pred bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.__call__] ASSIGNMENT PHASE ---

--- [utils/util.py::ComputeLoss.assign] PYTORCH ASSIGNMENT DEBUG ---
[utils/util.py::ComputeLoss.assign] pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] true_labels shape: torch.Size([4, 4, 1])
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 4, 4])
[utils/util.py::ComputeLoss.assign] true_mask shape: torch.Size([4, 4, 1])
[utils/util.py::ComputeLoss.assign] anchors shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.assign] Batch size: 4, Max boxes: 4
[utils/util.py::ComputeLoss.assign] Created indices tensor with shape: torch.Size([2, 4, 4])

--- [utils/util.py::ComputeLoss.assign] IOUs DEBUG ---
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 4, 4])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([4, 4, 1, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([4, 1, 512, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([4, 4, 1, 1]), h: torch.Size([4, 4, 1, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([4, 1, 512, 1]), h: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([4, 4, 512, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([4, 4, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([4, 4, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.000000, max: 0.095448
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([4, 4, 512, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([4, 4, 512, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([4, 4, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([4, 4, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: -0.668063, max: 0.089874
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.assign] overlaps shape: torch.Size([4, 4, 512])
[utils/util.py::ComputeLoss.assign] overlaps min: 0.0, max: 0.08987399190664291
[utils/util.py::ComputeLoss.assign] align_metric shape: torch.Size([4, 4, 512])
[utils/util.py::ComputeLoss.assign] align_metric min: 0.0, max: 9.643555287652816e-09
[utils/util.py::ComputeLoss.assign] mask_in_gts shape: torch.Size([4, 4, 512])
[utils/util.py::ComputeLoss.assign] mask_in_gts sum: 38.0
[utils/util.py::ComputeLoss.assign] metrics shape: torch.Size([4, 4, 512])
[utils/util.py::ComputeLoss.assign] top_k_mask shape: torch.Size([4, 4, 10])
[utils/util.py::ComputeLoss.assign] top_k_metrics shape: torch.Size([4, 4, 10])
[utils/util.py::ComputeLoss.assign] top_k_indices shape: torch.Size([4, 4, 10])
[utils/util.py::ComputeLoss.assign] is_in_top_k shape: torch.Size([4, 4, 512])
[utils/util.py::ComputeLoss.assign] mask_top_k shape: torch.Size([4, 4, 512])
[utils/util.py::ComputeLoss.assign] mask_pos shape: torch.Size([4, 4, 512])
[utils/util.py::ComputeLoss.assign] fg_mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] fg_mask sum: 28.0
[utils/util.py::ComputeLoss.assign] target_gt_idx shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_labels shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] Normalized target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] target_scores sum: 0.5993274450302124
--- [utils/util.py::ComputeLoss.assign] END PYTORCH ASSIGNMENT DEBUG ---

[utils/util.py::ComputeLoss.__call__] Target bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Target scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] FG mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.__call__] Target scores sum: 0.599327
[utils/util.py::ComputeLoss.__call__] Classification loss computed: 7.716983
[utils/util.py::ComputeLoss.__call__] Foreground count: 28
[utils/util.py::ComputeLoss.__call__] Weight shape: torch.Size([28, 1])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([28, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([28, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([28, 1]), h: torch.Size([28, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([28, 1]), h: torch.Size([28, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([28, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([28, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([28, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.011268, max: 0.092062
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([28, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([28, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([28, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([28, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: 0.009726, max: 0.089880
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.__call__] IoU values shape: torch.Size([28, 1])
[utils/util.py::ComputeLoss.__call__] Box loss computed: 0.917455
[utils/util.py::ComputeLoss.__call__] Target LT-RB shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.df_loss] PYTORCH DFL LOSS DEBUG ---
[utils/util.py::ComputeLoss.df_loss] pred_dist shape: torch.Size([112, 16])
[utils/util.py::ComputeLoss.df_loss] target shape: torch.Size([28, 4])
[utils/util.py::ComputeLoss.df_loss] DFL loss shape: torch.Size([28, 1])
[utils/util.py::ComputeLoss.df_loss] DFL loss mean: 2.748139
--- [utils/util.py::ComputeLoss.df_loss] END PYTORCH DFL LOSS DEBUG ---

[utils/util.py::ComputeLoss.__call__] DFL loss before weighting: 2.748139
[utils/util.py::ComputeLoss.__call__] DFL loss computed: 2.757978

--- [utils/util.py::ComputeLoss.__call__] LOSS COMPONENTS DEBUG ---
[utils/util.py::ComputeLoss.__call__] Raw loss_cls: 7.716983
[utils/util.py::ComputeLoss.__call__] Raw loss_box: 0.917455
[utils/util.py::ComputeLoss.__call__] Raw loss_dfl: 2.757978
[utils/util.py::ComputeLoss.__call__] Loss weights - cls: 0.5, box: 7.5, dfl: 1.5
[utils/util.py::ComputeLoss.__call__] target_scores_sum: 0.599327
[utils/util.py::ComputeLoss.__call__] fg_mask sum: 28
[utils/util.py::ComputeLoss.__call__] Weighted loss_cls: 3.858492
[utils/util.py::ComputeLoss.__call__] Weighted loss_box: 6.880911
[utils/util.py::ComputeLoss.__call__] Weighted loss_dfl: 4.136967
[utils/util.py::ComputeLoss.__call__] Total loss: 14.876369
--- [utils/util.py::ComputeLoss.__call__] END PYTORCH LOSS COMPUTATION DEBUG ---


--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([4, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: True
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([4, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - box shape: torch.Size([4, 64, 16, 32]), cls shape: torch.Size([4, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - final concat shape: torch.Size([4, 65, 16, 32])

--- [utils/util.py::ComputeLoss.__call__] PYTORCH LOSS COMPUTATION DEBUG ---
[utils/util.py::ComputeLoss.__call__] Outputs type: <class 'list'>
[utils/util.py::ComputeLoss.__call__] x type: <class 'list'>, len: 1
[utils/util.py::ComputeLoss.__call__] x[0] shape: torch.Size([4, 65, 16, 32])
[utils/util.py::ComputeLoss.__call__] Concatenated output shape: torch.Size([4, 65, 512])
[utils/util.py::ComputeLoss.__call__] self.no: 65, self.dfl_ch: 16, self.nc: 1
[utils/util.py::ComputeLoss.__call__] pred_output shape: torch.Size([4, 64, 512])
[utils/util.py::ComputeLoss.__call__] pred_scores shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.__call__] After permute - pred_output shape: torch.Size([4, 512, 64])
[utils/util.py::ComputeLoss.__call__] After permute - pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Size tensor: tensor([128., 256.], device='cuda:0', dtype=torch.float16)
[utils/util.py::ComputeLoss.__call__] Stride: tensor([8.])
[utils/util.py::ComputeLoss.__call__] Anchor points shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.__call__] Stride tensor shape: torch.Size([512, 1])

--- [utils/util.py::ComputeLoss.__call__] TARGET PROCESSING ---
[utils/util.py::ComputeLoss.__call__] Targets shape: torch.Size([7, 6])
[utils/util.py::ComputeLoss.__call__] Targets dtype: torch.float32
[utils/util.py::ComputeLoss.__call__] First few targets: tensor([[1.0000, 0.0000, 0.6257, 0.2792, 0.0523, 0.1141],
        [1.0000, 0.0000, 0.7637, 0.9384, 0.0555, 0.1231],
        [1.0000, 0.0000, 0.2126, 0.8973, 0.0546, 0.1164],
        [2.0000, 0.0000, 0.0568, 0.1374, 0.1136, 0.2372],
        [3.0000, 0.0000, 0.4080, 0.1161, 0.0572, 0.1209]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Image indices: tensor([1., 1., 1., 2., 3., 3., 3.], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Counts per image: tensor([3, 1, 3], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT tensor shape: torch.Size([4, 3, 5])
[utils/util.py::ComputeLoss.__call__] Image 1: 3 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 2: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 3: 3 targets assigned
[utils/util.py::ComputeLoss.__call__] GT before coordinate conversion: tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.6257, 0.2792, 0.0523, 0.1141],
         [0.0000, 0.7637, 0.9384, 0.0555, 0.1231],
         [0.0000, 0.2126, 0.8973, 0.0546, 0.1164]],

        [[0.0000, 0.0568, 0.1374, 0.1136, 0.2372],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.4080, 0.1161, 0.0572, 0.1209],
         [0.0000, 0.9781, 0.9284, 0.0438, 0.1433],
         [0.0000, 0.2768, 0.7920, 0.0648, 0.1208]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT after coordinate conversion: tensor([[[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000, 153.4778,  28.4331, 166.8616,  43.0359],
         [  0.0000, 188.3975, 112.2404, 202.6067, 127.9990],
         [  0.0000,  47.4489, 107.4088,  61.4168, 122.3036]],

        [[  0.0000,   0.0000,   2.4081,  29.0767,  32.7673],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000,  97.1197,   7.1199, 111.7550,  22.5913],
         [  0.0000, 244.7917, 109.6598, 256.0000, 127.9990],
         [  0.0000,  62.5701,  93.6425,  79.1539, 109.1070]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT labels shape: torch.Size([4, 3, 1])
[utils/util.py::ComputeLoss.__call__] GT bboxes shape: torch.Size([4, 3, 4])
[utils/util.py::ComputeLoss.__call__] GT mask shape: torch.Size([4, 3, 1])
[utils/util.py::ComputeLoss.__call__] Pred output dimensions - b: 4, a: 512, c: 64
[utils/util.py::ComputeLoss.__call__] Pred bboxes after softmax shape: torch.Size([4, 512, 4, 16])
[utils/util.py::ComputeLoss.__call__] Pred bboxes after matmul shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Final pred bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.__call__] ASSIGNMENT PHASE ---

--- [utils/util.py::ComputeLoss.assign] PYTORCH ASSIGNMENT DEBUG ---
[utils/util.py::ComputeLoss.assign] pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] true_labels shape: torch.Size([4, 3, 1])
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 3, 4])
[utils/util.py::ComputeLoss.assign] true_mask shape: torch.Size([4, 3, 1])
[utils/util.py::ComputeLoss.assign] anchors shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.assign] Batch size: 4, Max boxes: 3
[utils/util.py::ComputeLoss.assign] Created indices tensor with shape: torch.Size([2, 4, 3])

--- [utils/util.py::ComputeLoss.assign] IOUs DEBUG ---
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 3, 4])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([4, 3, 1, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([4, 1, 512, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([4, 3, 1, 1]), h: torch.Size([4, 3, 1, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([4, 1, 512, 1]), h: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.000000, max: 0.070730
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: -0.658065, max: 0.064102
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.assign] overlaps shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] overlaps min: 0.0, max: 0.06410154700279236
[utils/util.py::ComputeLoss.assign] align_metric shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] align_metric min: 0.0, max: 1.7435112242836226e-09
[utils/util.py::ComputeLoss.assign] mask_in_gts shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] mask_in_gts sum: 34.0
[utils/util.py::ComputeLoss.assign] metrics shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] top_k_mask shape: torch.Size([4, 3, 10])
[utils/util.py::ComputeLoss.assign] top_k_metrics shape: torch.Size([4, 3, 10])
[utils/util.py::ComputeLoss.assign] top_k_indices shape: torch.Size([4, 3, 10])
[utils/util.py::ComputeLoss.assign] is_in_top_k shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] mask_top_k shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] mask_pos shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] fg_mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] fg_mask sum: 28.0
[utils/util.py::ComputeLoss.assign] target_gt_idx shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_labels shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] Normalized target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] target_scores sum: 0.2918819189071655
--- [utils/util.py::ComputeLoss.assign] END PYTORCH ASSIGNMENT DEBUG ---

[utils/util.py::ComputeLoss.__call__] Target bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Target scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] FG mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.__call__] Target scores sum: 0.291882
[utils/util.py::ComputeLoss.__call__] Classification loss computed: 8.096704
[utils/util.py::ComputeLoss.__call__] Foreground count: 28
[utils/util.py::ComputeLoss.__call__] Weight shape: torch.Size([28, 1])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([28, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([28, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([28, 1]), h: torch.Size([28, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([28, 1]), h: torch.Size([28, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([28, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([28, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([28, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.014370, max: 0.070733
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([28, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([28, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([28, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([28, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: 0.012103, max: 0.064101
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.__call__] IoU values shape: torch.Size([28, 1])
[utils/util.py::ComputeLoss.__call__] Box loss computed: 0.939084
[utils/util.py::ComputeLoss.__call__] Target LT-RB shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.df_loss] PYTORCH DFL LOSS DEBUG ---
[utils/util.py::ComputeLoss.df_loss] pred_dist shape: torch.Size([112, 16])
[utils/util.py::ComputeLoss.df_loss] target shape: torch.Size([28, 4])
[utils/util.py::ComputeLoss.df_loss] DFL loss shape: torch.Size([28, 1])
[utils/util.py::ComputeLoss.df_loss] DFL loss mean: 2.800111
--- [utils/util.py::ComputeLoss.df_loss] END PYTORCH DFL LOSS DEBUG ---

[utils/util.py::ComputeLoss.__call__] DFL loss before weighting: 2.800111
[utils/util.py::ComputeLoss.__call__] DFL loss computed: 2.847595

--- [utils/util.py::ComputeLoss.__call__] LOSS COMPONENTS DEBUG ---
[utils/util.py::ComputeLoss.__call__] Raw loss_cls: 8.096704
[utils/util.py::ComputeLoss.__call__] Raw loss_box: 0.939084
[utils/util.py::ComputeLoss.__call__] Raw loss_dfl: 2.847595
[utils/util.py::ComputeLoss.__call__] Loss weights - cls: 0.5, box: 7.5, dfl: 1.5
[utils/util.py::ComputeLoss.__call__] target_scores_sum: 0.291882
[utils/util.py::ComputeLoss.__call__] fg_mask sum: 28
[utils/util.py::ComputeLoss.__call__] Weighted loss_cls: 4.048352
[utils/util.py::ComputeLoss.__call__] Weighted loss_box: 7.043128
[utils/util.py::ComputeLoss.__call__] Weighted loss_dfl: 4.271392
[utils/util.py::ComputeLoss.__call__] Total loss: 15.362871
--- [utils/util.py::ComputeLoss.__call__] END PYTORCH LOSS COMPUTATION DEBUG ---


--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([4, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: True
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([4, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - box shape: torch.Size([4, 64, 16, 32]), cls shape: torch.Size([4, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - final concat shape: torch.Size([4, 65, 16, 32])

--- [utils/util.py::ComputeLoss.__call__] PYTORCH LOSS COMPUTATION DEBUG ---
[utils/util.py::ComputeLoss.__call__] Outputs type: <class 'list'>
[utils/util.py::ComputeLoss.__call__] x type: <class 'list'>, len: 1
[utils/util.py::ComputeLoss.__call__] x[0] shape: torch.Size([4, 65, 16, 32])
[utils/util.py::ComputeLoss.__call__] Concatenated output shape: torch.Size([4, 65, 512])
[utils/util.py::ComputeLoss.__call__] self.no: 65, self.dfl_ch: 16, self.nc: 1
[utils/util.py::ComputeLoss.__call__] pred_output shape: torch.Size([4, 64, 512])
[utils/util.py::ComputeLoss.__call__] pred_scores shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.__call__] After permute - pred_output shape: torch.Size([4, 512, 64])
[utils/util.py::ComputeLoss.__call__] After permute - pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Size tensor: tensor([128., 256.], device='cuda:0', dtype=torch.float16)
[utils/util.py::ComputeLoss.__call__] Stride: tensor([8.])
[utils/util.py::ComputeLoss.__call__] Anchor points shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.__call__] Stride tensor shape: torch.Size([512, 1])

--- [utils/util.py::ComputeLoss.__call__] TARGET PROCESSING ---
[utils/util.py::ComputeLoss.__call__] Targets shape: torch.Size([3, 6])
[utils/util.py::ComputeLoss.__call__] Targets dtype: torch.float32
[utils/util.py::ComputeLoss.__call__] First few targets: tensor([[0.0000, 0.0000, 0.2858, 0.1740, 0.1303, 0.2513],
        [2.0000, 0.0000, 0.7056, 0.4058, 0.0892, 0.1753],
        [3.0000, 0.0000, 0.8169, 0.6121, 0.1142, 0.2175]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Image indices: tensor([0., 2., 3.], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Counts per image: tensor([1, 1, 1], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT tensor shape: torch.Size([4, 1, 5])
[utils/util.py::ComputeLoss.__call__] Image 0: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 2: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 3: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] GT before coordinate conversion: tensor([[[0.0000, 0.2858, 0.1740, 0.1303, 0.2513]],

        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.7056, 0.4058, 0.0892, 0.1753]],

        [[0.0000, 0.8169, 0.6121, 0.1142, 0.2175]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT after coordinate conversion: tensor([[[  0.0000,  56.4929,   6.1929,  89.8485,  38.3572]],

        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000, 169.2216,  40.7289, 192.0540,  63.1621]],

        [[  0.0000, 194.5091,  64.4309, 223.7334,  92.2724]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT labels shape: torch.Size([4, 1, 1])
[utils/util.py::ComputeLoss.__call__] GT bboxes shape: torch.Size([4, 1, 4])
[utils/util.py::ComputeLoss.__call__] GT mask shape: torch.Size([4, 1, 1])
[utils/util.py::ComputeLoss.__call__] Pred output dimensions - b: 4, a: 512, c: 64
[utils/util.py::ComputeLoss.__call__] Pred bboxes after softmax shape: torch.Size([4, 512, 4, 16])
[utils/util.py::ComputeLoss.__call__] Pred bboxes after matmul shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Final pred bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.__call__] ASSIGNMENT PHASE ---

--- [utils/util.py::ComputeLoss.assign] PYTORCH ASSIGNMENT DEBUG ---
[utils/util.py::ComputeLoss.assign] pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] true_labels shape: torch.Size([4, 1, 1])
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 1, 4])
[utils/util.py::ComputeLoss.assign] true_mask shape: torch.Size([4, 1, 1])
[utils/util.py::ComputeLoss.assign] anchors shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.assign] Batch size: 4, Max boxes: 1
[utils/util.py::ComputeLoss.assign] Created indices tensor with shape: torch.Size([2, 4, 1])

--- [utils/util.py::ComputeLoss.assign] IOUs DEBUG ---
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 1, 4])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([4, 1, 1, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([4, 1, 512, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([4, 1, 1, 1]), h: torch.Size([4, 1, 1, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([4, 1, 512, 1]), h: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.000000, max: 0.100965
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: -0.662513, max: 0.086463
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.assign] overlaps shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.assign] overlaps min: 0.0, max: 0.08646317571401596
[utils/util.py::ComputeLoss.assign] align_metric shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.assign] align_metric min: 0.0, max: 9.706875303550078e-09
[utils/util.py::ComputeLoss.assign] mask_in_gts shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.assign] mask_in_gts sum: 41.0
[utils/util.py::ComputeLoss.assign] metrics shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.assign] top_k_mask shape: torch.Size([4, 1, 10])
[utils/util.py::ComputeLoss.assign] top_k_metrics shape: torch.Size([4, 1, 10])
[utils/util.py::ComputeLoss.assign] top_k_indices shape: torch.Size([4, 1, 10])
[utils/util.py::ComputeLoss.assign] is_in_top_k shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.assign] mask_top_k shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.assign] mask_pos shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.assign] fg_mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] fg_mask sum: 29.0
[utils/util.py::ComputeLoss.assign] target_gt_idx shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_labels shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] Normalized target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] target_scores sum: 0.5767585039138794
--- [utils/util.py::ComputeLoss.assign] END PYTORCH ASSIGNMENT DEBUG ---

[utils/util.py::ComputeLoss.__call__] Target bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Target scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] FG mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.__call__] Target scores sum: 0.576759
[utils/util.py::ComputeLoss.__call__] Classification loss computed: 7.456815
[utils/util.py::ComputeLoss.__call__] Foreground count: 29
[utils/util.py::ComputeLoss.__call__] Weight shape: torch.Size([29, 1])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([29, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([29, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([29, 1]), h: torch.Size([29, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([29, 1]), h: torch.Size([29, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([29, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([29, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([29, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.031774, max: 0.089945
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([29, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([29, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([29, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([29, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: 0.031529, max: 0.082054
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.__call__] IoU values shape: torch.Size([29, 1])
[utils/util.py::ComputeLoss.__call__] Box loss computed: 0.926811
[utils/util.py::ComputeLoss.__call__] Target LT-RB shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.df_loss] PYTORCH DFL LOSS DEBUG ---
[utils/util.py::ComputeLoss.df_loss] pred_dist shape: torch.Size([116, 16])
[utils/util.py::ComputeLoss.df_loss] target shape: torch.Size([29, 4])
[utils/util.py::ComputeLoss.df_loss] DFL loss shape: torch.Size([29, 1])
[utils/util.py::ComputeLoss.df_loss] DFL loss mean: 2.911097
--- [utils/util.py::ComputeLoss.df_loss] END PYTORCH DFL LOSS DEBUG ---

[utils/util.py::ComputeLoss.__call__] DFL loss before weighting: 2.911097
[utils/util.py::ComputeLoss.__call__] DFL loss computed: 2.968338

--- [utils/util.py::ComputeLoss.__call__] LOSS COMPONENTS DEBUG ---
[utils/util.py::ComputeLoss.__call__] Raw loss_cls: 7.456815
[utils/util.py::ComputeLoss.__call__] Raw loss_box: 0.926811
[utils/util.py::ComputeLoss.__call__] Raw loss_dfl: 2.968338
[utils/util.py::ComputeLoss.__call__] Loss weights - cls: 0.5, box: 7.5, dfl: 1.5
[utils/util.py::ComputeLoss.__call__] target_scores_sum: 0.576759
[utils/util.py::ComputeLoss.__call__] fg_mask sum: 29
[utils/util.py::ComputeLoss.__call__] Weighted loss_cls: 3.728407
[utils/util.py::ComputeLoss.__call__] Weighted loss_box: 6.951083
[utils/util.py::ComputeLoss.__call__] Weighted loss_dfl: 4.452506
[utils/util.py::ComputeLoss.__call__] Total loss: 15.131996
--- [utils/util.py::ComputeLoss.__call__] END PYTORCH LOSS COMPUTATION DEBUG ---


--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([4, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: True
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([4, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - box shape: torch.Size([4, 64, 16, 32]), cls shape: torch.Size([4, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - final concat shape: torch.Size([4, 65, 16, 32])

--- [utils/util.py::ComputeLoss.__call__] PYTORCH LOSS COMPUTATION DEBUG ---
[utils/util.py::ComputeLoss.__call__] Outputs type: <class 'list'>
[utils/util.py::ComputeLoss.__call__] x type: <class 'list'>, len: 1
[utils/util.py::ComputeLoss.__call__] x[0] shape: torch.Size([4, 65, 16, 32])
[utils/util.py::ComputeLoss.__call__] Concatenated output shape: torch.Size([4, 65, 512])
[utils/util.py::ComputeLoss.__call__] self.no: 65, self.dfl_ch: 16, self.nc: 1
[utils/util.py::ComputeLoss.__call__] pred_output shape: torch.Size([4, 64, 512])
[utils/util.py::ComputeLoss.__call__] pred_scores shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.__call__] After permute - pred_output shape: torch.Size([4, 512, 64])
[utils/util.py::ComputeLoss.__call__] After permute - pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Size tensor: tensor([128., 256.], device='cuda:0', dtype=torch.float16)
[utils/util.py::ComputeLoss.__call__] Stride: tensor([8.])
[utils/util.py::ComputeLoss.__call__] Anchor points shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.__call__] Stride tensor shape: torch.Size([512, 1])

--- [utils/util.py::ComputeLoss.__call__] TARGET PROCESSING ---
[utils/util.py::ComputeLoss.__call__] Targets shape: torch.Size([3, 6])
[utils/util.py::ComputeLoss.__call__] Targets dtype: torch.float32
[utils/util.py::ComputeLoss.__call__] First few targets: tensor([[0.0000, 0.0000, 0.0199, 0.0634, 0.0398, 0.1268],
        [0.0000, 0.0000, 0.7857, 0.8521, 0.0818, 0.1664],
        [2.0000, 0.0000, 0.4855, 0.4526, 0.0877, 0.1712]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Image indices: tensor([0., 0., 2.], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Counts per image: tensor([2, 1], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT tensor shape: torch.Size([4, 2, 5])
[utils/util.py::ComputeLoss.__call__] Image 0: 2 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 2: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] GT before coordinate conversion: tensor([[[0.0000, 0.0199, 0.0634, 0.0398, 0.1268],
         [0.0000, 0.7857, 0.8521, 0.0818, 0.1664]],

        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.4855, 0.4526, 0.0877, 0.1712],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT after coordinate conversion: tensor([[[  0.0000,   0.0000,   0.0000,  10.1764,  16.2271],
         [  0.0000, 190.6666,  98.4176, 211.6093, 119.7135]],

        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000, 113.0487,  46.9805, 135.5042,  68.8883],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT labels shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.__call__] GT bboxes shape: torch.Size([4, 2, 4])
[utils/util.py::ComputeLoss.__call__] GT mask shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.__call__] Pred output dimensions - b: 4, a: 512, c: 64
[utils/util.py::ComputeLoss.__call__] Pred bboxes after softmax shape: torch.Size([4, 512, 4, 16])
[utils/util.py::ComputeLoss.__call__] Pred bboxes after matmul shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Final pred bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.__call__] ASSIGNMENT PHASE ---

--- [utils/util.py::ComputeLoss.assign] PYTORCH ASSIGNMENT DEBUG ---
[utils/util.py::ComputeLoss.assign] pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] true_labels shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 2, 4])
[utils/util.py::ComputeLoss.assign] true_mask shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.assign] anchors shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.assign] Batch size: 4, Max boxes: 2
[utils/util.py::ComputeLoss.assign] Created indices tensor with shape: torch.Size([2, 4, 2])

--- [utils/util.py::ComputeLoss.assign] IOUs DEBUG ---
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 2, 4])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([4, 2, 1, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([4, 1, 512, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([4, 2, 1, 1]), h: torch.Size([4, 2, 1, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([4, 1, 512, 1]), h: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.000000, max: 0.044232
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: -0.675842, max: 0.040613
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.assign] overlaps shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] overlaps min: 0.0, max: 0.04061318561434746
[utils/util.py::ComputeLoss.assign] align_metric shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] align_metric min: 0.0, max: 1.285247186455507e-10
[utils/util.py::ComputeLoss.assign] mask_in_gts shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] mask_in_gts sum: 17.0
[utils/util.py::ComputeLoss.assign] metrics shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] top_k_mask shape: torch.Size([4, 2, 10])
[utils/util.py::ComputeLoss.assign] top_k_metrics shape: torch.Size([4, 2, 10])
[utils/util.py::ComputeLoss.assign] top_k_indices shape: torch.Size([4, 2, 10])
[utils/util.py::ComputeLoss.assign] is_in_top_k shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] mask_top_k shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] mask_pos shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] fg_mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] fg_mask sum: 17.0
[utils/util.py::ComputeLoss.assign] target_gt_idx shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_labels shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] Normalized target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] target_scores sum: 0.016007443889975548
--- [utils/util.py::ComputeLoss.assign] END PYTORCH ASSIGNMENT DEBUG ---

[utils/util.py::ComputeLoss.__call__] Target bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Target scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] FG mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.__call__] Target scores sum: 0.016007
[utils/util.py::ComputeLoss.__call__] Classification loss computed: 8.540948
[utils/util.py::ComputeLoss.__call__] Foreground count: 17
[utils/util.py::ComputeLoss.__call__] Weight shape: torch.Size([17, 1])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([17, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([17, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([17, 1]), h: torch.Size([17, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([17, 1]), h: torch.Size([17, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([17, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([17, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([17, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.011500, max: 0.043033
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([17, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([17, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([17, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([17, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: 0.007894, max: 0.040620
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.__call__] IoU values shape: torch.Size([17, 1])
[utils/util.py::ComputeLoss.__call__] Box loss computed: 0.964691
[utils/util.py::ComputeLoss.__call__] Target LT-RB shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.df_loss] PYTORCH DFL LOSS DEBUG ---
[utils/util.py::ComputeLoss.df_loss] pred_dist shape: torch.Size([68, 16])
[utils/util.py::ComputeLoss.df_loss] target shape: torch.Size([17, 4])
[utils/util.py::ComputeLoss.df_loss] DFL loss shape: torch.Size([17, 1])
[utils/util.py::ComputeLoss.df_loss] DFL loss mean: 2.760957
--- [utils/util.py::ComputeLoss.df_loss] END PYTORCH DFL LOSS DEBUG ---

[utils/util.py::ComputeLoss.__call__] DFL loss before weighting: 2.760957
[utils/util.py::ComputeLoss.__call__] DFL loss computed: 2.765124

--- [utils/util.py::ComputeLoss.__call__] LOSS COMPONENTS DEBUG ---
[utils/util.py::ComputeLoss.__call__] Raw loss_cls: 8.540948
[utils/util.py::ComputeLoss.__call__] Raw loss_box: 0.964691
[utils/util.py::ComputeLoss.__call__] Raw loss_dfl: 2.765124
[utils/util.py::ComputeLoss.__call__] Loss weights - cls: 0.5, box: 7.5, dfl: 1.5
[utils/util.py::ComputeLoss.__call__] target_scores_sum: 0.016007
[utils/util.py::ComputeLoss.__call__] fg_mask sum: 17
[utils/util.py::ComputeLoss.__call__] Weighted loss_cls: 4.270474
[utils/util.py::ComputeLoss.__call__] Weighted loss_box: 7.235180
[utils/util.py::ComputeLoss.__call__] Weighted loss_dfl: 4.147686
[utils/util.py::ComputeLoss.__call__] Total loss: 15.653340
--- [utils/util.py::ComputeLoss.__call__] END PYTORCH LOSS COMPUTATION DEBUG ---


--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([4, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: True
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([4, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - box shape: torch.Size([4, 64, 16, 32]), cls shape: torch.Size([4, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - final concat shape: torch.Size([4, 65, 16, 32])

--- [utils/util.py::ComputeLoss.__call__] PYTORCH LOSS COMPUTATION DEBUG ---
[utils/util.py::ComputeLoss.__call__] Outputs type: <class 'list'>
[utils/util.py::ComputeLoss.__call__] x type: <class 'list'>, len: 1
[utils/util.py::ComputeLoss.__call__] x[0] shape: torch.Size([4, 65, 16, 32])
[utils/util.py::ComputeLoss.__call__] Concatenated output shape: torch.Size([4, 65, 512])
[utils/util.py::ComputeLoss.__call__] self.no: 65, self.dfl_ch: 16, self.nc: 1
[utils/util.py::ComputeLoss.__call__] pred_output shape: torch.Size([4, 64, 512])
[utils/util.py::ComputeLoss.__call__] pred_scores shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.__call__] After permute - pred_output shape: torch.Size([4, 512, 64])
[utils/util.py::ComputeLoss.__call__] After permute - pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Size tensor: tensor([128., 256.], device='cuda:0', dtype=torch.float16)
[utils/util.py::ComputeLoss.__call__] Stride: tensor([8.])
[utils/util.py::ComputeLoss.__call__] Anchor points shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.__call__] Stride tensor shape: torch.Size([512, 1])

--- [utils/util.py::ComputeLoss.__call__] TARGET PROCESSING ---
[utils/util.py::ComputeLoss.__call__] Targets shape: torch.Size([2, 6])
[utils/util.py::ComputeLoss.__call__] Targets dtype: torch.float32
[utils/util.py::ComputeLoss.__call__] First few targets: tensor([[1.0000, 0.0000, 0.3586, 0.3130, 0.0850, 0.1774],
        [2.0000, 0.0000, 0.7918, 0.5459, 0.0619, 0.1217]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Image indices: tensor([1., 2.], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Counts per image: tensor([1, 1], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT tensor shape: torch.Size([4, 1, 5])
[utils/util.py::ComputeLoss.__call__] Image 1: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 2: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] GT before coordinate conversion: tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.3586, 0.3130, 0.0850, 0.1774]],

        [[0.0000, 0.7918, 0.5459, 0.0619, 0.1217]],

        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT after coordinate conversion: tensor([[[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000,  80.9350,  28.7166, 102.6938,  51.4214]],

        [[  0.0000, 194.7894,  62.0840, 210.6304,  77.6606]],

        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT labels shape: torch.Size([4, 1, 1])
[utils/util.py::ComputeLoss.__call__] GT bboxes shape: torch.Size([4, 1, 4])
[utils/util.py::ComputeLoss.__call__] GT mask shape: torch.Size([4, 1, 1])
[utils/util.py::ComputeLoss.__call__] Pred output dimensions - b: 4, a: 512, c: 64
[utils/util.py::ComputeLoss.__call__] Pred bboxes after softmax shape: torch.Size([4, 512, 4, 16])
[utils/util.py::ComputeLoss.__call__] Pred bboxes after matmul shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Final pred bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.__call__] ASSIGNMENT PHASE ---

--- [utils/util.py::ComputeLoss.assign] PYTORCH ASSIGNMENT DEBUG ---
[utils/util.py::ComputeLoss.assign] pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] true_labels shape: torch.Size([4, 1, 1])
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 1, 4])
[utils/util.py::ComputeLoss.assign] true_mask shape: torch.Size([4, 1, 1])
[utils/util.py::ComputeLoss.assign] anchors shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.assign] Batch size: 4, Max boxes: 1
[utils/util.py::ComputeLoss.assign] Created indices tensor with shape: torch.Size([2, 4, 1])

--- [utils/util.py::ComputeLoss.assign] IOUs DEBUG ---
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 1, 4])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([4, 1, 1, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([4, 1, 512, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([4, 1, 1, 1]), h: torch.Size([4, 1, 1, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([4, 1, 512, 1]), h: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.000000, max: 0.044419
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: -0.670713, max: 0.040254
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.assign] overlaps shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.assign] overlaps min: 0.0, max: 0.04025391489267349
[utils/util.py::ComputeLoss.assign] align_metric shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.assign] align_metric min: 0.0, max: 5.33630466204027e-11
[utils/util.py::ComputeLoss.assign] mask_in_gts shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.assign] mask_in_gts sum: 10.0
[utils/util.py::ComputeLoss.assign] metrics shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.assign] top_k_mask shape: torch.Size([4, 1, 10])
[utils/util.py::ComputeLoss.assign] top_k_metrics shape: torch.Size([4, 1, 10])
[utils/util.py::ComputeLoss.assign] top_k_indices shape: torch.Size([4, 1, 10])
[utils/util.py::ComputeLoss.assign] is_in_top_k shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.assign] mask_top_k shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.assign] mask_pos shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.assign] fg_mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] fg_mask sum: 10.0
[utils/util.py::ComputeLoss.assign] target_gt_idx shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_labels shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] Normalized target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] target_scores sum: 0.009304724633693695
--- [utils/util.py::ComputeLoss.assign] END PYTORCH ASSIGNMENT DEBUG ---

[utils/util.py::ComputeLoss.__call__] Target bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Target scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] FG mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.__call__] Target scores sum: 0.009305
[utils/util.py::ComputeLoss.__call__] Classification loss computed: 11.754781
[utils/util.py::ComputeLoss.__call__] Foreground count: 10
[utils/util.py::ComputeLoss.__call__] Weight shape: torch.Size([10, 1])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([10, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([10, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([10, 1]), h: torch.Size([10, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([10, 1]), h: torch.Size([10, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([10, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([10, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([10, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.017164, max: 0.040951
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([10, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([10, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([10, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([10, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: 0.013254, max: 0.040251
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.__call__] IoU values shape: torch.Size([10, 1])
[utils/util.py::ComputeLoss.__call__] Box loss computed: 0.963125
[utils/util.py::ComputeLoss.__call__] Target LT-RB shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.df_loss] PYTORCH DFL LOSS DEBUG ---
[utils/util.py::ComputeLoss.df_loss] pred_dist shape: torch.Size([40, 16])
[utils/util.py::ComputeLoss.df_loss] target shape: torch.Size([10, 4])
[utils/util.py::ComputeLoss.df_loss] DFL loss shape: torch.Size([10, 1])
[utils/util.py::ComputeLoss.df_loss] DFL loss mean: 2.641952
--- [utils/util.py::ComputeLoss.df_loss] END PYTORCH DFL LOSS DEBUG ---

[utils/util.py::ComputeLoss.__call__] DFL loss before weighting: 2.641952
[utils/util.py::ComputeLoss.__call__] DFL loss computed: 2.663847

--- [utils/util.py::ComputeLoss.__call__] LOSS COMPONENTS DEBUG ---
[utils/util.py::ComputeLoss.__call__] Raw loss_cls: 11.754781
[utils/util.py::ComputeLoss.__call__] Raw loss_box: 0.963125
[utils/util.py::ComputeLoss.__call__] Raw loss_dfl: 2.663847
[utils/util.py::ComputeLoss.__call__] Loss weights - cls: 0.5, box: 7.5, dfl: 1.5
[utils/util.py::ComputeLoss.__call__] target_scores_sum: 0.009305
[utils/util.py::ComputeLoss.__call__] fg_mask sum: 10
[utils/util.py::ComputeLoss.__call__] Weighted loss_cls: 5.877390
[utils/util.py::ComputeLoss.__call__] Weighted loss_box: 7.223435
[utils/util.py::ComputeLoss.__call__] Weighted loss_dfl: 3.995770
[utils/util.py::ComputeLoss.__call__] Total loss: 17.096596
--- [utils/util.py::ComputeLoss.__call__] END PYTORCH LOSS COMPUTATION DEBUG ---


--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([4, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: True
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([4, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - box shape: torch.Size([4, 64, 16, 32]), cls shape: torch.Size([4, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - final concat shape: torch.Size([4, 65, 16, 32])

--- [utils/util.py::ComputeLoss.__call__] PYTORCH LOSS COMPUTATION DEBUG ---
[utils/util.py::ComputeLoss.__call__] Outputs type: <class 'list'>
[utils/util.py::ComputeLoss.__call__] x type: <class 'list'>, len: 1
[utils/util.py::ComputeLoss.__call__] x[0] shape: torch.Size([4, 65, 16, 32])
[utils/util.py::ComputeLoss.__call__] Concatenated output shape: torch.Size([4, 65, 512])
[utils/util.py::ComputeLoss.__call__] self.no: 65, self.dfl_ch: 16, self.nc: 1
[utils/util.py::ComputeLoss.__call__] pred_output shape: torch.Size([4, 64, 512])
[utils/util.py::ComputeLoss.__call__] pred_scores shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.__call__] After permute - pred_output shape: torch.Size([4, 512, 64])
[utils/util.py::ComputeLoss.__call__] After permute - pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Size tensor: tensor([128., 256.], device='cuda:0', dtype=torch.float16)
[utils/util.py::ComputeLoss.__call__] Stride: tensor([8.])
[utils/util.py::ComputeLoss.__call__] Anchor points shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.__call__] Stride tensor shape: torch.Size([512, 1])

--- [utils/util.py::ComputeLoss.__call__] TARGET PROCESSING ---
[utils/util.py::ComputeLoss.__call__] Targets shape: torch.Size([5, 6])
[utils/util.py::ComputeLoss.__call__] Targets dtype: torch.float32
[utils/util.py::ComputeLoss.__call__] First few targets: tensor([[0.0000, 0.0000, 0.7019, 0.0164, 0.0957, 0.0329],
        [0.0000, 0.0000, 0.4767, 0.7195, 0.0892, 0.1779],
        [1.0000, 0.0000, 0.0188, 0.0558, 0.0375, 0.1116],
        [1.0000, 0.0000, 0.7090, 0.6446, 0.0670, 0.1398],
        [2.0000, 0.0000, 0.0737, 0.1115, 0.1474, 0.2231]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Image indices: tensor([0., 0., 1., 1., 2.], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Counts per image: tensor([2, 2, 1], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT tensor shape: torch.Size([4, 2, 5])
[utils/util.py::ComputeLoss.__call__] Image 0: 2 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 1: 2 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 2: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] GT before coordinate conversion: tensor([[[0.0000, 0.7019, 0.0164, 0.0957, 0.0329],
         [0.0000, 0.4767, 0.7195, 0.0892, 0.1779]],

        [[0.0000, 0.0188, 0.0558, 0.0375, 0.1116],
         [0.0000, 0.7090, 0.6446, 0.0670, 0.1398]],

        [[0.0000, 0.0737, 0.1115, 0.1474, 0.2231],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT after coordinate conversion: tensor([[[  0.0000, 167.4544,   0.0000, 191.9413,   4.2063],
         [  0.0000, 110.6097,  80.7098, 133.4387, 103.4841]],

        [[  0.0000,   0.0000,   0.0000,   9.6109,  14.2875],
         [  0.0000, 172.9306,  73.5599, 190.0829,  91.4579]],

        [[  0.0000,   0.0000,   0.0000,  37.7434,  28.5537],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT labels shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.__call__] GT bboxes shape: torch.Size([4, 2, 4])
[utils/util.py::ComputeLoss.__call__] GT mask shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.__call__] Pred output dimensions - b: 4, a: 512, c: 64
[utils/util.py::ComputeLoss.__call__] Pred bboxes after softmax shape: torch.Size([4, 512, 4, 16])
[utils/util.py::ComputeLoss.__call__] Pred bboxes after matmul shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Final pred bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.__call__] ASSIGNMENT PHASE ---

--- [utils/util.py::ComputeLoss.assign] PYTORCH ASSIGNMENT DEBUG ---
[utils/util.py::ComputeLoss.assign] pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] true_labels shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 2, 4])
[utils/util.py::ComputeLoss.assign] true_mask shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.assign] anchors shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.assign] Batch size: 4, Max boxes: 2
[utils/util.py::ComputeLoss.assign] Created indices tensor with shape: torch.Size([2, 4, 2])

--- [utils/util.py::ComputeLoss.assign] IOUs DEBUG ---
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 2, 4])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([4, 2, 1, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([4, 1, 512, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([4, 2, 1, 1]), h: torch.Size([4, 2, 1, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([4, 1, 512, 1]), h: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.000000, max: 0.088066
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: -0.664300, max: 0.082789
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.assign] overlaps shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] overlaps min: 0.0, max: 0.08278903365135193
[utils/util.py::ComputeLoss.assign] align_metric shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] align_metric min: 0.0, max: 6.387050000000727e-09
[utils/util.py::ComputeLoss.assign] mask_in_gts shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] mask_in_gts sum: 38.0
[utils/util.py::ComputeLoss.assign] metrics shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] top_k_mask shape: torch.Size([4, 2, 10])
[utils/util.py::ComputeLoss.assign] top_k_metrics shape: torch.Size([4, 2, 10])
[utils/util.py::ComputeLoss.assign] top_k_indices shape: torch.Size([4, 2, 10])
[utils/util.py::ComputeLoss.assign] is_in_top_k shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] mask_top_k shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] mask_pos shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] fg_mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] fg_mask sum: 25.0
[utils/util.py::ComputeLoss.assign] target_gt_idx shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_labels shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] Normalized target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] target_scores sum: 0.5457600355148315
--- [utils/util.py::ComputeLoss.assign] END PYTORCH ASSIGNMENT DEBUG ---

[utils/util.py::ComputeLoss.__call__] Target bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Target scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] FG mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.__call__] Target scores sum: 0.545760
[utils/util.py::ComputeLoss.__call__] Classification loss computed: 7.715731
[utils/util.py::ComputeLoss.__call__] Foreground count: 25
[utils/util.py::ComputeLoss.__call__] Weight shape: torch.Size([25, 1])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([25, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([25, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([25, 1]), h: torch.Size([25, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([25, 1]), h: torch.Size([25, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([25, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([25, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([25, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.010211, max: 0.084726
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([25, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([25, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([25, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([25, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: 0.006560, max: 0.082827
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.__call__] IoU values shape: torch.Size([25, 1])
[utils/util.py::ComputeLoss.__call__] Box loss computed: 0.924008
[utils/util.py::ComputeLoss.__call__] Target LT-RB shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.df_loss] PYTORCH DFL LOSS DEBUG ---
[utils/util.py::ComputeLoss.df_loss] pred_dist shape: torch.Size([100, 16])
[utils/util.py::ComputeLoss.df_loss] target shape: torch.Size([25, 4])
[utils/util.py::ComputeLoss.df_loss] DFL loss shape: torch.Size([25, 1])
[utils/util.py::ComputeLoss.df_loss] DFL loss mean: 2.877323
--- [utils/util.py::ComputeLoss.df_loss] END PYTORCH DFL LOSS DEBUG ---

[utils/util.py::ComputeLoss.__call__] DFL loss before weighting: 2.877323
[utils/util.py::ComputeLoss.__call__] DFL loss computed: 2.813850

--- [utils/util.py::ComputeLoss.__call__] LOSS COMPONENTS DEBUG ---
[utils/util.py::ComputeLoss.__call__] Raw loss_cls: 7.715731
[utils/util.py::ComputeLoss.__call__] Raw loss_box: 0.924008
[utils/util.py::ComputeLoss.__call__] Raw loss_dfl: 2.813850
[utils/util.py::ComputeLoss.__call__] Loss weights - cls: 0.5, box: 7.5, dfl: 1.5
[utils/util.py::ComputeLoss.__call__] target_scores_sum: 0.545760
[utils/util.py::ComputeLoss.__call__] fg_mask sum: 25
[utils/util.py::ComputeLoss.__call__] Weighted loss_cls: 3.857865
[utils/util.py::ComputeLoss.__call__] Weighted loss_box: 6.930063
[utils/util.py::ComputeLoss.__call__] Weighted loss_dfl: 4.220775
[utils/util.py::ComputeLoss.__call__] Total loss: 15.008703
--- [utils/util.py::ComputeLoss.__call__] END PYTORCH LOSS COMPUTATION DEBUG ---


--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([4, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: True
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([4, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - box shape: torch.Size([4, 64, 16, 32]), cls shape: torch.Size([4, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - final concat shape: torch.Size([4, 65, 16, 32])

--- [utils/util.py::ComputeLoss.__call__] PYTORCH LOSS COMPUTATION DEBUG ---
[utils/util.py::ComputeLoss.__call__] Outputs type: <class 'list'>
[utils/util.py::ComputeLoss.__call__] x type: <class 'list'>, len: 1
[utils/util.py::ComputeLoss.__call__] x[0] shape: torch.Size([4, 65, 16, 32])
[utils/util.py::ComputeLoss.__call__] Concatenated output shape: torch.Size([4, 65, 512])
[utils/util.py::ComputeLoss.__call__] self.no: 65, self.dfl_ch: 16, self.nc: 1
[utils/util.py::ComputeLoss.__call__] pred_output shape: torch.Size([4, 64, 512])
[utils/util.py::ComputeLoss.__call__] pred_scores shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.__call__] After permute - pred_output shape: torch.Size([4, 512, 64])
[utils/util.py::ComputeLoss.__call__] After permute - pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Size tensor: tensor([128., 256.], device='cuda:0', dtype=torch.float16)
[utils/util.py::ComputeLoss.__call__] Stride: tensor([8.])
[utils/util.py::ComputeLoss.__call__] Anchor points shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.__call__] Stride tensor shape: torch.Size([512, 1])

--- [utils/util.py::ComputeLoss.__call__] TARGET PROCESSING ---
[utils/util.py::ComputeLoss.__call__] Targets shape: torch.Size([9, 6])
[utils/util.py::ComputeLoss.__call__] Targets dtype: torch.float32
[utils/util.py::ComputeLoss.__call__] First few targets: tensor([[0.0000, 0.0000, 0.0300, 0.0175, 0.0600, 0.0349],
        [0.0000, 0.0000, 0.5354, 0.0460, 0.0752, 0.0920],
        [0.0000, 0.0000, 0.7298, 0.6127, 0.0709, 0.1483],
        [1.0000, 0.0000, 0.0592, 0.6186, 0.1185, 0.2359],
        [2.0000, 0.0000, 0.1338, 0.0364, 0.0683, 0.0727]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Image indices: tensor([0., 0., 0., 1., 2., 2., 2., 2., 3.], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Counts per image: tensor([3, 1, 4, 1], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT tensor shape: torch.Size([4, 4, 5])
[utils/util.py::ComputeLoss.__call__] Image 0: 3 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 1: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 2: 4 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 3: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] GT before coordinate conversion: tensor([[[0.0000, 0.0300, 0.0175, 0.0600, 0.0349],
         [0.0000, 0.5354, 0.0460, 0.0752, 0.0920],
         [0.0000, 0.7298, 0.6127, 0.0709, 0.1483],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.0592, 0.6186, 0.1185, 0.2359],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.1338, 0.0364, 0.0683, 0.0727],
         [0.0000, 0.2911, 0.0398, 0.0670, 0.0796],
         [0.0000, 0.1349, 0.8407, 0.0799, 0.1704],
         [0.0000, 0.8471, 0.7283, 0.0825, 0.1634]],

        [[0.0000, 0.4818, 0.5214, 0.1228, 0.2457],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT after coordinate conversion: tensor([[[0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5356e+01, 4.4677e+00],
         [0.0000e+00, 1.2742e+02, 0.0000e+00, 1.4668e+02, 1.1776e+01],
         [0.0000e+00, 1.7775e+02, 6.8932e+01, 1.9589e+02, 8.7908e+01],
         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],

        [[0.0000e+00, 9.9945e-04, 6.4087e+01, 3.0326e+01, 9.4280e+01],
         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],

        [[0.0000e+00, 2.5505e+01, 0.0000e+00, 4.2995e+01, 9.3063e+00],
         [0.0000e+00, 6.5951e+01, 0.0000e+00, 8.3108e+01, 1.0186e+01],
         [0.0000e+00, 2.4312e+01, 9.6708e+01, 4.4777e+01, 1.1852e+02],
         [0.0000e+00, 2.0630e+02, 8.2765e+01, 2.2742e+02, 1.0368e+02]],

        [[0.0000e+00, 1.0761e+02, 5.1011e+01, 1.3905e+02, 8.2455e+01],
         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]]],
       device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT labels shape: torch.Size([4, 4, 1])
[utils/util.py::ComputeLoss.__call__] GT bboxes shape: torch.Size([4, 4, 4])
[utils/util.py::ComputeLoss.__call__] GT mask shape: torch.Size([4, 4, 1])
[utils/util.py::ComputeLoss.__call__] Pred output dimensions - b: 4, a: 512, c: 64
[utils/util.py::ComputeLoss.__call__] Pred bboxes after softmax shape: torch.Size([4, 512, 4, 16])
[utils/util.py::ComputeLoss.__call__] Pred bboxes after matmul shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Final pred bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.__call__] ASSIGNMENT PHASE ---

--- [utils/util.py::ComputeLoss.assign] PYTORCH ASSIGNMENT DEBUG ---
[utils/util.py::ComputeLoss.assign] pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] true_labels shape: torch.Size([4, 4, 1])
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 4, 4])
[utils/util.py::ComputeLoss.assign] true_mask shape: torch.Size([4, 4, 1])
[utils/util.py::ComputeLoss.assign] anchors shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.assign] Batch size: 4, Max boxes: 4
[utils/util.py::ComputeLoss.assign] Created indices tensor with shape: torch.Size([2, 4, 4])

--- [utils/util.py::ComputeLoss.assign] IOUs DEBUG ---
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 4, 4])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([4, 4, 1, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([4, 1, 512, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([4, 4, 1, 1]), h: torch.Size([4, 4, 1, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([4, 1, 512, 1]), h: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([4, 4, 512, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([4, 4, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([4, 4, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.000000, max: 0.087294
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([4, 4, 512, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([4, 4, 512, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([4, 4, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([4, 4, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: -0.702724, max: 0.075521
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.assign] overlaps shape: torch.Size([4, 4, 512])
[utils/util.py::ComputeLoss.assign] overlaps min: 0.0, max: 0.07552069425582886
[utils/util.py::ComputeLoss.assign] align_metric shape: torch.Size([4, 4, 512])
[utils/util.py::ComputeLoss.assign] align_metric min: 0.0, max: 3.1492268792732148e-09
[utils/util.py::ComputeLoss.assign] mask_in_gts shape: torch.Size([4, 4, 512])
[utils/util.py::ComputeLoss.assign] mask_in_gts sum: 59.0
[utils/util.py::ComputeLoss.assign] metrics shape: torch.Size([4, 4, 512])
[utils/util.py::ComputeLoss.assign] top_k_mask shape: torch.Size([4, 4, 10])
[utils/util.py::ComputeLoss.assign] top_k_metrics shape: torch.Size([4, 4, 10])
[utils/util.py::ComputeLoss.assign] top_k_indices shape: torch.Size([4, 4, 10])
[utils/util.py::ComputeLoss.assign] is_in_top_k shape: torch.Size([4, 4, 512])
[utils/util.py::ComputeLoss.assign] mask_top_k shape: torch.Size([4, 4, 512])
[utils/util.py::ComputeLoss.assign] mask_pos shape: torch.Size([4, 4, 512])
[utils/util.py::ComputeLoss.assign] fg_mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] fg_mask sum: 47.0
[utils/util.py::ComputeLoss.assign] target_gt_idx shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_labels shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] Normalized target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] target_scores sum: 0.7431379556655884
--- [utils/util.py::ComputeLoss.assign] END PYTORCH ASSIGNMENT DEBUG ---

[utils/util.py::ComputeLoss.__call__] Target bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Target scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] FG mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.__call__] Target scores sum: 0.743138
[utils/util.py::ComputeLoss.__call__] Classification loss computed: 8.252589
[utils/util.py::ComputeLoss.__call__] Foreground count: 47
[utils/util.py::ComputeLoss.__call__] Weight shape: torch.Size([47, 1])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([47, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([47, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([47, 1]), h: torch.Size([47, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([47, 1]), h: torch.Size([47, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([47, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([47, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([47, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.004794, max: 0.081902
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([47, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([47, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([47, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([47, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: -0.007161, max: 0.075476
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.__call__] IoU values shape: torch.Size([47, 1])
[utils/util.py::ComputeLoss.__call__] Box loss computed: 0.931132
[utils/util.py::ComputeLoss.__call__] Target LT-RB shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.df_loss] PYTORCH DFL LOSS DEBUG ---
[utils/util.py::ComputeLoss.df_loss] pred_dist shape: torch.Size([188, 16])
[utils/util.py::ComputeLoss.df_loss] target shape: torch.Size([47, 4])
[utils/util.py::ComputeLoss.df_loss] DFL loss shape: torch.Size([47, 1])
[utils/util.py::ComputeLoss.df_loss] DFL loss mean: 2.701157
--- [utils/util.py::ComputeLoss.df_loss] END PYTORCH DFL LOSS DEBUG ---

[utils/util.py::ComputeLoss.__call__] DFL loss before weighting: 2.701157
[utils/util.py::ComputeLoss.__call__] DFL loss computed: 2.702578

--- [utils/util.py::ComputeLoss.__call__] LOSS COMPONENTS DEBUG ---
[utils/util.py::ComputeLoss.__call__] Raw loss_cls: 8.252589
[utils/util.py::ComputeLoss.__call__] Raw loss_box: 0.931132
[utils/util.py::ComputeLoss.__call__] Raw loss_dfl: 2.702578
[utils/util.py::ComputeLoss.__call__] Loss weights - cls: 0.5, box: 7.5, dfl: 1.5
[utils/util.py::ComputeLoss.__call__] target_scores_sum: 0.743138
[utils/util.py::ComputeLoss.__call__] fg_mask sum: 47
[utils/util.py::ComputeLoss.__call__] Weighted loss_cls: 4.126295
[utils/util.py::ComputeLoss.__call__] Weighted loss_box: 6.983491
[utils/util.py::ComputeLoss.__call__] Weighted loss_dfl: 4.053867
[utils/util.py::ComputeLoss.__call__] Total loss: 15.163652
--- [utils/util.py::ComputeLoss.__call__] END PYTORCH LOSS COMPUTATION DEBUG ---


--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([4, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: True
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([4, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - box shape: torch.Size([4, 64, 16, 32]), cls shape: torch.Size([4, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - final concat shape: torch.Size([4, 65, 16, 32])

--- [utils/util.py::ComputeLoss.__call__] PYTORCH LOSS COMPUTATION DEBUG ---
[utils/util.py::ComputeLoss.__call__] Outputs type: <class 'list'>
[utils/util.py::ComputeLoss.__call__] x type: <class 'list'>, len: 1
[utils/util.py::ComputeLoss.__call__] x[0] shape: torch.Size([4, 65, 16, 32])
[utils/util.py::ComputeLoss.__call__] Concatenated output shape: torch.Size([4, 65, 512])
[utils/util.py::ComputeLoss.__call__] self.no: 65, self.dfl_ch: 16, self.nc: 1
[utils/util.py::ComputeLoss.__call__] pred_output shape: torch.Size([4, 64, 512])
[utils/util.py::ComputeLoss.__call__] pred_scores shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.__call__] After permute - pred_output shape: torch.Size([4, 512, 64])
[utils/util.py::ComputeLoss.__call__] After permute - pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Size tensor: tensor([128., 256.], device='cuda:0', dtype=torch.float16)
[utils/util.py::ComputeLoss.__call__] Stride: tensor([8.])
[utils/util.py::ComputeLoss.__call__] Anchor points shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.__call__] Stride tensor shape: torch.Size([512, 1])

--- [utils/util.py::ComputeLoss.__call__] TARGET PROCESSING ---
[utils/util.py::ComputeLoss.__call__] Targets shape: torch.Size([6, 6])
[utils/util.py::ComputeLoss.__call__] Targets dtype: torch.float32
[utils/util.py::ComputeLoss.__call__] First few targets: tensor([[0.0000, 0.0000, 0.9809, 0.9530, 0.0382, 0.0939],
        [1.0000, 0.0000, 0.6493, 0.1387, 0.0885, 0.1686],
        [1.0000, 0.0000, 0.2558, 0.3240, 0.1064, 0.2047],
        [2.0000, 0.0000, 0.9506, 0.6720, 0.0769, 0.1534],
        [3.0000, 0.0000, 0.4958, 0.3748, 0.0844, 0.1800]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Image indices: tensor([0., 1., 1., 2., 3., 3.], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Counts per image: tensor([1, 2, 1, 2], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT tensor shape: torch.Size([4, 2, 5])
[utils/util.py::ComputeLoss.__call__] Image 0: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 1: 2 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 2: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 3: 2 targets assigned
[utils/util.py::ComputeLoss.__call__] GT before coordinate conversion: tensor([[[0.0000, 0.9809, 0.9530, 0.0382, 0.0939],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.6493, 0.1387, 0.0885, 0.1686],
         [0.0000, 0.2558, 0.3240, 0.1064, 0.2047]],

        [[0.0000, 0.9506, 0.6720, 0.0769, 0.1534],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.4958, 0.3748, 0.0844, 0.1800],
         [0.0000, 0.3309, 0.3165, 0.0708, 0.1451]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT after coordinate conversion: tensor([[[  0.0000, 246.2235, 115.9753, 256.0000, 127.9990],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000, 154.8948,   6.9595, 177.5402,  28.5453],
         [  0.0000,  51.8718,  28.3686,  79.1091,  54.5659]],

        [[  0.0000, 233.5091,  76.1991, 253.1853,  95.8281],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000, 116.1269,  36.4624, 137.7373,  59.4961],
         [  0.0000,  75.6503,  31.2275,  93.7680,  49.7951]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT labels shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.__call__] GT bboxes shape: torch.Size([4, 2, 4])
[utils/util.py::ComputeLoss.__call__] GT mask shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.__call__] Pred output dimensions - b: 4, a: 512, c: 64
[utils/util.py::ComputeLoss.__call__] Pred bboxes after softmax shape: torch.Size([4, 512, 4, 16])
[utils/util.py::ComputeLoss.__call__] Pred bboxes after matmul shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Final pred bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.__call__] ASSIGNMENT PHASE ---

--- [utils/util.py::ComputeLoss.assign] PYTORCH ASSIGNMENT DEBUG ---
[utils/util.py::ComputeLoss.assign] pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] true_labels shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 2, 4])
[utils/util.py::ComputeLoss.assign] true_mask shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.assign] anchors shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.assign] Batch size: 4, Max boxes: 2
[utils/util.py::ComputeLoss.assign] Created indices tensor with shape: torch.Size([2, 4, 2])

--- [utils/util.py::ComputeLoss.assign] IOUs DEBUG ---
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 2, 4])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([4, 2, 1, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([4, 1, 512, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([4, 2, 1, 1]), h: torch.Size([4, 2, 1, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([4, 1, 512, 1]), h: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.000000, max: 0.061568
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: -0.701690, max: 0.059062
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.assign] overlaps shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] overlaps min: 0.0, max: 0.059062130749225616
[utils/util.py::ComputeLoss.assign] align_metric shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] align_metric min: 0.0, max: 6.969265164968874e-10
[utils/util.py::ComputeLoss.assign] mask_in_gts shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] mask_in_gts sum: 39.0
[utils/util.py::ComputeLoss.assign] metrics shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] top_k_mask shape: torch.Size([4, 2, 10])
[utils/util.py::ComputeLoss.assign] top_k_metrics shape: torch.Size([4, 2, 10])
[utils/util.py::ComputeLoss.assign] top_k_indices shape: torch.Size([4, 2, 10])
[utils/util.py::ComputeLoss.assign] is_in_top_k shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] mask_top_k shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] mask_pos shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] fg_mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] fg_mask sum: 37.0
[utils/util.py::ComputeLoss.assign] target_gt_idx shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_labels shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] Normalized target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] target_scores sum: 0.1465533971786499
--- [utils/util.py::ComputeLoss.assign] END PYTORCH ASSIGNMENT DEBUG ---

[utils/util.py::ComputeLoss.__call__] Target bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Target scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] FG mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.__call__] Target scores sum: 0.146553
[utils/util.py::ComputeLoss.__call__] Classification loss computed: 8.102849
[utils/util.py::ComputeLoss.__call__] Foreground count: 37
[utils/util.py::ComputeLoss.__call__] Weight shape: torch.Size([37, 1])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([37, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([37, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([37, 1]), h: torch.Size([37, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([37, 1]), h: torch.Size([37, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([37, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([37, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([37, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.008684, max: 0.061217
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([37, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([37, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([37, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([37, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: 0.005941, max: 0.059080
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.__call__] IoU values shape: torch.Size([37, 1])
[utils/util.py::ComputeLoss.__call__] Box loss computed: 0.949474
[utils/util.py::ComputeLoss.__call__] Target LT-RB shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.df_loss] PYTORCH DFL LOSS DEBUG ---
[utils/util.py::ComputeLoss.df_loss] pred_dist shape: torch.Size([148, 16])
[utils/util.py::ComputeLoss.df_loss] target shape: torch.Size([37, 4])
[utils/util.py::ComputeLoss.df_loss] DFL loss shape: torch.Size([37, 1])
[utils/util.py::ComputeLoss.df_loss] DFL loss mean: 2.685801
--- [utils/util.py::ComputeLoss.df_loss] END PYTORCH DFL LOSS DEBUG ---

[utils/util.py::ComputeLoss.__call__] DFL loss before weighting: 2.685801
[utils/util.py::ComputeLoss.__call__] DFL loss computed: 2.601019

--- [utils/util.py::ComputeLoss.__call__] LOSS COMPONENTS DEBUG ---
[utils/util.py::ComputeLoss.__call__] Raw loss_cls: 8.102849
[utils/util.py::ComputeLoss.__call__] Raw loss_box: 0.949474
[utils/util.py::ComputeLoss.__call__] Raw loss_dfl: 2.601019
[utils/util.py::ComputeLoss.__call__] Loss weights - cls: 0.5, box: 7.5, dfl: 1.5
[utils/util.py::ComputeLoss.__call__] target_scores_sum: 0.146553
[utils/util.py::ComputeLoss.__call__] fg_mask sum: 37
[utils/util.py::ComputeLoss.__call__] Weighted loss_cls: 4.051425
[utils/util.py::ComputeLoss.__call__] Weighted loss_box: 7.121054
[utils/util.py::ComputeLoss.__call__] Weighted loss_dfl: 3.901528
[utils/util.py::ComputeLoss.__call__] Total loss: 15.074006
--- [utils/util.py::ComputeLoss.__call__] END PYTORCH LOSS COMPUTATION DEBUG ---


--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([4, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: True
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([4, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - box shape: torch.Size([4, 64, 16, 32]), cls shape: torch.Size([4, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - final concat shape: torch.Size([4, 65, 16, 32])

--- [utils/util.py::ComputeLoss.__call__] PYTORCH LOSS COMPUTATION DEBUG ---
[utils/util.py::ComputeLoss.__call__] Outputs type: <class 'list'>
[utils/util.py::ComputeLoss.__call__] x type: <class 'list'>, len: 1
[utils/util.py::ComputeLoss.__call__] x[0] shape: torch.Size([4, 65, 16, 32])
[utils/util.py::ComputeLoss.__call__] Concatenated output shape: torch.Size([4, 65, 512])
[utils/util.py::ComputeLoss.__call__] self.no: 65, self.dfl_ch: 16, self.nc: 1
[utils/util.py::ComputeLoss.__call__] pred_output shape: torch.Size([4, 64, 512])
[utils/util.py::ComputeLoss.__call__] pred_scores shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.__call__] After permute - pred_output shape: torch.Size([4, 512, 64])
[utils/util.py::ComputeLoss.__call__] After permute - pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Size tensor: tensor([128., 256.], device='cuda:0', dtype=torch.float16)
[utils/util.py::ComputeLoss.__call__] Stride: tensor([8.])
[utils/util.py::ComputeLoss.__call__] Anchor points shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.__call__] Stride tensor shape: torch.Size([512, 1])

--- [utils/util.py::ComputeLoss.__call__] TARGET PROCESSING ---
[utils/util.py::ComputeLoss.__call__] Targets shape: torch.Size([6, 6])
[utils/util.py::ComputeLoss.__call__] Targets dtype: torch.float32
[utils/util.py::ComputeLoss.__call__] First few targets: tensor([[0.0000, 0.0000, 0.8698, 0.9203, 0.1151, 0.1595],
        [1.0000, 0.0000, 0.7026, 0.4166, 0.0988, 0.1936],
        [2.0000, 0.0000, 0.8327, 0.4082, 0.0663, 0.1388],
        [2.0000, 0.0000, 0.3446, 0.2825, 0.0545, 0.1025],
        [2.0000, 0.0000, 0.7848, 0.9431, 0.0583, 0.1137]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Image indices: tensor([0., 1., 2., 2., 2., 3.], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Counts per image: tensor([1, 1, 3, 1], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT tensor shape: torch.Size([4, 3, 5])
[utils/util.py::ComputeLoss.__call__] Image 0: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 1: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 2: 3 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 3: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] GT before coordinate conversion: tensor([[[0.0000, 0.8698, 0.9203, 0.1151, 0.1595],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.7026, 0.4166, 0.0988, 0.1936],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.8327, 0.4082, 0.0663, 0.1388],
         [0.0000, 0.3446, 0.2825, 0.0545, 0.1025],
         [0.0000, 0.7848, 0.9431, 0.0583, 0.1137]],

        [[0.0000, 0.8932, 0.8793, 0.1067, 0.2057],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT after coordinate conversion: tensor([[[  0.0000, 207.9465, 107.5874, 237.4012, 127.9990],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000, 167.2240,  40.9421, 192.5224,  65.7184],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000, 204.6928,  43.3645, 221.6561,  61.1351],
         [  0.0000,  81.2469,  29.5986,  95.1881,  42.7138],
         [  0.0000, 193.4297, 113.4455, 208.3658, 127.9990]],

        [[  0.0000, 215.0034,  99.3890, 242.3085, 125.7125],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT labels shape: torch.Size([4, 3, 1])
[utils/util.py::ComputeLoss.__call__] GT bboxes shape: torch.Size([4, 3, 4])
[utils/util.py::ComputeLoss.__call__] GT mask shape: torch.Size([4, 3, 1])
[utils/util.py::ComputeLoss.__call__] Pred output dimensions - b: 4, a: 512, c: 64
[utils/util.py::ComputeLoss.__call__] Pred bboxes after softmax shape: torch.Size([4, 512, 4, 16])
[utils/util.py::ComputeLoss.__call__] Pred bboxes after matmul shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Final pred bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.__call__] ASSIGNMENT PHASE ---

--- [utils/util.py::ComputeLoss.assign] PYTORCH ASSIGNMENT DEBUG ---
[utils/util.py::ComputeLoss.assign] pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] true_labels shape: torch.Size([4, 3, 1])
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 3, 4])
[utils/util.py::ComputeLoss.assign] true_mask shape: torch.Size([4, 3, 1])
[utils/util.py::ComputeLoss.assign] anchors shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.assign] Batch size: 4, Max boxes: 3
[utils/util.py::ComputeLoss.assign] Created indices tensor with shape: torch.Size([2, 4, 3])

--- [utils/util.py::ComputeLoss.assign] IOUs DEBUG ---
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 3, 4])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([4, 3, 1, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([4, 1, 512, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([4, 3, 1, 1]), h: torch.Size([4, 3, 1, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([4, 1, 512, 1]), h: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.000000, max: 0.065700
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: -0.678463, max: 0.057049
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.assign] overlaps shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] overlaps min: 0.0, max: 0.05704896152019501
[utils/util.py::ComputeLoss.assign] align_metric shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] align_metric min: 0.0, max: 4.2991979420925475e-10
[utils/util.py::ComputeLoss.assign] mask_in_gts shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] mask_in_gts sum: 45.0
[utils/util.py::ComputeLoss.assign] metrics shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] top_k_mask shape: torch.Size([4, 3, 10])
[utils/util.py::ComputeLoss.assign] top_k_metrics shape: torch.Size([4, 3, 10])
[utils/util.py::ComputeLoss.assign] top_k_indices shape: torch.Size([4, 3, 10])
[utils/util.py::ComputeLoss.assign] is_in_top_k shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] mask_top_k shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] mask_pos shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] fg_mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] fg_mask sum: 41.0
[utils/util.py::ComputeLoss.assign] target_gt_idx shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_labels shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] Normalized target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] target_scores sum: 0.2055981457233429
--- [utils/util.py::ComputeLoss.assign] END PYTORCH ASSIGNMENT DEBUG ---

[utils/util.py::ComputeLoss.__call__] Target bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Target scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] FG mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.__call__] Target scores sum: 0.205598
[utils/util.py::ComputeLoss.__call__] Classification loss computed: 8.777742
[utils/util.py::ComputeLoss.__call__] Foreground count: 41
[utils/util.py::ComputeLoss.__call__] Weight shape: torch.Size([41, 1])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([41, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([41, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([41, 1]), h: torch.Size([41, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([41, 1]), h: torch.Size([41, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([41, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([41, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([41, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.016558, max: 0.060789
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([41, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([41, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([41, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([41, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: 0.013360, max: 0.057044
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.__call__] IoU values shape: torch.Size([41, 1])
[utils/util.py::ComputeLoss.__call__] Box loss computed: 0.949338
[utils/util.py::ComputeLoss.__call__] Target LT-RB shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.df_loss] PYTORCH DFL LOSS DEBUG ---
[utils/util.py::ComputeLoss.df_loss] pred_dist shape: torch.Size([164, 16])
[utils/util.py::ComputeLoss.df_loss] target shape: torch.Size([41, 4])
[utils/util.py::ComputeLoss.df_loss] DFL loss shape: torch.Size([41, 1])
[utils/util.py::ComputeLoss.df_loss] DFL loss mean: 2.616327
--- [utils/util.py::ComputeLoss.df_loss] END PYTORCH DFL LOSS DEBUG ---

[utils/util.py::ComputeLoss.__call__] DFL loss before weighting: 2.616327
[utils/util.py::ComputeLoss.__call__] DFL loss computed: 2.582595

--- [utils/util.py::ComputeLoss.__call__] LOSS COMPONENTS DEBUG ---
[utils/util.py::ComputeLoss.__call__] Raw loss_cls: 8.777742
[utils/util.py::ComputeLoss.__call__] Raw loss_box: 0.949338
[utils/util.py::ComputeLoss.__call__] Raw loss_dfl: 2.582595
[utils/util.py::ComputeLoss.__call__] Loss weights - cls: 0.5, box: 7.5, dfl: 1.5
[utils/util.py::ComputeLoss.__call__] target_scores_sum: 0.205598
[utils/util.py::ComputeLoss.__call__] fg_mask sum: 41
[utils/util.py::ComputeLoss.__call__] Weighted loss_cls: 4.388871
[utils/util.py::ComputeLoss.__call__] Weighted loss_box: 7.120031
[utils/util.py::ComputeLoss.__call__] Weighted loss_dfl: 3.873892
[utils/util.py::ComputeLoss.__call__] Total loss: 15.382795
--- [utils/util.py::ComputeLoss.__call__] END PYTORCH LOSS COMPUTATION DEBUG ---


--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([4, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: True
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([4, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - box shape: torch.Size([4, 64, 16, 32]), cls shape: torch.Size([4, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - final concat shape: torch.Size([4, 65, 16, 32])

--- [utils/util.py::ComputeLoss.__call__] PYTORCH LOSS COMPUTATION DEBUG ---
[utils/util.py::ComputeLoss.__call__] Outputs type: <class 'list'>
[utils/util.py::ComputeLoss.__call__] x type: <class 'list'>, len: 1
[utils/util.py::ComputeLoss.__call__] x[0] shape: torch.Size([4, 65, 16, 32])
[utils/util.py::ComputeLoss.__call__] Concatenated output shape: torch.Size([4, 65, 512])
[utils/util.py::ComputeLoss.__call__] self.no: 65, self.dfl_ch: 16, self.nc: 1
[utils/util.py::ComputeLoss.__call__] pred_output shape: torch.Size([4, 64, 512])
[utils/util.py::ComputeLoss.__call__] pred_scores shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.__call__] After permute - pred_output shape: torch.Size([4, 512, 64])
[utils/util.py::ComputeLoss.__call__] After permute - pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Size tensor: tensor([128., 256.], device='cuda:0', dtype=torch.float16)
[utils/util.py::ComputeLoss.__call__] Stride: tensor([8.])
[utils/util.py::ComputeLoss.__call__] Anchor points shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.__call__] Stride tensor shape: torch.Size([512, 1])

--- [utils/util.py::ComputeLoss.__call__] TARGET PROCESSING ---
[utils/util.py::ComputeLoss.__call__] Targets shape: torch.Size([5, 6])
[utils/util.py::ComputeLoss.__call__] Targets dtype: torch.float32
[utils/util.py::ComputeLoss.__call__] First few targets: tensor([[1.0000, 0.0000, 0.8476, 0.3087, 0.0529, 0.1115],
        [1.0000, 0.0000, 0.3151, 0.3292, 0.0595, 0.1207],
        [3.0000, 0.0000, 0.3048, 0.2605, 0.0477, 0.0889],
        [3.0000, 0.0000, 0.9230, 0.7382, 0.0448, 0.0934],
        [3.0000, 0.0000, 0.2700, 0.8531, 0.0569, 0.1114]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Image indices: tensor([1., 1., 3., 3., 3.], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Counts per image: tensor([2, 3], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT tensor shape: torch.Size([4, 3, 5])
[utils/util.py::ComputeLoss.__call__] Image 1: 2 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 3: 3 targets assigned
[utils/util.py::ComputeLoss.__call__] GT before coordinate conversion: tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.8476, 0.3087, 0.0529, 0.1115],
         [0.0000, 0.3151, 0.3292, 0.0595, 0.1207],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.3048, 0.2605, 0.0477, 0.0889],
         [0.0000, 0.9230, 0.7382, 0.0448, 0.0934],
         [0.0000, 0.2700, 0.8531, 0.0569, 0.1114]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT after coordinate conversion: tensor([[[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000, 210.2074,  32.3755, 223.7561,  46.6454],
         [  0.0000,  73.0500,  34.4104,  88.2793,  49.8651],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000,  71.9112,  27.6558,  84.1336,  39.0288],
         [  0.0000, 230.5514,  88.5167, 242.0259, 100.4667],
         [  0.0000,  61.8309, 102.0639,  76.3931, 116.3216]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT labels shape: torch.Size([4, 3, 1])
[utils/util.py::ComputeLoss.__call__] GT bboxes shape: torch.Size([4, 3, 4])
[utils/util.py::ComputeLoss.__call__] GT mask shape: torch.Size([4, 3, 1])
[utils/util.py::ComputeLoss.__call__] Pred output dimensions - b: 4, a: 512, c: 64
[utils/util.py::ComputeLoss.__call__] Pred bboxes after softmax shape: torch.Size([4, 512, 4, 16])
[utils/util.py::ComputeLoss.__call__] Pred bboxes after matmul shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Final pred bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.__call__] ASSIGNMENT PHASE ---

--- [utils/util.py::ComputeLoss.assign] PYTORCH ASSIGNMENT DEBUG ---
[utils/util.py::ComputeLoss.assign] pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] true_labels shape: torch.Size([4, 3, 1])
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 3, 4])
[utils/util.py::ComputeLoss.assign] true_mask shape: torch.Size([4, 3, 1])
[utils/util.py::ComputeLoss.assign] anchors shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.assign] Batch size: 4, Max boxes: 3
[utils/util.py::ComputeLoss.assign] Created indices tensor with shape: torch.Size([2, 4, 3])

--- [utils/util.py::ComputeLoss.assign] IOUs DEBUG ---
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 3, 4])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([4, 3, 1, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([4, 1, 512, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([4, 3, 1, 1]), h: torch.Size([4, 3, 1, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([4, 1, 512, 1]), h: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.000000, max: 0.026639
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: -0.691706, max: 0.019195
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.assign] overlaps shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] overlaps min: 0.0, max: 0.01919533684849739
[utils/util.py::ComputeLoss.assign] align_metric shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] align_metric min: 0.0, max: 5.690969613961205e-13
[utils/util.py::ComputeLoss.assign] mask_in_gts shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] mask_in_gts sum: 18.0
[utils/util.py::ComputeLoss.assign] metrics shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] top_k_mask shape: torch.Size([4, 3, 10])
[utils/util.py::ComputeLoss.assign] top_k_metrics shape: torch.Size([4, 3, 10])
[utils/util.py::ComputeLoss.assign] top_k_indices shape: torch.Size([4, 3, 10])
[utils/util.py::ComputeLoss.assign] is_in_top_k shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] mask_top_k shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] mask_pos shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] fg_mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] fg_mask sum: 18.0
[utils/util.py::ComputeLoss.assign] target_gt_idx shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_labels shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] Normalized target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] target_scores sum: 4.8074802180053666e-05
--- [utils/util.py::ComputeLoss.assign] END PYTORCH ASSIGNMENT DEBUG ---

[utils/util.py::ComputeLoss.__call__] Target bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Target scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] FG mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.__call__] Target scores sum: 0.000048
[utils/util.py::ComputeLoss.__call__] Classification loss computed: 0.000000
[utils/util.py::ComputeLoss.__call__] Foreground count: 18
[utils/util.py::ComputeLoss.__call__] Weight shape: torch.Size([18, 1])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([18, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([18, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([18, 1]), h: torch.Size([18, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([18, 1]), h: torch.Size([18, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([18, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([18, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([18, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.011239, max: 0.021151
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([18, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([18, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([18, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([18, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: 0.003203, max: 0.019199
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.__call__] IoU values shape: torch.Size([18, 1])
[utils/util.py::ComputeLoss.__call__] Box loss computed: 0.982312
[utils/util.py::ComputeLoss.__call__] Target LT-RB shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.df_loss] PYTORCH DFL LOSS DEBUG ---
[utils/util.py::ComputeLoss.df_loss] pred_dist shape: torch.Size([72, 16])
[utils/util.py::ComputeLoss.df_loss] target shape: torch.Size([18, 4])
[utils/util.py::ComputeLoss.df_loss] DFL loss shape: torch.Size([18, 1])
[utils/util.py::ComputeLoss.df_loss] DFL loss mean: 2.549459
--- [utils/util.py::ComputeLoss.df_loss] END PYTORCH DFL LOSS DEBUG ---

[utils/util.py::ComputeLoss.__call__] DFL loss before weighting: 2.549459
[utils/util.py::ComputeLoss.__call__] DFL loss computed: 2.467725

--- [utils/util.py::ComputeLoss.__call__] LOSS COMPONENTS DEBUG ---
[utils/util.py::ComputeLoss.__call__] Raw loss_cls: 0.000000
[utils/util.py::ComputeLoss.__call__] Raw loss_box: 0.982312
[utils/util.py::ComputeLoss.__call__] Raw loss_dfl: 2.467725
[utils/util.py::ComputeLoss.__call__] Loss weights - cls: 0.5, box: 7.5, dfl: 1.5
[utils/util.py::ComputeLoss.__call__] target_scores_sum: 0.000048
[utils/util.py::ComputeLoss.__call__] fg_mask sum: 18
[utils/util.py::ComputeLoss.__call__] Weighted loss_cls: 0.000000
[utils/util.py::ComputeLoss.__call__] Weighted loss_box: 7.367339
[utils/util.py::ComputeLoss.__call__] Weighted loss_dfl: 3.701588
[utils/util.py::ComputeLoss.__call__] Total loss: 11.068926
--- [utils/util.py::ComputeLoss.__call__] END PYTORCH LOSS COMPUTATION DEBUG ---


--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([4, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: True
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([4, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - box shape: torch.Size([4, 64, 16, 32]), cls shape: torch.Size([4, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - final concat shape: torch.Size([4, 65, 16, 32])

--- [utils/util.py::ComputeLoss.__call__] PYTORCH LOSS COMPUTATION DEBUG ---
[utils/util.py::ComputeLoss.__call__] Outputs type: <class 'list'>
[utils/util.py::ComputeLoss.__call__] x type: <class 'list'>, len: 1
[utils/util.py::ComputeLoss.__call__] x[0] shape: torch.Size([4, 65, 16, 32])
[utils/util.py::ComputeLoss.__call__] Concatenated output shape: torch.Size([4, 65, 512])
[utils/util.py::ComputeLoss.__call__] self.no: 65, self.dfl_ch: 16, self.nc: 1
[utils/util.py::ComputeLoss.__call__] pred_output shape: torch.Size([4, 64, 512])
[utils/util.py::ComputeLoss.__call__] pred_scores shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.__call__] After permute - pred_output shape: torch.Size([4, 512, 64])
[utils/util.py::ComputeLoss.__call__] After permute - pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Size tensor: tensor([128., 256.], device='cuda:0', dtype=torch.float16)
[utils/util.py::ComputeLoss.__call__] Stride: tensor([8.])
[utils/util.py::ComputeLoss.__call__] Anchor points shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.__call__] Stride tensor shape: torch.Size([512, 1])

--- [utils/util.py::ComputeLoss.__call__] TARGET PROCESSING ---
[utils/util.py::ComputeLoss.__call__] Targets shape: torch.Size([9, 6])
[utils/util.py::ComputeLoss.__call__] Targets dtype: torch.float32
[utils/util.py::ComputeLoss.__call__] First few targets: tensor([[0.0000, 0.0000, 0.1388, 0.1782, 0.0661, 0.1383],
        [0.0000, 0.0000, 0.6317, 0.2082, 0.0788, 0.1535],
        [0.0000, 0.0000, 0.3788, 0.9300, 0.0731, 0.1399],
        [1.0000, 0.0000, 0.7841, 0.5910, 0.0688, 0.1424],
        [1.0000, 0.0000, 0.3148, 0.5786, 0.0712, 0.1424]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Image indices: tensor([0., 0., 0., 1., 1., 3., 3., 3., 3.], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Counts per image: tensor([3, 2, 4], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT tensor shape: torch.Size([4, 4, 5])
[utils/util.py::ComputeLoss.__call__] Image 0: 3 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 1: 2 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 3: 4 targets assigned
[utils/util.py::ComputeLoss.__call__] GT before coordinate conversion: tensor([[[0.0000, 0.1388, 0.1782, 0.0661, 0.1383],
         [0.0000, 0.6317, 0.2082, 0.0788, 0.1535],
         [0.0000, 0.3788, 0.9300, 0.0731, 0.1399],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.7841, 0.5910, 0.0688, 0.1424],
         [0.0000, 0.3148, 0.5786, 0.0712, 0.1424],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.9051, 0.2780, 0.0535, 0.1087],
         [0.0000, 0.1685, 0.2801, 0.0537, 0.1043],
         [0.0000, 0.7424, 0.9682, 0.0585, 0.0635],
         [0.0000, 0.2058, 0.8104, 0.0500, 0.0956]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT after coordinate conversion: tensor([[[  0.0000,  27.0748,  13.9567,  43.9930,  31.6535],
         [  0.0000, 151.6436,  16.8310, 171.8072,  36.4779],
         [  0.0000,  87.6092, 110.0921, 106.3174, 127.9990],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000, 191.9298,  66.5361, 209.5382,  84.7626],
         [  0.0000,  71.4762,  64.9512,  89.7027,  83.1777],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000, 224.8718,  28.6259, 238.5587,  42.5354],
         [  0.0000,  36.2537,  29.1823,  49.9963,  42.5354],
         [  0.0000, 182.5675, 119.8721, 197.5508, 127.9990],
         [  0.0000,  46.2741,  97.6169,  59.0708, 109.8573]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT labels shape: torch.Size([4, 4, 1])
[utils/util.py::ComputeLoss.__call__] GT bboxes shape: torch.Size([4, 4, 4])
[utils/util.py::ComputeLoss.__call__] GT mask shape: torch.Size([4, 4, 1])
[utils/util.py::ComputeLoss.__call__] Pred output dimensions - b: 4, a: 512, c: 64
[utils/util.py::ComputeLoss.__call__] Pred bboxes after softmax shape: torch.Size([4, 512, 4, 16])
[utils/util.py::ComputeLoss.__call__] Pred bboxes after matmul shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Final pred bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.__call__] ASSIGNMENT PHASE ---

--- [utils/util.py::ComputeLoss.assign] PYTORCH ASSIGNMENT DEBUG ---
[utils/util.py::ComputeLoss.assign] pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] true_labels shape: torch.Size([4, 4, 1])
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 4, 4])
[utils/util.py::ComputeLoss.assign] true_mask shape: torch.Size([4, 4, 1])
[utils/util.py::ComputeLoss.assign] anchors shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.assign] Batch size: 4, Max boxes: 4
[utils/util.py::ComputeLoss.assign] Created indices tensor with shape: torch.Size([2, 4, 4])

--- [utils/util.py::ComputeLoss.assign] IOUs DEBUG ---
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 4, 4])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([4, 4, 1, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([4, 1, 512, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([4, 4, 1, 1]), h: torch.Size([4, 4, 1, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([4, 1, 512, 1]), h: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([4, 4, 512, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([4, 4, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([4, 4, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.000000, max: 0.037907
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([4, 4, 512, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([4, 4, 512, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([4, 4, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([4, 4, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: -0.698075, max: 0.031814
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.assign] overlaps shape: torch.Size([4, 4, 512])
[utils/util.py::ComputeLoss.assign] overlaps min: 0.0, max: 0.03181418776512146
[utils/util.py::ComputeLoss.assign] align_metric shape: torch.Size([4, 4, 512])
[utils/util.py::ComputeLoss.assign] align_metric min: 0.0, max: 1.1296484581091448e-11
[utils/util.py::ComputeLoss.assign] mask_in_gts shape: torch.Size([4, 4, 512])
[utils/util.py::ComputeLoss.assign] mask_in_gts sum: 31.0
[utils/util.py::ComputeLoss.assign] metrics shape: torch.Size([4, 4, 512])
[utils/util.py::ComputeLoss.assign] top_k_mask shape: torch.Size([4, 4, 10])
[utils/util.py::ComputeLoss.assign] top_k_metrics shape: torch.Size([4, 4, 10])
[utils/util.py::ComputeLoss.assign] top_k_indices shape: torch.Size([4, 4, 10])
[utils/util.py::ComputeLoss.assign] is_in_top_k shape: torch.Size([4, 4, 512])
[utils/util.py::ComputeLoss.assign] mask_top_k shape: torch.Size([4, 4, 512])
[utils/util.py::ComputeLoss.assign] mask_pos shape: torch.Size([4, 4, 512])
[utils/util.py::ComputeLoss.assign] fg_mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] fg_mask sum: 31.0
[utils/util.py::ComputeLoss.assign] target_gt_idx shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_labels shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] Normalized target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] target_scores sum: 0.0028901752084493637
--- [utils/util.py::ComputeLoss.assign] END PYTORCH ASSIGNMENT DEBUG ---

[utils/util.py::ComputeLoss.__call__] Target bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Target scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] FG mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.__call__] Target scores sum: 0.002890
[utils/util.py::ComputeLoss.__call__] Classification loss computed: 2.703123
[utils/util.py::ComputeLoss.__call__] Foreground count: 31
[utils/util.py::ComputeLoss.__call__] Weight shape: torch.Size([31, 1])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([31, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([31, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([31, 1]), h: torch.Size([31, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([31, 1]), h: torch.Size([31, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([31, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([31, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([31, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.009670, max: 0.034824
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([31, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([31, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([31, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([31, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: 0.007544, max: 0.031825
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.__call__] IoU values shape: torch.Size([31, 1])
[utils/util.py::ComputeLoss.__call__] Box loss computed: 0.971704
[utils/util.py::ComputeLoss.__call__] Target LT-RB shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.df_loss] PYTORCH DFL LOSS DEBUG ---
[utils/util.py::ComputeLoss.df_loss] pred_dist shape: torch.Size([124, 16])
[utils/util.py::ComputeLoss.df_loss] target shape: torch.Size([31, 4])
[utils/util.py::ComputeLoss.df_loss] DFL loss shape: torch.Size([31, 1])
[utils/util.py::ComputeLoss.df_loss] DFL loss mean: 2.503108
--- [utils/util.py::ComputeLoss.df_loss] END PYTORCH DFL LOSS DEBUG ---

[utils/util.py::ComputeLoss.__call__] DFL loss before weighting: 2.503108
[utils/util.py::ComputeLoss.__call__] DFL loss computed: 2.484185

--- [utils/util.py::ComputeLoss.__call__] LOSS COMPONENTS DEBUG ---
[utils/util.py::ComputeLoss.__call__] Raw loss_cls: 2.703123
[utils/util.py::ComputeLoss.__call__] Raw loss_box: 0.971704
[utils/util.py::ComputeLoss.__call__] Raw loss_dfl: 2.484185
[utils/util.py::ComputeLoss.__call__] Loss weights - cls: 0.5, box: 7.5, dfl: 1.5
[utils/util.py::ComputeLoss.__call__] target_scores_sum: 0.002890
[utils/util.py::ComputeLoss.__call__] fg_mask sum: 31
[utils/util.py::ComputeLoss.__call__] Weighted loss_cls: 1.351562
[utils/util.py::ComputeLoss.__call__] Weighted loss_box: 7.287777
[utils/util.py::ComputeLoss.__call__] Weighted loss_dfl: 3.726278
[utils/util.py::ComputeLoss.__call__] Total loss: 12.365617
--- [utils/util.py::ComputeLoss.__call__] END PYTORCH LOSS COMPUTATION DEBUG ---


--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([4, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: True
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([4, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - box shape: torch.Size([4, 64, 16, 32]), cls shape: torch.Size([4, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - final concat shape: torch.Size([4, 65, 16, 32])

--- [utils/util.py::ComputeLoss.__call__] PYTORCH LOSS COMPUTATION DEBUG ---
[utils/util.py::ComputeLoss.__call__] Outputs type: <class 'list'>
[utils/util.py::ComputeLoss.__call__] x type: <class 'list'>, len: 1
[utils/util.py::ComputeLoss.__call__] x[0] shape: torch.Size([4, 65, 16, 32])
[utils/util.py::ComputeLoss.__call__] Concatenated output shape: torch.Size([4, 65, 512])
[utils/util.py::ComputeLoss.__call__] self.no: 65, self.dfl_ch: 16, self.nc: 1
[utils/util.py::ComputeLoss.__call__] pred_output shape: torch.Size([4, 64, 512])
[utils/util.py::ComputeLoss.__call__] pred_scores shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.__call__] After permute - pred_output shape: torch.Size([4, 512, 64])
[utils/util.py::ComputeLoss.__call__] After permute - pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Size tensor: tensor([128., 256.], device='cuda:0', dtype=torch.float16)
[utils/util.py::ComputeLoss.__call__] Stride: tensor([8.])
[utils/util.py::ComputeLoss.__call__] Anchor points shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.__call__] Stride tensor shape: torch.Size([512, 1])

--- [utils/util.py::ComputeLoss.__call__] TARGET PROCESSING ---
[utils/util.py::ComputeLoss.__call__] Targets shape: torch.Size([4, 6])
[utils/util.py::ComputeLoss.__call__] Targets dtype: torch.float32
[utils/util.py::ComputeLoss.__call__] First few targets: tensor([[0.0000, 0.0000, 0.5743, 0.0358, 0.1362, 0.0716],
        [0.0000, 0.0000, 0.5806, 0.9846, 0.1144, 0.0308],
        [1.0000, 0.0000, 0.5398, 0.5108, 0.0956, 0.1861],
        [2.0000, 0.0000, 0.3865, 0.0783, 0.0807, 0.1567]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Image indices: tensor([0., 0., 1., 2.], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Counts per image: tensor([2, 1, 1], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT tensor shape: torch.Size([4, 2, 5])
[utils/util.py::ComputeLoss.__call__] Image 0: 2 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 1: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 2: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] GT before coordinate conversion: tensor([[[0.0000, 0.5743, 0.0358, 0.1362, 0.0716],
         [0.0000, 0.5806, 0.9846, 0.1144, 0.0308]],

        [[0.0000, 0.5398, 0.5108, 0.0956, 0.1861],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.3865, 0.0783, 0.0807, 0.1567],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT after coordinate conversion: tensor([[[  0.0000, 129.5699,   0.0000, 164.4498,   9.1673],
         [  0.0000, 133.9970, 124.0537, 163.2946, 127.9990]],

        [[  0.0000, 125.9434,  53.4653, 150.4088,  77.2924],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000,  88.6124,   0.0000, 109.2597,  20.0572],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT labels shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.__call__] GT bboxes shape: torch.Size([4, 2, 4])
[utils/util.py::ComputeLoss.__call__] GT mask shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.__call__] Pred output dimensions - b: 4, a: 512, c: 64
[utils/util.py::ComputeLoss.__call__] Pred bboxes after softmax shape: torch.Size([4, 512, 4, 16])
[utils/util.py::ComputeLoss.__call__] Pred bboxes after matmul shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Final pred bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.__call__] ASSIGNMENT PHASE ---

--- [utils/util.py::ComputeLoss.assign] PYTORCH ASSIGNMENT DEBUG ---
[utils/util.py::ComputeLoss.assign] pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] true_labels shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 2, 4])
[utils/util.py::ComputeLoss.assign] true_mask shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.assign] anchors shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.assign] Batch size: 4, Max boxes: 2
[utils/util.py::ComputeLoss.assign] Created indices tensor with shape: torch.Size([2, 4, 2])

--- [utils/util.py::ComputeLoss.assign] IOUs DEBUG ---
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 2, 4])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([4, 2, 1, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([4, 1, 512, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([4, 2, 1, 1]), h: torch.Size([4, 2, 1, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([4, 1, 512, 1]), h: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.000000, max: 0.063776
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: -0.695016, max: 0.055594
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.assign] overlaps shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] overlaps min: 0.0, max: 0.05559416115283966
[utils/util.py::ComputeLoss.assign] align_metric shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] align_metric min: 0.0, max: 3.658063019162938e-10
[utils/util.py::ComputeLoss.assign] mask_in_gts shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] mask_in_gts sum: 23.0
[utils/util.py::ComputeLoss.assign] metrics shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] top_k_mask shape: torch.Size([4, 2, 10])
[utils/util.py::ComputeLoss.assign] top_k_metrics shape: torch.Size([4, 2, 10])
[utils/util.py::ComputeLoss.assign] top_k_indices shape: torch.Size([4, 2, 10])
[utils/util.py::ComputeLoss.assign] is_in_top_k shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] mask_top_k shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] mask_pos shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] fg_mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] fg_mask sum: 22.0
[utils/util.py::ComputeLoss.assign] target_gt_idx shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_labels shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] Normalized target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] target_scores sum: 0.07393558323383331
--- [utils/util.py::ComputeLoss.assign] END PYTORCH ASSIGNMENT DEBUG ---

[utils/util.py::ComputeLoss.__call__] Target bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Target scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] FG mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.__call__] Target scores sum: 0.073936
[utils/util.py::ComputeLoss.__call__] Classification loss computed: 9.087302
[utils/util.py::ComputeLoss.__call__] Foreground count: 22
[utils/util.py::ComputeLoss.__call__] Weight shape: torch.Size([22, 1])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([22, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([22, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([22, 1]), h: torch.Size([22, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([22, 1]), h: torch.Size([22, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([22, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([22, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([22, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.029940, max: 0.057877
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([22, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([22, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([22, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([22, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: 0.006530, max: 0.055600
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.__call__] IoU values shape: torch.Size([22, 1])
[utils/util.py::ComputeLoss.__call__] Box loss computed: 0.949313
[utils/util.py::ComputeLoss.__call__] Target LT-RB shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.df_loss] PYTORCH DFL LOSS DEBUG ---
[utils/util.py::ComputeLoss.df_loss] pred_dist shape: torch.Size([88, 16])
[utils/util.py::ComputeLoss.df_loss] target shape: torch.Size([22, 4])
[utils/util.py::ComputeLoss.df_loss] DFL loss shape: torch.Size([22, 1])
[utils/util.py::ComputeLoss.df_loss] DFL loss mean: 2.647175
--- [utils/util.py::ComputeLoss.df_loss] END PYTORCH DFL LOSS DEBUG ---

[utils/util.py::ComputeLoss.__call__] DFL loss before weighting: 2.647175
[utils/util.py::ComputeLoss.__call__] DFL loss computed: 2.799654

--- [utils/util.py::ComputeLoss.__call__] LOSS COMPONENTS DEBUG ---
[utils/util.py::ComputeLoss.__call__] Raw loss_cls: 9.087302
[utils/util.py::ComputeLoss.__call__] Raw loss_box: 0.949313
[utils/util.py::ComputeLoss.__call__] Raw loss_dfl: 2.799654
[utils/util.py::ComputeLoss.__call__] Loss weights - cls: 0.5, box: 7.5, dfl: 1.5
[utils/util.py::ComputeLoss.__call__] target_scores_sum: 0.073936
[utils/util.py::ComputeLoss.__call__] fg_mask sum: 22
[utils/util.py::ComputeLoss.__call__] Weighted loss_cls: 4.543651
[utils/util.py::ComputeLoss.__call__] Weighted loss_box: 7.119847
[utils/util.py::ComputeLoss.__call__] Weighted loss_dfl: 4.199481
[utils/util.py::ComputeLoss.__call__] Total loss: 15.862978
--- [utils/util.py::ComputeLoss.__call__] END PYTORCH LOSS COMPUTATION DEBUG ---


--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([4, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: True
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([4, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - box shape: torch.Size([4, 64, 16, 32]), cls shape: torch.Size([4, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - final concat shape: torch.Size([4, 65, 16, 32])

--- [utils/util.py::ComputeLoss.__call__] PYTORCH LOSS COMPUTATION DEBUG ---
[utils/util.py::ComputeLoss.__call__] Outputs type: <class 'list'>
[utils/util.py::ComputeLoss.__call__] x type: <class 'list'>, len: 1
[utils/util.py::ComputeLoss.__call__] x[0] shape: torch.Size([4, 65, 16, 32])
[utils/util.py::ComputeLoss.__call__] Concatenated output shape: torch.Size([4, 65, 512])
[utils/util.py::ComputeLoss.__call__] self.no: 65, self.dfl_ch: 16, self.nc: 1
[utils/util.py::ComputeLoss.__call__] pred_output shape: torch.Size([4, 64, 512])
[utils/util.py::ComputeLoss.__call__] pred_scores shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.__call__] After permute - pred_output shape: torch.Size([4, 512, 64])
[utils/util.py::ComputeLoss.__call__] After permute - pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Size tensor: tensor([128., 256.], device='cuda:0', dtype=torch.float16)
[utils/util.py::ComputeLoss.__call__] Stride: tensor([8.])
[utils/util.py::ComputeLoss.__call__] Anchor points shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.__call__] Stride tensor shape: torch.Size([512, 1])

--- [utils/util.py::ComputeLoss.__call__] TARGET PROCESSING ---
[utils/util.py::ComputeLoss.__call__] Targets shape: torch.Size([6, 6])
[utils/util.py::ComputeLoss.__call__] Targets dtype: torch.float32
[utils/util.py::ComputeLoss.__call__] First few targets: tensor([[1.0000, 0.0000, 0.2827, 0.0415, 0.0666, 0.0831],
        [1.0000, 0.0000, 0.4787, 0.0592, 0.0596, 0.1085],
        [1.0000, 0.0000, 0.1192, 0.6735, 0.0578, 0.1163],
        [1.0000, 0.0000, 0.4825, 0.4777, 0.0576, 0.1110],
        [2.0000, 0.0000, 0.6632, 0.4620, 0.0684, 0.1267]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Image indices: tensor([1., 1., 1., 1., 2., 3.], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Counts per image: tensor([4, 1, 1], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT tensor shape: torch.Size([4, 4, 5])
[utils/util.py::ComputeLoss.__call__] Image 1: 4 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 2: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 3: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] GT before coordinate conversion: tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.2827, 0.0415, 0.0666, 0.0831],
         [0.0000, 0.4787, 0.0592, 0.0596, 0.1085],
         [0.0000, 0.1192, 0.6735, 0.0578, 0.1163],
         [0.0000, 0.4825, 0.4777, 0.0576, 0.1110]],

        [[0.0000, 0.6632, 0.4620, 0.0684, 0.1267],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.8950, 0.4974, 0.0870, 0.1723],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT after coordinate conversion: tensor([[[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000,  63.8583,   0.0000,  80.9057,  10.6322],
         [  0.0000, 114.9175,   0.6337, 130.1644,  14.5270],
         [  0.0000,  23.1298,  78.7643,  37.9169,  93.6536],
         [  0.0000, 116.1466,  54.0424, 130.8890,  68.2550]],

        [[  0.0000, 161.0202,  51.0315, 178.5223,  67.2454],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000, 217.9996,  52.6377, 240.2603,  74.6898],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT labels shape: torch.Size([4, 4, 1])
[utils/util.py::ComputeLoss.__call__] GT bboxes shape: torch.Size([4, 4, 4])
[utils/util.py::ComputeLoss.__call__] GT mask shape: torch.Size([4, 4, 1])
[utils/util.py::ComputeLoss.__call__] Pred output dimensions - b: 4, a: 512, c: 64
[utils/util.py::ComputeLoss.__call__] Pred bboxes after softmax shape: torch.Size([4, 512, 4, 16])
[utils/util.py::ComputeLoss.__call__] Pred bboxes after matmul shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Final pred bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.__call__] ASSIGNMENT PHASE ---

--- [utils/util.py::ComputeLoss.assign] PYTORCH ASSIGNMENT DEBUG ---
[utils/util.py::ComputeLoss.assign] pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] true_labels shape: torch.Size([4, 4, 1])
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 4, 4])
[utils/util.py::ComputeLoss.assign] true_mask shape: torch.Size([4, 4, 1])
[utils/util.py::ComputeLoss.assign] anchors shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.assign] Batch size: 4, Max boxes: 4
[utils/util.py::ComputeLoss.assign] Created indices tensor with shape: torch.Size([2, 4, 4])

--- [utils/util.py::ComputeLoss.assign] IOUs DEBUG ---
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 4, 4])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([4, 4, 1, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([4, 1, 512, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([4, 4, 1, 1]), h: torch.Size([4, 4, 1, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([4, 1, 512, 1]), h: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([4, 4, 512, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([4, 4, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([4, 4, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.000000, max: 0.055943
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([4, 4, 512, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([4, 4, 512, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([4, 4, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([4, 4, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: -0.751135, max: 0.052956
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.assign] overlaps shape: torch.Size([4, 4, 512])
[utils/util.py::ComputeLoss.assign] overlaps min: 0.0, max: 0.05295620858669281
[utils/util.py::ComputeLoss.assign] align_metric shape: torch.Size([4, 4, 512])
[utils/util.py::ComputeLoss.assign] align_metric min: 0.0, max: 2.8537586183041697e-10
[utils/util.py::ComputeLoss.assign] mask_in_gts shape: torch.Size([4, 4, 512])
[utils/util.py::ComputeLoss.assign] mask_in_gts sum: 22.0
[utils/util.py::ComputeLoss.assign] metrics shape: torch.Size([4, 4, 512])
[utils/util.py::ComputeLoss.assign] top_k_mask shape: torch.Size([4, 4, 10])
[utils/util.py::ComputeLoss.assign] top_k_metrics shape: torch.Size([4, 4, 10])
[utils/util.py::ComputeLoss.assign] top_k_indices shape: torch.Size([4, 4, 10])
[utils/util.py::ComputeLoss.assign] is_in_top_k shape: torch.Size([4, 4, 512])
[utils/util.py::ComputeLoss.assign] mask_top_k shape: torch.Size([4, 4, 512])
[utils/util.py::ComputeLoss.assign] mask_pos shape: torch.Size([4, 4, 512])
[utils/util.py::ComputeLoss.assign] fg_mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] fg_mask sum: 22.0
[utils/util.py::ComputeLoss.assign] target_gt_idx shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_labels shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] Normalized target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] target_scores sum: 0.022976674139499664
--- [utils/util.py::ComputeLoss.assign] END PYTORCH ASSIGNMENT DEBUG ---

[utils/util.py::ComputeLoss.__call__] Target bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Target scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] FG mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.__call__] Target scores sum: 0.022977
[utils/util.py::ComputeLoss.__call__] Classification loss computed: 9.180506
[utils/util.py::ComputeLoss.__call__] Foreground count: 22
[utils/util.py::ComputeLoss.__call__] Weight shape: torch.Size([22, 1])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([22, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([22, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([22, 1]), h: torch.Size([22, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([22, 1]), h: torch.Size([22, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([22, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([22, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([22, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.018118, max: 0.055987
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([22, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([22, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([22, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([22, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: 0.012291, max: 0.053000
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.__call__] IoU values shape: torch.Size([22, 1])
[utils/util.py::ComputeLoss.__call__] Box loss computed: 0.951010
[utils/util.py::ComputeLoss.__call__] Target LT-RB shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.df_loss] PYTORCH DFL LOSS DEBUG ---
[utils/util.py::ComputeLoss.df_loss] pred_dist shape: torch.Size([88, 16])
[utils/util.py::ComputeLoss.df_loss] target shape: torch.Size([22, 4])
[utils/util.py::ComputeLoss.df_loss] DFL loss shape: torch.Size([22, 1])
[utils/util.py::ComputeLoss.df_loss] DFL loss mean: 2.537133
--- [utils/util.py::ComputeLoss.df_loss] END PYTORCH DFL LOSS DEBUG ---

[utils/util.py::ComputeLoss.__call__] DFL loss before weighting: 2.537133
[utils/util.py::ComputeLoss.__call__] DFL loss computed: 2.923639

--- [utils/util.py::ComputeLoss.__call__] LOSS COMPONENTS DEBUG ---
[utils/util.py::ComputeLoss.__call__] Raw loss_cls: 9.180506
[utils/util.py::ComputeLoss.__call__] Raw loss_box: 0.951010
[utils/util.py::ComputeLoss.__call__] Raw loss_dfl: 2.923639
[utils/util.py::ComputeLoss.__call__] Loss weights - cls: 0.5, box: 7.5, dfl: 1.5
[utils/util.py::ComputeLoss.__call__] target_scores_sum: 0.022977
[utils/util.py::ComputeLoss.__call__] fg_mask sum: 22
[utils/util.py::ComputeLoss.__call__] Weighted loss_cls: 4.590253
[utils/util.py::ComputeLoss.__call__] Weighted loss_box: 7.132573
[utils/util.py::ComputeLoss.__call__] Weighted loss_dfl: 4.385459
[utils/util.py::ComputeLoss.__call__] Total loss: 16.108284
--- [utils/util.py::ComputeLoss.__call__] END PYTORCH LOSS COMPUTATION DEBUG ---


--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([4, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: True
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([4, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - box shape: torch.Size([4, 64, 16, 32]), cls shape: torch.Size([4, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - final concat shape: torch.Size([4, 65, 16, 32])

--- [utils/util.py::ComputeLoss.__call__] PYTORCH LOSS COMPUTATION DEBUG ---
[utils/util.py::ComputeLoss.__call__] Outputs type: <class 'list'>
[utils/util.py::ComputeLoss.__call__] x type: <class 'list'>, len: 1
[utils/util.py::ComputeLoss.__call__] x[0] shape: torch.Size([4, 65, 16, 32])
[utils/util.py::ComputeLoss.__call__] Concatenated output shape: torch.Size([4, 65, 512])
[utils/util.py::ComputeLoss.__call__] self.no: 65, self.dfl_ch: 16, self.nc: 1
[utils/util.py::ComputeLoss.__call__] pred_output shape: torch.Size([4, 64, 512])
[utils/util.py::ComputeLoss.__call__] pred_scores shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.__call__] After permute - pred_output shape: torch.Size([4, 512, 64])
[utils/util.py::ComputeLoss.__call__] After permute - pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Size tensor: tensor([128., 256.], device='cuda:0', dtype=torch.float16)
[utils/util.py::ComputeLoss.__call__] Stride: tensor([8.])
[utils/util.py::ComputeLoss.__call__] Anchor points shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.__call__] Stride tensor shape: torch.Size([512, 1])

--- [utils/util.py::ComputeLoss.__call__] TARGET PROCESSING ---
[utils/util.py::ComputeLoss.__call__] Targets shape: torch.Size([3, 6])
[utils/util.py::ComputeLoss.__call__] Targets dtype: torch.float32
[utils/util.py::ComputeLoss.__call__] First few targets: tensor([[2.0000, 0.0000, 0.1734, 0.7080, 0.0717, 0.1477],
        [3.0000, 0.0000, 0.8361, 0.3327, 0.1088, 0.2016],
        [3.0000, 0.0000, 0.2265, 0.1435, 0.1050, 0.2118]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Image indices: tensor([2., 3., 3.], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Counts per image: tensor([1, 2], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT tensor shape: torch.Size([4, 2, 5])
[utils/util.py::ComputeLoss.__call__] Image 2: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 3: 2 targets assigned
[utils/util.py::ComputeLoss.__call__] GT before coordinate conversion: tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.1734, 0.7080, 0.0717, 0.1477],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.8361, 0.3327, 0.1088, 0.2016],
         [0.0000, 0.2265, 0.1435, 0.1050, 0.2118]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT after coordinate conversion: tensor([[[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000,  35.2293,  81.1671,  53.5747, 100.0723],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000, 200.1122,  29.6785, 227.9740,  55.4896],
         [  0.0000,  44.5386,   4.8103,  71.4103,  31.9178]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT labels shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.__call__] GT bboxes shape: torch.Size([4, 2, 4])
[utils/util.py::ComputeLoss.__call__] GT mask shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.__call__] Pred output dimensions - b: 4, a: 512, c: 64
[utils/util.py::ComputeLoss.__call__] Pred bboxes after softmax shape: torch.Size([4, 512, 4, 16])
[utils/util.py::ComputeLoss.__call__] Pred bboxes after matmul shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Final pred bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.__call__] ASSIGNMENT PHASE ---

--- [utils/util.py::ComputeLoss.assign] PYTORCH ASSIGNMENT DEBUG ---
[utils/util.py::ComputeLoss.assign] pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] true_labels shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 2, 4])
[utils/util.py::ComputeLoss.assign] true_mask shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.assign] anchors shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.assign] Batch size: 4, Max boxes: 2
[utils/util.py::ComputeLoss.assign] Created indices tensor with shape: torch.Size([2, 4, 2])

--- [utils/util.py::ComputeLoss.assign] IOUs DEBUG ---
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 2, 4])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([4, 2, 1, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([4, 1, 512, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([4, 2, 1, 1]), h: torch.Size([4, 2, 1, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([4, 1, 512, 1]), h: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.000000, max: 0.093158
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: -0.716412, max: 0.081514
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.assign] overlaps shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] overlaps min: 0.0, max: 0.08151355385780334
[utils/util.py::ComputeLoss.assign] align_metric shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] align_metric min: 0.0, max: 2.3924713321576974e-09
[utils/util.py::ComputeLoss.assign] mask_in_gts shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] mask_in_gts sum: 27.0
[utils/util.py::ComputeLoss.assign] metrics shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] top_k_mask shape: torch.Size([4, 2, 10])
[utils/util.py::ComputeLoss.assign] top_k_metrics shape: torch.Size([4, 2, 10])
[utils/util.py::ComputeLoss.assign] top_k_indices shape: torch.Size([4, 2, 10])
[utils/util.py::ComputeLoss.assign] is_in_top_k shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] mask_top_k shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] mask_pos shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] fg_mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] fg_mask sum: 27.0
[utils/util.py::ComputeLoss.assign] target_gt_idx shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_labels shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] Normalized target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] target_scores sum: 0.3210139572620392
--- [utils/util.py::ComputeLoss.assign] END PYTORCH ASSIGNMENT DEBUG ---

[utils/util.py::ComputeLoss.__call__] Target bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Target scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] FG mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.__call__] Target scores sum: 0.321014
[utils/util.py::ComputeLoss.__call__] Classification loss computed: 9.832127
[utils/util.py::ComputeLoss.__call__] Foreground count: 27
[utils/util.py::ComputeLoss.__call__] Weight shape: torch.Size([27, 1])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([27, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([27, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([27, 1]), h: torch.Size([27, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([27, 1]), h: torch.Size([27, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([27, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([27, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([27, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.028447, max: 0.082851
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([27, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([27, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([27, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([27, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: 0.024452, max: 0.081567
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.__call__] IoU values shape: torch.Size([27, 1])
[utils/util.py::ComputeLoss.__call__] Box loss computed: 0.930708
[utils/util.py::ComputeLoss.__call__] Target LT-RB shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.df_loss] PYTORCH DFL LOSS DEBUG ---
[utils/util.py::ComputeLoss.df_loss] pred_dist shape: torch.Size([108, 16])
[utils/util.py::ComputeLoss.df_loss] target shape: torch.Size([27, 4])
[utils/util.py::ComputeLoss.df_loss] DFL loss shape: torch.Size([27, 1])
[utils/util.py::ComputeLoss.df_loss] DFL loss mean: 2.455517
--- [utils/util.py::ComputeLoss.df_loss] END PYTORCH DFL LOSS DEBUG ---

[utils/util.py::ComputeLoss.__call__] DFL loss before weighting: 2.455517
[utils/util.py::ComputeLoss.__call__] DFL loss computed: 2.497149

--- [utils/util.py::ComputeLoss.__call__] LOSS COMPONENTS DEBUG ---
[utils/util.py::ComputeLoss.__call__] Raw loss_cls: 9.832127
[utils/util.py::ComputeLoss.__call__] Raw loss_box: 0.930708
[utils/util.py::ComputeLoss.__call__] Raw loss_dfl: 2.497149
[utils/util.py::ComputeLoss.__call__] Loss weights - cls: 0.5, box: 7.5, dfl: 1.5
[utils/util.py::ComputeLoss.__call__] target_scores_sum: 0.321014
[utils/util.py::ComputeLoss.__call__] fg_mask sum: 27
[utils/util.py::ComputeLoss.__call__] Weighted loss_cls: 4.916063
[utils/util.py::ComputeLoss.__call__] Weighted loss_box: 6.980312
[utils/util.py::ComputeLoss.__call__] Weighted loss_dfl: 3.745723
[utils/util.py::ComputeLoss.__call__] Total loss: 15.642099
--- [utils/util.py::ComputeLoss.__call__] END PYTORCH LOSS COMPUTATION DEBUG ---


--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([4, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: True
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([4, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - box shape: torch.Size([4, 64, 16, 32]), cls shape: torch.Size([4, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - final concat shape: torch.Size([4, 65, 16, 32])

--- [utils/util.py::ComputeLoss.__call__] PYTORCH LOSS COMPUTATION DEBUG ---
[utils/util.py::ComputeLoss.__call__] Outputs type: <class 'list'>
[utils/util.py::ComputeLoss.__call__] x type: <class 'list'>, len: 1
[utils/util.py::ComputeLoss.__call__] x[0] shape: torch.Size([4, 65, 16, 32])
[utils/util.py::ComputeLoss.__call__] Concatenated output shape: torch.Size([4, 65, 512])
[utils/util.py::ComputeLoss.__call__] self.no: 65, self.dfl_ch: 16, self.nc: 1
[utils/util.py::ComputeLoss.__call__] pred_output shape: torch.Size([4, 64, 512])
[utils/util.py::ComputeLoss.__call__] pred_scores shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.__call__] After permute - pred_output shape: torch.Size([4, 512, 64])
[utils/util.py::ComputeLoss.__call__] After permute - pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Size tensor: tensor([128., 256.], device='cuda:0', dtype=torch.float16)
[utils/util.py::ComputeLoss.__call__] Stride: tensor([8.])
[utils/util.py::ComputeLoss.__call__] Anchor points shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.__call__] Stride tensor shape: torch.Size([512, 1])

--- [utils/util.py::ComputeLoss.__call__] TARGET PROCESSING ---
[utils/util.py::ComputeLoss.__call__] Targets shape: torch.Size([6, 6])
[utils/util.py::ComputeLoss.__call__] Targets dtype: torch.float32
[utils/util.py::ComputeLoss.__call__] First few targets: tensor([[0.0000, 0.0000, 0.0154, 0.6220, 0.0308, 0.3143],
        [0.0000, 0.0000, 0.7260, 0.7468, 0.1310, 0.2948],
        [1.0000, 0.0000, 0.1125, 0.9207, 0.1146, 0.1586],
        [2.0000, 0.0000, 0.7707, 0.5208, 0.0840, 0.1489],
        [3.0000, 0.0000, 0.9798, 0.8163, 0.0404, 0.1911]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Image indices: tensor([0., 0., 1., 2., 3., 3.], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Counts per image: tensor([2, 1, 1, 2], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT tensor shape: torch.Size([4, 2, 5])
[utils/util.py::ComputeLoss.__call__] Image 0: 2 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 1: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 2: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 3: 2 targets assigned
[utils/util.py::ComputeLoss.__call__] GT before coordinate conversion: tensor([[[0.0000, 0.0154, 0.6220, 0.0308, 0.3143],
         [0.0000, 0.7260, 0.7468, 0.1310, 0.2948]],

        [[0.0000, 0.1125, 0.9207, 0.1146, 0.1586],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.7707, 0.5208, 0.0840, 0.1489],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.9798, 0.8163, 0.0404, 0.1911],
         [0.0000, 0.2770, 0.8478, 0.0956, 0.2136]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT after coordinate conversion: tensor([[[  0.0000,   0.0000,  59.5070,   7.8910,  99.7326],
         [  0.0000, 169.1014,  76.7219, 202.6275, 114.4513]],

        [[  0.0000,  14.1322, 107.6982,  43.4734, 127.9990],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000, 186.5536,  57.1340, 208.0697,  76.1913],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000, 245.6484,  92.2591, 256.0000, 116.7194],
         [  0.0000,  58.6701,  94.8451,  83.1413, 122.1811]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT labels shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.__call__] GT bboxes shape: torch.Size([4, 2, 4])
[utils/util.py::ComputeLoss.__call__] GT mask shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.__call__] Pred output dimensions - b: 4, a: 512, c: 64
[utils/util.py::ComputeLoss.__call__] Pred bboxes after softmax shape: torch.Size([4, 512, 4, 16])
[utils/util.py::ComputeLoss.__call__] Pred bboxes after matmul shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Final pred bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.__call__] ASSIGNMENT PHASE ---

--- [utils/util.py::ComputeLoss.assign] PYTORCH ASSIGNMENT DEBUG ---
[utils/util.py::ComputeLoss.assign] pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] true_labels shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 2, 4])
[utils/util.py::ComputeLoss.assign] true_mask shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.assign] anchors shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.assign] Batch size: 4, Max boxes: 2
[utils/util.py::ComputeLoss.assign] Created indices tensor with shape: torch.Size([2, 4, 2])

--- [utils/util.py::ComputeLoss.assign] IOUs DEBUG ---
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 2, 4])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([4, 2, 1, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([4, 1, 512, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([4, 2, 1, 1]), h: torch.Size([4, 2, 1, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([4, 1, 512, 1]), h: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.000000, max: 0.136771
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: -0.753852, max: 0.120151
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.assign] overlaps shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] overlaps min: 0.0, max: 0.12015114724636078
[utils/util.py::ComputeLoss.assign] align_metric shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] align_metric min: 0.0, max: 2.174887647754531e-08
[utils/util.py::ComputeLoss.assign] mask_in_gts shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] mask_in_gts sum: 51.0
[utils/util.py::ComputeLoss.assign] metrics shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] top_k_mask shape: torch.Size([4, 2, 10])
[utils/util.py::ComputeLoss.assign] top_k_metrics shape: torch.Size([4, 2, 10])
[utils/util.py::ComputeLoss.assign] top_k_indices shape: torch.Size([4, 2, 10])
[utils/util.py::ComputeLoss.assign] is_in_top_k shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] mask_top_k shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] mask_pos shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] fg_mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] fg_mask sum: 44.0
[utils/util.py::ComputeLoss.assign] target_gt_idx shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_labels shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] Normalized target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] target_scores sum: 0.8539028763771057
--- [utils/util.py::ComputeLoss.assign] END PYTORCH ASSIGNMENT DEBUG ---

[utils/util.py::ComputeLoss.__call__] Target bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Target scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] FG mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.__call__] Target scores sum: 0.853903
[utils/util.py::ComputeLoss.__call__] Classification loss computed: 10.219620
[utils/util.py::ComputeLoss.__call__] Foreground count: 44
[utils/util.py::ComputeLoss.__call__] Weight shape: torch.Size([44, 1])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([44, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([44, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([44, 1]), h: torch.Size([44, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([44, 1]), h: torch.Size([44, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([44, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([44, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([44, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.022952, max: 0.125388
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([44, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([44, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([44, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([44, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: 0.002242, max: 0.120167
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.__call__] IoU values shape: torch.Size([44, 1])
[utils/util.py::ComputeLoss.__call__] Box loss computed: 0.893268
[utils/util.py::ComputeLoss.__call__] Target LT-RB shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.df_loss] PYTORCH DFL LOSS DEBUG ---
[utils/util.py::ComputeLoss.df_loss] pred_dist shape: torch.Size([176, 16])
[utils/util.py::ComputeLoss.df_loss] target shape: torch.Size([44, 4])
[utils/util.py::ComputeLoss.df_loss] DFL loss shape: torch.Size([44, 1])
[utils/util.py::ComputeLoss.df_loss] DFL loss mean: 2.381786
--- [utils/util.py::ComputeLoss.df_loss] END PYTORCH DFL LOSS DEBUG ---

[utils/util.py::ComputeLoss.__call__] DFL loss before weighting: 2.381786
[utils/util.py::ComputeLoss.__call__] DFL loss computed: 2.384322

--- [utils/util.py::ComputeLoss.__call__] LOSS COMPONENTS DEBUG ---
[utils/util.py::ComputeLoss.__call__] Raw loss_cls: 10.219620
[utils/util.py::ComputeLoss.__call__] Raw loss_box: 0.893268
[utils/util.py::ComputeLoss.__call__] Raw loss_dfl: 2.384322
[utils/util.py::ComputeLoss.__call__] Loss weights - cls: 0.5, box: 7.5, dfl: 1.5
[utils/util.py::ComputeLoss.__call__] target_scores_sum: 0.853903
[utils/util.py::ComputeLoss.__call__] fg_mask sum: 44
[utils/util.py::ComputeLoss.__call__] Weighted loss_cls: 5.109810
[utils/util.py::ComputeLoss.__call__] Weighted loss_box: 6.699513
[utils/util.py::ComputeLoss.__call__] Weighted loss_dfl: 3.576483
[utils/util.py::ComputeLoss.__call__] Total loss: 15.385806
--- [utils/util.py::ComputeLoss.__call__] END PYTORCH LOSS COMPUTATION DEBUG ---


--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([4, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: True
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([4, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - box shape: torch.Size([4, 64, 16, 32]), cls shape: torch.Size([4, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - final concat shape: torch.Size([4, 65, 16, 32])

--- [utils/util.py::ComputeLoss.__call__] PYTORCH LOSS COMPUTATION DEBUG ---
[utils/util.py::ComputeLoss.__call__] Outputs type: <class 'list'>
[utils/util.py::ComputeLoss.__call__] x type: <class 'list'>, len: 1
[utils/util.py::ComputeLoss.__call__] x[0] shape: torch.Size([4, 65, 16, 32])
[utils/util.py::ComputeLoss.__call__] Concatenated output shape: torch.Size([4, 65, 512])
[utils/util.py::ComputeLoss.__call__] self.no: 65, self.dfl_ch: 16, self.nc: 1
[utils/util.py::ComputeLoss.__call__] pred_output shape: torch.Size([4, 64, 512])
[utils/util.py::ComputeLoss.__call__] pred_scores shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.__call__] After permute - pred_output shape: torch.Size([4, 512, 64])
[utils/util.py::ComputeLoss.__call__] After permute - pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Size tensor: tensor([128., 256.], device='cuda:0', dtype=torch.float16)
[utils/util.py::ComputeLoss.__call__] Stride: tensor([8.])
[utils/util.py::ComputeLoss.__call__] Anchor points shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.__call__] Stride tensor shape: torch.Size([512, 1])

--- [utils/util.py::ComputeLoss.__call__] TARGET PROCESSING ---
[utils/util.py::ComputeLoss.__call__] Targets shape: torch.Size([5, 6])
[utils/util.py::ComputeLoss.__call__] Targets dtype: torch.float32
[utils/util.py::ComputeLoss.__call__] First few targets: tensor([[0.0000, 0.0000, 0.6592, 0.4552, 0.1556, 0.3016],
        [1.0000, 0.0000, 0.4644, 0.2099, 0.0679, 0.1359],
        [1.0000, 0.0000, 0.7309, 0.2424, 0.0676, 0.1418],
        [3.0000, 0.0000, 0.8627, 0.6746, 0.1400, 0.2866],
        [3.0000, 0.0000, 0.2913, 0.4723, 0.1241, 0.2378]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Image indices: tensor([0., 1., 1., 3., 3.], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Counts per image: tensor([1, 2, 2], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT tensor shape: torch.Size([4, 2, 5])
[utils/util.py::ComputeLoss.__call__] Image 0: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 1: 2 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 3: 2 targets assigned
[utils/util.py::ComputeLoss.__call__] GT before coordinate conversion: tensor([[[0.0000, 0.6592, 0.4552, 0.1556, 0.3016],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.4644, 0.2099, 0.0679, 0.1359],
         [0.0000, 0.7309, 0.2424, 0.0676, 0.1418]],

        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.8627, 0.6746, 0.1400, 0.2866],
         [0.0000, 0.2913, 0.4723, 0.1241, 0.2378]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT after coordinate conversion: tensor([[[  0.0000, 148.8468,  38.9660, 188.6742,  77.5752],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000, 110.1966,  18.1752, 127.5877,  35.5663],
         [  0.0000, 178.4567,  21.9558, 195.7495,  40.1031]],

        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000, 202.9431,  68.0037, 238.7814, 104.6889],
         [  0.0000,  58.6903,  45.2408,  90.4524,  75.6795]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT labels shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.__call__] GT bboxes shape: torch.Size([4, 2, 4])
[utils/util.py::ComputeLoss.__call__] GT mask shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.__call__] Pred output dimensions - b: 4, a: 512, c: 64
[utils/util.py::ComputeLoss.__call__] Pred bboxes after softmax shape: torch.Size([4, 512, 4, 16])
[utils/util.py::ComputeLoss.__call__] Pred bboxes after matmul shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Final pred bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.__call__] ASSIGNMENT PHASE ---

--- [utils/util.py::ComputeLoss.assign] PYTORCH ASSIGNMENT DEBUG ---
[utils/util.py::ComputeLoss.assign] pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] true_labels shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 2, 4])
[utils/util.py::ComputeLoss.assign] true_mask shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.assign] anchors shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.assign] Batch size: 4, Max boxes: 2
[utils/util.py::ComputeLoss.assign] Created indices tensor with shape: torch.Size([2, 4, 2])

--- [utils/util.py::ComputeLoss.assign] IOUs DEBUG ---
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 2, 4])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([4, 2, 1, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([4, 1, 512, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([4, 2, 1, 1]), h: torch.Size([4, 2, 1, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([4, 1, 512, 1]), h: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.000000, max: 0.163169
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: -0.707123, max: 0.150680
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.assign] overlaps shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] overlaps min: 0.0, max: 0.15068021416664124
[utils/util.py::ComputeLoss.assign] align_metric shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] align_metric min: 0.0, max: 8.079916113956642e-08
[utils/util.py::ComputeLoss.assign] mask_in_gts shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] mask_in_gts sum: 65.0
[utils/util.py::ComputeLoss.assign] metrics shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] top_k_mask shape: torch.Size([4, 2, 10])
[utils/util.py::ComputeLoss.assign] top_k_metrics shape: torch.Size([4, 2, 10])
[utils/util.py::ComputeLoss.assign] top_k_indices shape: torch.Size([4, 2, 10])
[utils/util.py::ComputeLoss.assign] is_in_top_k shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] mask_top_k shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] mask_pos shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] fg_mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] fg_mask sum: 38.0
[utils/util.py::ComputeLoss.assign] target_gt_idx shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_labels shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] Normalized target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] target_scores sum: 2.504373073577881
--- [utils/util.py::ComputeLoss.assign] END PYTORCH ASSIGNMENT DEBUG ---

[utils/util.py::ComputeLoss.__call__] Target bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Target scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] FG mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.__call__] Target scores sum: 2.504373
[utils/util.py::ComputeLoss.__call__] Classification loss computed: 10.431752
[utils/util.py::ComputeLoss.__call__] Foreground count: 38
[utils/util.py::ComputeLoss.__call__] Weight shape: torch.Size([38, 1])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([38, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([38, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([38, 1]), h: torch.Size([38, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([38, 1]), h: torch.Size([38, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([38, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([38, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([38, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.028619, max: 0.156525
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([38, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([38, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([38, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([38, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: 0.017284, max: 0.150764
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.__call__] IoU values shape: torch.Size([38, 1])
[utils/util.py::ComputeLoss.__call__] Box loss computed: 0.870929
[utils/util.py::ComputeLoss.__call__] Target LT-RB shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.df_loss] PYTORCH DFL LOSS DEBUG ---
[utils/util.py::ComputeLoss.df_loss] pred_dist shape: torch.Size([152, 16])
[utils/util.py::ComputeLoss.df_loss] target shape: torch.Size([38, 4])
[utils/util.py::ComputeLoss.df_loss] DFL loss shape: torch.Size([38, 1])
[utils/util.py::ComputeLoss.df_loss] DFL loss mean: 2.335044
--- [utils/util.py::ComputeLoss.df_loss] END PYTORCH DFL LOSS DEBUG ---

[utils/util.py::ComputeLoss.__call__] DFL loss before weighting: 2.335044
[utils/util.py::ComputeLoss.__call__] DFL loss computed: 2.343360

--- [utils/util.py::ComputeLoss.__call__] LOSS COMPONENTS DEBUG ---
[utils/util.py::ComputeLoss.__call__] Raw loss_cls: 10.431752
[utils/util.py::ComputeLoss.__call__] Raw loss_box: 0.870929
[utils/util.py::ComputeLoss.__call__] Raw loss_dfl: 2.343360
[utils/util.py::ComputeLoss.__call__] Loss weights - cls: 0.5, box: 7.5, dfl: 1.5
[utils/util.py::ComputeLoss.__call__] target_scores_sum: 2.504373
[utils/util.py::ComputeLoss.__call__] fg_mask sum: 38
[utils/util.py::ComputeLoss.__call__] Weighted loss_cls: 5.215876
[utils/util.py::ComputeLoss.__call__] Weighted loss_box: 6.531965
[utils/util.py::ComputeLoss.__call__] Weighted loss_dfl: 3.515041
[utils/util.py::ComputeLoss.__call__] Total loss: 15.262881
--- [utils/util.py::ComputeLoss.__call__] END PYTORCH LOSS COMPUTATION DEBUG ---


--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([4, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: True
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([4, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - box shape: torch.Size([4, 64, 16, 32]), cls shape: torch.Size([4, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - final concat shape: torch.Size([4, 65, 16, 32])

--- [utils/util.py::ComputeLoss.__call__] PYTORCH LOSS COMPUTATION DEBUG ---
[utils/util.py::ComputeLoss.__call__] Outputs type: <class 'list'>
[utils/util.py::ComputeLoss.__call__] x type: <class 'list'>, len: 1
[utils/util.py::ComputeLoss.__call__] x[0] shape: torch.Size([4, 65, 16, 32])
[utils/util.py::ComputeLoss.__call__] Concatenated output shape: torch.Size([4, 65, 512])
[utils/util.py::ComputeLoss.__call__] self.no: 65, self.dfl_ch: 16, self.nc: 1
[utils/util.py::ComputeLoss.__call__] pred_output shape: torch.Size([4, 64, 512])
[utils/util.py::ComputeLoss.__call__] pred_scores shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.__call__] After permute - pred_output shape: torch.Size([4, 512, 64])
[utils/util.py::ComputeLoss.__call__] After permute - pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Size tensor: tensor([128., 256.], device='cuda:0', dtype=torch.float16)
[utils/util.py::ComputeLoss.__call__] Stride: tensor([8.])
[utils/util.py::ComputeLoss.__call__] Anchor points shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.__call__] Stride tensor shape: torch.Size([512, 1])

--- [utils/util.py::ComputeLoss.__call__] TARGET PROCESSING ---
[utils/util.py::ComputeLoss.__call__] Targets shape: torch.Size([3, 6])
[utils/util.py::ComputeLoss.__call__] Targets dtype: torch.float32
[utils/util.py::ComputeLoss.__call__] First few targets: tensor([[1.0000, 0.0000, 0.7103, 0.5190, 0.0875, 0.1816],
        [2.0000, 0.0000, 0.4218, 0.5261, 0.0792, 0.1679],
        [3.0000, 0.0000, 0.0261, 0.3823, 0.0522, 0.1954]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Image indices: tensor([1., 2., 3.], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Counts per image: tensor([1, 1, 1], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT tensor shape: torch.Size([4, 1, 5])
[utils/util.py::ComputeLoss.__call__] Image 1: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 2: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 3: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] GT before coordinate conversion: tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.7103, 0.5190, 0.0875, 0.1816]],

        [[0.0000, 0.4218, 0.5261, 0.0792, 0.1679]],

        [[0.0000, 0.0261, 0.3823, 0.0522, 0.1954]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT after coordinate conversion: tensor([[[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],

        [[0.0000e+00, 1.7065e+02, 5.4807e+01, 1.9305e+02, 7.8047e+01]],

        [[0.0000e+00, 9.7840e+01, 5.6593e+01, 1.1810e+02, 7.8078e+01]],

        [[0.0000e+00, 9.9945e-04, 3.6426e+01, 1.3356e+01, 6.1441e+01]]],
       device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT labels shape: torch.Size([4, 1, 1])
[utils/util.py::ComputeLoss.__call__] GT bboxes shape: torch.Size([4, 1, 4])
[utils/util.py::ComputeLoss.__call__] GT mask shape: torch.Size([4, 1, 1])
[utils/util.py::ComputeLoss.__call__] Pred output dimensions - b: 4, a: 512, c: 64
[utils/util.py::ComputeLoss.__call__] Pred bboxes after softmax shape: torch.Size([4, 512, 4, 16])
[utils/util.py::ComputeLoss.__call__] Pred bboxes after matmul shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Final pred bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.__call__] ASSIGNMENT PHASE ---

--- [utils/util.py::ComputeLoss.assign] PYTORCH ASSIGNMENT DEBUG ---
[utils/util.py::ComputeLoss.assign] pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] true_labels shape: torch.Size([4, 1, 1])
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 1, 4])
[utils/util.py::ComputeLoss.assign] true_mask shape: torch.Size([4, 1, 1])
[utils/util.py::ComputeLoss.assign] anchors shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.assign] Batch size: 4, Max boxes: 1
[utils/util.py::ComputeLoss.assign] Created indices tensor with shape: torch.Size([2, 4, 1])

--- [utils/util.py::ComputeLoss.assign] IOUs DEBUG ---
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 1, 4])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([4, 1, 1, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([4, 1, 512, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([4, 1, 1, 1]), h: torch.Size([4, 1, 1, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([4, 1, 512, 1]), h: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.000000, max: 0.064714
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: -0.713380, max: 0.054811
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.assign] overlaps shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.assign] overlaps min: 0.0, max: 0.05481113865971565
[utils/util.py::ComputeLoss.assign] align_metric shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.assign] align_metric min: 0.0, max: 1.6756682152951896e-10
[utils/util.py::ComputeLoss.assign] mask_in_gts shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.assign] mask_in_gts sum: 24.0
[utils/util.py::ComputeLoss.assign] metrics shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.assign] top_k_mask shape: torch.Size([4, 1, 10])
[utils/util.py::ComputeLoss.assign] top_k_metrics shape: torch.Size([4, 1, 10])
[utils/util.py::ComputeLoss.assign] top_k_indices shape: torch.Size([4, 1, 10])
[utils/util.py::ComputeLoss.assign] is_in_top_k shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.assign] mask_top_k shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.assign] mask_pos shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.assign] fg_mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] fg_mask sum: 24.0
[utils/util.py::ComputeLoss.assign] target_gt_idx shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_labels shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] Normalized target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] target_scores sum: 0.0557231642305851
--- [utils/util.py::ComputeLoss.assign] END PYTORCH ASSIGNMENT DEBUG ---

[utils/util.py::ComputeLoss.__call__] Target bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Target scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] FG mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.__call__] Target scores sum: 0.055723
[utils/util.py::ComputeLoss.__call__] Classification loss computed: 10.374949
[utils/util.py::ComputeLoss.__call__] Foreground count: 24
[utils/util.py::ComputeLoss.__call__] Weight shape: torch.Size([24, 1])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([24, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([24, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([24, 1]), h: torch.Size([24, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([24, 1]), h: torch.Size([24, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([24, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([24, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([24, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.032574, max: 0.057940
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([24, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([24, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([24, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([24, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: 0.025307, max: 0.054788
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.__call__] IoU values shape: torch.Size([24, 1])
[utils/util.py::ComputeLoss.__call__] Box loss computed: 0.952045
[utils/util.py::ComputeLoss.__call__] Target LT-RB shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.df_loss] PYTORCH DFL LOSS DEBUG ---
[utils/util.py::ComputeLoss.df_loss] pred_dist shape: torch.Size([96, 16])
[utils/util.py::ComputeLoss.df_loss] target shape: torch.Size([24, 4])
[utils/util.py::ComputeLoss.df_loss] DFL loss shape: torch.Size([24, 1])
[utils/util.py::ComputeLoss.df_loss] DFL loss mean: 2.324543
--- [utils/util.py::ComputeLoss.df_loss] END PYTORCH DFL LOSS DEBUG ---

[utils/util.py::ComputeLoss.__call__] DFL loss before weighting: 2.324543
[utils/util.py::ComputeLoss.__call__] DFL loss computed: 2.281176

--- [utils/util.py::ComputeLoss.__call__] LOSS COMPONENTS DEBUG ---
[utils/util.py::ComputeLoss.__call__] Raw loss_cls: 10.374949
[utils/util.py::ComputeLoss.__call__] Raw loss_box: 0.952045
[utils/util.py::ComputeLoss.__call__] Raw loss_dfl: 2.281176
[utils/util.py::ComputeLoss.__call__] Loss weights - cls: 0.5, box: 7.5, dfl: 1.5
[utils/util.py::ComputeLoss.__call__] target_scores_sum: 0.055723
[utils/util.py::ComputeLoss.__call__] fg_mask sum: 24
[utils/util.py::ComputeLoss.__call__] Weighted loss_cls: 5.187475
[utils/util.py::ComputeLoss.__call__] Weighted loss_box: 7.140337
[utils/util.py::ComputeLoss.__call__] Weighted loss_dfl: 3.421763
[utils/util.py::ComputeLoss.__call__] Total loss: 15.749575
--- [utils/util.py::ComputeLoss.__call__] END PYTORCH LOSS COMPUTATION DEBUG ---


--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([4, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: True
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([4, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - box shape: torch.Size([4, 64, 16, 32]), cls shape: torch.Size([4, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - final concat shape: torch.Size([4, 65, 16, 32])

--- [utils/util.py::ComputeLoss.__call__] PYTORCH LOSS COMPUTATION DEBUG ---
[utils/util.py::ComputeLoss.__call__] Outputs type: <class 'list'>
[utils/util.py::ComputeLoss.__call__] x type: <class 'list'>, len: 1
[utils/util.py::ComputeLoss.__call__] x[0] shape: torch.Size([4, 65, 16, 32])
[utils/util.py::ComputeLoss.__call__] Concatenated output shape: torch.Size([4, 65, 512])
[utils/util.py::ComputeLoss.__call__] self.no: 65, self.dfl_ch: 16, self.nc: 1
[utils/util.py::ComputeLoss.__call__] pred_output shape: torch.Size([4, 64, 512])
[utils/util.py::ComputeLoss.__call__] pred_scores shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.__call__] After permute - pred_output shape: torch.Size([4, 512, 64])
[utils/util.py::ComputeLoss.__call__] After permute - pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Size tensor: tensor([128., 256.], device='cuda:0', dtype=torch.float16)
[utils/util.py::ComputeLoss.__call__] Stride: tensor([8.])
[utils/util.py::ComputeLoss.__call__] Anchor points shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.__call__] Stride tensor shape: torch.Size([512, 1])

--- [utils/util.py::ComputeLoss.__call__] TARGET PROCESSING ---
[utils/util.py::ComputeLoss.__call__] Targets shape: torch.Size([6, 6])
[utils/util.py::ComputeLoss.__call__] Targets dtype: torch.float32
[utils/util.py::ComputeLoss.__call__] First few targets: tensor([[0.0000, 0.0000, 0.4145, 0.3407, 0.0804, 0.1590],
        [1.0000, 0.0000, 0.3337, 0.2191, 0.0622, 0.1224],
        [1.0000, 0.0000, 0.6554, 0.2036, 0.0640, 0.1247],
        [1.0000, 0.0000, 0.3428, 0.9405, 0.0663, 0.1190],
        [1.0000, 0.0000, 0.9015, 0.9433, 0.0667, 0.1135]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Image indices: tensor([0., 1., 1., 1., 1., 2.], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Counts per image: tensor([1, 4, 1], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT tensor shape: torch.Size([4, 4, 5])
[utils/util.py::ComputeLoss.__call__] Image 0: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 1: 4 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 2: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] GT before coordinate conversion: tensor([[[0.0000, 0.4145, 0.3407, 0.0804, 0.1590],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.3337, 0.2191, 0.0622, 0.1224],
         [0.0000, 0.6554, 0.2036, 0.0640, 0.1247],
         [0.0000, 0.3428, 0.9405, 0.0663, 0.1190],
         [0.0000, 0.9015, 0.9433, 0.0667, 0.1135]],

        [[0.0000, 0.0966, 0.1196, 0.1174, 0.2162],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT after coordinate conversion: tensor([[[  0.0000,  95.8243,  33.4360, 116.4055,  53.7895],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000,  77.4773,  20.2169,  93.3950,  35.8783],
         [  0.0000, 159.6001,  18.0777, 175.9734,  34.0452],
         [  0.0000,  79.2748, 112.7616,  96.2390, 127.9990],
         [  0.0000, 222.2458, 113.4735, 239.3310, 127.9990]],

        [[  0.0000,   9.6937,   1.4745,  39.7429,  29.1533],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT labels shape: torch.Size([4, 4, 1])
[utils/util.py::ComputeLoss.__call__] GT bboxes shape: torch.Size([4, 4, 4])
[utils/util.py::ComputeLoss.__call__] GT mask shape: torch.Size([4, 4, 1])
[utils/util.py::ComputeLoss.__call__] Pred output dimensions - b: 4, a: 512, c: 64
[utils/util.py::ComputeLoss.__call__] Pred bboxes after softmax shape: torch.Size([4, 512, 4, 16])
[utils/util.py::ComputeLoss.__call__] Pred bboxes after matmul shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Final pred bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.__call__] ASSIGNMENT PHASE ---

--- [utils/util.py::ComputeLoss.assign] PYTORCH ASSIGNMENT DEBUG ---
[utils/util.py::ComputeLoss.assign] pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] true_labels shape: torch.Size([4, 4, 1])
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 4, 4])
[utils/util.py::ComputeLoss.assign] true_mask shape: torch.Size([4, 4, 1])
[utils/util.py::ComputeLoss.assign] anchors shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.assign] Batch size: 4, Max boxes: 4
[utils/util.py::ComputeLoss.assign] Created indices tensor with shape: torch.Size([2, 4, 4])

--- [utils/util.py::ComputeLoss.assign] IOUs DEBUG ---
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 4, 4])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([4, 4, 1, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([4, 1, 512, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([4, 4, 1, 1]), h: torch.Size([4, 4, 1, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([4, 1, 512, 1]), h: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([4, 4, 512, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([4, 4, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([4, 4, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.000000, max: 0.115565
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([4, 4, 512, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([4, 4, 512, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([4, 4, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([4, 4, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: -0.721379, max: 0.095240
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.assign] overlaps shape: torch.Size([4, 4, 512])
[utils/util.py::ComputeLoss.assign] overlaps min: 0.0, max: 0.09523993730545044
[utils/util.py::ComputeLoss.assign] align_metric shape: torch.Size([4, 4, 512])
[utils/util.py::ComputeLoss.assign] align_metric min: 0.0, max: 4.9841442084641585e-09
[utils/util.py::ComputeLoss.assign] mask_in_gts shape: torch.Size([4, 4, 512])
[utils/util.py::ComputeLoss.assign] mask_in_gts sum: 39.0
[utils/util.py::ComputeLoss.assign] metrics shape: torch.Size([4, 4, 512])
[utils/util.py::ComputeLoss.assign] top_k_mask shape: torch.Size([4, 4, 10])
[utils/util.py::ComputeLoss.assign] top_k_metrics shape: torch.Size([4, 4, 10])
[utils/util.py::ComputeLoss.assign] top_k_indices shape: torch.Size([4, 4, 10])
[utils/util.py::ComputeLoss.assign] is_in_top_k shape: torch.Size([4, 4, 512])
[utils/util.py::ComputeLoss.assign] mask_top_k shape: torch.Size([4, 4, 512])
[utils/util.py::ComputeLoss.assign] mask_pos shape: torch.Size([4, 4, 512])
[utils/util.py::ComputeLoss.assign] fg_mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] fg_mask sum: 33.0
[utils/util.py::ComputeLoss.assign] target_gt_idx shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_labels shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] Normalized target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] target_scores sum: 0.4924054443836212
--- [utils/util.py::ComputeLoss.assign] END PYTORCH ASSIGNMENT DEBUG ---

[utils/util.py::ComputeLoss.__call__] Target bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Target scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] FG mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.__call__] Target scores sum: 0.492405
[utils/util.py::ComputeLoss.__call__] Classification loss computed: 10.106636
[utils/util.py::ComputeLoss.__call__] Foreground count: 33
[utils/util.py::ComputeLoss.__call__] Weight shape: torch.Size([33, 1])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([33, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([33, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([33, 1]), h: torch.Size([33, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([33, 1]), h: torch.Size([33, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([33, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([33, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([33, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.025732, max: 0.103758
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([33, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([33, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([33, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([33, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: 0.016191, max: 0.095233
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.__call__] IoU values shape: torch.Size([33, 1])
[utils/util.py::ComputeLoss.__call__] Box loss computed: 0.911972
[utils/util.py::ComputeLoss.__call__] Target LT-RB shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.df_loss] PYTORCH DFL LOSS DEBUG ---
[utils/util.py::ComputeLoss.df_loss] pred_dist shape: torch.Size([132, 16])
[utils/util.py::ComputeLoss.df_loss] target shape: torch.Size([33, 4])
[utils/util.py::ComputeLoss.df_loss] DFL loss shape: torch.Size([33, 1])
[utils/util.py::ComputeLoss.df_loss] DFL loss mean: 2.318222
--- [utils/util.py::ComputeLoss.df_loss] END PYTORCH DFL LOSS DEBUG ---

[utils/util.py::ComputeLoss.__call__] DFL loss before weighting: 2.318222
[utils/util.py::ComputeLoss.__call__] DFL loss computed: 2.311435

--- [utils/util.py::ComputeLoss.__call__] LOSS COMPONENTS DEBUG ---
[utils/util.py::ComputeLoss.__call__] Raw loss_cls: 10.106636
[utils/util.py::ComputeLoss.__call__] Raw loss_box: 0.911972
[utils/util.py::ComputeLoss.__call__] Raw loss_dfl: 2.311435
[utils/util.py::ComputeLoss.__call__] Loss weights - cls: 0.5, box: 7.5, dfl: 1.5
[utils/util.py::ComputeLoss.__call__] target_scores_sum: 0.492405
[utils/util.py::ComputeLoss.__call__] fg_mask sum: 33
[utils/util.py::ComputeLoss.__call__] Weighted loss_cls: 5.053318
[utils/util.py::ComputeLoss.__call__] Weighted loss_box: 6.839790
[utils/util.py::ComputeLoss.__call__] Weighted loss_dfl: 3.467153
[utils/util.py::ComputeLoss.__call__] Total loss: 15.360261
--- [utils/util.py::ComputeLoss.__call__] END PYTORCH LOSS COMPUTATION DEBUG ---


--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([4, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: True
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([4, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - box shape: torch.Size([4, 64, 16, 32]), cls shape: torch.Size([4, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - final concat shape: torch.Size([4, 65, 16, 32])

--- [utils/util.py::ComputeLoss.__call__] PYTORCH LOSS COMPUTATION DEBUG ---
[utils/util.py::ComputeLoss.__call__] Outputs type: <class 'list'>
[utils/util.py::ComputeLoss.__call__] x type: <class 'list'>, len: 1
[utils/util.py::ComputeLoss.__call__] x[0] shape: torch.Size([4, 65, 16, 32])
[utils/util.py::ComputeLoss.__call__] Concatenated output shape: torch.Size([4, 65, 512])
[utils/util.py::ComputeLoss.__call__] self.no: 65, self.dfl_ch: 16, self.nc: 1
[utils/util.py::ComputeLoss.__call__] pred_output shape: torch.Size([4, 64, 512])
[utils/util.py::ComputeLoss.__call__] pred_scores shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.__call__] After permute - pred_output shape: torch.Size([4, 512, 64])
[utils/util.py::ComputeLoss.__call__] After permute - pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Size tensor: tensor([128., 256.], device='cuda:0', dtype=torch.float16)
[utils/util.py::ComputeLoss.__call__] Stride: tensor([8.])
[utils/util.py::ComputeLoss.__call__] Anchor points shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.__call__] Stride tensor shape: torch.Size([512, 1])

--- [utils/util.py::ComputeLoss.__call__] TARGET PROCESSING ---
[utils/util.py::ComputeLoss.__call__] Targets shape: torch.Size([6, 6])
[utils/util.py::ComputeLoss.__call__] Targets dtype: torch.float32
[utils/util.py::ComputeLoss.__call__] First few targets: tensor([[0.0000, 0.0000, 0.5649, 0.8277, 0.0950, 0.1848],
        [1.0000, 0.0000, 0.7416, 0.5936, 0.1158, 0.2396],
        [2.0000, 0.0000, 0.9487, 0.3725, 0.1027, 0.1943],
        [3.0000, 0.0000, 0.2901, 0.0622, 0.0557, 0.1105],
        [3.0000, 0.0000, 0.2554, 0.6248, 0.0619, 0.1311]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Image indices: tensor([0., 1., 2., 3., 3., 3.], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Counts per image: tensor([1, 1, 1, 3], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT tensor shape: torch.Size([4, 3, 5])
[utils/util.py::ComputeLoss.__call__] Image 0: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 1: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 2: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 3: 3 targets assigned
[utils/util.py::ComputeLoss.__call__] GT before coordinate conversion: tensor([[[0.0000, 0.5649, 0.8277, 0.0950, 0.1848],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.7416, 0.5936, 0.1158, 0.2396],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.9487, 0.3725, 0.1027, 0.1943],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.2901, 0.0622, 0.0557, 0.1105],
         [0.0000, 0.2554, 0.6248, 0.0619, 0.1311],
         [0.0000, 0.9932, 0.5173, 0.0137, 0.1016]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT after coordinate conversion: tensor([[[  0.0000, 132.4510,  94.1243, 156.7679, 117.7728],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000, 175.0219,  60.6528, 204.6600,  91.3175],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000, 229.7153,  35.2430, 255.9990,  60.1182],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000,  67.1270,   0.8961,  81.3954,  15.0345],
         [  0.0000,  57.4619,  71.5881,  73.3139,  88.3732],
         [  0.0000, 252.4984,  59.7118, 255.9990,  72.7192]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT labels shape: torch.Size([4, 3, 1])
[utils/util.py::ComputeLoss.__call__] GT bboxes shape: torch.Size([4, 3, 4])
[utils/util.py::ComputeLoss.__call__] GT mask shape: torch.Size([4, 3, 1])
[utils/util.py::ComputeLoss.__call__] Pred output dimensions - b: 4, a: 512, c: 64
[utils/util.py::ComputeLoss.__call__] Pred bboxes after softmax shape: torch.Size([4, 512, 4, 16])
[utils/util.py::ComputeLoss.__call__] Pred bboxes after matmul shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Final pred bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.__call__] ASSIGNMENT PHASE ---

--- [utils/util.py::ComputeLoss.assign] PYTORCH ASSIGNMENT DEBUG ---
[utils/util.py::ComputeLoss.assign] pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] true_labels shape: torch.Size([4, 3, 1])
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 3, 4])
[utils/util.py::ComputeLoss.assign] true_mask shape: torch.Size([4, 3, 1])
[utils/util.py::ComputeLoss.assign] anchors shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.assign] Batch size: 4, Max boxes: 3
[utils/util.py::ComputeLoss.assign] Created indices tensor with shape: torch.Size([2, 4, 3])

--- [utils/util.py::ComputeLoss.assign] IOUs DEBUG ---
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 3, 4])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([4, 3, 1, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([4, 1, 512, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([4, 3, 1, 1]), h: torch.Size([4, 3, 1, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([4, 1, 512, 1]), h: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.000000, max: 0.114870
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: -0.747550, max: 0.110413
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.assign] overlaps shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] overlaps min: 0.0, max: 0.1104130819439888
[utils/util.py::ComputeLoss.assign] align_metric shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] align_metric min: 0.0, max: 8.344271940075032e-09
[utils/util.py::ComputeLoss.assign] mask_in_gts shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] mask_in_gts sum: 41.0
[utils/util.py::ComputeLoss.assign] metrics shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] top_k_mask shape: torch.Size([4, 3, 10])
[utils/util.py::ComputeLoss.assign] top_k_metrics shape: torch.Size([4, 3, 10])
[utils/util.py::ComputeLoss.assign] top_k_indices shape: torch.Size([4, 3, 10])
[utils/util.py::ComputeLoss.assign] is_in_top_k shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] mask_top_k shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] mask_pos shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] fg_mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] fg_mask sum: 37.0
[utils/util.py::ComputeLoss.assign] target_gt_idx shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_labels shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] Normalized target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] target_scores sum: 1.0847777128219604
--- [utils/util.py::ComputeLoss.assign] END PYTORCH ASSIGNMENT DEBUG ---

[utils/util.py::ComputeLoss.__call__] Target bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Target scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] FG mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.__call__] Target scores sum: 1.084778
[utils/util.py::ComputeLoss.__call__] Classification loss computed: 10.233952
[utils/util.py::ComputeLoss.__call__] Foreground count: 37
[utils/util.py::ComputeLoss.__call__] Weight shape: torch.Size([37, 1])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([37, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([37, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([37, 1]), h: torch.Size([37, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([37, 1]), h: torch.Size([37, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([37, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([37, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([37, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.020636, max: 0.114927
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([37, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([37, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([37, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([37, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: 0.018234, max: 0.110470
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.__call__] IoU values shape: torch.Size([37, 1])
[utils/util.py::ComputeLoss.__call__] Box loss computed: 0.913345
[utils/util.py::ComputeLoss.__call__] Target LT-RB shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.df_loss] PYTORCH DFL LOSS DEBUG ---
[utils/util.py::ComputeLoss.df_loss] pred_dist shape: torch.Size([148, 16])
[utils/util.py::ComputeLoss.df_loss] target shape: torch.Size([37, 4])
[utils/util.py::ComputeLoss.df_loss] DFL loss shape: torch.Size([37, 1])
[utils/util.py::ComputeLoss.df_loss] DFL loss mean: 2.188735
--- [utils/util.py::ComputeLoss.df_loss] END PYTORCH DFL LOSS DEBUG ---

[utils/util.py::ComputeLoss.__call__] DFL loss before weighting: 2.188735
[utils/util.py::ComputeLoss.__call__] DFL loss computed: 2.104714

--- [utils/util.py::ComputeLoss.__call__] LOSS COMPONENTS DEBUG ---
[utils/util.py::ComputeLoss.__call__] Raw loss_cls: 10.233952
[utils/util.py::ComputeLoss.__call__] Raw loss_box: 0.913345
[utils/util.py::ComputeLoss.__call__] Raw loss_dfl: 2.104714
[utils/util.py::ComputeLoss.__call__] Loss weights - cls: 0.5, box: 7.5, dfl: 1.5
[utils/util.py::ComputeLoss.__call__] target_scores_sum: 1.084778
[utils/util.py::ComputeLoss.__call__] fg_mask sum: 37
[utils/util.py::ComputeLoss.__call__] Weighted loss_cls: 5.116976
[utils/util.py::ComputeLoss.__call__] Weighted loss_box: 6.850088
[utils/util.py::ComputeLoss.__call__] Weighted loss_dfl: 3.157072
[utils/util.py::ComputeLoss.__call__] Total loss: 15.124136
--- [utils/util.py::ComputeLoss.__call__] END PYTORCH LOSS COMPUTATION DEBUG ---


--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([4, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: True
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([4, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - box shape: torch.Size([4, 64, 16, 32]), cls shape: torch.Size([4, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - final concat shape: torch.Size([4, 65, 16, 32])

--- [utils/util.py::ComputeLoss.__call__] PYTORCH LOSS COMPUTATION DEBUG ---
[utils/util.py::ComputeLoss.__call__] Outputs type: <class 'list'>
[utils/util.py::ComputeLoss.__call__] x type: <class 'list'>, len: 1
[utils/util.py::ComputeLoss.__call__] x[0] shape: torch.Size([4, 65, 16, 32])
[utils/util.py::ComputeLoss.__call__] Concatenated output shape: torch.Size([4, 65, 512])
[utils/util.py::ComputeLoss.__call__] self.no: 65, self.dfl_ch: 16, self.nc: 1
[utils/util.py::ComputeLoss.__call__] pred_output shape: torch.Size([4, 64, 512])
[utils/util.py::ComputeLoss.__call__] pred_scores shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.__call__] After permute - pred_output shape: torch.Size([4, 512, 64])
[utils/util.py::ComputeLoss.__call__] After permute - pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Size tensor: tensor([128., 256.], device='cuda:0', dtype=torch.float16)
[utils/util.py::ComputeLoss.__call__] Stride: tensor([8.])
[utils/util.py::ComputeLoss.__call__] Anchor points shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.__call__] Stride tensor shape: torch.Size([512, 1])

--- [utils/util.py::ComputeLoss.__call__] TARGET PROCESSING ---
[utils/util.py::ComputeLoss.__call__] Targets shape: torch.Size([6, 6])
[utils/util.py::ComputeLoss.__call__] Targets dtype: torch.float32
[utils/util.py::ComputeLoss.__call__] First few targets: tensor([[0.0000, 0.0000, 0.0223, 0.5022, 0.0445, 0.1086],
        [0.0000, 0.0000, 0.9816, 0.6318, 0.0368, 0.1346],
        [1.0000, 0.0000, 0.0876, 0.6024, 0.1036, 0.2145],
        [1.0000, 0.0000, 0.9775, 0.8048, 0.0450, 0.2649],
        [2.0000, 0.0000, 0.7066, 0.0678, 0.0748, 0.1355]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Image indices: tensor([0., 0., 1., 1., 2., 2.], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Counts per image: tensor([2, 2, 2], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT tensor shape: torch.Size([4, 2, 5])
[utils/util.py::ComputeLoss.__call__] Image 0: 2 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 1: 2 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 2: 2 targets assigned
[utils/util.py::ComputeLoss.__call__] GT before coordinate conversion: tensor([[[0.0000, 0.0223, 0.5022, 0.0445, 0.1086],
         [0.0000, 0.9816, 0.6318, 0.0368, 0.1346]],

        [[0.0000, 0.0876, 0.6024, 0.1036, 0.2145],
         [0.0000, 0.9775, 0.8048, 0.0450, 0.2649]],

        [[0.0000, 0.7066, 0.0678, 0.0748, 0.1355],
         [0.0000, 0.9620, 0.9449, 0.0759, 0.1101]],

        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT after coordinate conversion: tensor([[[  0.0000,   0.0000,  57.3264,  11.3938,  71.2253],
         [  0.0000, 246.5852,  72.2477, 255.9990,  89.4804]],

        [[  0.0000,   9.1649,  63.3835,  35.6920,  90.8419],
         [  0.0000, 244.4766,  86.0665, 255.9990, 119.9715]],

        [[  0.0000, 171.3099,   0.0000, 190.4619,  17.3457],
         [  0.0000, 236.5701, 113.9032, 255.9990, 127.9990]],

        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT labels shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.__call__] GT bboxes shape: torch.Size([4, 2, 4])
[utils/util.py::ComputeLoss.__call__] GT mask shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.__call__] Pred output dimensions - b: 4, a: 512, c: 64
[utils/util.py::ComputeLoss.__call__] Pred bboxes after softmax shape: torch.Size([4, 512, 4, 16])
[utils/util.py::ComputeLoss.__call__] Pred bboxes after matmul shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Final pred bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.__call__] ASSIGNMENT PHASE ---

--- [utils/util.py::ComputeLoss.assign] PYTORCH ASSIGNMENT DEBUG ---
[utils/util.py::ComputeLoss.assign] pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] true_labels shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 2, 4])
[utils/util.py::ComputeLoss.assign] true_mask shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.assign] anchors shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.assign] Batch size: 4, Max boxes: 2
[utils/util.py::ComputeLoss.assign] Created indices tensor with shape: torch.Size([2, 4, 2])

--- [utils/util.py::ComputeLoss.assign] IOUs DEBUG ---
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 2, 4])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([4, 2, 1, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([4, 1, 512, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([4, 2, 1, 1]), h: torch.Size([4, 2, 1, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([4, 1, 512, 1]), h: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.000000, max: 0.107723
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: -0.760011, max: 0.095474
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.assign] overlaps shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] overlaps min: 0.0, max: 0.09547395259141922
[utils/util.py::ComputeLoss.assign] align_metric shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] align_metric min: 0.0, max: 4.6313011203835686e-09
[utils/util.py::ComputeLoss.assign] mask_in_gts shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] mask_in_gts sum: 27.0
[utils/util.py::ComputeLoss.assign] metrics shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] top_k_mask shape: torch.Size([4, 2, 10])
[utils/util.py::ComputeLoss.assign] top_k_metrics shape: torch.Size([4, 2, 10])
[utils/util.py::ComputeLoss.assign] top_k_indices shape: torch.Size([4, 2, 10])
[utils/util.py::ComputeLoss.assign] is_in_top_k shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] mask_top_k shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] mask_pos shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] fg_mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] fg_mask sum: 27.0
[utils/util.py::ComputeLoss.assign] target_gt_idx shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_labels shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] Normalized target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] target_scores sum: 0.4386668801307678
--- [utils/util.py::ComputeLoss.assign] END PYTORCH ASSIGNMENT DEBUG ---

[utils/util.py::ComputeLoss.__call__] Target bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Target scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] FG mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.__call__] Target scores sum: 0.438667
[utils/util.py::ComputeLoss.__call__] Classification loss computed: 10.098067
[utils/util.py::ComputeLoss.__call__] Foreground count: 27
[utils/util.py::ComputeLoss.__call__] Weight shape: torch.Size([27, 1])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([27, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([27, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([27, 1]), h: torch.Size([27, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([27, 1]), h: torch.Size([27, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([27, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([27, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([27, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.019257, max: 0.097744
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([27, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([27, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([27, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([27, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: 0.016054, max: 0.095474
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.__call__] IoU values shape: torch.Size([27, 1])
[utils/util.py::ComputeLoss.__call__] Box loss computed: 0.914367
[utils/util.py::ComputeLoss.__call__] Target LT-RB shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.df_loss] PYTORCH DFL LOSS DEBUG ---
[utils/util.py::ComputeLoss.df_loss] pred_dist shape: torch.Size([108, 16])
[utils/util.py::ComputeLoss.df_loss] target shape: torch.Size([27, 4])
[utils/util.py::ComputeLoss.df_loss] DFL loss shape: torch.Size([27, 1])
[utils/util.py::ComputeLoss.df_loss] DFL loss mean: 2.153135
--- [utils/util.py::ComputeLoss.df_loss] END PYTORCH DFL LOSS DEBUG ---

[utils/util.py::ComputeLoss.__call__] DFL loss before weighting: 2.153135
[utils/util.py::ComputeLoss.__call__] DFL loss computed: 2.017008

--- [utils/util.py::ComputeLoss.__call__] LOSS COMPONENTS DEBUG ---
[utils/util.py::ComputeLoss.__call__] Raw loss_cls: 10.098067
[utils/util.py::ComputeLoss.__call__] Raw loss_box: 0.914367
[utils/util.py::ComputeLoss.__call__] Raw loss_dfl: 2.017008
[utils/util.py::ComputeLoss.__call__] Loss weights - cls: 0.5, box: 7.5, dfl: 1.5
[utils/util.py::ComputeLoss.__call__] target_scores_sum: 0.438667
[utils/util.py::ComputeLoss.__call__] fg_mask sum: 27
[utils/util.py::ComputeLoss.__call__] Weighted loss_cls: 5.049034
[utils/util.py::ComputeLoss.__call__] Weighted loss_box: 6.857755
[utils/util.py::ComputeLoss.__call__] Weighted loss_dfl: 3.025512
[utils/util.py::ComputeLoss.__call__] Total loss: 14.932300
--- [utils/util.py::ComputeLoss.__call__] END PYTORCH LOSS COMPUTATION DEBUG ---


--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([4, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: True
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([4, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - box shape: torch.Size([4, 64, 16, 32]), cls shape: torch.Size([4, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - final concat shape: torch.Size([4, 65, 16, 32])

--- [utils/util.py::ComputeLoss.__call__] PYTORCH LOSS COMPUTATION DEBUG ---
[utils/util.py::ComputeLoss.__call__] Outputs type: <class 'list'>
[utils/util.py::ComputeLoss.__call__] x type: <class 'list'>, len: 1
[utils/util.py::ComputeLoss.__call__] x[0] shape: torch.Size([4, 65, 16, 32])
[utils/util.py::ComputeLoss.__call__] Concatenated output shape: torch.Size([4, 65, 512])
[utils/util.py::ComputeLoss.__call__] self.no: 65, self.dfl_ch: 16, self.nc: 1
[utils/util.py::ComputeLoss.__call__] pred_output shape: torch.Size([4, 64, 512])
[utils/util.py::ComputeLoss.__call__] pred_scores shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.__call__] After permute - pred_output shape: torch.Size([4, 512, 64])
[utils/util.py::ComputeLoss.__call__] After permute - pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Size tensor: tensor([128., 256.], device='cuda:0', dtype=torch.float16)
[utils/util.py::ComputeLoss.__call__] Stride: tensor([8.])
[utils/util.py::ComputeLoss.__call__] Anchor points shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.__call__] Stride tensor shape: torch.Size([512, 1])

--- [utils/util.py::ComputeLoss.__call__] TARGET PROCESSING ---
[utils/util.py::ComputeLoss.__call__] Targets shape: torch.Size([3, 6])
[utils/util.py::ComputeLoss.__call__] Targets dtype: torch.float32
[utils/util.py::ComputeLoss.__call__] First few targets: tensor([[0.0000, 0.0000, 0.7280, 0.3251, 0.0903, 0.1733],
        [1.0000, 0.0000, 0.5112, 0.9684, 0.0776, 0.0631],
        [3.0000, 0.0000, 0.0672, 0.6379, 0.1000, 0.1796]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Image indices: tensor([0., 1., 3.], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Counts per image: tensor([1, 1, 1], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT tensor shape: torch.Size([4, 1, 5])
[utils/util.py::ComputeLoss.__call__] Image 0: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 1: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 3: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] GT before coordinate conversion: tensor([[[0.0000, 0.7280, 0.3251, 0.0903, 0.1733]],

        [[0.0000, 0.5112, 0.9684, 0.0776, 0.0631]],

        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.0672, 0.6379, 0.1000, 0.1796]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT after coordinate conversion: tensor([[[  0.0000, 174.7964,  30.5251, 197.9151,  52.7042]],

        [[  0.0000, 120.9462, 119.9220, 140.7995, 127.9990]],

        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000,   4.3858,  70.1563,  29.9961,  93.1424]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT labels shape: torch.Size([4, 1, 1])
[utils/util.py::ComputeLoss.__call__] GT bboxes shape: torch.Size([4, 1, 4])
[utils/util.py::ComputeLoss.__call__] GT mask shape: torch.Size([4, 1, 1])
[utils/util.py::ComputeLoss.__call__] Pred output dimensions - b: 4, a: 512, c: 64
[utils/util.py::ComputeLoss.__call__] Pred bboxes after softmax shape: torch.Size([4, 512, 4, 16])
[utils/util.py::ComputeLoss.__call__] Pred bboxes after matmul shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Final pred bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.__call__] ASSIGNMENT PHASE ---

--- [utils/util.py::ComputeLoss.assign] PYTORCH ASSIGNMENT DEBUG ---
[utils/util.py::ComputeLoss.assign] pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] true_labels shape: torch.Size([4, 1, 1])
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 1, 4])
[utils/util.py::ComputeLoss.assign] true_mask shape: torch.Size([4, 1, 1])
[utils/util.py::ComputeLoss.assign] anchors shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.assign] Batch size: 4, Max boxes: 1
[utils/util.py::ComputeLoss.assign] Created indices tensor with shape: torch.Size([2, 4, 1])

--- [utils/util.py::ComputeLoss.assign] IOUs DEBUG ---
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 1, 4])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([4, 1, 1, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([4, 1, 512, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([4, 1, 1, 1]), h: torch.Size([4, 1, 1, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([4, 1, 512, 1]), h: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.000000, max: 0.087700
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: -0.747722, max: 0.081201
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.assign] overlaps shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.assign] overlaps min: 0.0, max: 0.08120059967041016
[utils/util.py::ComputeLoss.assign] align_metric shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.assign] align_metric min: 0.0, max: 2.557287048787771e-09
[utils/util.py::ComputeLoss.assign] mask_in_gts shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.assign] mask_in_gts sum: 21.0
[utils/util.py::ComputeLoss.assign] metrics shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.assign] top_k_mask shape: torch.Size([4, 1, 10])
[utils/util.py::ComputeLoss.assign] top_k_metrics shape: torch.Size([4, 1, 10])
[utils/util.py::ComputeLoss.assign] top_k_indices shape: torch.Size([4, 1, 10])
[utils/util.py::ComputeLoss.assign] is_in_top_k shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.assign] mask_top_k shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.assign] mask_pos shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.assign] fg_mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] fg_mask sum: 21.0
[utils/util.py::ComputeLoss.assign] target_gt_idx shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_labels shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] Normalized target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] target_scores sum: 0.495475709438324
--- [utils/util.py::ComputeLoss.assign] END PYTORCH ASSIGNMENT DEBUG ---

[utils/util.py::ComputeLoss.__call__] Target bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Target scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] FG mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.__call__] Target scores sum: 0.495476
[utils/util.py::ComputeLoss.__call__] Classification loss computed: 9.760191
[utils/util.py::ComputeLoss.__call__] Foreground count: 21
[utils/util.py::ComputeLoss.__call__] Weight shape: torch.Size([21, 1])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([21, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([21, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([21, 1]), h: torch.Size([21, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([21, 1]), h: torch.Size([21, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([21, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([21, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([21, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.019965, max: 0.086775
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([21, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([21, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([21, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([21, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: 0.011996, max: 0.081198
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.__call__] IoU values shape: torch.Size([21, 1])
[utils/util.py::ComputeLoss.__call__] Box loss computed: 0.926494
[utils/util.py::ComputeLoss.__call__] Target LT-RB shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.df_loss] PYTORCH DFL LOSS DEBUG ---
[utils/util.py::ComputeLoss.df_loss] pred_dist shape: torch.Size([84, 16])
[utils/util.py::ComputeLoss.df_loss] target shape: torch.Size([21, 4])
[utils/util.py::ComputeLoss.df_loss] DFL loss shape: torch.Size([21, 1])
[utils/util.py::ComputeLoss.df_loss] DFL loss mean: 2.068133
--- [utils/util.py::ComputeLoss.df_loss] END PYTORCH DFL LOSS DEBUG ---

[utils/util.py::ComputeLoss.__call__] DFL loss before weighting: 2.068133
[utils/util.py::ComputeLoss.__call__] DFL loss computed: 1.992165

--- [utils/util.py::ComputeLoss.__call__] LOSS COMPONENTS DEBUG ---
[utils/util.py::ComputeLoss.__call__] Raw loss_cls: 9.760191
[utils/util.py::ComputeLoss.__call__] Raw loss_box: 0.926494
[utils/util.py::ComputeLoss.__call__] Raw loss_dfl: 1.992165
[utils/util.py::ComputeLoss.__call__] Loss weights - cls: 0.5, box: 7.5, dfl: 1.5
[utils/util.py::ComputeLoss.__call__] target_scores_sum: 0.495476
[utils/util.py::ComputeLoss.__call__] fg_mask sum: 21
[utils/util.py::ComputeLoss.__call__] Weighted loss_cls: 4.880095
[utils/util.py::ComputeLoss.__call__] Weighted loss_box: 6.948707
[utils/util.py::ComputeLoss.__call__] Weighted loss_dfl: 2.988248
[utils/util.py::ComputeLoss.__call__] Total loss: 14.817050
--- [utils/util.py::ComputeLoss.__call__] END PYTORCH LOSS COMPUTATION DEBUG ---


--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([4, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: True
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([4, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - box shape: torch.Size([4, 64, 16, 32]), cls shape: torch.Size([4, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - final concat shape: torch.Size([4, 65, 16, 32])

--- [utils/util.py::ComputeLoss.__call__] PYTORCH LOSS COMPUTATION DEBUG ---
[utils/util.py::ComputeLoss.__call__] Outputs type: <class 'list'>
[utils/util.py::ComputeLoss.__call__] x type: <class 'list'>, len: 1
[utils/util.py::ComputeLoss.__call__] x[0] shape: torch.Size([4, 65, 16, 32])
[utils/util.py::ComputeLoss.__call__] Concatenated output shape: torch.Size([4, 65, 512])
[utils/util.py::ComputeLoss.__call__] self.no: 65, self.dfl_ch: 16, self.nc: 1
[utils/util.py::ComputeLoss.__call__] pred_output shape: torch.Size([4, 64, 512])
[utils/util.py::ComputeLoss.__call__] pred_scores shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.__call__] After permute - pred_output shape: torch.Size([4, 512, 64])
[utils/util.py::ComputeLoss.__call__] After permute - pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Size tensor: tensor([128., 256.], device='cuda:0', dtype=torch.float16)
[utils/util.py::ComputeLoss.__call__] Stride: tensor([8.])
[utils/util.py::ComputeLoss.__call__] Anchor points shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.__call__] Stride tensor shape: torch.Size([512, 1])

--- [utils/util.py::ComputeLoss.__call__] TARGET PROCESSING ---
[utils/util.py::ComputeLoss.__call__] Targets shape: torch.Size([12, 6])
[utils/util.py::ComputeLoss.__call__] Targets dtype: torch.float32
[utils/util.py::ComputeLoss.__call__] First few targets: tensor([[0.0000, 0.0000, 0.8935, 0.0732, 0.0639, 0.1272],
        [0.0000, 0.0000, 0.5958, 0.8240, 0.0620, 0.1210],
        [0.0000, 0.0000, 0.3003, 0.6562, 0.0680, 0.1269],
        [1.0000, 0.0000, 0.4615, 0.8435, 0.0934, 0.1937],
        [1.0000, 0.0000, 0.0067, 0.8406, 0.0133, 0.2050]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Image indices: tensor([0., 0., 0., 1., 1., 2., 2., 2., 3., 3., 3., 3.], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Counts per image: tensor([3, 2, 3, 4], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT tensor shape: torch.Size([4, 4, 5])
[utils/util.py::ComputeLoss.__call__] Image 0: 3 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 1: 2 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 2: 3 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 3: 4 targets assigned
[utils/util.py::ComputeLoss.__call__] GT before coordinate conversion: tensor([[[0.0000, 0.8935, 0.0732, 0.0639, 0.1272],
         [0.0000, 0.5958, 0.8240, 0.0620, 0.1210],
         [0.0000, 0.3003, 0.6562, 0.0680, 0.1269],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.4615, 0.8435, 0.0934, 0.1937],
         [0.0000, 0.0067, 0.8406, 0.0133, 0.2050],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.3470, 0.3104, 0.0544, 0.1173],
         [0.0000, 0.1633, 0.2240, 0.0529, 0.1055],
         [0.0000, 0.5863, 0.7367, 0.0506, 0.0944],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.6021, 0.1410, 0.0494, 0.1019],
         [0.0000, 0.8365, 0.2071, 0.0468, 0.0853],
         [0.0000, 0.6387, 0.5428, 0.0429, 0.0905],
         [0.0000, 0.8531, 0.5375, 0.0451, 0.0879]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT after coordinate conversion: tensor([[[0.0000e+00, 2.2056e+02, 1.2332e+00, 2.3692e+02, 1.7514e+01],
         [0.0000e+00, 1.4460e+02, 9.7733e+01, 1.6046e+02, 1.1322e+02],
         [0.0000e+00, 6.8167e+01, 7.5867e+01, 8.5588e+01, 9.2112e+01],
         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],

        [[0.0000e+00, 1.0620e+02, 9.5568e+01, 1.3010e+02, 1.2036e+02],
         [0.0000e+00, 9.9945e-04, 9.4473e+01, 3.4114e+00, 1.2071e+02],
         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],

        [[0.0000e+00, 8.1855e+01, 3.2224e+01, 9.5789e+01, 4.7243e+01],
         [0.0000e+00, 3.5027e+01, 2.1923e+01, 4.8561e+01, 3.5424e+01],
         [0.0000e+00, 1.4361e+02, 8.8253e+01, 1.5657e+02, 1.0034e+02],
         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],

        [[0.0000e+00, 1.4781e+02, 1.1523e+01, 1.6046e+02, 2.4562e+01],
         [0.0000e+00, 2.0815e+02, 2.1052e+01, 2.2012e+02, 3.1965e+01],
         [0.0000e+00, 1.5801e+02, 6.3684e+01, 1.6899e+02, 7.5274e+01],
         [0.0000e+00, 2.1262e+02, 6.3177e+01, 2.2416e+02, 7.4426e+01]]],
       device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT labels shape: torch.Size([4, 4, 1])
[utils/util.py::ComputeLoss.__call__] GT bboxes shape: torch.Size([4, 4, 4])
[utils/util.py::ComputeLoss.__call__] GT mask shape: torch.Size([4, 4, 1])
[utils/util.py::ComputeLoss.__call__] Pred output dimensions - b: 4, a: 512, c: 64
[utils/util.py::ComputeLoss.__call__] Pred bboxes after softmax shape: torch.Size([4, 512, 4, 16])
[utils/util.py::ComputeLoss.__call__] Pred bboxes after matmul shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Final pred bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.__call__] ASSIGNMENT PHASE ---

--- [utils/util.py::ComputeLoss.assign] PYTORCH ASSIGNMENT DEBUG ---
[utils/util.py::ComputeLoss.assign] pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] true_labels shape: torch.Size([4, 4, 1])
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 4, 4])
[utils/util.py::ComputeLoss.assign] true_mask shape: torch.Size([4, 4, 1])
[utils/util.py::ComputeLoss.assign] anchors shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.assign] Batch size: 4, Max boxes: 4
[utils/util.py::ComputeLoss.assign] Created indices tensor with shape: torch.Size([2, 4, 4])

--- [utils/util.py::ComputeLoss.assign] IOUs DEBUG ---
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 4, 4])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([4, 4, 1, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([4, 1, 512, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([4, 4, 1, 1]), h: torch.Size([4, 4, 1, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([4, 1, 512, 1]), h: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([4, 4, 512, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([4, 4, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([4, 4, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.000000, max: 0.095170
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([4, 4, 512, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([4, 4, 512, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([4, 4, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([4, 4, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: -0.786399, max: 0.086252
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.assign] overlaps shape: torch.Size([4, 4, 512])
[utils/util.py::ComputeLoss.assign] overlaps min: 0.0, max: 0.08625219017267227
[utils/util.py::ComputeLoss.assign] align_metric shape: torch.Size([4, 4, 512])
[utils/util.py::ComputeLoss.assign] align_metric min: 0.0, max: 3.216702015862438e-09
[utils/util.py::ComputeLoss.assign] mask_in_gts shape: torch.Size([4, 4, 512])
[utils/util.py::ComputeLoss.assign] mask_in_gts sum: 41.0
[utils/util.py::ComputeLoss.assign] metrics shape: torch.Size([4, 4, 512])
[utils/util.py::ComputeLoss.assign] top_k_mask shape: torch.Size([4, 4, 10])
[utils/util.py::ComputeLoss.assign] top_k_metrics shape: torch.Size([4, 4, 10])
[utils/util.py::ComputeLoss.assign] top_k_indices shape: torch.Size([4, 4, 10])
[utils/util.py::ComputeLoss.assign] is_in_top_k shape: torch.Size([4, 4, 512])
[utils/util.py::ComputeLoss.assign] mask_top_k shape: torch.Size([4, 4, 512])
[utils/util.py::ComputeLoss.assign] mask_pos shape: torch.Size([4, 4, 512])
[utils/util.py::ComputeLoss.assign] fg_mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] fg_mask sum: 41.0
[utils/util.py::ComputeLoss.assign] target_gt_idx shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_labels shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] Normalized target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] target_scores sum: 0.372292697429657
--- [utils/util.py::ComputeLoss.assign] END PYTORCH ASSIGNMENT DEBUG ---

[utils/util.py::ComputeLoss.__call__] Target bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Target scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] FG mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.__call__] Target scores sum: 0.372293
[utils/util.py::ComputeLoss.__call__] Classification loss computed: 9.820902
[utils/util.py::ComputeLoss.__call__] Foreground count: 41
[utils/util.py::ComputeLoss.__call__] Weight shape: torch.Size([41, 1])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([41, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([41, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([41, 1]), h: torch.Size([41, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([41, 1]), h: torch.Size([41, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([41, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([41, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([41, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.017158, max: 0.089562
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([41, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([41, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([41, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([41, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: 0.014533, max: 0.086258
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.__call__] IoU values shape: torch.Size([41, 1])
[utils/util.py::ComputeLoss.__call__] Box loss computed: 0.920098
[utils/util.py::ComputeLoss.__call__] Target LT-RB shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.df_loss] PYTORCH DFL LOSS DEBUG ---
[utils/util.py::ComputeLoss.df_loss] pred_dist shape: torch.Size([164, 16])
[utils/util.py::ComputeLoss.df_loss] target shape: torch.Size([41, 4])
[utils/util.py::ComputeLoss.df_loss] DFL loss shape: torch.Size([41, 1])
[utils/util.py::ComputeLoss.df_loss] DFL loss mean: 2.065193
--- [utils/util.py::ComputeLoss.df_loss] END PYTORCH DFL LOSS DEBUG ---

[utils/util.py::ComputeLoss.__call__] DFL loss before weighting: 2.065193
[utils/util.py::ComputeLoss.__call__] DFL loss computed: 1.969082

--- [utils/util.py::ComputeLoss.__call__] LOSS COMPONENTS DEBUG ---
[utils/util.py::ComputeLoss.__call__] Raw loss_cls: 9.820902
[utils/util.py::ComputeLoss.__call__] Raw loss_box: 0.920098
[utils/util.py::ComputeLoss.__call__] Raw loss_dfl: 1.969082
[utils/util.py::ComputeLoss.__call__] Loss weights - cls: 0.5, box: 7.5, dfl: 1.5
[utils/util.py::ComputeLoss.__call__] target_scores_sum: 0.372293
[utils/util.py::ComputeLoss.__call__] fg_mask sum: 41
[utils/util.py::ComputeLoss.__call__] Weighted loss_cls: 4.910451
[utils/util.py::ComputeLoss.__call__] Weighted loss_box: 6.900739
[utils/util.py::ComputeLoss.__call__] Weighted loss_dfl: 2.953624
[utils/util.py::ComputeLoss.__call__] Total loss: 14.764813
--- [utils/util.py::ComputeLoss.__call__] END PYTORCH LOSS COMPUTATION DEBUG ---


--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([4, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: True
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([4, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - box shape: torch.Size([4, 64, 16, 32]), cls shape: torch.Size([4, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - final concat shape: torch.Size([4, 65, 16, 32])

--- [utils/util.py::ComputeLoss.__call__] PYTORCH LOSS COMPUTATION DEBUG ---
[utils/util.py::ComputeLoss.__call__] Outputs type: <class 'list'>
[utils/util.py::ComputeLoss.__call__] x type: <class 'list'>, len: 1
[utils/util.py::ComputeLoss.__call__] x[0] shape: torch.Size([4, 65, 16, 32])
[utils/util.py::ComputeLoss.__call__] Concatenated output shape: torch.Size([4, 65, 512])
[utils/util.py::ComputeLoss.__call__] self.no: 65, self.dfl_ch: 16, self.nc: 1
[utils/util.py::ComputeLoss.__call__] pred_output shape: torch.Size([4, 64, 512])
[utils/util.py::ComputeLoss.__call__] pred_scores shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.__call__] After permute - pred_output shape: torch.Size([4, 512, 64])
[utils/util.py::ComputeLoss.__call__] After permute - pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Size tensor: tensor([128., 256.], device='cuda:0', dtype=torch.float16)
[utils/util.py::ComputeLoss.__call__] Stride: tensor([8.])
[utils/util.py::ComputeLoss.__call__] Anchor points shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.__call__] Stride tensor shape: torch.Size([512, 1])

--- [utils/util.py::ComputeLoss.__call__] TARGET PROCESSING ---
[utils/util.py::ComputeLoss.__call__] Targets shape: torch.Size([5, 6])
[utils/util.py::ComputeLoss.__call__] Targets dtype: torch.float32
[utils/util.py::ComputeLoss.__call__] First few targets: tensor([[0.0000, 0.0000, 0.9032, 0.4396, 0.0928, 0.2009],
        [1.0000, 0.0000, 0.3211, 0.7167, 0.1145, 0.2479],
        [2.0000, 0.0000, 0.7322, 0.3196, 0.0639, 0.1198],
        [2.0000, 0.0000, 0.8067, 0.2844, 0.0604, 0.1205],
        [3.0000, 0.0000, 0.9583, 0.0974, 0.0834, 0.1947]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Image indices: tensor([0., 1., 2., 2., 3.], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Counts per image: tensor([1, 1, 2, 1], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT tensor shape: torch.Size([4, 2, 5])
[utils/util.py::ComputeLoss.__call__] Image 0: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 1: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 2: 2 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 3: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] GT before coordinate conversion: tensor([[[0.0000, 0.9032, 0.4396, 0.0928, 0.2009],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.3211, 0.7167, 0.1145, 0.2479],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.7322, 0.3196, 0.0639, 0.1198],
         [0.0000, 0.8067, 0.2844, 0.0604, 0.1205]],

        [[0.0000, 0.9583, 0.0974, 0.0834, 0.1947],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT after coordinate conversion: tensor([[[  0.0000, 219.3466,  43.4147, 243.0984,  69.1256],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000,  67.5523,  75.8799,  96.8605, 107.6055],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000, 179.2552,  33.2389, 195.6159,  48.5780],
         [  0.0000, 198.7968,  28.6922, 214.2590,  44.1110]],

        [[  0.0000, 234.6378,   0.0000, 256.0000,  24.9234],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT labels shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.__call__] GT bboxes shape: torch.Size([4, 2, 4])
[utils/util.py::ComputeLoss.__call__] GT mask shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.__call__] Pred output dimensions - b: 4, a: 512, c: 64
[utils/util.py::ComputeLoss.__call__] Pred bboxes after softmax shape: torch.Size([4, 512, 4, 16])
[utils/util.py::ComputeLoss.__call__] Pred bboxes after matmul shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Final pred bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.__call__] ASSIGNMENT PHASE ---

--- [utils/util.py::ComputeLoss.assign] PYTORCH ASSIGNMENT DEBUG ---
[utils/util.py::ComputeLoss.assign] pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] true_labels shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 2, 4])
[utils/util.py::ComputeLoss.assign] true_mask shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.assign] anchors shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.assign] Batch size: 4, Max boxes: 2
[utils/util.py::ComputeLoss.assign] Created indices tensor with shape: torch.Size([2, 4, 2])

--- [utils/util.py::ComputeLoss.assign] IOUs DEBUG ---
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 2, 4])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([4, 2, 1, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([4, 1, 512, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([4, 2, 1, 1]), h: torch.Size([4, 2, 1, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([4, 1, 512, 1]), h: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.000000, max: 0.155511
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: -0.784564, max: 0.146441
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.assign] overlaps shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] overlaps min: 0.0, max: 0.1464405506849289
[utils/util.py::ComputeLoss.assign] align_metric shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] align_metric min: 0.0, max: 9.934499445307665e-08
[utils/util.py::ComputeLoss.assign] mask_in_gts shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] mask_in_gts sum: 45.0
[utils/util.py::ComputeLoss.assign] metrics shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] top_k_mask shape: torch.Size([4, 2, 10])
[utils/util.py::ComputeLoss.assign] top_k_metrics shape: torch.Size([4, 2, 10])
[utils/util.py::ComputeLoss.assign] top_k_indices shape: torch.Size([4, 2, 10])
[utils/util.py::ComputeLoss.assign] is_in_top_k shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] mask_top_k shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] mask_pos shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] fg_mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] fg_mask sum: 37.0
[utils/util.py::ComputeLoss.assign] target_gt_idx shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_labels shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] Normalized target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] target_scores sum: 1.7480778694152832
--- [utils/util.py::ComputeLoss.assign] END PYTORCH ASSIGNMENT DEBUG ---

[utils/util.py::ComputeLoss.__call__] Target bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Target scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] FG mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.__call__] Target scores sum: 1.748078
[utils/util.py::ComputeLoss.__call__] Classification loss computed: 9.278048
[utils/util.py::ComputeLoss.__call__] Foreground count: 37
[utils/util.py::ComputeLoss.__call__] Weight shape: torch.Size([37, 1])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([37, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([37, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([37, 1]), h: torch.Size([37, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([37, 1]), h: torch.Size([37, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([37, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([37, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([37, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.038330, max: 0.153842
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([37, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([37, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([37, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([37, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: 0.028900, max: 0.146442
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.__call__] IoU values shape: torch.Size([37, 1])
[utils/util.py::ComputeLoss.__call__] Box loss computed: 0.883040
[utils/util.py::ComputeLoss.__call__] Target LT-RB shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.df_loss] PYTORCH DFL LOSS DEBUG ---
[utils/util.py::ComputeLoss.df_loss] pred_dist shape: torch.Size([148, 16])
[utils/util.py::ComputeLoss.df_loss] target shape: torch.Size([37, 4])
[utils/util.py::ComputeLoss.df_loss] DFL loss shape: torch.Size([37, 1])
[utils/util.py::ComputeLoss.df_loss] DFL loss mean: 2.031160
--- [utils/util.py::ComputeLoss.df_loss] END PYTORCH DFL LOSS DEBUG ---

[utils/util.py::ComputeLoss.__call__] DFL loss before weighting: 2.031160
[utils/util.py::ComputeLoss.__call__] DFL loss computed: 1.948240

--- [utils/util.py::ComputeLoss.__call__] LOSS COMPONENTS DEBUG ---
[utils/util.py::ComputeLoss.__call__] Raw loss_cls: 9.278048
[utils/util.py::ComputeLoss.__call__] Raw loss_box: 0.883040
[utils/util.py::ComputeLoss.__call__] Raw loss_dfl: 1.948240
[utils/util.py::ComputeLoss.__call__] Loss weights - cls: 0.5, box: 7.5, dfl: 1.5
[utils/util.py::ComputeLoss.__call__] target_scores_sum: 1.748078
[utils/util.py::ComputeLoss.__call__] fg_mask sum: 37
[utils/util.py::ComputeLoss.__call__] Weighted loss_cls: 4.639024
[utils/util.py::ComputeLoss.__call__] Weighted loss_box: 6.622800
[utils/util.py::ComputeLoss.__call__] Weighted loss_dfl: 2.922360
[utils/util.py::ComputeLoss.__call__] Total loss: 14.184183
--- [utils/util.py::ComputeLoss.__call__] END PYTORCH LOSS COMPUTATION DEBUG ---


--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([4, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: True
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([4, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - box shape: torch.Size([4, 64, 16, 32]), cls shape: torch.Size([4, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - final concat shape: torch.Size([4, 65, 16, 32])

--- [utils/util.py::ComputeLoss.__call__] PYTORCH LOSS COMPUTATION DEBUG ---
[utils/util.py::ComputeLoss.__call__] Outputs type: <class 'list'>
[utils/util.py::ComputeLoss.__call__] x type: <class 'list'>, len: 1
[utils/util.py::ComputeLoss.__call__] x[0] shape: torch.Size([4, 65, 16, 32])
[utils/util.py::ComputeLoss.__call__] Concatenated output shape: torch.Size([4, 65, 512])
[utils/util.py::ComputeLoss.__call__] self.no: 65, self.dfl_ch: 16, self.nc: 1
[utils/util.py::ComputeLoss.__call__] pred_output shape: torch.Size([4, 64, 512])
[utils/util.py::ComputeLoss.__call__] pred_scores shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.__call__] After permute - pred_output shape: torch.Size([4, 512, 64])
[utils/util.py::ComputeLoss.__call__] After permute - pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Size tensor: tensor([128., 256.], device='cuda:0', dtype=torch.float16)
[utils/util.py::ComputeLoss.__call__] Stride: tensor([8.])
[utils/util.py::ComputeLoss.__call__] Anchor points shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.__call__] Stride tensor shape: torch.Size([512, 1])

--- [utils/util.py::ComputeLoss.__call__] TARGET PROCESSING ---
[utils/util.py::ComputeLoss.__call__] Targets shape: torch.Size([6, 6])
[utils/util.py::ComputeLoss.__call__] Targets dtype: torch.float32
[utils/util.py::ComputeLoss.__call__] First few targets: tensor([[0.0000, 0.0000, 0.4181, 0.4383, 0.1048, 0.2058],
        [1.0000, 0.0000, 0.8018, 0.2888, 0.0752, 0.1331],
        [1.0000, 0.0000, 0.3170, 0.0570, 0.0762, 0.1141],
        [1.0000, 0.0000, 0.8980, 0.8750, 0.0682, 0.1491],
        [2.0000, 0.0000, 0.1179, 0.0343, 0.1114, 0.0686]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Image indices: tensor([0., 1., 1., 1., 2., 3.], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Counts per image: tensor([1, 3, 1, 1], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT tensor shape: torch.Size([4, 3, 5])
[utils/util.py::ComputeLoss.__call__] Image 0: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 1: 3 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 2: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 3: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] GT before coordinate conversion: tensor([[[0.0000, 0.4181, 0.4383, 0.1048, 0.2058],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.8018, 0.2888, 0.0752, 0.1331],
         [0.0000, 0.3170, 0.0570, 0.0762, 0.1141],
         [0.0000, 0.8980, 0.8750, 0.0682, 0.1491]],

        [[0.0000, 0.1179, 0.0343, 0.1114, 0.0686],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.0463, 0.8071, 0.0925, 0.2961],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT after coordinate conversion: tensor([[[0.0000e+00, 9.3611e+01, 4.2928e+01, 1.2044e+02, 6.9268e+01],
         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],

        [[0.0000e+00, 1.9564e+02, 2.8446e+01, 2.1488e+02, 4.5486e+01],
         [0.0000e+00, 7.1388e+01, 0.0000e+00, 9.0901e+01, 1.4604e+01],
         [0.0000e+00, 2.2115e+02, 1.0246e+02, 2.3860e+02, 1.2154e+02]],

        [[0.0000e+00, 1.5927e+01, 0.0000e+00, 4.4451e+01, 8.7756e+00],
         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],

        [[0.0000e+00, 1.0071e-03, 8.4355e+01, 2.3679e+01, 1.2226e+02],
         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]]],
       device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT labels shape: torch.Size([4, 3, 1])
[utils/util.py::ComputeLoss.__call__] GT bboxes shape: torch.Size([4, 3, 4])
[utils/util.py::ComputeLoss.__call__] GT mask shape: torch.Size([4, 3, 1])
[utils/util.py::ComputeLoss.__call__] Pred output dimensions - b: 4, a: 512, c: 64
[utils/util.py::ComputeLoss.__call__] Pred bboxes after softmax shape: torch.Size([4, 512, 4, 16])
[utils/util.py::ComputeLoss.__call__] Pred bboxes after matmul shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Final pred bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.__call__] ASSIGNMENT PHASE ---

--- [utils/util.py::ComputeLoss.assign] PYTORCH ASSIGNMENT DEBUG ---
[utils/util.py::ComputeLoss.assign] pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] true_labels shape: torch.Size([4, 3, 1])
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 3, 4])
[utils/util.py::ComputeLoss.assign] true_mask shape: torch.Size([4, 3, 1])
[utils/util.py::ComputeLoss.assign] anchors shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.assign] Batch size: 4, Max boxes: 3
[utils/util.py::ComputeLoss.assign] Created indices tensor with shape: torch.Size([2, 4, 3])

--- [utils/util.py::ComputeLoss.assign] IOUs DEBUG ---
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 3, 4])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([4, 3, 1, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([4, 1, 512, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([4, 3, 1, 1]), h: torch.Size([4, 3, 1, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([4, 1, 512, 1]), h: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.000000, max: 0.179204
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: -0.808095, max: 0.174264
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.assign] overlaps shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] overlaps min: 0.0, max: 0.17426422238349915
[utils/util.py::ComputeLoss.assign] align_metric shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] align_metric min: 0.0, max: 3.471379557140608e-07
[utils/util.py::ComputeLoss.assign] mask_in_gts shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] mask_in_gts sum: 42.0
[utils/util.py::ComputeLoss.assign] metrics shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] top_k_mask shape: torch.Size([4, 3, 10])
[utils/util.py::ComputeLoss.assign] top_k_metrics shape: torch.Size([4, 3, 10])
[utils/util.py::ComputeLoss.assign] top_k_indices shape: torch.Size([4, 3, 10])
[utils/util.py::ComputeLoss.assign] is_in_top_k shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] mask_top_k shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] mask_pos shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] fg_mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] fg_mask sum: 38.0
[utils/util.py::ComputeLoss.assign] target_gt_idx shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_labels shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] Normalized target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] target_scores sum: 1.5299246311187744
--- [utils/util.py::ComputeLoss.assign] END PYTORCH ASSIGNMENT DEBUG ---

[utils/util.py::ComputeLoss.__call__] Target bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Target scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] FG mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.__call__] Target scores sum: 1.529925
[utils/util.py::ComputeLoss.__call__] Classification loss computed: 8.762687
[utils/util.py::ComputeLoss.__call__] Foreground count: 38
[utils/util.py::ComputeLoss.__call__] Weight shape: torch.Size([38, 1])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([38, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([38, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([38, 1]), h: torch.Size([38, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([38, 1]), h: torch.Size([38, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([38, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([38, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([38, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.045512, max: 0.179221
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([38, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([38, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([38, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([38, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: 0.023552, max: 0.174281
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.__call__] IoU values shape: torch.Size([38, 1])
[utils/util.py::ComputeLoss.__call__] Box loss computed: 0.869791
[utils/util.py::ComputeLoss.__call__] Target LT-RB shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.df_loss] PYTORCH DFL LOSS DEBUG ---
[utils/util.py::ComputeLoss.df_loss] pred_dist shape: torch.Size([152, 16])
[utils/util.py::ComputeLoss.df_loss] target shape: torch.Size([38, 4])
[utils/util.py::ComputeLoss.df_loss] DFL loss shape: torch.Size([38, 1])
[utils/util.py::ComputeLoss.df_loss] DFL loss mean: 1.992236
--- [utils/util.py::ComputeLoss.df_loss] END PYTORCH DFL LOSS DEBUG ---

[utils/util.py::ComputeLoss.__call__] DFL loss before weighting: 1.992236
[utils/util.py::ComputeLoss.__call__] DFL loss computed: 1.989457

--- [utils/util.py::ComputeLoss.__call__] LOSS COMPONENTS DEBUG ---
[utils/util.py::ComputeLoss.__call__] Raw loss_cls: 8.762687
[utils/util.py::ComputeLoss.__call__] Raw loss_box: 0.869791
[utils/util.py::ComputeLoss.__call__] Raw loss_dfl: 1.989457
[utils/util.py::ComputeLoss.__call__] Loss weights - cls: 0.5, box: 7.5, dfl: 1.5
[utils/util.py::ComputeLoss.__call__] target_scores_sum: 1.529925
[utils/util.py::ComputeLoss.__call__] fg_mask sum: 38
[utils/util.py::ComputeLoss.__call__] Weighted loss_cls: 4.381343
[utils/util.py::ComputeLoss.__call__] Weighted loss_box: 6.523433
[utils/util.py::ComputeLoss.__call__] Weighted loss_dfl: 2.984185
[utils/util.py::ComputeLoss.__call__] Total loss: 13.888962
--- [utils/util.py::ComputeLoss.__call__] END PYTORCH LOSS COMPUTATION DEBUG ---


--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([4, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: True
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([4, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - box shape: torch.Size([4, 64, 16, 32]), cls shape: torch.Size([4, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - final concat shape: torch.Size([4, 65, 16, 32])

--- [utils/util.py::ComputeLoss.__call__] PYTORCH LOSS COMPUTATION DEBUG ---
[utils/util.py::ComputeLoss.__call__] Outputs type: <class 'list'>
[utils/util.py::ComputeLoss.__call__] x type: <class 'list'>, len: 1
[utils/util.py::ComputeLoss.__call__] x[0] shape: torch.Size([4, 65, 16, 32])
[utils/util.py::ComputeLoss.__call__] Concatenated output shape: torch.Size([4, 65, 512])
[utils/util.py::ComputeLoss.__call__] self.no: 65, self.dfl_ch: 16, self.nc: 1
[utils/util.py::ComputeLoss.__call__] pred_output shape: torch.Size([4, 64, 512])
[utils/util.py::ComputeLoss.__call__] pred_scores shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.__call__] After permute - pred_output shape: torch.Size([4, 512, 64])
[utils/util.py::ComputeLoss.__call__] After permute - pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Size tensor: tensor([128., 256.], device='cuda:0', dtype=torch.float16)
[utils/util.py::ComputeLoss.__call__] Stride: tensor([8.])
[utils/util.py::ComputeLoss.__call__] Anchor points shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.__call__] Stride tensor shape: torch.Size([512, 1])

--- [utils/util.py::ComputeLoss.__call__] TARGET PROCESSING ---
[utils/util.py::ComputeLoss.__call__] Targets shape: torch.Size([2, 6])
[utils/util.py::ComputeLoss.__call__] Targets dtype: torch.float32
[utils/util.py::ComputeLoss.__call__] First few targets: tensor([[2.0000, 0.0000, 0.6539, 0.8512, 0.1135, 0.2233],
        [3.0000, 0.0000, 0.3044, 0.6724, 0.1246, 0.2440]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Image indices: tensor([2., 3.], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Counts per image: tensor([1, 1], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT tensor shape: torch.Size([4, 1, 5])
[utils/util.py::ComputeLoss.__call__] Image 2: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 3: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] GT before coordinate conversion: tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.6539, 0.8512, 0.1135, 0.2233]],

        [[0.0000, 0.3044, 0.6724, 0.1246, 0.2440]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT after coordinate conversion: tensor([[[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000, 152.8638,  94.6586, 181.9122, 123.2393]],

        [[  0.0000,  61.9852,  70.4456,  93.8744, 101.6765]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT labels shape: torch.Size([4, 1, 1])
[utils/util.py::ComputeLoss.__call__] GT bboxes shape: torch.Size([4, 1, 4])
[utils/util.py::ComputeLoss.__call__] GT mask shape: torch.Size([4, 1, 1])
[utils/util.py::ComputeLoss.__call__] Pred output dimensions - b: 4, a: 512, c: 64
[utils/util.py::ComputeLoss.__call__] Pred bboxes after softmax shape: torch.Size([4, 512, 4, 16])
[utils/util.py::ComputeLoss.__call__] Pred bboxes after matmul shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Final pred bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.__call__] ASSIGNMENT PHASE ---

--- [utils/util.py::ComputeLoss.assign] PYTORCH ASSIGNMENT DEBUG ---
[utils/util.py::ComputeLoss.assign] pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] true_labels shape: torch.Size([4, 1, 1])
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 1, 4])
[utils/util.py::ComputeLoss.assign] true_mask shape: torch.Size([4, 1, 1])
[utils/util.py::ComputeLoss.assign] anchors shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.assign] Batch size: 4, Max boxes: 1
[utils/util.py::ComputeLoss.assign] Created indices tensor with shape: torch.Size([2, 4, 1])

--- [utils/util.py::ComputeLoss.assign] IOUs DEBUG ---
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 1, 4])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([4, 1, 1, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([4, 1, 512, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([4, 1, 1, 1]), h: torch.Size([4, 1, 1, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([4, 1, 512, 1]), h: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.000000, max: 0.247511
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: -0.799309, max: 0.196039
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.assign] overlaps shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.assign] overlaps min: 0.0, max: 0.19603948295116425
[utils/util.py::ComputeLoss.assign] align_metric shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.assign] align_metric min: 0.0, max: 1.0016078704211395e-06
[utils/util.py::ComputeLoss.assign] mask_in_gts shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.assign] mask_in_gts sum: 28.0
[utils/util.py::ComputeLoss.assign] metrics shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.assign] top_k_mask shape: torch.Size([4, 1, 10])
[utils/util.py::ComputeLoss.assign] top_k_metrics shape: torch.Size([4, 1, 10])
[utils/util.py::ComputeLoss.assign] top_k_indices shape: torch.Size([4, 1, 10])
[utils/util.py::ComputeLoss.assign] is_in_top_k shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.assign] mask_top_k shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.assign] mask_pos shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.assign] fg_mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] fg_mask sum: 20.0
[utils/util.py::ComputeLoss.assign] target_gt_idx shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_labels shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] Normalized target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] target_scores sum: 2.0003480911254883
--- [utils/util.py::ComputeLoss.assign] END PYTORCH ASSIGNMENT DEBUG ---

[utils/util.py::ComputeLoss.__call__] Target bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Target scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] FG mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.__call__] Target scores sum: 2.000348
[utils/util.py::ComputeLoss.__call__] Classification loss computed: 8.529765
[utils/util.py::ComputeLoss.__call__] Foreground count: 20
[utils/util.py::ComputeLoss.__call__] Weight shape: torch.Size([20, 1])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([20, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([20, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([20, 1]), h: torch.Size([20, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([20, 1]), h: torch.Size([20, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([20, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([20, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([20, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.157478, max: 0.201605
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([20, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([20, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([20, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([20, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: 0.142587, max: 0.195877
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.__call__] IoU values shape: torch.Size([20, 1])
[utils/util.py::ComputeLoss.__call__] Box loss computed: 0.824882
[utils/util.py::ComputeLoss.__call__] Target LT-RB shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.df_loss] PYTORCH DFL LOSS DEBUG ---
[utils/util.py::ComputeLoss.df_loss] pred_dist shape: torch.Size([80, 16])
[utils/util.py::ComputeLoss.df_loss] target shape: torch.Size([20, 4])
[utils/util.py::ComputeLoss.df_loss] DFL loss shape: torch.Size([20, 1])
[utils/util.py::ComputeLoss.df_loss] DFL loss mean: 1.931396
--- [utils/util.py::ComputeLoss.df_loss] END PYTORCH DFL LOSS DEBUG ---

[utils/util.py::ComputeLoss.__call__] DFL loss before weighting: 1.931396
[utils/util.py::ComputeLoss.__call__] DFL loss computed: 1.899739

--- [utils/util.py::ComputeLoss.__call__] LOSS COMPONENTS DEBUG ---
[utils/util.py::ComputeLoss.__call__] Raw loss_cls: 8.529765
[utils/util.py::ComputeLoss.__call__] Raw loss_box: 0.824882
[utils/util.py::ComputeLoss.__call__] Raw loss_dfl: 1.899739
[utils/util.py::ComputeLoss.__call__] Loss weights - cls: 0.5, box: 7.5, dfl: 1.5
[utils/util.py::ComputeLoss.__call__] target_scores_sum: 2.000348
[utils/util.py::ComputeLoss.__call__] fg_mask sum: 20
[utils/util.py::ComputeLoss.__call__] Weighted loss_cls: 4.264883
[utils/util.py::ComputeLoss.__call__] Weighted loss_box: 6.186617
[utils/util.py::ComputeLoss.__call__] Weighted loss_dfl: 2.849608
[utils/util.py::ComputeLoss.__call__] Total loss: 13.301107
--- [utils/util.py::ComputeLoss.__call__] END PYTORCH LOSS COMPUTATION DEBUG ---


--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([4, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: True
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([4, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - box shape: torch.Size([4, 64, 16, 32]), cls shape: torch.Size([4, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - final concat shape: torch.Size([4, 65, 16, 32])

--- [utils/util.py::ComputeLoss.__call__] PYTORCH LOSS COMPUTATION DEBUG ---
[utils/util.py::ComputeLoss.__call__] Outputs type: <class 'list'>
[utils/util.py::ComputeLoss.__call__] x type: <class 'list'>, len: 1
[utils/util.py::ComputeLoss.__call__] x[0] shape: torch.Size([4, 65, 16, 32])
[utils/util.py::ComputeLoss.__call__] Concatenated output shape: torch.Size([4, 65, 512])
[utils/util.py::ComputeLoss.__call__] self.no: 65, self.dfl_ch: 16, self.nc: 1
[utils/util.py::ComputeLoss.__call__] pred_output shape: torch.Size([4, 64, 512])
[utils/util.py::ComputeLoss.__call__] pred_scores shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.__call__] After permute - pred_output shape: torch.Size([4, 512, 64])
[utils/util.py::ComputeLoss.__call__] After permute - pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Size tensor: tensor([128., 256.], device='cuda:0', dtype=torch.float16)
[utils/util.py::ComputeLoss.__call__] Stride: tensor([8.])
[utils/util.py::ComputeLoss.__call__] Anchor points shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.__call__] Stride tensor shape: torch.Size([512, 1])

--- [utils/util.py::ComputeLoss.__call__] TARGET PROCESSING ---
[utils/util.py::ComputeLoss.__call__] Targets shape: torch.Size([5, 6])
[utils/util.py::ComputeLoss.__call__] Targets dtype: torch.float32
[utils/util.py::ComputeLoss.__call__] First few targets: tensor([[0.0000, 0.0000, 0.5567, 0.1430, 0.1579, 0.2861],
        [1.0000, 0.0000, 0.4981, 0.0909, 0.0955, 0.1817],
        [2.0000, 0.0000, 0.0863, 0.4118, 0.0592, 0.1225],
        [2.0000, 0.0000, 0.8935, 0.4411, 0.0657, 0.1278],
        [3.0000, 0.0000, 0.6022, 0.2903, 0.1300, 0.2545]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Image indices: tensor([0., 1., 2., 2., 3.], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Counts per image: tensor([1, 1, 2, 1], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT tensor shape: torch.Size([4, 2, 5])
[utils/util.py::ComputeLoss.__call__] Image 0: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 1: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 2: 2 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 3: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] GT before coordinate conversion: tensor([[[0.0000, 0.5567, 0.1430, 0.1579, 0.2861],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.4981, 0.0909, 0.0955, 0.1817],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.0863, 0.4118, 0.0592, 0.1225],
         [0.0000, 0.8935, 0.4411, 0.0657, 0.1278]],

        [[0.0000, 0.6022, 0.2903, 0.1300, 0.2545],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT after coordinate conversion: tensor([[[  0.0000, 122.2982,   0.0000, 162.7303,  36.6186],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000, 115.2760,   0.0000, 139.7326,  23.2589],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000,  14.5141,  44.8765,  29.6676,  60.5548],
         [  0.0000, 220.3200,  48.2848, 237.1436,  64.6448]],

        [[  0.0000, 137.5388,  20.8682, 170.8098,  53.4435],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT labels shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.__call__] GT bboxes shape: torch.Size([4, 2, 4])
[utils/util.py::ComputeLoss.__call__] GT mask shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.__call__] Pred output dimensions - b: 4, a: 512, c: 64
[utils/util.py::ComputeLoss.__call__] Pred bboxes after softmax shape: torch.Size([4, 512, 4, 16])
[utils/util.py::ComputeLoss.__call__] Pred bboxes after matmul shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Final pred bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.__call__] ASSIGNMENT PHASE ---

--- [utils/util.py::ComputeLoss.assign] PYTORCH ASSIGNMENT DEBUG ---
[utils/util.py::ComputeLoss.assign] pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] true_labels shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 2, 4])
[utils/util.py::ComputeLoss.assign] true_mask shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.assign] anchors shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.assign] Batch size: 4, Max boxes: 2
[utils/util.py::ComputeLoss.assign] Created indices tensor with shape: torch.Size([2, 4, 2])

--- [utils/util.py::ComputeLoss.assign] IOUs DEBUG ---
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 2, 4])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([4, 2, 1, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([4, 1, 512, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([4, 2, 1, 1]), h: torch.Size([4, 2, 1, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([4, 1, 512, 1]), h: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.000000, max: 0.368810
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: -0.804230, max: 0.355825
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.assign] overlaps shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] overlaps min: 0.0, max: 0.3558254837989807
[utils/util.py::ComputeLoss.assign] align_metric shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] align_metric min: 0.0, max: 5.091481580166146e-05
[utils/util.py::ComputeLoss.assign] mask_in_gts shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] mask_in_gts sum: 58.0
[utils/util.py::ComputeLoss.assign] metrics shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] top_k_mask shape: torch.Size([4, 2, 10])
[utils/util.py::ComputeLoss.assign] top_k_metrics shape: torch.Size([4, 2, 10])
[utils/util.py::ComputeLoss.assign] top_k_indices shape: torch.Size([4, 2, 10])
[utils/util.py::ComputeLoss.assign] is_in_top_k shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] mask_top_k shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] mask_pos shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] fg_mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] fg_mask sum: 37.0
[utils/util.py::ComputeLoss.assign] target_gt_idx shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_labels shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] Normalized target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] target_scores sum: 3.095933437347412
--- [utils/util.py::ComputeLoss.assign] END PYTORCH ASSIGNMENT DEBUG ---

[utils/util.py::ComputeLoss.__call__] Target bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Target scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] FG mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.__call__] Target scores sum: 3.095933
[utils/util.py::ComputeLoss.__call__] Classification loss computed: 7.858090
[utils/util.py::ComputeLoss.__call__] Foreground count: 37
[utils/util.py::ComputeLoss.__call__] Weight shape: torch.Size([37, 1])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([37, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([37, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([37, 1]), h: torch.Size([37, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([37, 1]), h: torch.Size([37, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([37, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([37, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([37, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.044450, max: 0.369035
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([37, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([37, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([37, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([37, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: 0.033266, max: 0.355865
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.__call__] IoU values shape: torch.Size([37, 1])
[utils/util.py::ComputeLoss.__call__] Box loss computed: 0.737174
[utils/util.py::ComputeLoss.__call__] Target LT-RB shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.df_loss] PYTORCH DFL LOSS DEBUG ---
[utils/util.py::ComputeLoss.df_loss] pred_dist shape: torch.Size([148, 16])
[utils/util.py::ComputeLoss.df_loss] target shape: torch.Size([37, 4])
[utils/util.py::ComputeLoss.df_loss] DFL loss shape: torch.Size([37, 1])
[utils/util.py::ComputeLoss.df_loss] DFL loss mean: 2.033076
--- [utils/util.py::ComputeLoss.df_loss] END PYTORCH DFL LOSS DEBUG ---

[utils/util.py::ComputeLoss.__call__] DFL loss before weighting: 2.033076
[utils/util.py::ComputeLoss.__call__] DFL loss computed: 2.057060

--- [utils/util.py::ComputeLoss.__call__] LOSS COMPONENTS DEBUG ---
[utils/util.py::ComputeLoss.__call__] Raw loss_cls: 7.858090
[utils/util.py::ComputeLoss.__call__] Raw loss_box: 0.737174
[utils/util.py::ComputeLoss.__call__] Raw loss_dfl: 2.057060
[utils/util.py::ComputeLoss.__call__] Loss weights - cls: 0.5, box: 7.5, dfl: 1.5
[utils/util.py::ComputeLoss.__call__] target_scores_sum: 3.095933
[utils/util.py::ComputeLoss.__call__] fg_mask sum: 37
[utils/util.py::ComputeLoss.__call__] Weighted loss_cls: 3.929045
[utils/util.py::ComputeLoss.__call__] Weighted loss_box: 5.528806
[utils/util.py::ComputeLoss.__call__] Weighted loss_dfl: 3.085591
[utils/util.py::ComputeLoss.__call__] Total loss: 12.543442
--- [utils/util.py::ComputeLoss.__call__] END PYTORCH LOSS COMPUTATION DEBUG ---


--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([4, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: True
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([4, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - box shape: torch.Size([4, 64, 16, 32]), cls shape: torch.Size([4, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - final concat shape: torch.Size([4, 65, 16, 32])

--- [utils/util.py::ComputeLoss.__call__] PYTORCH LOSS COMPUTATION DEBUG ---
[utils/util.py::ComputeLoss.__call__] Outputs type: <class 'list'>
[utils/util.py::ComputeLoss.__call__] x type: <class 'list'>, len: 1
[utils/util.py::ComputeLoss.__call__] x[0] shape: torch.Size([4, 65, 16, 32])
[utils/util.py::ComputeLoss.__call__] Concatenated output shape: torch.Size([4, 65, 512])
[utils/util.py::ComputeLoss.__call__] self.no: 65, self.dfl_ch: 16, self.nc: 1
[utils/util.py::ComputeLoss.__call__] pred_output shape: torch.Size([4, 64, 512])
[utils/util.py::ComputeLoss.__call__] pred_scores shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.__call__] After permute - pred_output shape: torch.Size([4, 512, 64])
[utils/util.py::ComputeLoss.__call__] After permute - pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Size tensor: tensor([128., 256.], device='cuda:0', dtype=torch.float16)
[utils/util.py::ComputeLoss.__call__] Stride: tensor([8.])
[utils/util.py::ComputeLoss.__call__] Anchor points shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.__call__] Stride tensor shape: torch.Size([512, 1])

--- [utils/util.py::ComputeLoss.__call__] TARGET PROCESSING ---
[utils/util.py::ComputeLoss.__call__] Targets shape: torch.Size([7, 6])
[utils/util.py::ComputeLoss.__call__] Targets dtype: torch.float32
[utils/util.py::ComputeLoss.__call__] First few targets: tensor([[0.0000, 0.0000, 0.0956, 0.7335, 0.1402, 0.2837],
        [1.0000, 0.0000, 0.0123, 0.2995, 0.0245, 0.1969],
        [1.0000, 0.0000, 0.9819, 0.9573, 0.0361, 0.0854],
        [2.0000, 0.0000, 0.1354, 0.0868, 0.0706, 0.1522],
        [2.0000, 0.0000, 0.9001, 0.8547, 0.0755, 0.1456]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Image indices: tensor([0., 1., 1., 2., 2., 2., 3.], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Counts per image: tensor([1, 2, 3, 1], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT tensor shape: torch.Size([4, 3, 5])
[utils/util.py::ComputeLoss.__call__] Image 0: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 1: 2 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 2: 3 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 3: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] GT before coordinate conversion: tensor([[[0.0000, 0.0956, 0.7335, 0.1402, 0.2837],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.0123, 0.2995, 0.0245, 0.1969],
         [0.0000, 0.9819, 0.9573, 0.0361, 0.0854],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.1354, 0.0868, 0.0706, 0.1522],
         [0.0000, 0.9001, 0.8547, 0.0755, 0.1456],
         [0.0000, 0.4644, 0.8341, 0.0600, 0.1105]],

        [[0.0000, 0.0330, 0.1517, 0.0660, 0.2329],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT after coordinate conversion: tensor([[[  0.0000,   6.5420,  75.7337,  42.4241, 112.0437],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000,   0.0000,  25.7404,   6.2795,  50.9402],
         [  0.0000, 246.7572, 117.0723, 255.9990, 127.9990],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000,  25.6346,   1.3774,  43.7053,  20.8559],
         [  0.0000, 220.7558, 100.0866, 240.0732, 118.7246],
         [  0.0000, 111.2147,  99.6909, 126.5747, 113.8392]],

        [[  0.0000,   0.0000,   4.5151,  16.8996,  34.3288],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT labels shape: torch.Size([4, 3, 1])
[utils/util.py::ComputeLoss.__call__] GT bboxes shape: torch.Size([4, 3, 4])
[utils/util.py::ComputeLoss.__call__] GT mask shape: torch.Size([4, 3, 1])
[utils/util.py::ComputeLoss.__call__] Pred output dimensions - b: 4, a: 512, c: 64
[utils/util.py::ComputeLoss.__call__] Pred bboxes after softmax shape: torch.Size([4, 512, 4, 16])
[utils/util.py::ComputeLoss.__call__] Pred bboxes after matmul shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Final pred bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.__call__] ASSIGNMENT PHASE ---

--- [utils/util.py::ComputeLoss.assign] PYTORCH ASSIGNMENT DEBUG ---
[utils/util.py::ComputeLoss.assign] pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] true_labels shape: torch.Size([4, 3, 1])
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 3, 4])
[utils/util.py::ComputeLoss.assign] true_mask shape: torch.Size([4, 3, 1])
[utils/util.py::ComputeLoss.assign] anchors shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.assign] Batch size: 4, Max boxes: 3
[utils/util.py::ComputeLoss.assign] Created indices tensor with shape: torch.Size([2, 4, 3])

--- [utils/util.py::ComputeLoss.assign] IOUs DEBUG ---
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 3, 4])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([4, 3, 1, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([4, 1, 512, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([4, 3, 1, 1]), h: torch.Size([4, 3, 1, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([4, 1, 512, 1]), h: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.000000, max: 0.353096
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: -0.857448, max: 0.351672
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.assign] overlaps shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] overlaps min: 0.0, max: 0.3516715168952942
[utils/util.py::ComputeLoss.assign] align_metric shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] align_metric min: 0.0, max: 4.837458618567325e-05
[utils/util.py::ComputeLoss.assign] mask_in_gts shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] mask_in_gts sum: 44.0
[utils/util.py::ComputeLoss.assign] metrics shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] top_k_mask shape: torch.Size([4, 3, 10])
[utils/util.py::ComputeLoss.assign] top_k_metrics shape: torch.Size([4, 3, 10])
[utils/util.py::ComputeLoss.assign] top_k_indices shape: torch.Size([4, 3, 10])
[utils/util.py::ComputeLoss.assign] is_in_top_k shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] mask_top_k shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] mask_pos shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] fg_mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] fg_mask sum: 34.0
[utils/util.py::ComputeLoss.assign] target_gt_idx shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_labels shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] Normalized target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] target_scores sum: 2.2531590461730957
--- [utils/util.py::ComputeLoss.assign] END PYTORCH ASSIGNMENT DEBUG ---

[utils/util.py::ComputeLoss.__call__] Target bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Target scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] FG mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.__call__] Target scores sum: 2.253159
[utils/util.py::ComputeLoss.__call__] Classification loss computed: 7.614309
[utils/util.py::ComputeLoss.__call__] Foreground count: 34
[utils/util.py::ComputeLoss.__call__] Weight shape: torch.Size([34, 1])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([34, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([34, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([34, 1]), h: torch.Size([34, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([34, 1]), h: torch.Size([34, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([34, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([34, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([34, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.023332, max: 0.353084
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([34, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([34, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([34, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([34, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: 0.012986, max: 0.351659
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.__call__] IoU values shape: torch.Size([34, 1])
[utils/util.py::ComputeLoss.__call__] Box loss computed: 0.756154
[utils/util.py::ComputeLoss.__call__] Target LT-RB shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.df_loss] PYTORCH DFL LOSS DEBUG ---
[utils/util.py::ComputeLoss.df_loss] pred_dist shape: torch.Size([136, 16])
[utils/util.py::ComputeLoss.df_loss] target shape: torch.Size([34, 4])
[utils/util.py::ComputeLoss.df_loss] DFL loss shape: torch.Size([34, 1])
[utils/util.py::ComputeLoss.df_loss] DFL loss mean: 1.841178
--- [utils/util.py::ComputeLoss.df_loss] END PYTORCH DFL LOSS DEBUG ---

[utils/util.py::ComputeLoss.__call__] DFL loss before weighting: 1.841178
[utils/util.py::ComputeLoss.__call__] DFL loss computed: 1.841875

--- [utils/util.py::ComputeLoss.__call__] LOSS COMPONENTS DEBUG ---
[utils/util.py::ComputeLoss.__call__] Raw loss_cls: 7.614309
[utils/util.py::ComputeLoss.__call__] Raw loss_box: 0.756154
[utils/util.py::ComputeLoss.__call__] Raw loss_dfl: 1.841875
[utils/util.py::ComputeLoss.__call__] Loss weights - cls: 0.5, box: 7.5, dfl: 1.5
[utils/util.py::ComputeLoss.__call__] target_scores_sum: 2.253159
[utils/util.py::ComputeLoss.__call__] fg_mask sum: 34
[utils/util.py::ComputeLoss.__call__] Weighted loss_cls: 3.807155
[utils/util.py::ComputeLoss.__call__] Weighted loss_box: 5.671157
[utils/util.py::ComputeLoss.__call__] Weighted loss_dfl: 2.762812
[utils/util.py::ComputeLoss.__call__] Total loss: 12.241123
--- [utils/util.py::ComputeLoss.__call__] END PYTORCH LOSS COMPUTATION DEBUG ---


--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([4, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: True
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([4, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - box shape: torch.Size([4, 64, 16, 32]), cls shape: torch.Size([4, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - final concat shape: torch.Size([4, 65, 16, 32])

--- [utils/util.py::ComputeLoss.__call__] PYTORCH LOSS COMPUTATION DEBUG ---
[utils/util.py::ComputeLoss.__call__] Outputs type: <class 'list'>
[utils/util.py::ComputeLoss.__call__] x type: <class 'list'>, len: 1
[utils/util.py::ComputeLoss.__call__] x[0] shape: torch.Size([4, 65, 16, 32])
[utils/util.py::ComputeLoss.__call__] Concatenated output shape: torch.Size([4, 65, 512])
[utils/util.py::ComputeLoss.__call__] self.no: 65, self.dfl_ch: 16, self.nc: 1
[utils/util.py::ComputeLoss.__call__] pred_output shape: torch.Size([4, 64, 512])
[utils/util.py::ComputeLoss.__call__] pred_scores shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.__call__] After permute - pred_output shape: torch.Size([4, 512, 64])
[utils/util.py::ComputeLoss.__call__] After permute - pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Size tensor: tensor([128., 256.], device='cuda:0', dtype=torch.float16)
[utils/util.py::ComputeLoss.__call__] Stride: tensor([8.])
[utils/util.py::ComputeLoss.__call__] Anchor points shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.__call__] Stride tensor shape: torch.Size([512, 1])

--- [utils/util.py::ComputeLoss.__call__] TARGET PROCESSING ---
[utils/util.py::ComputeLoss.__call__] Targets shape: torch.Size([6, 6])
[utils/util.py::ComputeLoss.__call__] Targets dtype: torch.float32
[utils/util.py::ComputeLoss.__call__] First few targets: tensor([[0.0000, 0.0000, 0.5777, 0.6004, 0.1035, 0.1989],
        [0.0000, 0.0000, 0.0242, 0.4393, 0.0484, 0.1741],
        [1.0000, 0.0000, 0.8894, 0.2096, 0.0753, 0.1590],
        [2.0000, 0.0000, 0.6376, 0.3497, 0.0678, 0.1418],
        [2.0000, 0.0000, 0.3865, 0.3324, 0.0745, 0.1440]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Image indices: tensor([0., 0., 1., 2., 2., 3.], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Counts per image: tensor([2, 1, 2, 1], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT tensor shape: torch.Size([4, 2, 5])
[utils/util.py::ComputeLoss.__call__] Image 0: 2 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 1: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 2: 2 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 3: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] GT before coordinate conversion: tensor([[[0.0000, 0.5777, 0.6004, 0.1035, 0.1989],
         [0.0000, 0.0242, 0.4393, 0.0484, 0.1741]],

        [[0.0000, 0.8894, 0.2096, 0.0753, 0.1590],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.6376, 0.3497, 0.0678, 0.1418],
         [0.0000, 0.3865, 0.3324, 0.0745, 0.1440]],

        [[0.0000, 0.8668, 0.6542, 0.0825, 0.1667],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT after coordinate conversion: tensor([[[0.0000e+00, 1.3464e+02, 6.4118e+01, 1.6114e+02, 8.9575e+01],
         [0.0000e+00, 1.0071e-03, 4.5085e+01, 1.2386e+01, 6.7367e+01]],

        [[0.0000e+00, 2.1805e+02, 1.6652e+01, 2.3733e+02, 3.7009e+01],
         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],

        [[0.0000e+00, 1.5455e+02, 3.5682e+01, 1.7191e+02, 5.3837e+01],
         [0.0000e+00, 8.9404e+01, 3.3334e+01, 1.0847e+02, 5.1768e+01]],

        [[0.0000e+00, 2.1135e+02, 7.3073e+01, 2.3246e+02, 9.4411e+01],
         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]]],
       device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT labels shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.__call__] GT bboxes shape: torch.Size([4, 2, 4])
[utils/util.py::ComputeLoss.__call__] GT mask shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.__call__] Pred output dimensions - b: 4, a: 512, c: 64
[utils/util.py::ComputeLoss.__call__] Pred bboxes after softmax shape: torch.Size([4, 512, 4, 16])
[utils/util.py::ComputeLoss.__call__] Pred bboxes after matmul shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Final pred bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.__call__] ASSIGNMENT PHASE ---

--- [utils/util.py::ComputeLoss.assign] PYTORCH ASSIGNMENT DEBUG ---
[utils/util.py::ComputeLoss.assign] pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] true_labels shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 2, 4])
[utils/util.py::ComputeLoss.assign] true_mask shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.assign] anchors shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.assign] Batch size: 4, Max boxes: 2
[utils/util.py::ComputeLoss.assign] Created indices tensor with shape: torch.Size([2, 4, 2])

--- [utils/util.py::ComputeLoss.assign] IOUs DEBUG ---
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 2, 4])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([4, 2, 1, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([4, 1, 512, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([4, 2, 1, 1]), h: torch.Size([4, 2, 1, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([4, 1, 512, 1]), h: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.000000, max: 0.193136
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: -0.880266, max: 0.181385
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.assign] overlaps shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] overlaps min: 0.0, max: 0.18138465285301208
[utils/util.py::ComputeLoss.assign] align_metric shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] align_metric min: 0.0, max: 8.324958571392926e-07
[utils/util.py::ComputeLoss.assign] mask_in_gts shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] mask_in_gts sum: 43.0
[utils/util.py::ComputeLoss.assign] metrics shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] top_k_mask shape: torch.Size([4, 2, 10])
[utils/util.py::ComputeLoss.assign] top_k_metrics shape: torch.Size([4, 2, 10])
[utils/util.py::ComputeLoss.assign] top_k_indices shape: torch.Size([4, 2, 10])
[utils/util.py::ComputeLoss.assign] is_in_top_k shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] mask_top_k shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] mask_pos shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] fg_mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] fg_mask sum: 43.0
[utils/util.py::ComputeLoss.assign] target_gt_idx shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_labels shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] Normalized target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] target_scores sum: 2.455564498901367
--- [utils/util.py::ComputeLoss.assign] END PYTORCH ASSIGNMENT DEBUG ---

[utils/util.py::ComputeLoss.__call__] Target bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Target scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] FG mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.__call__] Target scores sum: 2.455564
[utils/util.py::ComputeLoss.__call__] Classification loss computed: 7.387558
[utils/util.py::ComputeLoss.__call__] Foreground count: 43
[utils/util.py::ComputeLoss.__call__] Weight shape: torch.Size([43, 1])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([43, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([43, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([43, 1]), h: torch.Size([43, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([43, 1]), h: torch.Size([43, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([43, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([43, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([43, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.069408, max: 0.188065
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([43, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([43, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([43, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([43, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: 0.058196, max: 0.181364
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.__call__] IoU values shape: torch.Size([43, 1])
[utils/util.py::ComputeLoss.__call__] Box loss computed: 0.875785
[utils/util.py::ComputeLoss.__call__] Target LT-RB shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.df_loss] PYTORCH DFL LOSS DEBUG ---
[utils/util.py::ComputeLoss.df_loss] pred_dist shape: torch.Size([172, 16])
[utils/util.py::ComputeLoss.df_loss] target shape: torch.Size([43, 4])
[utils/util.py::ComputeLoss.df_loss] DFL loss shape: torch.Size([43, 1])
[utils/util.py::ComputeLoss.df_loss] DFL loss mean: 1.802796
--- [utils/util.py::ComputeLoss.df_loss] END PYTORCH DFL LOSS DEBUG ---

[utils/util.py::ComputeLoss.__call__] DFL loss before weighting: 1.802796
[utils/util.py::ComputeLoss.__call__] DFL loss computed: 1.744062

--- [utils/util.py::ComputeLoss.__call__] LOSS COMPONENTS DEBUG ---
[utils/util.py::ComputeLoss.__call__] Raw loss_cls: 7.387558
[utils/util.py::ComputeLoss.__call__] Raw loss_box: 0.875785
[utils/util.py::ComputeLoss.__call__] Raw loss_dfl: 1.744062
[utils/util.py::ComputeLoss.__call__] Loss weights - cls: 0.5, box: 7.5, dfl: 1.5
[utils/util.py::ComputeLoss.__call__] target_scores_sum: 2.455564
[utils/util.py::ComputeLoss.__call__] fg_mask sum: 43
[utils/util.py::ComputeLoss.__call__] Weighted loss_cls: 3.693779
[utils/util.py::ComputeLoss.__call__] Weighted loss_box: 6.568390
[utils/util.py::ComputeLoss.__call__] Weighted loss_dfl: 2.616093
[utils/util.py::ComputeLoss.__call__] Total loss: 12.878262
--- [utils/util.py::ComputeLoss.__call__] END PYTORCH LOSS COMPUTATION DEBUG ---


--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([4, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: True
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([4, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - box shape: torch.Size([4, 64, 16, 32]), cls shape: torch.Size([4, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - final concat shape: torch.Size([4, 65, 16, 32])

--- [utils/util.py::ComputeLoss.__call__] PYTORCH LOSS COMPUTATION DEBUG ---
[utils/util.py::ComputeLoss.__call__] Outputs type: <class 'list'>
[utils/util.py::ComputeLoss.__call__] x type: <class 'list'>, len: 1
[utils/util.py::ComputeLoss.__call__] x[0] shape: torch.Size([4, 65, 16, 32])
[utils/util.py::ComputeLoss.__call__] Concatenated output shape: torch.Size([4, 65, 512])
[utils/util.py::ComputeLoss.__call__] self.no: 65, self.dfl_ch: 16, self.nc: 1
[utils/util.py::ComputeLoss.__call__] pred_output shape: torch.Size([4, 64, 512])
[utils/util.py::ComputeLoss.__call__] pred_scores shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.__call__] After permute - pred_output shape: torch.Size([4, 512, 64])
[utils/util.py::ComputeLoss.__call__] After permute - pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Size tensor: tensor([128., 256.], device='cuda:0', dtype=torch.float16)
[utils/util.py::ComputeLoss.__call__] Stride: tensor([8.])
[utils/util.py::ComputeLoss.__call__] Anchor points shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.__call__] Stride tensor shape: torch.Size([512, 1])

--- [utils/util.py::ComputeLoss.__call__] TARGET PROCESSING ---
[utils/util.py::ComputeLoss.__call__] Targets shape: torch.Size([3, 6])
[utils/util.py::ComputeLoss.__call__] Targets dtype: torch.float32
[utils/util.py::ComputeLoss.__call__] First few targets: tensor([[0.0000, 0.0000, 0.5313, 0.7310, 0.1324, 0.2574],
        [3.0000, 0.0000, 0.4362, 0.4348, 0.0585, 0.1129],
        [3.0000, 0.0000, 0.5769, 0.4743, 0.0463, 0.0949]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Image indices: tensor([0., 3., 3.], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Counts per image: tensor([1, 2], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT tensor shape: torch.Size([4, 2, 5])
[utils/util.py::ComputeLoss.__call__] Image 0: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 3: 2 targets assigned
[utils/util.py::ComputeLoss.__call__] GT before coordinate conversion: tensor([[[0.0000, 0.5313, 0.7310, 0.1324, 0.2574],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.4362, 0.4348, 0.0585, 0.1129],
         [0.0000, 0.5769, 0.4743, 0.0463, 0.0949]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT after coordinate conversion: tensor([[[  0.0000, 119.0680,  77.0890, 152.9544, 110.0417],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000, 104.1750,  48.4320, 119.1623,  62.8840],
         [  0.0000, 141.7477,  54.6410, 153.6037,  66.7915]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT labels shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.__call__] GT bboxes shape: torch.Size([4, 2, 4])
[utils/util.py::ComputeLoss.__call__] GT mask shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.__call__] Pred output dimensions - b: 4, a: 512, c: 64
[utils/util.py::ComputeLoss.__call__] Pred bboxes after softmax shape: torch.Size([4, 512, 4, 16])
[utils/util.py::ComputeLoss.__call__] Pred bboxes after matmul shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Final pred bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.__call__] ASSIGNMENT PHASE ---

--- [utils/util.py::ComputeLoss.assign] PYTORCH ASSIGNMENT DEBUG ---
[utils/util.py::ComputeLoss.assign] pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] true_labels shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 2, 4])
[utils/util.py::ComputeLoss.assign] true_mask shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.assign] anchors shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.assign] Batch size: 4, Max boxes: 2
[utils/util.py::ComputeLoss.assign] Created indices tensor with shape: torch.Size([2, 4, 2])

--- [utils/util.py::ComputeLoss.assign] IOUs DEBUG ---
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 2, 4])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([4, 2, 1, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([4, 1, 512, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([4, 2, 1, 1]), h: torch.Size([4, 2, 1, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([4, 1, 512, 1]), h: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.000000, max: 0.357246
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: -0.845361, max: 0.354518
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.assign] overlaps shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] overlaps min: 0.0, max: 0.35451754927635193
[utils/util.py::ComputeLoss.assign] align_metric shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] align_metric min: 0.0, max: 6.870518700452521e-05
[utils/util.py::ComputeLoss.assign] mask_in_gts shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] mask_in_gts sum: 21.0
[utils/util.py::ComputeLoss.assign] metrics shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] top_k_mask shape: torch.Size([4, 2, 10])
[utils/util.py::ComputeLoss.assign] top_k_metrics shape: torch.Size([4, 2, 10])
[utils/util.py::ComputeLoss.assign] top_k_indices shape: torch.Size([4, 2, 10])
[utils/util.py::ComputeLoss.assign] is_in_top_k shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] mask_top_k shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] mask_pos shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] fg_mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] fg_mask sum: 15.0
[utils/util.py::ComputeLoss.assign] target_gt_idx shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_labels shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] Normalized target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] target_scores sum: 1.6156059503555298
--- [utils/util.py::ComputeLoss.assign] END PYTORCH ASSIGNMENT DEBUG ---

[utils/util.py::ComputeLoss.__call__] Target bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Target scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] FG mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.__call__] Target scores sum: 1.615606
[utils/util.py::ComputeLoss.__call__] Classification loss computed: 7.214785
[utils/util.py::ComputeLoss.__call__] Foreground count: 15
[utils/util.py::ComputeLoss.__call__] Weight shape: torch.Size([15, 1])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([15, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([15, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([15, 1]), h: torch.Size([15, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([15, 1]), h: torch.Size([15, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([15, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([15, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([15, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.038231, max: 0.357214
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([15, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([15, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([15, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([15, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: 0.034441, max: 0.354485
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.__call__] IoU values shape: torch.Size([15, 1])
[utils/util.py::ComputeLoss.__call__] Box loss computed: 0.686081
[utils/util.py::ComputeLoss.__call__] Target LT-RB shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.df_loss] PYTORCH DFL LOSS DEBUG ---
[utils/util.py::ComputeLoss.df_loss] pred_dist shape: torch.Size([60, 16])
[utils/util.py::ComputeLoss.df_loss] target shape: torch.Size([15, 4])
[utils/util.py::ComputeLoss.df_loss] DFL loss shape: torch.Size([15, 1])
[utils/util.py::ComputeLoss.df_loss] DFL loss mean: 1.756623
--- [utils/util.py::ComputeLoss.df_loss] END PYTORCH DFL LOSS DEBUG ---

[utils/util.py::ComputeLoss.__call__] DFL loss before weighting: 1.756623
[utils/util.py::ComputeLoss.__call__] DFL loss computed: 1.706100

--- [utils/util.py::ComputeLoss.__call__] LOSS COMPONENTS DEBUG ---
[utils/util.py::ComputeLoss.__call__] Raw loss_cls: 7.214785
[utils/util.py::ComputeLoss.__call__] Raw loss_box: 0.686081
[utils/util.py::ComputeLoss.__call__] Raw loss_dfl: 1.706100
[utils/util.py::ComputeLoss.__call__] Loss weights - cls: 0.5, box: 7.5, dfl: 1.5
[utils/util.py::ComputeLoss.__call__] target_scores_sum: 1.615606
[utils/util.py::ComputeLoss.__call__] fg_mask sum: 15
[utils/util.py::ComputeLoss.__call__] Weighted loss_cls: 3.607393
[utils/util.py::ComputeLoss.__call__] Weighted loss_box: 5.145611
[utils/util.py::ComputeLoss.__call__] Weighted loss_dfl: 2.559150
[utils/util.py::ComputeLoss.__call__] Total loss: 11.312153
--- [utils/util.py::ComputeLoss.__call__] END PYTORCH LOSS COMPUTATION DEBUG ---


--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([4, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: True
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([4, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - box shape: torch.Size([4, 64, 16, 32]), cls shape: torch.Size([4, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - final concat shape: torch.Size([4, 65, 16, 32])

--- [utils/util.py::ComputeLoss.__call__] PYTORCH LOSS COMPUTATION DEBUG ---
[utils/util.py::ComputeLoss.__call__] Outputs type: <class 'list'>
[utils/util.py::ComputeLoss.__call__] x type: <class 'list'>, len: 1
[utils/util.py::ComputeLoss.__call__] x[0] shape: torch.Size([4, 65, 16, 32])
[utils/util.py::ComputeLoss.__call__] Concatenated output shape: torch.Size([4, 65, 512])
[utils/util.py::ComputeLoss.__call__] self.no: 65, self.dfl_ch: 16, self.nc: 1
[utils/util.py::ComputeLoss.__call__] pred_output shape: torch.Size([4, 64, 512])
[utils/util.py::ComputeLoss.__call__] pred_scores shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.__call__] After permute - pred_output shape: torch.Size([4, 512, 64])
[utils/util.py::ComputeLoss.__call__] After permute - pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Size tensor: tensor([128., 256.], device='cuda:0', dtype=torch.float16)
[utils/util.py::ComputeLoss.__call__] Stride: tensor([8.])
[utils/util.py::ComputeLoss.__call__] Anchor points shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.__call__] Stride tensor shape: torch.Size([512, 1])

--- [utils/util.py::ComputeLoss.__call__] TARGET PROCESSING ---
[utils/util.py::ComputeLoss.__call__] Targets shape: torch.Size([3, 6])
[utils/util.py::ComputeLoss.__call__] Targets dtype: torch.float32
[utils/util.py::ComputeLoss.__call__] First few targets: tensor([[0.0000, 0.0000, 0.1845, 0.6969, 0.0624, 0.1150],
        [2.0000, 0.0000, 0.3263, 0.9059, 0.1229, 0.1882],
        [3.0000, 0.0000, 0.3534, 0.2419, 0.1255, 0.2531]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Image indices: tensor([0., 2., 3.], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Counts per image: tensor([1, 1, 1], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT tensor shape: torch.Size([4, 1, 5])
[utils/util.py::ComputeLoss.__call__] Image 0: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 2: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 3: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] GT before coordinate conversion: tensor([[[0.0000, 0.1845, 0.6969, 0.0624, 0.1150]],

        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.3263, 0.9059, 0.1229, 0.1882]],

        [[0.0000, 0.3534, 0.2419, 0.1255, 0.2531]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT after coordinate conversion: tensor([[[  0.0000,  39.2310,  81.8344,  55.2178,  96.5601]],

        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000,  67.8151, 103.9148,  99.2685, 127.9990]],

        [[  0.0000,  74.4113,  14.7616, 106.5402,  47.1624]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT labels shape: torch.Size([4, 1, 1])
[utils/util.py::ComputeLoss.__call__] GT bboxes shape: torch.Size([4, 1, 4])
[utils/util.py::ComputeLoss.__call__] GT mask shape: torch.Size([4, 1, 1])
[utils/util.py::ComputeLoss.__call__] Pred output dimensions - b: 4, a: 512, c: 64
[utils/util.py::ComputeLoss.__call__] Pred bboxes after softmax shape: torch.Size([4, 512, 4, 16])
[utils/util.py::ComputeLoss.__call__] Pred bboxes after matmul shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Final pred bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.__call__] ASSIGNMENT PHASE ---

--- [utils/util.py::ComputeLoss.assign] PYTORCH ASSIGNMENT DEBUG ---
[utils/util.py::ComputeLoss.assign] pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] true_labels shape: torch.Size([4, 1, 1])
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 1, 4])
[utils/util.py::ComputeLoss.assign] true_mask shape: torch.Size([4, 1, 1])
[utils/util.py::ComputeLoss.assign] anchors shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.assign] Batch size: 4, Max boxes: 1
[utils/util.py::ComputeLoss.assign] Created indices tensor with shape: torch.Size([2, 4, 1])

--- [utils/util.py::ComputeLoss.assign] IOUs DEBUG ---
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 1, 4])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([4, 1, 1, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([4, 1, 512, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([4, 1, 1, 1]), h: torch.Size([4, 1, 1, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([4, 1, 512, 1]), h: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.000000, max: 0.384920
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: -0.883529, max: 0.378998
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.assign] overlaps shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.assign] overlaps min: 0.0, max: 0.3789980411529541
[utils/util.py::ComputeLoss.assign] align_metric shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.assign] align_metric min: 0.0, max: 0.00013846725050825626
[utils/util.py::ComputeLoss.assign] mask_in_gts shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.assign] mask_in_gts sum: 32.0
[utils/util.py::ComputeLoss.assign] metrics shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.assign] top_k_mask shape: torch.Size([4, 1, 10])
[utils/util.py::ComputeLoss.assign] top_k_metrics shape: torch.Size([4, 1, 10])
[utils/util.py::ComputeLoss.assign] top_k_indices shape: torch.Size([4, 1, 10])
[utils/util.py::ComputeLoss.assign] is_in_top_k shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.assign] mask_top_k shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.assign] mask_pos shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.assign] fg_mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] fg_mask sum: 24.0
[utils/util.py::ComputeLoss.assign] target_gt_idx shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_labels shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] Normalized target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] target_scores sum: 2.5984621047973633
--- [utils/util.py::ComputeLoss.assign] END PYTORCH ASSIGNMENT DEBUG ---

[utils/util.py::ComputeLoss.__call__] Target bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Target scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] FG mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.__call__] Target scores sum: 2.598462
[utils/util.py::ComputeLoss.__call__] Classification loss computed: 6.686647
[utils/util.py::ComputeLoss.__call__] Foreground count: 24
[utils/util.py::ComputeLoss.__call__] Weight shape: torch.Size([24, 1])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([24, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([24, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([24, 1]), h: torch.Size([24, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([24, 1]), h: torch.Size([24, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([24, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([24, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([24, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.074310, max: 0.384986
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([24, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([24, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([24, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([24, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: 0.053433, max: 0.379064
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.__call__] IoU values shape: torch.Size([24, 1])
[utils/util.py::ComputeLoss.__call__] Box loss computed: 0.709033
[utils/util.py::ComputeLoss.__call__] Target LT-RB shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.df_loss] PYTORCH DFL LOSS DEBUG ---
[utils/util.py::ComputeLoss.df_loss] pred_dist shape: torch.Size([96, 16])
[utils/util.py::ComputeLoss.df_loss] target shape: torch.Size([24, 4])
[utils/util.py::ComputeLoss.df_loss] DFL loss shape: torch.Size([24, 1])
[utils/util.py::ComputeLoss.df_loss] DFL loss mean: 1.730440
--- [utils/util.py::ComputeLoss.df_loss] END PYTORCH DFL LOSS DEBUG ---

[utils/util.py::ComputeLoss.__call__] DFL loss before weighting: 1.730440
[utils/util.py::ComputeLoss.__call__] DFL loss computed: 1.675036

--- [utils/util.py::ComputeLoss.__call__] LOSS COMPONENTS DEBUG ---
[utils/util.py::ComputeLoss.__call__] Raw loss_cls: 6.686647
[utils/util.py::ComputeLoss.__call__] Raw loss_box: 0.709033
[utils/util.py::ComputeLoss.__call__] Raw loss_dfl: 1.675036
[utils/util.py::ComputeLoss.__call__] Loss weights - cls: 0.5, box: 7.5, dfl: 1.5
[utils/util.py::ComputeLoss.__call__] target_scores_sum: 2.598462
[utils/util.py::ComputeLoss.__call__] fg_mask sum: 24
[utils/util.py::ComputeLoss.__call__] Weighted loss_cls: 3.343324
[utils/util.py::ComputeLoss.__call__] Weighted loss_box: 5.317744
[utils/util.py::ComputeLoss.__call__] Weighted loss_dfl: 2.512554
[utils/util.py::ComputeLoss.__call__] Total loss: 11.173622
--- [utils/util.py::ComputeLoss.__call__] END PYTORCH LOSS COMPUTATION DEBUG ---


--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([4, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: True
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([4, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - box shape: torch.Size([4, 64, 16, 32]), cls shape: torch.Size([4, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - final concat shape: torch.Size([4, 65, 16, 32])

--- [utils/util.py::ComputeLoss.__call__] PYTORCH LOSS COMPUTATION DEBUG ---
[utils/util.py::ComputeLoss.__call__] Outputs type: <class 'list'>
[utils/util.py::ComputeLoss.__call__] x type: <class 'list'>, len: 1
[utils/util.py::ComputeLoss.__call__] x[0] shape: torch.Size([4, 65, 16, 32])
[utils/util.py::ComputeLoss.__call__] Concatenated output shape: torch.Size([4, 65, 512])
[utils/util.py::ComputeLoss.__call__] self.no: 65, self.dfl_ch: 16, self.nc: 1
[utils/util.py::ComputeLoss.__call__] pred_output shape: torch.Size([4, 64, 512])
[utils/util.py::ComputeLoss.__call__] pred_scores shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.__call__] After permute - pred_output shape: torch.Size([4, 512, 64])
[utils/util.py::ComputeLoss.__call__] After permute - pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Size tensor: tensor([128., 256.], device='cuda:0', dtype=torch.float16)
[utils/util.py::ComputeLoss.__call__] Stride: tensor([8.])
[utils/util.py::ComputeLoss.__call__] Anchor points shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.__call__] Stride tensor shape: torch.Size([512, 1])

--- [utils/util.py::ComputeLoss.__call__] TARGET PROCESSING ---
[utils/util.py::ComputeLoss.__call__] Targets shape: torch.Size([4, 6])
[utils/util.py::ComputeLoss.__call__] Targets dtype: torch.float32
[utils/util.py::ComputeLoss.__call__] First few targets: tensor([[1.0000, 0.0000, 0.8514, 0.5738, 0.0725, 0.1528],
        [2.0000, 0.0000, 0.4527, 0.0146, 0.0812, 0.0291],
        [2.0000, 0.0000, 0.6828, 0.5861, 0.0690, 0.1448],
        [3.0000, 0.0000, 0.0130, 0.4126, 0.0260, 0.1990]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Image indices: tensor([1., 2., 2., 3.], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Counts per image: tensor([1, 2, 1], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT tensor shape: torch.Size([4, 2, 5])
[utils/util.py::ComputeLoss.__call__] Image 1: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 2: 2 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 3: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] GT before coordinate conversion: tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.8514, 0.5738, 0.0725, 0.1528],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.4527, 0.0146, 0.0812, 0.0291],
         [0.0000, 0.6828, 0.5861, 0.0690, 0.1448]],

        [[0.0000, 0.0130, 0.4126, 0.0260, 0.1990],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT after coordinate conversion: tensor([[[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000, 208.6708,  63.6723, 227.2361,  83.2258],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000, 105.4968,   0.0000, 126.2779,   3.7304],
         [  0.0000, 165.9743,  65.7452, 183.6421,  84.2859]],

        [[  0.0000,   0.0000,  40.0731,   6.6478,  65.5467],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT labels shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.__call__] GT bboxes shape: torch.Size([4, 2, 4])
[utils/util.py::ComputeLoss.__call__] GT mask shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.__call__] Pred output dimensions - b: 4, a: 512, c: 64
[utils/util.py::ComputeLoss.__call__] Pred bboxes after softmax shape: torch.Size([4, 512, 4, 16])
[utils/util.py::ComputeLoss.__call__] Pred bboxes after matmul shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Final pred bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.__call__] ASSIGNMENT PHASE ---

--- [utils/util.py::ComputeLoss.assign] PYTORCH ASSIGNMENT DEBUG ---
[utils/util.py::ComputeLoss.assign] pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] true_labels shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 2, 4])
[utils/util.py::ComputeLoss.assign] true_mask shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.assign] anchors shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.assign] Batch size: 4, Max boxes: 2
[utils/util.py::ComputeLoss.assign] Created indices tensor with shape: torch.Size([2, 4, 2])

--- [utils/util.py::ComputeLoss.assign] IOUs DEBUG ---
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 2, 4])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([4, 2, 1, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([4, 1, 512, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([4, 2, 1, 1]), h: torch.Size([4, 2, 1, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([4, 1, 512, 1]), h: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.000000, max: 0.155353
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: -0.897768, max: 0.145692
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.assign] overlaps shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] overlaps min: 0.0, max: 0.14569218456745148
[utils/util.py::ComputeLoss.assign] align_metric shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] align_metric min: 0.0, max: 5.65615607683867e-07
[utils/util.py::ComputeLoss.assign] mask_in_gts shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] mask_in_gts sum: 13.0
[utils/util.py::ComputeLoss.assign] metrics shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] top_k_mask shape: torch.Size([4, 2, 10])
[utils/util.py::ComputeLoss.assign] top_k_metrics shape: torch.Size([4, 2, 10])
[utils/util.py::ComputeLoss.assign] top_k_indices shape: torch.Size([4, 2, 10])
[utils/util.py::ComputeLoss.assign] is_in_top_k shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] mask_top_k shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] mask_pos shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] fg_mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] fg_mask sum: 13.0
[utils/util.py::ComputeLoss.assign] target_gt_idx shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_labels shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] Normalized target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] target_scores sum: 0.4722723960876465
--- [utils/util.py::ComputeLoss.assign] END PYTORCH ASSIGNMENT DEBUG ---

[utils/util.py::ComputeLoss.__call__] Target bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Target scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] FG mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.__call__] Target scores sum: 0.472272
[utils/util.py::ComputeLoss.__call__] Classification loss computed: 7.427520
[utils/util.py::ComputeLoss.__call__] Foreground count: 13
[utils/util.py::ComputeLoss.__call__] Weight shape: torch.Size([13, 1])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([13, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([13, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([13, 1]), h: torch.Size([13, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([13, 1]), h: torch.Size([13, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([13, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([13, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([13, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.057757, max: 0.153691
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([13, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([13, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([13, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([13, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: 0.022332, max: 0.145754
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.__call__] IoU values shape: torch.Size([13, 1])
[utils/util.py::ComputeLoss.__call__] Box loss computed: 0.875039
[utils/util.py::ComputeLoss.__call__] Target LT-RB shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.df_loss] PYTORCH DFL LOSS DEBUG ---
[utils/util.py::ComputeLoss.df_loss] pred_dist shape: torch.Size([52, 16])
[utils/util.py::ComputeLoss.df_loss] target shape: torch.Size([13, 4])
[utils/util.py::ComputeLoss.df_loss] DFL loss shape: torch.Size([13, 1])
[utils/util.py::ComputeLoss.df_loss] DFL loss mean: 1.710692
--- [utils/util.py::ComputeLoss.df_loss] END PYTORCH DFL LOSS DEBUG ---

[utils/util.py::ComputeLoss.__call__] DFL loss before weighting: 1.710692
[utils/util.py::ComputeLoss.__call__] DFL loss computed: 1.635537

--- [utils/util.py::ComputeLoss.__call__] LOSS COMPONENTS DEBUG ---
[utils/util.py::ComputeLoss.__call__] Raw loss_cls: 7.427520
[utils/util.py::ComputeLoss.__call__] Raw loss_box: 0.875039
[utils/util.py::ComputeLoss.__call__] Raw loss_dfl: 1.635537
[utils/util.py::ComputeLoss.__call__] Loss weights - cls: 0.5, box: 7.5, dfl: 1.5
[utils/util.py::ComputeLoss.__call__] target_scores_sum: 0.472272
[utils/util.py::ComputeLoss.__call__] fg_mask sum: 13
[utils/util.py::ComputeLoss.__call__] Weighted loss_cls: 3.713760
[utils/util.py::ComputeLoss.__call__] Weighted loss_box: 6.562793
[utils/util.py::ComputeLoss.__call__] Weighted loss_dfl: 2.453306
[utils/util.py::ComputeLoss.__call__] Total loss: 12.729859
--- [utils/util.py::ComputeLoss.__call__] END PYTORCH LOSS COMPUTATION DEBUG ---


--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([4, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: True
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([4, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - box shape: torch.Size([4, 64, 16, 32]), cls shape: torch.Size([4, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - final concat shape: torch.Size([4, 65, 16, 32])

--- [utils/util.py::ComputeLoss.__call__] PYTORCH LOSS COMPUTATION DEBUG ---
[utils/util.py::ComputeLoss.__call__] Outputs type: <class 'list'>
[utils/util.py::ComputeLoss.__call__] x type: <class 'list'>, len: 1
[utils/util.py::ComputeLoss.__call__] x[0] shape: torch.Size([4, 65, 16, 32])
[utils/util.py::ComputeLoss.__call__] Concatenated output shape: torch.Size([4, 65, 512])
[utils/util.py::ComputeLoss.__call__] self.no: 65, self.dfl_ch: 16, self.nc: 1
[utils/util.py::ComputeLoss.__call__] pred_output shape: torch.Size([4, 64, 512])
[utils/util.py::ComputeLoss.__call__] pred_scores shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.__call__] After permute - pred_output shape: torch.Size([4, 512, 64])
[utils/util.py::ComputeLoss.__call__] After permute - pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Size tensor: tensor([128., 256.], device='cuda:0', dtype=torch.float16)
[utils/util.py::ComputeLoss.__call__] Stride: tensor([8.])
[utils/util.py::ComputeLoss.__call__] Anchor points shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.__call__] Stride tensor shape: torch.Size([512, 1])

--- [utils/util.py::ComputeLoss.__call__] TARGET PROCESSING ---
[utils/util.py::ComputeLoss.__call__] Targets shape: torch.Size([6, 6])
[utils/util.py::ComputeLoss.__call__] Targets dtype: torch.float32
[utils/util.py::ComputeLoss.__call__] First few targets: tensor([[0.0000, 0.0000, 0.0911, 0.7151, 0.1051, 0.2222],
        [2.0000, 0.0000, 0.4614, 0.2642, 0.0605, 0.1365],
        [2.0000, 0.0000, 0.8660, 0.8100, 0.0578, 0.1195],
        [2.0000, 0.0000, 0.0889, 0.8178, 0.0575, 0.1143],
        [3.0000, 0.0000, 0.7527, 0.5197, 0.1104, 0.2120]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Image indices: tensor([0., 2., 2., 2., 3., 3.], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Counts per image: tensor([1, 3, 2], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT tensor shape: torch.Size([4, 3, 5])
[utils/util.py::ComputeLoss.__call__] Image 0: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 2: 3 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 3: 2 targets assigned
[utils/util.py::ComputeLoss.__call__] GT before coordinate conversion: tensor([[[0.0000, 0.0911, 0.7151, 0.1051, 0.2222],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.4614, 0.2642, 0.0605, 0.1365],
         [0.0000, 0.8660, 0.8100, 0.0578, 0.1195],
         [0.0000, 0.0889, 0.8178, 0.0575, 0.1143]],

        [[0.0000, 0.7527, 0.5197, 0.1104, 0.2120],
         [0.0000, 0.0537, 0.3557, 0.0887, 0.1856],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT after coordinate conversion: tensor([[[  0.0000,   9.8639,  77.3171,  36.7626, 105.7525],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000, 110.3780,  25.0803, 125.8765,  42.5477],
         [  0.0000, 214.3011,  96.0341, 229.0878, 111.3331],
         [  0.0000,  15.4081,  97.3645,  30.1284, 111.9983]],

        [[  0.0000, 178.5669,  52.9514, 206.8253,  80.0913],
         [  0.0000,   2.3947,  33.6506,  25.1103,  57.4054],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT labels shape: torch.Size([4, 3, 1])
[utils/util.py::ComputeLoss.__call__] GT bboxes shape: torch.Size([4, 3, 4])
[utils/util.py::ComputeLoss.__call__] GT mask shape: torch.Size([4, 3, 1])
[utils/util.py::ComputeLoss.__call__] Pred output dimensions - b: 4, a: 512, c: 64
[utils/util.py::ComputeLoss.__call__] Pred bboxes after softmax shape: torch.Size([4, 512, 4, 16])
[utils/util.py::ComputeLoss.__call__] Pred bboxes after matmul shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Final pred bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.__call__] ASSIGNMENT PHASE ---

--- [utils/util.py::ComputeLoss.assign] PYTORCH ASSIGNMENT DEBUG ---
[utils/util.py::ComputeLoss.assign] pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] true_labels shape: torch.Size([4, 3, 1])
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 3, 4])
[utils/util.py::ComputeLoss.assign] true_mask shape: torch.Size([4, 3, 1])
[utils/util.py::ComputeLoss.assign] anchors shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.assign] Batch size: 4, Max boxes: 3
[utils/util.py::ComputeLoss.assign] Created indices tensor with shape: torch.Size([2, 4, 3])

--- [utils/util.py::ComputeLoss.assign] IOUs DEBUG ---
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 3, 4])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([4, 3, 1, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([4, 1, 512, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([4, 3, 1, 1]), h: torch.Size([4, 3, 1, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([4, 1, 512, 1]), h: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.000000, max: 0.346359
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: -0.893968, max: 0.318996
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.assign] overlaps shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] overlaps min: 0.0, max: 0.3189963698387146
[utils/util.py::ComputeLoss.assign] align_metric shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] align_metric min: 0.0, max: 5.86528803978581e-05
[utils/util.py::ComputeLoss.assign] mask_in_gts shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] mask_in_gts sum: 45.0
[utils/util.py::ComputeLoss.assign] metrics shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] top_k_mask shape: torch.Size([4, 3, 10])
[utils/util.py::ComputeLoss.assign] top_k_metrics shape: torch.Size([4, 3, 10])
[utils/util.py::ComputeLoss.assign] top_k_indices shape: torch.Size([4, 3, 10])
[utils/util.py::ComputeLoss.assign] is_in_top_k shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] mask_top_k shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] mask_pos shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] fg_mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] fg_mask sum: 41.0
[utils/util.py::ComputeLoss.assign] target_gt_idx shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_labels shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] Normalized target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] target_scores sum: 4.817873477935791
--- [utils/util.py::ComputeLoss.assign] END PYTORCH ASSIGNMENT DEBUG ---

[utils/util.py::ComputeLoss.__call__] Target bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Target scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] FG mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.__call__] Target scores sum: 4.817873
[utils/util.py::ComputeLoss.__call__] Classification loss computed: 6.726256
[utils/util.py::ComputeLoss.__call__] Foreground count: 41
[utils/util.py::ComputeLoss.__call__] Weight shape: torch.Size([41, 1])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([41, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([41, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([41, 1]), h: torch.Size([41, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([41, 1]), h: torch.Size([41, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([41, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([41, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([41, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.085009, max: 0.346096
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([41, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([41, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([41, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([41, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: 0.073140, max: 0.318733
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.__call__] IoU values shape: torch.Size([41, 1])
[utils/util.py::ComputeLoss.__call__] Box loss computed: 0.759091
[utils/util.py::ComputeLoss.__call__] Target LT-RB shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.df_loss] PYTORCH DFL LOSS DEBUG ---
[utils/util.py::ComputeLoss.df_loss] pred_dist shape: torch.Size([164, 16])
[utils/util.py::ComputeLoss.df_loss] target shape: torch.Size([41, 4])
[utils/util.py::ComputeLoss.df_loss] DFL loss shape: torch.Size([41, 1])
[utils/util.py::ComputeLoss.df_loss] DFL loss mean: 1.666711
--- [utils/util.py::ComputeLoss.df_loss] END PYTORCH DFL LOSS DEBUG ---

[utils/util.py::ComputeLoss.__call__] DFL loss before weighting: 1.666711
[utils/util.py::ComputeLoss.__call__] DFL loss computed: 1.593099

--- [utils/util.py::ComputeLoss.__call__] LOSS COMPONENTS DEBUG ---
[utils/util.py::ComputeLoss.__call__] Raw loss_cls: 6.726256
[utils/util.py::ComputeLoss.__call__] Raw loss_box: 0.759091
[utils/util.py::ComputeLoss.__call__] Raw loss_dfl: 1.593099
[utils/util.py::ComputeLoss.__call__] Loss weights - cls: 0.5, box: 7.5, dfl: 1.5
[utils/util.py::ComputeLoss.__call__] target_scores_sum: 4.817873
[utils/util.py::ComputeLoss.__call__] fg_mask sum: 41
[utils/util.py::ComputeLoss.__call__] Weighted loss_cls: 3.363128
[utils/util.py::ComputeLoss.__call__] Weighted loss_box: 5.693181
[utils/util.py::ComputeLoss.__call__] Weighted loss_dfl: 2.389649
[utils/util.py::ComputeLoss.__call__] Total loss: 11.445957
--- [utils/util.py::ComputeLoss.__call__] END PYTORCH LOSS COMPUTATION DEBUG ---


--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([4, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: True
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([4, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - box shape: torch.Size([4, 64, 16, 32]), cls shape: torch.Size([4, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - final concat shape: torch.Size([4, 65, 16, 32])

--- [utils/util.py::ComputeLoss.__call__] PYTORCH LOSS COMPUTATION DEBUG ---
[utils/util.py::ComputeLoss.__call__] Outputs type: <class 'list'>
[utils/util.py::ComputeLoss.__call__] x type: <class 'list'>, len: 1
[utils/util.py::ComputeLoss.__call__] x[0] shape: torch.Size([4, 65, 16, 32])
[utils/util.py::ComputeLoss.__call__] Concatenated output shape: torch.Size([4, 65, 512])
[utils/util.py::ComputeLoss.__call__] self.no: 65, self.dfl_ch: 16, self.nc: 1
[utils/util.py::ComputeLoss.__call__] pred_output shape: torch.Size([4, 64, 512])
[utils/util.py::ComputeLoss.__call__] pred_scores shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.__call__] After permute - pred_output shape: torch.Size([4, 512, 64])
[utils/util.py::ComputeLoss.__call__] After permute - pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Size tensor: tensor([128., 256.], device='cuda:0', dtype=torch.float16)
[utils/util.py::ComputeLoss.__call__] Stride: tensor([8.])
[utils/util.py::ComputeLoss.__call__] Anchor points shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.__call__] Stride tensor shape: torch.Size([512, 1])

--- [utils/util.py::ComputeLoss.__call__] TARGET PROCESSING ---
[utils/util.py::ComputeLoss.__call__] Targets shape: torch.Size([7, 6])
[utils/util.py::ComputeLoss.__call__] Targets dtype: torch.float32
[utils/util.py::ComputeLoss.__call__] First few targets: tensor([[0.0000, 0.0000, 0.3823, 0.0126, 0.1164, 0.0252],
        [1.0000, 0.0000, 0.8170, 0.2445, 0.0890, 0.1718],
        [1.0000, 0.0000, 0.4375, 0.8269, 0.0743, 0.1485],
        [2.0000, 0.0000, 0.8991, 0.6852, 0.0748, 0.1568],
        [2.0000, 0.0000, 0.1911, 0.5598, 0.0614, 0.1270]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Image indices: tensor([0., 1., 1., 2., 2., 3., 3.], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Counts per image: tensor([1, 2, 2, 2], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT tensor shape: torch.Size([4, 2, 5])
[utils/util.py::ComputeLoss.__call__] Image 0: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 1: 2 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 2: 2 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 3: 2 targets assigned
[utils/util.py::ComputeLoss.__call__] GT before coordinate conversion: tensor([[[0.0000, 0.3823, 0.0126, 0.1164, 0.0252],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.8170, 0.2445, 0.0890, 0.1718],
         [0.0000, 0.4375, 0.8269, 0.0743, 0.1485]],

        [[0.0000, 0.8991, 0.6852, 0.0748, 0.1568],
         [0.0000, 0.1911, 0.5598, 0.0614, 0.1270]],

        [[0.0000, 0.6455, 0.2898, 0.1121, 0.2345],
         [0.0000, 0.2976, 0.1005, 0.1071, 0.2010]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT after coordinate conversion: tensor([[[  0.0000,  82.9785,   0.0000, 112.7752,   3.2254],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000, 197.7428,  20.2956, 220.5394,  42.2905],
         [  0.0000, 102.4977,  96.3354, 121.5087, 115.3464]],

        [[  0.0000, 220.5773,  77.6636, 239.7375,  97.7354],
         [  0.0000,  41.0612,  63.5284,  56.7724,  79.7838]],

        [[  0.0000, 150.9055,  22.0881, 179.5998,  52.1030],
         [  0.0000,  62.4713,   0.0000,  89.8945,  25.7289]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT labels shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.__call__] GT bboxes shape: torch.Size([4, 2, 4])
[utils/util.py::ComputeLoss.__call__] GT mask shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.__call__] Pred output dimensions - b: 4, a: 512, c: 64
[utils/util.py::ComputeLoss.__call__] Pred bboxes after softmax shape: torch.Size([4, 512, 4, 16])
[utils/util.py::ComputeLoss.__call__] Pred bboxes after matmul shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Final pred bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.__call__] ASSIGNMENT PHASE ---

--- [utils/util.py::ComputeLoss.assign] PYTORCH ASSIGNMENT DEBUG ---
[utils/util.py::ComputeLoss.assign] pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] true_labels shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 2, 4])
[utils/util.py::ComputeLoss.assign] true_mask shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.assign] anchors shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.assign] Batch size: 4, Max boxes: 2
[utils/util.py::ComputeLoss.assign] Created indices tensor with shape: torch.Size([2, 4, 2])

--- [utils/util.py::ComputeLoss.assign] IOUs DEBUG ---
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 2, 4])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([4, 2, 1, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([4, 1, 512, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([4, 2, 1, 1]), h: torch.Size([4, 2, 1, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([4, 1, 512, 1]), h: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.000000, max: 0.392242
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: -0.887148, max: 0.388891
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.assign] overlaps shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] overlaps min: 0.0, max: 0.3888906240463257
[utils/util.py::ComputeLoss.assign] align_metric shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] align_metric min: 0.0, max: 0.00012889337085653096
[utils/util.py::ComputeLoss.assign] mask_in_gts shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] mask_in_gts sum: 39.0
[utils/util.py::ComputeLoss.assign] metrics shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] top_k_mask shape: torch.Size([4, 2, 10])
[utils/util.py::ComputeLoss.assign] top_k_metrics shape: torch.Size([4, 2, 10])
[utils/util.py::ComputeLoss.assign] top_k_indices shape: torch.Size([4, 2, 10])
[utils/util.py::ComputeLoss.assign] is_in_top_k shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] mask_top_k shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] mask_pos shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] fg_mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] fg_mask sum: 37.0
[utils/util.py::ComputeLoss.assign] target_gt_idx shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_labels shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] Normalized target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] target_scores sum: 3.6713414192199707
--- [utils/util.py::ComputeLoss.assign] END PYTORCH ASSIGNMENT DEBUG ---

[utils/util.py::ComputeLoss.__call__] Target bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Target scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] FG mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.__call__] Target scores sum: 3.671341
[utils/util.py::ComputeLoss.__call__] Classification loss computed: 6.737149
[utils/util.py::ComputeLoss.__call__] Foreground count: 37
[utils/util.py::ComputeLoss.__call__] Weight shape: torch.Size([37, 1])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([37, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([37, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([37, 1]), h: torch.Size([37, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([37, 1]), h: torch.Size([37, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([37, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([37, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([37, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.096084, max: 0.392099
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([37, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([37, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([37, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([37, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: 0.084529, max: 0.388911
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.__call__] IoU values shape: torch.Size([37, 1])
[utils/util.py::ComputeLoss.__call__] Box loss computed: 0.713468
[utils/util.py::ComputeLoss.__call__] Target LT-RB shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.df_loss] PYTORCH DFL LOSS DEBUG ---
[utils/util.py::ComputeLoss.df_loss] pred_dist shape: torch.Size([148, 16])
[utils/util.py::ComputeLoss.df_loss] target shape: torch.Size([37, 4])
[utils/util.py::ComputeLoss.df_loss] DFL loss shape: torch.Size([37, 1])
[utils/util.py::ComputeLoss.df_loss] DFL loss mean: 1.652525
--- [utils/util.py::ComputeLoss.df_loss] END PYTORCH DFL LOSS DEBUG ---

[utils/util.py::ComputeLoss.__call__] DFL loss before weighting: 1.652525
[utils/util.py::ComputeLoss.__call__] DFL loss computed: 1.592558

--- [utils/util.py::ComputeLoss.__call__] LOSS COMPONENTS DEBUG ---
[utils/util.py::ComputeLoss.__call__] Raw loss_cls: 6.737149
[utils/util.py::ComputeLoss.__call__] Raw loss_box: 0.713468
[utils/util.py::ComputeLoss.__call__] Raw loss_dfl: 1.592558
[utils/util.py::ComputeLoss.__call__] Loss weights - cls: 0.5, box: 7.5, dfl: 1.5
[utils/util.py::ComputeLoss.__call__] target_scores_sum: 3.671341
[utils/util.py::ComputeLoss.__call__] fg_mask sum: 37
[utils/util.py::ComputeLoss.__call__] Weighted loss_cls: 3.368575
[utils/util.py::ComputeLoss.__call__] Weighted loss_box: 5.351010
[utils/util.py::ComputeLoss.__call__] Weighted loss_dfl: 2.388837
[utils/util.py::ComputeLoss.__call__] Total loss: 11.108423
--- [utils/util.py::ComputeLoss.__call__] END PYTORCH LOSS COMPUTATION DEBUG ---


--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([4, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: True
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([4, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - box shape: torch.Size([4, 64, 16, 32]), cls shape: torch.Size([4, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - final concat shape: torch.Size([4, 65, 16, 32])

--- [utils/util.py::ComputeLoss.__call__] PYTORCH LOSS COMPUTATION DEBUG ---
[utils/util.py::ComputeLoss.__call__] Outputs type: <class 'list'>
[utils/util.py::ComputeLoss.__call__] x type: <class 'list'>, len: 1
[utils/util.py::ComputeLoss.__call__] x[0] shape: torch.Size([4, 65, 16, 32])
[utils/util.py::ComputeLoss.__call__] Concatenated output shape: torch.Size([4, 65, 512])
[utils/util.py::ComputeLoss.__call__] self.no: 65, self.dfl_ch: 16, self.nc: 1
[utils/util.py::ComputeLoss.__call__] pred_output shape: torch.Size([4, 64, 512])
[utils/util.py::ComputeLoss.__call__] pred_scores shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.__call__] After permute - pred_output shape: torch.Size([4, 512, 64])
[utils/util.py::ComputeLoss.__call__] After permute - pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Size tensor: tensor([128., 256.], device='cuda:0', dtype=torch.float16)
[utils/util.py::ComputeLoss.__call__] Stride: tensor([8.])
[utils/util.py::ComputeLoss.__call__] Anchor points shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.__call__] Stride tensor shape: torch.Size([512, 1])

--- [utils/util.py::ComputeLoss.__call__] TARGET PROCESSING ---
[utils/util.py::ComputeLoss.__call__] Targets shape: torch.Size([7, 6])
[utils/util.py::ComputeLoss.__call__] Targets dtype: torch.float32
[utils/util.py::ComputeLoss.__call__] First few targets: tensor([[0.0000, 0.0000, 0.1916, 0.6663, 0.1055, 0.1995],
        [1.0000, 0.0000, 0.4618, 0.9668, 0.1253, 0.0665],
        [2.0000, 0.0000, 0.4436, 0.0138, 0.1031, 0.0275],
        [3.0000, 0.0000, 0.1870, 0.3726, 0.0515, 0.1103],
        [3.0000, 0.0000, 0.8912, 0.4170, 0.0644, 0.1242]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Image indices: tensor([0., 1., 2., 3., 3., 3., 3.], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Counts per image: tensor([1, 1, 1, 4], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT tensor shape: torch.Size([4, 4, 5])
[utils/util.py::ComputeLoss.__call__] Image 0: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 1: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 2: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 3: 4 targets assigned
[utils/util.py::ComputeLoss.__call__] GT before coordinate conversion: tensor([[[0.0000, 0.1916, 0.6663, 0.1055, 0.1995],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.4618, 0.9668, 0.1253, 0.0665],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.4436, 0.0138, 0.1031, 0.0275],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.1870, 0.3726, 0.0515, 0.1103],
         [0.0000, 0.8912, 0.4170, 0.0644, 0.1242],
         [0.0000, 0.0567, 0.8404, 0.0537, 0.1121],
         [0.0000, 0.5294, 0.8348, 0.0560, 0.1083]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT after coordinate conversion: tensor([[[  0.0000,  35.5577,  72.5209,  62.5569,  98.0577],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000, 102.1687, 119.4906, 134.2580, 127.9990],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000, 100.3738,   0.0000, 126.7697,   3.5247],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000,  41.2900,  40.6392,  54.4616,  54.7551],
         [  0.0000, 219.9078,  45.4232, 236.3903,  61.3260],
         [  0.0000,   7.6377, 100.4017,  21.3831, 114.7446],
         [  0.0000, 128.3578,  99.9236, 142.7008, 113.7884]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT labels shape: torch.Size([4, 4, 1])
[utils/util.py::ComputeLoss.__call__] GT bboxes shape: torch.Size([4, 4, 4])
[utils/util.py::ComputeLoss.__call__] GT mask shape: torch.Size([4, 4, 1])
[utils/util.py::ComputeLoss.__call__] Pred output dimensions - b: 4, a: 512, c: 64
[utils/util.py::ComputeLoss.__call__] Pred bboxes after softmax shape: torch.Size([4, 512, 4, 16])
[utils/util.py::ComputeLoss.__call__] Pred bboxes after matmul shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Final pred bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.__call__] ASSIGNMENT PHASE ---

--- [utils/util.py::ComputeLoss.assign] PYTORCH ASSIGNMENT DEBUG ---
[utils/util.py::ComputeLoss.assign] pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] true_labels shape: torch.Size([4, 4, 1])
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 4, 4])
[utils/util.py::ComputeLoss.assign] true_mask shape: torch.Size([4, 4, 1])
[utils/util.py::ComputeLoss.assign] anchors shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.assign] Batch size: 4, Max boxes: 4
[utils/util.py::ComputeLoss.assign] Created indices tensor with shape: torch.Size([2, 4, 4])

--- [utils/util.py::ComputeLoss.assign] IOUs DEBUG ---
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 4, 4])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([4, 4, 1, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([4, 1, 512, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([4, 4, 1, 1]), h: torch.Size([4, 4, 1, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([4, 1, 512, 1]), h: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([4, 4, 512, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([4, 4, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([4, 4, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.000000, max: 0.370411
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([4, 4, 512, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([4, 4, 512, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([4, 4, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([4, 4, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: -0.924776, max: 0.354329
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.assign] overlaps shape: torch.Size([4, 4, 512])
[utils/util.py::ComputeLoss.assign] overlaps min: 0.0, max: 0.35432907938957214
[utils/util.py::ComputeLoss.assign] align_metric shape: torch.Size([4, 4, 512])
[utils/util.py::ComputeLoss.assign] align_metric min: 0.0, max: 0.000111244989966508
[utils/util.py::ComputeLoss.assign] mask_in_gts shape: torch.Size([4, 4, 512])
[utils/util.py::ComputeLoss.assign] mask_in_gts sum: 32.0
[utils/util.py::ComputeLoss.assign] metrics shape: torch.Size([4, 4, 512])
[utils/util.py::ComputeLoss.assign] top_k_mask shape: torch.Size([4, 4, 10])
[utils/util.py::ComputeLoss.assign] top_k_metrics shape: torch.Size([4, 4, 10])
[utils/util.py::ComputeLoss.assign] top_k_indices shape: torch.Size([4, 4, 10])
[utils/util.py::ComputeLoss.assign] is_in_top_k shape: torch.Size([4, 4, 512])
[utils/util.py::ComputeLoss.assign] mask_top_k shape: torch.Size([4, 4, 512])
[utils/util.py::ComputeLoss.assign] mask_pos shape: torch.Size([4, 4, 512])
[utils/util.py::ComputeLoss.assign] fg_mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] fg_mask sum: 30.0
[utils/util.py::ComputeLoss.assign] target_gt_idx shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_labels shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] Normalized target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] target_scores sum: 1.9467754364013672
--- [utils/util.py::ComputeLoss.assign] END PYTORCH ASSIGNMENT DEBUG ---

[utils/util.py::ComputeLoss.__call__] Target bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Target scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] FG mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.__call__] Target scores sum: 1.946775
[utils/util.py::ComputeLoss.__call__] Classification loss computed: 6.701787
[utils/util.py::ComputeLoss.__call__] Foreground count: 30
[utils/util.py::ComputeLoss.__call__] Weight shape: torch.Size([30, 1])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([30, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([30, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([30, 1]), h: torch.Size([30, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([30, 1]), h: torch.Size([30, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([30, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([30, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([30, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.075890, max: 0.370486
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([30, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([30, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([30, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([30, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: 0.035115, max: 0.354404
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.__call__] IoU values shape: torch.Size([30, 1])
[utils/util.py::ComputeLoss.__call__] Box loss computed: 0.784185
[utils/util.py::ComputeLoss.__call__] Target LT-RB shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.df_loss] PYTORCH DFL LOSS DEBUG ---
[utils/util.py::ComputeLoss.df_loss] pred_dist shape: torch.Size([120, 16])
[utils/util.py::ComputeLoss.df_loss] target shape: torch.Size([30, 4])
[utils/util.py::ComputeLoss.df_loss] DFL loss shape: torch.Size([30, 1])
[utils/util.py::ComputeLoss.df_loss] DFL loss mean: 1.689016
--- [utils/util.py::ComputeLoss.df_loss] END PYTORCH DFL LOSS DEBUG ---

[utils/util.py::ComputeLoss.__call__] DFL loss before weighting: 1.689016
[utils/util.py::ComputeLoss.__call__] DFL loss computed: 1.642874

--- [utils/util.py::ComputeLoss.__call__] LOSS COMPONENTS DEBUG ---
[utils/util.py::ComputeLoss.__call__] Raw loss_cls: 6.701787
[utils/util.py::ComputeLoss.__call__] Raw loss_box: 0.784185
[utils/util.py::ComputeLoss.__call__] Raw loss_dfl: 1.642874
[utils/util.py::ComputeLoss.__call__] Loss weights - cls: 0.5, box: 7.5, dfl: 1.5
[utils/util.py::ComputeLoss.__call__] target_scores_sum: 1.946775
[utils/util.py::ComputeLoss.__call__] fg_mask sum: 30
[utils/util.py::ComputeLoss.__call__] Weighted loss_cls: 3.350894
[utils/util.py::ComputeLoss.__call__] Weighted loss_box: 5.881385
[utils/util.py::ComputeLoss.__call__] Weighted loss_dfl: 2.464311
[utils/util.py::ComputeLoss.__call__] Total loss: 11.696590
--- [utils/util.py::ComputeLoss.__call__] END PYTORCH LOSS COMPUTATION DEBUG ---


--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([4, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: True
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([4, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - box shape: torch.Size([4, 64, 16, 32]), cls shape: torch.Size([4, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - final concat shape: torch.Size([4, 65, 16, 32])

--- [utils/util.py::ComputeLoss.__call__] PYTORCH LOSS COMPUTATION DEBUG ---
[utils/util.py::ComputeLoss.__call__] Outputs type: <class 'list'>
[utils/util.py::ComputeLoss.__call__] x type: <class 'list'>, len: 1
[utils/util.py::ComputeLoss.__call__] x[0] shape: torch.Size([4, 65, 16, 32])
[utils/util.py::ComputeLoss.__call__] Concatenated output shape: torch.Size([4, 65, 512])
[utils/util.py::ComputeLoss.__call__] self.no: 65, self.dfl_ch: 16, self.nc: 1
[utils/util.py::ComputeLoss.__call__] pred_output shape: torch.Size([4, 64, 512])
[utils/util.py::ComputeLoss.__call__] pred_scores shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.__call__] After permute - pred_output shape: torch.Size([4, 512, 64])
[utils/util.py::ComputeLoss.__call__] After permute - pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Size tensor: tensor([128., 256.], device='cuda:0', dtype=torch.float16)
[utils/util.py::ComputeLoss.__call__] Stride: tensor([8.])
[utils/util.py::ComputeLoss.__call__] Anchor points shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.__call__] Stride tensor shape: torch.Size([512, 1])

--- [utils/util.py::ComputeLoss.__call__] TARGET PROCESSING ---
[utils/util.py::ComputeLoss.__call__] Targets shape: torch.Size([5, 6])
[utils/util.py::ComputeLoss.__call__] Targets dtype: torch.float32
[utils/util.py::ComputeLoss.__call__] First few targets: tensor([[0.0000, 0.0000, 0.6381, 0.0821, 0.0667, 0.1429],
        [0.0000, 0.0000, 0.0218, 0.9138, 0.0436, 0.1610],
        [0.0000, 0.0000, 0.9831, 0.8177, 0.0338, 0.1673],
        [1.0000, 0.0000, 0.2808, 0.0612, 0.1082, 0.1224],
        [3.0000, 0.0000, 0.1985, 0.6467, 0.1259, 0.2518]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Image indices: tensor([0., 0., 0., 1., 3.], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Counts per image: tensor([3, 1, 1], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT tensor shape: torch.Size([4, 3, 5])
[utils/util.py::ComputeLoss.__call__] Image 0: 3 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 1: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 3: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] GT before coordinate conversion: tensor([[[0.0000, 0.6381, 0.0821, 0.0667, 0.1429],
         [0.0000, 0.0218, 0.9138, 0.0436, 0.1610],
         [0.0000, 0.9831, 0.8177, 0.0338, 0.1673]],

        [[0.0000, 0.2808, 0.0612, 0.1082, 0.1224],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.1985, 0.6467, 0.1259, 0.2518],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT after coordinate conversion: tensor([[[  0.0000, 154.8159,   1.3645, 171.8799,  19.6518],
         [  0.0000,   0.0000, 106.6637,  11.1652, 127.2659],
         [  0.0000, 247.3363,  93.9624, 255.9990, 115.3776]],

        [[  0.0000,  58.0339,   0.0000,  85.7432,  15.6695],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000,  34.6920,  66.6599,  66.9236,  98.8915],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT labels shape: torch.Size([4, 3, 1])
[utils/util.py::ComputeLoss.__call__] GT bboxes shape: torch.Size([4, 3, 4])
[utils/util.py::ComputeLoss.__call__] GT mask shape: torch.Size([4, 3, 1])
[utils/util.py::ComputeLoss.__call__] Pred output dimensions - b: 4, a: 512, c: 64
[utils/util.py::ComputeLoss.__call__] Pred bboxes after softmax shape: torch.Size([4, 512, 4, 16])
[utils/util.py::ComputeLoss.__call__] Pred bboxes after matmul shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Final pred bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.__call__] ASSIGNMENT PHASE ---

--- [utils/util.py::ComputeLoss.assign] PYTORCH ASSIGNMENT DEBUG ---
[utils/util.py::ComputeLoss.assign] pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] true_labels shape: torch.Size([4, 3, 1])
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 3, 4])
[utils/util.py::ComputeLoss.assign] true_mask shape: torch.Size([4, 3, 1])
[utils/util.py::ComputeLoss.assign] anchors shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.assign] Batch size: 4, Max boxes: 3
[utils/util.py::ComputeLoss.assign] Created indices tensor with shape: torch.Size([2, 4, 3])

--- [utils/util.py::ComputeLoss.assign] IOUs DEBUG ---
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 3, 4])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([4, 3, 1, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([4, 1, 512, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([4, 3, 1, 1]), h: torch.Size([4, 3, 1, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([4, 1, 512, 1]), h: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.000000, max: 0.549246
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: -0.896623, max: 0.530798
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.assign] overlaps shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] overlaps min: 0.0, max: 0.5307978987693787
[utils/util.py::ComputeLoss.assign] align_metric shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] align_metric min: 0.0, max: 0.0013486901298165321
[utils/util.py::ComputeLoss.assign] mask_in_gts shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] mask_in_gts sum: 33.0
[utils/util.py::ComputeLoss.assign] metrics shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] top_k_mask shape: torch.Size([4, 3, 10])
[utils/util.py::ComputeLoss.assign] top_k_metrics shape: torch.Size([4, 3, 10])
[utils/util.py::ComputeLoss.assign] top_k_indices shape: torch.Size([4, 3, 10])
[utils/util.py::ComputeLoss.assign] is_in_top_k shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] mask_top_k shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] mask_pos shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] fg_mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] fg_mask sum: 27.0
[utils/util.py::ComputeLoss.assign] target_gt_idx shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_labels shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] Normalized target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] target_scores sum: 2.5772533416748047
--- [utils/util.py::ComputeLoss.assign] END PYTORCH ASSIGNMENT DEBUG ---

[utils/util.py::ComputeLoss.__call__] Target bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Target scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] FG mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.__call__] Target scores sum: 2.577253
[utils/util.py::ComputeLoss.__call__] Classification loss computed: 6.396102
[utils/util.py::ComputeLoss.__call__] Foreground count: 27
[utils/util.py::ComputeLoss.__call__] Weight shape: torch.Size([27, 1])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([27, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([27, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([27, 1]), h: torch.Size([27, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([27, 1]), h: torch.Size([27, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([27, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([27, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([27, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.077040, max: 0.549246
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([27, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([27, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([27, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([27, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: 0.064421, max: 0.530798
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.__call__] IoU values shape: torch.Size([27, 1])
[utils/util.py::ComputeLoss.__call__] Box loss computed: 0.657559
[utils/util.py::ComputeLoss.__call__] Target LT-RB shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.df_loss] PYTORCH DFL LOSS DEBUG ---
[utils/util.py::ComputeLoss.df_loss] pred_dist shape: torch.Size([108, 16])
[utils/util.py::ComputeLoss.df_loss] target shape: torch.Size([27, 4])
[utils/util.py::ComputeLoss.df_loss] DFL loss shape: torch.Size([27, 1])
[utils/util.py::ComputeLoss.df_loss] DFL loss mean: 1.731991
--- [utils/util.py::ComputeLoss.df_loss] END PYTORCH DFL LOSS DEBUG ---

[utils/util.py::ComputeLoss.__call__] DFL loss before weighting: 1.731991
[utils/util.py::ComputeLoss.__call__] DFL loss computed: 1.644659

--- [utils/util.py::ComputeLoss.__call__] LOSS COMPONENTS DEBUG ---
[utils/util.py::ComputeLoss.__call__] Raw loss_cls: 6.396102
[utils/util.py::ComputeLoss.__call__] Raw loss_box: 0.657559
[utils/util.py::ComputeLoss.__call__] Raw loss_dfl: 1.644659
[utils/util.py::ComputeLoss.__call__] Loss weights - cls: 0.5, box: 7.5, dfl: 1.5
[utils/util.py::ComputeLoss.__call__] target_scores_sum: 2.577253
[utils/util.py::ComputeLoss.__call__] fg_mask sum: 27
[utils/util.py::ComputeLoss.__call__] Weighted loss_cls: 3.198051
[utils/util.py::ComputeLoss.__call__] Weighted loss_box: 4.931692
[utils/util.py::ComputeLoss.__call__] Weighted loss_dfl: 2.466988
[utils/util.py::ComputeLoss.__call__] Total loss: 10.596730
--- [utils/util.py::ComputeLoss.__call__] END PYTORCH LOSS COMPUTATION DEBUG ---


--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([4, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: True
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([4, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - box shape: torch.Size([4, 64, 16, 32]), cls shape: torch.Size([4, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - final concat shape: torch.Size([4, 65, 16, 32])

--- [utils/util.py::ComputeLoss.__call__] PYTORCH LOSS COMPUTATION DEBUG ---
[utils/util.py::ComputeLoss.__call__] Outputs type: <class 'list'>
[utils/util.py::ComputeLoss.__call__] x type: <class 'list'>, len: 1
[utils/util.py::ComputeLoss.__call__] x[0] shape: torch.Size([4, 65, 16, 32])
[utils/util.py::ComputeLoss.__call__] Concatenated output shape: torch.Size([4, 65, 512])
[utils/util.py::ComputeLoss.__call__] self.no: 65, self.dfl_ch: 16, self.nc: 1
[utils/util.py::ComputeLoss.__call__] pred_output shape: torch.Size([4, 64, 512])
[utils/util.py::ComputeLoss.__call__] pred_scores shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.__call__] After permute - pred_output shape: torch.Size([4, 512, 64])
[utils/util.py::ComputeLoss.__call__] After permute - pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Size tensor: tensor([128., 256.], device='cuda:0', dtype=torch.float16)
[utils/util.py::ComputeLoss.__call__] Stride: tensor([8.])
[utils/util.py::ComputeLoss.__call__] Anchor points shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.__call__] Stride tensor shape: torch.Size([512, 1])

--- [utils/util.py::ComputeLoss.__call__] TARGET PROCESSING ---
[utils/util.py::ComputeLoss.__call__] Targets shape: torch.Size([8, 6])
[utils/util.py::ComputeLoss.__call__] Targets dtype: torch.float32
[utils/util.py::ComputeLoss.__call__] First few targets: tensor([[0.0000, 0.0000, 0.5193, 0.8776, 0.0952, 0.1920],
        [0.0000, 0.0000, 0.8509, 0.8145, 0.0713, 0.1450],
        [1.0000, 0.0000, 0.5268, 0.0403, 0.0862, 0.0806],
        [1.0000, 0.0000, 0.2839, 0.9418, 0.0883, 0.1164],
        [3.0000, 0.0000, 0.9921, 0.0911, 0.0159, 0.0997]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Image indices: tensor([0., 0., 1., 1., 3., 3., 3., 3.], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Counts per image: tensor([2, 2, 4], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT tensor shape: torch.Size([4, 4, 5])
[utils/util.py::ComputeLoss.__call__] Image 0: 2 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 1: 2 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 3: 4 targets assigned
[utils/util.py::ComputeLoss.__call__] GT before coordinate conversion: tensor([[[0.0000, 0.5193, 0.8776, 0.0952, 0.1920],
         [0.0000, 0.8509, 0.8145, 0.0713, 0.1450],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.5268, 0.0403, 0.0862, 0.0806],
         [0.0000, 0.2839, 0.9418, 0.0883, 0.1164],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.9921, 0.0911, 0.0159, 0.0997],
         [0.0000, 0.4046, 0.1034, 0.0537, 0.0976],
         [0.0000, 0.7651, 0.7888, 0.0504, 0.1003],
         [0.0000, 0.3934, 0.8723, 0.0534, 0.0973]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT after coordinate conversion: tensor([[[  0.0000, 120.7442, 100.0430, 145.1274, 124.6144],
         [  0.0000, 208.7112,  94.9757, 226.9623, 113.5346],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000, 123.8415,   0.0000, 145.8961,  10.3194],
         [  0.0000,  61.3633, 113.1029,  83.9698, 127.9990],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000, 251.9396,   5.2793, 256.0000,  18.0410],
         [  0.0000,  96.7191,   6.9933, 110.4536,  19.4860],
         [  0.0000, 189.4045,  94.5511, 202.3035, 107.3871],
         [  0.0000,  93.8806, 105.4271, 107.5465, 117.8798]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT labels shape: torch.Size([4, 4, 1])
[utils/util.py::ComputeLoss.__call__] GT bboxes shape: torch.Size([4, 4, 4])
[utils/util.py::ComputeLoss.__call__] GT mask shape: torch.Size([4, 4, 1])
[utils/util.py::ComputeLoss.__call__] Pred output dimensions - b: 4, a: 512, c: 64
[utils/util.py::ComputeLoss.__call__] Pred bboxes after softmax shape: torch.Size([4, 512, 4, 16])
[utils/util.py::ComputeLoss.__call__] Pred bboxes after matmul shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Final pred bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.__call__] ASSIGNMENT PHASE ---

--- [utils/util.py::ComputeLoss.assign] PYTORCH ASSIGNMENT DEBUG ---
[utils/util.py::ComputeLoss.assign] pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] true_labels shape: torch.Size([4, 4, 1])
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 4, 4])
[utils/util.py::ComputeLoss.assign] true_mask shape: torch.Size([4, 4, 1])
[utils/util.py::ComputeLoss.assign] anchors shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.assign] Batch size: 4, Max boxes: 4
[utils/util.py::ComputeLoss.assign] Created indices tensor with shape: torch.Size([2, 4, 4])

--- [utils/util.py::ComputeLoss.assign] IOUs DEBUG ---
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 4, 4])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([4, 4, 1, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([4, 1, 512, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([4, 4, 1, 1]), h: torch.Size([4, 4, 1, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([4, 1, 512, 1]), h: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([4, 4, 512, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([4, 4, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([4, 4, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.000000, max: 0.374753
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([4, 4, 512, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([4, 4, 512, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([4, 4, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([4, 4, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: -0.913202, max: 0.370787
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.assign] overlaps shape: torch.Size([4, 4, 512])
[utils/util.py::ComputeLoss.assign] overlaps min: 0.0, max: 0.37078654766082764
[utils/util.py::ComputeLoss.assign] align_metric shape: torch.Size([4, 4, 512])
[utils/util.py::ComputeLoss.assign] align_metric min: 0.0, max: 0.00020254185074009
[utils/util.py::ComputeLoss.assign] mask_in_gts shape: torch.Size([4, 4, 512])
[utils/util.py::ComputeLoss.assign] mask_in_gts sum: 26.0
[utils/util.py::ComputeLoss.assign] metrics shape: torch.Size([4, 4, 512])
[utils/util.py::ComputeLoss.assign] top_k_mask shape: torch.Size([4, 4, 10])
[utils/util.py::ComputeLoss.assign] top_k_metrics shape: torch.Size([4, 4, 10])
[utils/util.py::ComputeLoss.assign] top_k_indices shape: torch.Size([4, 4, 10])
[utils/util.py::ComputeLoss.assign] is_in_top_k shape: torch.Size([4, 4, 512])
[utils/util.py::ComputeLoss.assign] mask_top_k shape: torch.Size([4, 4, 512])
[utils/util.py::ComputeLoss.assign] mask_pos shape: torch.Size([4, 4, 512])
[utils/util.py::ComputeLoss.assign] fg_mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] fg_mask sum: 26.0
[utils/util.py::ComputeLoss.assign] target_gt_idx shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_labels shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] Normalized target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] target_scores sum: 1.9438204765319824
--- [utils/util.py::ComputeLoss.assign] END PYTORCH ASSIGNMENT DEBUG ---

[utils/util.py::ComputeLoss.__call__] Target bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Target scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] FG mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.__call__] Target scores sum: 1.943820
[utils/util.py::ComputeLoss.__call__] Classification loss computed: 6.374367
[utils/util.py::ComputeLoss.__call__] Foreground count: 26
[utils/util.py::ComputeLoss.__call__] Weight shape: torch.Size([26, 1])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([26, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([26, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([26, 1]), h: torch.Size([26, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([26, 1]), h: torch.Size([26, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([26, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([26, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([26, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.027504, max: 0.374691
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([26, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([26, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([26, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([26, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: 0.020698, max: 0.370724
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.__call__] IoU values shape: torch.Size([26, 1])
[utils/util.py::ComputeLoss.__call__] Box loss computed: 0.803091
[utils/util.py::ComputeLoss.__call__] Target LT-RB shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.df_loss] PYTORCH DFL LOSS DEBUG ---
[utils/util.py::ComputeLoss.df_loss] pred_dist shape: torch.Size([104, 16])
[utils/util.py::ComputeLoss.df_loss] target shape: torch.Size([26, 4])
[utils/util.py::ComputeLoss.df_loss] DFL loss shape: torch.Size([26, 1])
[utils/util.py::ComputeLoss.df_loss] DFL loss mean: 1.628972
--- [utils/util.py::ComputeLoss.df_loss] END PYTORCH DFL LOSS DEBUG ---

[utils/util.py::ComputeLoss.__call__] DFL loss before weighting: 1.628972
[utils/util.py::ComputeLoss.__call__] DFL loss computed: 1.500582

--- [utils/util.py::ComputeLoss.__call__] LOSS COMPONENTS DEBUG ---
[utils/util.py::ComputeLoss.__call__] Raw loss_cls: 6.374367
[utils/util.py::ComputeLoss.__call__] Raw loss_box: 0.803091
[utils/util.py::ComputeLoss.__call__] Raw loss_dfl: 1.500582
[utils/util.py::ComputeLoss.__call__] Loss weights - cls: 0.5, box: 7.5, dfl: 1.5
[utils/util.py::ComputeLoss.__call__] target_scores_sum: 1.943820
[utils/util.py::ComputeLoss.__call__] fg_mask sum: 26
[utils/util.py::ComputeLoss.__call__] Weighted loss_cls: 3.187183
[utils/util.py::ComputeLoss.__call__] Weighted loss_box: 6.023180
[utils/util.py::ComputeLoss.__call__] Weighted loss_dfl: 2.250873
[utils/util.py::ComputeLoss.__call__] Total loss: 11.461236
--- [utils/util.py::ComputeLoss.__call__] END PYTORCH LOSS COMPUTATION DEBUG ---


--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([4, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: True
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([4, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - box shape: torch.Size([4, 64, 16, 32]), cls shape: torch.Size([4, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - final concat shape: torch.Size([4, 65, 16, 32])

--- [utils/util.py::ComputeLoss.__call__] PYTORCH LOSS COMPUTATION DEBUG ---
[utils/util.py::ComputeLoss.__call__] Outputs type: <class 'list'>
[utils/util.py::ComputeLoss.__call__] x type: <class 'list'>, len: 1
[utils/util.py::ComputeLoss.__call__] x[0] shape: torch.Size([4, 65, 16, 32])
[utils/util.py::ComputeLoss.__call__] Concatenated output shape: torch.Size([4, 65, 512])
[utils/util.py::ComputeLoss.__call__] self.no: 65, self.dfl_ch: 16, self.nc: 1
[utils/util.py::ComputeLoss.__call__] pred_output shape: torch.Size([4, 64, 512])
[utils/util.py::ComputeLoss.__call__] pred_scores shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.__call__] After permute - pred_output shape: torch.Size([4, 512, 64])
[utils/util.py::ComputeLoss.__call__] After permute - pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Size tensor: tensor([128., 256.], device='cuda:0', dtype=torch.float16)
[utils/util.py::ComputeLoss.__call__] Stride: tensor([8.])
[utils/util.py::ComputeLoss.__call__] Anchor points shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.__call__] Stride tensor shape: torch.Size([512, 1])

--- [utils/util.py::ComputeLoss.__call__] TARGET PROCESSING ---
[utils/util.py::ComputeLoss.__call__] Targets shape: torch.Size([6, 6])
[utils/util.py::ComputeLoss.__call__] Targets dtype: torch.float32
[utils/util.py::ComputeLoss.__call__] First few targets: tensor([[0.0000, 0.0000, 0.8064, 0.5850, 0.1095, 0.2130],
        [1.0000, 0.0000, 0.8094, 0.4638, 0.0855, 0.1692],
        [1.0000, 0.0000, 0.9930, 0.3031, 0.0140, 0.1537],
        [2.0000, 0.0000, 0.3143, 0.0339, 0.1085, 0.0677],
        [3.0000, 0.0000, 0.9889, 0.6377, 0.0223, 0.2036]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Image indices: tensor([0., 1., 1., 2., 3., 3.], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Counts per image: tensor([1, 2, 1, 2], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT tensor shape: torch.Size([4, 2, 5])
[utils/util.py::ComputeLoss.__call__] Image 0: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 1: 2 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 2: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 3: 2 targets assigned
[utils/util.py::ComputeLoss.__call__] GT before coordinate conversion: tensor([[[0.0000, 0.8064, 0.5850, 0.1095, 0.2130],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.8094, 0.4638, 0.0855, 0.1692],
         [0.0000, 0.9930, 0.3031, 0.0140, 0.1537]],

        [[0.0000, 0.3143, 0.0339, 0.1085, 0.0677],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.9889, 0.6377, 0.0223, 0.2036],
         [0.0000, 0.0713, 0.4528, 0.0876, 0.1669]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT after coordinate conversion: tensor([[[  0.0000, 192.4253,  61.2462, 220.4553,  88.5059],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000, 196.2625,  48.5391, 218.1603,  70.1946],
         [  0.0000, 252.4140,  28.9662, 255.9990,  48.6369]],

        [[  0.0000,  66.5618,   0.0000,  94.3408,   8.6684],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000, 250.3031,  68.5971, 256.0000,  94.6586],
         [  0.0000,   7.0261,  47.2728,  29.4547,  68.6401]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT labels shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.__call__] GT bboxes shape: torch.Size([4, 2, 4])
[utils/util.py::ComputeLoss.__call__] GT mask shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.__call__] Pred output dimensions - b: 4, a: 512, c: 64
[utils/util.py::ComputeLoss.__call__] Pred bboxes after softmax shape: torch.Size([4, 512, 4, 16])
[utils/util.py::ComputeLoss.__call__] Pred bboxes after matmul shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Final pred bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.__call__] ASSIGNMENT PHASE ---

--- [utils/util.py::ComputeLoss.assign] PYTORCH ASSIGNMENT DEBUG ---
[utils/util.py::ComputeLoss.assign] pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] true_labels shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 2, 4])
[utils/util.py::ComputeLoss.assign] true_mask shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.assign] anchors shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.assign] Batch size: 4, Max boxes: 2
[utils/util.py::ComputeLoss.assign] Created indices tensor with shape: torch.Size([2, 4, 2])

--- [utils/util.py::ComputeLoss.assign] IOUs DEBUG ---
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 2, 4])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([4, 2, 1, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([4, 1, 512, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([4, 2, 1, 1]), h: torch.Size([4, 2, 1, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([4, 1, 512, 1]), h: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.000000, max: 0.477133
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: -0.885973, max: 0.473837
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.assign] overlaps shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] overlaps min: 0.0, max: 0.47383683919906616
[utils/util.py::ComputeLoss.assign] align_metric shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] align_metric min: 0.0, max: 0.0010893932776525617
[utils/util.py::ComputeLoss.assign] mask_in_gts shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] mask_in_gts sum: 34.0
[utils/util.py::ComputeLoss.assign] metrics shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] top_k_mask shape: torch.Size([4, 2, 10])
[utils/util.py::ComputeLoss.assign] top_k_metrics shape: torch.Size([4, 2, 10])
[utils/util.py::ComputeLoss.assign] top_k_indices shape: torch.Size([4, 2, 10])
[utils/util.py::ComputeLoss.assign] is_in_top_k shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] mask_top_k shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] mask_pos shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] fg_mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] fg_mask sum: 32.0
[utils/util.py::ComputeLoss.assign] target_gt_idx shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_labels shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] Normalized target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] target_scores sum: 2.4752721786499023
--- [utils/util.py::ComputeLoss.assign] END PYTORCH ASSIGNMENT DEBUG ---

[utils/util.py::ComputeLoss.__call__] Target bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Target scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] FG mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.__call__] Target scores sum: 2.475272
[utils/util.py::ComputeLoss.__call__] Classification loss computed: 6.173563
[utils/util.py::ComputeLoss.__call__] Foreground count: 32
[utils/util.py::ComputeLoss.__call__] Weight shape: torch.Size([32, 1])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([32, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([32, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([32, 1]), h: torch.Size([32, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([32, 1]), h: torch.Size([32, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([32, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([32, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([32, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.066281, max: 0.477257
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([32, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([32, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([32, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([32, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: 0.017864, max: 0.473960
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.__call__] IoU values shape: torch.Size([32, 1])
[utils/util.py::ComputeLoss.__call__] Box loss computed: 0.715310
[utils/util.py::ComputeLoss.__call__] Target LT-RB shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.df_loss] PYTORCH DFL LOSS DEBUG ---
[utils/util.py::ComputeLoss.df_loss] pred_dist shape: torch.Size([128, 16])
[utils/util.py::ComputeLoss.df_loss] target shape: torch.Size([32, 4])
[utils/util.py::ComputeLoss.df_loss] DFL loss shape: torch.Size([32, 1])
[utils/util.py::ComputeLoss.df_loss] DFL loss mean: 1.722642
--- [utils/util.py::ComputeLoss.df_loss] END PYTORCH DFL LOSS DEBUG ---

[utils/util.py::ComputeLoss.__call__] DFL loss before weighting: 1.722642
[utils/util.py::ComputeLoss.__call__] DFL loss computed: 1.549563

--- [utils/util.py::ComputeLoss.__call__] LOSS COMPONENTS DEBUG ---
[utils/util.py::ComputeLoss.__call__] Raw loss_cls: 6.173563
[utils/util.py::ComputeLoss.__call__] Raw loss_box: 0.715310
[utils/util.py::ComputeLoss.__call__] Raw loss_dfl: 1.549563
[utils/util.py::ComputeLoss.__call__] Loss weights - cls: 0.5, box: 7.5, dfl: 1.5
[utils/util.py::ComputeLoss.__call__] target_scores_sum: 2.475272
[utils/util.py::ComputeLoss.__call__] fg_mask sum: 32
[utils/util.py::ComputeLoss.__call__] Weighted loss_cls: 3.086782
[utils/util.py::ComputeLoss.__call__] Weighted loss_box: 5.364822
[utils/util.py::ComputeLoss.__call__] Weighted loss_dfl: 2.324345
[utils/util.py::ComputeLoss.__call__] Total loss: 10.775949
--- [utils/util.py::ComputeLoss.__call__] END PYTORCH LOSS COMPUTATION DEBUG ---


--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([4, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: True
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([4, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - box shape: torch.Size([4, 64, 16, 32]), cls shape: torch.Size([4, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - final concat shape: torch.Size([4, 65, 16, 32])

--- [utils/util.py::ComputeLoss.__call__] PYTORCH LOSS COMPUTATION DEBUG ---
[utils/util.py::ComputeLoss.__call__] Outputs type: <class 'list'>
[utils/util.py::ComputeLoss.__call__] x type: <class 'list'>, len: 1
[utils/util.py::ComputeLoss.__call__] x[0] shape: torch.Size([4, 65, 16, 32])
[utils/util.py::ComputeLoss.__call__] Concatenated output shape: torch.Size([4, 65, 512])
[utils/util.py::ComputeLoss.__call__] self.no: 65, self.dfl_ch: 16, self.nc: 1
[utils/util.py::ComputeLoss.__call__] pred_output shape: torch.Size([4, 64, 512])
[utils/util.py::ComputeLoss.__call__] pred_scores shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.__call__] After permute - pred_output shape: torch.Size([4, 512, 64])
[utils/util.py::ComputeLoss.__call__] After permute - pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Size tensor: tensor([128., 256.], device='cuda:0', dtype=torch.float16)
[utils/util.py::ComputeLoss.__call__] Stride: tensor([8.])
[utils/util.py::ComputeLoss.__call__] Anchor points shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.__call__] Stride tensor shape: torch.Size([512, 1])

--- [utils/util.py::ComputeLoss.__call__] TARGET PROCESSING ---
[utils/util.py::ComputeLoss.__call__] Targets shape: torch.Size([6, 6])
[utils/util.py::ComputeLoss.__call__] Targets dtype: torch.float32
[utils/util.py::ComputeLoss.__call__] First few targets: tensor([[1.0000, 0.0000, 0.1112, 0.6746, 0.0639, 0.1249],
        [1.0000, 0.0000, 0.6666, 0.6691, 0.0656, 0.1251],
        [2.0000, 0.0000, 0.5099, 0.0422, 0.0489, 0.0843],
        [2.0000, 0.0000, 0.8128, 0.6035, 0.0616, 0.1181],
        [2.0000, 0.0000, 0.2329, 0.6901, 0.0636, 0.1212]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Image indices: tensor([1., 1., 2., 2., 2., 3.], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Counts per image: tensor([2, 3, 1], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT tensor shape: torch.Size([4, 3, 5])
[utils/util.py::ComputeLoss.__call__] Image 1: 2 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 2: 3 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 3: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] GT before coordinate conversion: tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.1112, 0.6746, 0.0639, 0.1249],
         [0.0000, 0.6666, 0.6691, 0.0656, 0.1251],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.5099, 0.0422, 0.0489, 0.0843],
         [0.0000, 0.8128, 0.6035, 0.0616, 0.1181],
         [0.0000, 0.2329, 0.6901, 0.0636, 0.1212]],

        [[0.0000, 0.4306, 0.3433, 0.0777, 0.1591],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT after coordinate conversion: tensor([[[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000,  20.2769,  78.3552,  36.6364,  94.3370],
         [  0.0000, 162.2490,  77.6324, 179.0370,  93.6505],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000, 124.2713,   0.0000, 136.7818,  10.7929],
         [  0.0000, 200.1867,  69.6892, 215.9488,  84.8106],
         [  0.0000,  51.4895,  80.5800,  67.7653,  96.0883]],

        [[  0.0000, 100.2805,  33.7587, 120.1705,  54.1188],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT labels shape: torch.Size([4, 3, 1])
[utils/util.py::ComputeLoss.__call__] GT bboxes shape: torch.Size([4, 3, 4])
[utils/util.py::ComputeLoss.__call__] GT mask shape: torch.Size([4, 3, 1])
[utils/util.py::ComputeLoss.__call__] Pred output dimensions - b: 4, a: 512, c: 64
[utils/util.py::ComputeLoss.__call__] Pred bboxes after softmax shape: torch.Size([4, 512, 4, 16])
[utils/util.py::ComputeLoss.__call__] Pred bboxes after matmul shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Final pred bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.__call__] ASSIGNMENT PHASE ---

--- [utils/util.py::ComputeLoss.assign] PYTORCH ASSIGNMENT DEBUG ---
[utils/util.py::ComputeLoss.assign] pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] true_labels shape: torch.Size([4, 3, 1])
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 3, 4])
[utils/util.py::ComputeLoss.assign] true_mask shape: torch.Size([4, 3, 1])
[utils/util.py::ComputeLoss.assign] anchors shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.assign] Batch size: 4, Max boxes: 3
[utils/util.py::ComputeLoss.assign] Created indices tensor with shape: torch.Size([2, 4, 3])

--- [utils/util.py::ComputeLoss.assign] IOUs DEBUG ---
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 3, 4])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([4, 3, 1, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([4, 1, 512, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([4, 3, 1, 1]), h: torch.Size([4, 3, 1, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([4, 1, 512, 1]), h: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.000000, max: 0.292980
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: -0.996122, max: 0.273567
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.assign] overlaps shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] overlaps min: 0.0, max: 0.2735671103000641
[utils/util.py::ComputeLoss.assign] align_metric shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] align_metric min: 0.0, max: 2.2436905055656098e-05
[utils/util.py::ComputeLoss.assign] mask_in_gts shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] mask_in_gts sum: 23.0
[utils/util.py::ComputeLoss.assign] metrics shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] top_k_mask shape: torch.Size([4, 3, 10])
[utils/util.py::ComputeLoss.assign] top_k_metrics shape: torch.Size([4, 3, 10])
[utils/util.py::ComputeLoss.assign] top_k_indices shape: torch.Size([4, 3, 10])
[utils/util.py::ComputeLoss.assign] is_in_top_k shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] mask_top_k shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] mask_pos shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] fg_mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] fg_mask sum: 23.0
[utils/util.py::ComputeLoss.assign] target_gt_idx shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_labels shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] Normalized target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] target_scores sum: 1.975028395652771
--- [utils/util.py::ComputeLoss.assign] END PYTORCH ASSIGNMENT DEBUG ---

[utils/util.py::ComputeLoss.__call__] Target bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Target scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] FG mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.__call__] Target scores sum: 1.975028
[utils/util.py::ComputeLoss.__call__] Classification loss computed: 6.744365
[utils/util.py::ComputeLoss.__call__] Foreground count: 23
[utils/util.py::ComputeLoss.__call__] Weight shape: torch.Size([23, 1])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([23, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([23, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([23, 1]), h: torch.Size([23, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([23, 1]), h: torch.Size([23, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([23, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([23, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([23, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.073865, max: 0.292813
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([23, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([23, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([23, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([23, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: 0.072353, max: 0.273401
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.__call__] IoU values shape: torch.Size([23, 1])
[utils/util.py::ComputeLoss.__call__] Box loss computed: 0.832637
[utils/util.py::ComputeLoss.__call__] Target LT-RB shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.df_loss] PYTORCH DFL LOSS DEBUG ---
[utils/util.py::ComputeLoss.df_loss] pred_dist shape: torch.Size([92, 16])
[utils/util.py::ComputeLoss.df_loss] target shape: torch.Size([23, 4])
[utils/util.py::ComputeLoss.df_loss] DFL loss shape: torch.Size([23, 1])
[utils/util.py::ComputeLoss.df_loss] DFL loss mean: 1.579944
--- [utils/util.py::ComputeLoss.df_loss] END PYTORCH DFL LOSS DEBUG ---

[utils/util.py::ComputeLoss.__call__] DFL loss before weighting: 1.579944
[utils/util.py::ComputeLoss.__call__] DFL loss computed: 1.571486

--- [utils/util.py::ComputeLoss.__call__] LOSS COMPONENTS DEBUG ---
[utils/util.py::ComputeLoss.__call__] Raw loss_cls: 6.744365
[utils/util.py::ComputeLoss.__call__] Raw loss_box: 0.832637
[utils/util.py::ComputeLoss.__call__] Raw loss_dfl: 1.571486
[utils/util.py::ComputeLoss.__call__] Loss weights - cls: 0.5, box: 7.5, dfl: 1.5
[utils/util.py::ComputeLoss.__call__] target_scores_sum: 1.975028
[utils/util.py::ComputeLoss.__call__] fg_mask sum: 23
[utils/util.py::ComputeLoss.__call__] Weighted loss_cls: 3.372183
[utils/util.py::ComputeLoss.__call__] Weighted loss_box: 6.244775
[utils/util.py::ComputeLoss.__call__] Weighted loss_dfl: 2.357229
[utils/util.py::ComputeLoss.__call__] Total loss: 11.974187
--- [utils/util.py::ComputeLoss.__call__] END PYTORCH LOSS COMPUTATION DEBUG ---


--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([4, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: True
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([4, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - box shape: torch.Size([4, 64, 16, 32]), cls shape: torch.Size([4, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - final concat shape: torch.Size([4, 65, 16, 32])

--- [utils/util.py::ComputeLoss.__call__] PYTORCH LOSS COMPUTATION DEBUG ---
[utils/util.py::ComputeLoss.__call__] Outputs type: <class 'list'>
[utils/util.py::ComputeLoss.__call__] x type: <class 'list'>, len: 1
[utils/util.py::ComputeLoss.__call__] x[0] shape: torch.Size([4, 65, 16, 32])
[utils/util.py::ComputeLoss.__call__] Concatenated output shape: torch.Size([4, 65, 512])
[utils/util.py::ComputeLoss.__call__] self.no: 65, self.dfl_ch: 16, self.nc: 1
[utils/util.py::ComputeLoss.__call__] pred_output shape: torch.Size([4, 64, 512])
[utils/util.py::ComputeLoss.__call__] pred_scores shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.__call__] After permute - pred_output shape: torch.Size([4, 512, 64])
[utils/util.py::ComputeLoss.__call__] After permute - pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Size tensor: tensor([128., 256.], device='cuda:0', dtype=torch.float16)
[utils/util.py::ComputeLoss.__call__] Stride: tensor([8.])
[utils/util.py::ComputeLoss.__call__] Anchor points shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.__call__] Stride tensor shape: torch.Size([512, 1])

--- [utils/util.py::ComputeLoss.__call__] TARGET PROCESSING ---
[utils/util.py::ComputeLoss.__call__] Targets shape: torch.Size([4, 6])
[utils/util.py::ComputeLoss.__call__] Targets dtype: torch.float32
[utils/util.py::ComputeLoss.__call__] First few targets: tensor([[0.0000, 0.0000, 0.9744, 0.0833, 0.0512, 0.1666],
        [1.0000, 0.0000, 0.7475, 0.7282, 0.0785, 0.1631],
        [1.0000, 0.0000, 0.0518, 0.7085, 0.0703, 0.1350],
        [2.0000, 0.0000, 0.6911, 0.8133, 0.0906, 0.1811]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Image indices: tensor([0., 1., 1., 2.], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Counts per image: tensor([1, 2, 1], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT tensor shape: torch.Size([4, 2, 5])
[utils/util.py::ComputeLoss.__call__] Image 0: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 1: 2 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 2: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] GT before coordinate conversion: tensor([[[0.0000, 0.9744, 0.0833, 0.0512, 0.1666],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.7475, 0.7282, 0.0785, 0.1631],
         [0.0000, 0.0518, 0.7085, 0.0703, 0.1350]],

        [[0.0000, 0.6911, 0.8133, 0.0906, 0.1811],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT after coordinate conversion: tensor([[[  0.0000, 242.9012,   0.0000, 255.9990,  21.3213],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000, 181.3145,  82.7765, 201.4179, 103.6500],
         [  0.0000,   4.2529,  82.0567,  22.2473,  99.3314]],

        [[  0.0000, 165.3349,  92.5052, 188.5208, 115.6912],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT labels shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.__call__] GT bboxes shape: torch.Size([4, 2, 4])
[utils/util.py::ComputeLoss.__call__] GT mask shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.__call__] Pred output dimensions - b: 4, a: 512, c: 64
[utils/util.py::ComputeLoss.__call__] Pred bboxes after softmax shape: torch.Size([4, 512, 4, 16])
[utils/util.py::ComputeLoss.__call__] Pred bboxes after matmul shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Final pred bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.__call__] ASSIGNMENT PHASE ---

--- [utils/util.py::ComputeLoss.assign] PYTORCH ASSIGNMENT DEBUG ---
[utils/util.py::ComputeLoss.assign] pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] true_labels shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 2, 4])
[utils/util.py::ComputeLoss.assign] true_mask shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.assign] anchors shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.assign] Batch size: 4, Max boxes: 2
[utils/util.py::ComputeLoss.assign] Created indices tensor with shape: torch.Size([2, 4, 2])

--- [utils/util.py::ComputeLoss.assign] IOUs DEBUG ---
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 2, 4])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([4, 2, 1, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([4, 1, 512, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([4, 2, 1, 1]), h: torch.Size([4, 2, 1, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([4, 1, 512, 1]), h: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.000000, max: 0.362013
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: -0.934364, max: 0.351196
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.assign] overlaps shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] overlaps min: 0.0, max: 0.3511962294578552
[utils/util.py::ComputeLoss.assign] align_metric shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] align_metric min: 0.0, max: 0.00011315757728880271
[utils/util.py::ComputeLoss.assign] mask_in_gts shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] mask_in_gts sum: 22.0
[utils/util.py::ComputeLoss.assign] metrics shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] top_k_mask shape: torch.Size([4, 2, 10])
[utils/util.py::ComputeLoss.assign] top_k_metrics shape: torch.Size([4, 2, 10])
[utils/util.py::ComputeLoss.assign] top_k_indices shape: torch.Size([4, 2, 10])
[utils/util.py::ComputeLoss.assign] is_in_top_k shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] mask_top_k shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] mask_pos shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] fg_mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] fg_mask sum: 22.0
[utils/util.py::ComputeLoss.assign] target_gt_idx shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_labels shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] Normalized target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] target_scores sum: 2.3608129024505615
--- [utils/util.py::ComputeLoss.assign] END PYTORCH ASSIGNMENT DEBUG ---

[utils/util.py::ComputeLoss.__call__] Target bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Target scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] FG mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.__call__] Target scores sum: 2.360813
[utils/util.py::ComputeLoss.__call__] Classification loss computed: 6.539061
[utils/util.py::ComputeLoss.__call__] Foreground count: 22
[utils/util.py::ComputeLoss.__call__] Weight shape: torch.Size([22, 1])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([22, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([22, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([22, 1]), h: torch.Size([22, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([22, 1]), h: torch.Size([22, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([22, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([22, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([22, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.139561, max: 0.362013
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([22, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([22, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([22, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([22, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: 0.106969, max: 0.351196
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.__call__] IoU values shape: torch.Size([22, 1])
[utils/util.py::ComputeLoss.__call__] Box loss computed: 0.755245
[utils/util.py::ComputeLoss.__call__] Target LT-RB shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.df_loss] PYTORCH DFL LOSS DEBUG ---
[utils/util.py::ComputeLoss.df_loss] pred_dist shape: torch.Size([88, 16])
[utils/util.py::ComputeLoss.df_loss] target shape: torch.Size([22, 4])
[utils/util.py::ComputeLoss.df_loss] DFL loss shape: torch.Size([22, 1])
[utils/util.py::ComputeLoss.df_loss] DFL loss mean: 1.543229
--- [utils/util.py::ComputeLoss.df_loss] END PYTORCH DFL LOSS DEBUG ---

[utils/util.py::ComputeLoss.__call__] DFL loss before weighting: 1.543229
[utils/util.py::ComputeLoss.__call__] DFL loss computed: 1.442285

--- [utils/util.py::ComputeLoss.__call__] LOSS COMPONENTS DEBUG ---
[utils/util.py::ComputeLoss.__call__] Raw loss_cls: 6.539061
[utils/util.py::ComputeLoss.__call__] Raw loss_box: 0.755245
[utils/util.py::ComputeLoss.__call__] Raw loss_dfl: 1.442285
[utils/util.py::ComputeLoss.__call__] Loss weights - cls: 0.5, box: 7.5, dfl: 1.5
[utils/util.py::ComputeLoss.__call__] target_scores_sum: 2.360813
[utils/util.py::ComputeLoss.__call__] fg_mask sum: 22
[utils/util.py::ComputeLoss.__call__] Weighted loss_cls: 3.269531
[utils/util.py::ComputeLoss.__call__] Weighted loss_box: 5.664336
[utils/util.py::ComputeLoss.__call__] Weighted loss_dfl: 2.163427
[utils/util.py::ComputeLoss.__call__] Total loss: 11.097294
--- [utils/util.py::ComputeLoss.__call__] END PYTORCH LOSS COMPUTATION DEBUG ---

Evaluating on training data...

--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([8, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: False
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([8, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Inference mode - processing...
[nets/tinysimov35.py::Head.forward] Box feature shape: torch.Size([8, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Cls feature shape: torch.Size([8, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Anchors shape: torch.Size([2, 512])
[nets/tinysimov35.py::Head.forward] Strides shape: torch.Size([1, 512])
[nets/tinysimov35.py::Head.forward] Combined features shape: torch.Size([8, 65, 16, 32])
[nets/tinysimov35.py::Head.forward] Combined flat shape: torch.Size([8, 65, 512])
[nets/tinysimov35.py::Head.forward] Expected self.no: 65
[nets/tinysimov35.py::Head.forward] Split - box shape: torch.Size([8, 64, 512]), cls shape: torch.Size([8, 1, 512])

--- [nets/tinysimov35.py::DFL.forward] PYTORCH DFL DEBUG ---
[nets/tinysimov35.py::DFL.forward] Input shape: torch.Size([8, 64, 512])
[nets/tinysimov35.py::DFL.forward] DFL channels (self.ch): 16
[nets/tinysimov35.py::DFL.forward] Parsed dimensions - batch: 8, channels: 64, anchors: 512
[nets/tinysimov35.py::DFL.forward] After view(b, 4, ch, a): torch.Size([8, 4, 16, 512])
[nets/tinysimov35.py::DFL.forward] After transpose(2, 1): torch.Size([8, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After softmax(1): torch.Size([8, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After conv: torch.Size([8, 1, 4, 512])
[nets/tinysimov35.py::DFL.forward] Final output shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL output shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL split - a shape: torch.Size([8, 2, 512]), b shape: torch.Size([8, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchors expanded shape: torch.Size([1, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchor adjusted - a: torch.Size([8, 2, 512]), b: torch.Size([8, 2, 512])
[nets/tinysimov35.py::Head.forward] Box coordinates shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] Scaled boxes shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] Sigmoid classes shape: torch.Size([8, 1, 512])
[nets/tinysimov35.py::Head.forward] Final output shape: torch.Size([8, 5, 512])
[main.py::test] Model outputs shape: torch.Size([8, 5, 512])

--- [utils/util.py::non_max_suppression] PYTORCH NMS DEBUG ---
[utils/util.py::non_max_suppression] Prediction shape: torch.Size([8, 5, 512])
[utils/util.py::non_max_suppression] Conf threshold: 0.25, IoU threshold: 0.45
[utils/util.py::non_max_suppression] Number of classes: 1
[utils/util.py::non_max_suppression] Candidates per image: [0, 0, 0, 0, 0, 0, 0, 0]

--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([8, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: False
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([8, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Inference mode - processing...
[nets/tinysimov35.py::Head.forward] Box feature shape: torch.Size([8, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Cls feature shape: torch.Size([8, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Anchors shape: torch.Size([2, 512])
[nets/tinysimov35.py::Head.forward] Strides shape: torch.Size([1, 512])
[nets/tinysimov35.py::Head.forward] Combined features shape: torch.Size([8, 65, 16, 32])
[nets/tinysimov35.py::Head.forward] Combined flat shape: torch.Size([8, 65, 512])
[nets/tinysimov35.py::Head.forward] Expected self.no: 65
[nets/tinysimov35.py::Head.forward] Split - box shape: torch.Size([8, 64, 512]), cls shape: torch.Size([8, 1, 512])

--- [nets/tinysimov35.py::DFL.forward] PYTORCH DFL DEBUG ---
[nets/tinysimov35.py::DFL.forward] Input shape: torch.Size([8, 64, 512])
[nets/tinysimov35.py::DFL.forward] DFL channels (self.ch): 16
[nets/tinysimov35.py::DFL.forward] Parsed dimensions - batch: 8, channels: 64, anchors: 512
[nets/tinysimov35.py::DFL.forward] After view(b, 4, ch, a): torch.Size([8, 4, 16, 512])
[nets/tinysimov35.py::DFL.forward] After transpose(2, 1): torch.Size([8, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After softmax(1): torch.Size([8, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After conv: torch.Size([8, 1, 4, 512])
[nets/tinysimov35.py::DFL.forward] Final output shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL output shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL split - a shape: torch.Size([8, 2, 512]), b shape: torch.Size([8, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchors expanded shape: torch.Size([1, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchor adjusted - a: torch.Size([8, 2, 512]), b: torch.Size([8, 2, 512])
[nets/tinysimov35.py::Head.forward] Box coordinates shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] Scaled boxes shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] Sigmoid classes shape: torch.Size([8, 1, 512])
[nets/tinysimov35.py::Head.forward] Final output shape: torch.Size([8, 5, 512])
[main.py::test] Model outputs shape: torch.Size([8, 5, 512])

--- [utils/util.py::non_max_suppression] PYTORCH NMS DEBUG ---
[utils/util.py::non_max_suppression] Prediction shape: torch.Size([8, 5, 512])
[utils/util.py::non_max_suppression] Conf threshold: 0.25, IoU threshold: 0.45
[utils/util.py::non_max_suppression] Number of classes: 1
[utils/util.py::non_max_suppression] Candidates per image: [0, 0, 0, 0, 0, 0, 0, 0]

--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([8, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: False
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([8, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Inference mode - processing...
[nets/tinysimov35.py::Head.forward] Box feature shape: torch.Size([8, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Cls feature shape: torch.Size([8, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Anchors shape: torch.Size([2, 512])
[nets/tinysimov35.py::Head.forward] Strides shape: torch.Size([1, 512])
[nets/tinysimov35.py::Head.forward] Combined features shape: torch.Size([8, 65, 16, 32])
[nets/tinysimov35.py::Head.forward] Combined flat shape: torch.Size([8, 65, 512])
[nets/tinysimov35.py::Head.forward] Expected self.no: 65
[nets/tinysimov35.py::Head.forward] Split - box shape: torch.Size([8, 64, 512]), cls shape: torch.Size([8, 1, 512])

--- [nets/tinysimov35.py::DFL.forward] PYTORCH DFL DEBUG ---
[nets/tinysimov35.py::DFL.forward] Input shape: torch.Size([8, 64, 512])
[nets/tinysimov35.py::DFL.forward] DFL channels (self.ch): 16
[nets/tinysimov35.py::DFL.forward] Parsed dimensions - batch: 8, channels: 64, anchors: 512
[nets/tinysimov35.py::DFL.forward] After view(b, 4, ch, a): torch.Size([8, 4, 16, 512])
[nets/tinysimov35.py::DFL.forward] After transpose(2, 1): torch.Size([8, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After softmax(1): torch.Size([8, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After conv: torch.Size([8, 1, 4, 512])
[nets/tinysimov35.py::DFL.forward] Final output shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL output shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL split - a shape: torch.Size([8, 2, 512]), b shape: torch.Size([8, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchors expanded shape: torch.Size([1, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchor adjusted - a: torch.Size([8, 2, 512]), b: torch.Size([8, 2, 512])
[nets/tinysimov35.py::Head.forward] Box coordinates shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] Scaled boxes shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] Sigmoid classes shape: torch.Size([8, 1, 512])
[nets/tinysimov35.py::Head.forward] Final output shape: torch.Size([8, 5, 512])
[main.py::test] Model outputs shape: torch.Size([8, 5, 512])

--- [utils/util.py::non_max_suppression] PYTORCH NMS DEBUG ---
[utils/util.py::non_max_suppression] Prediction shape: torch.Size([8, 5, 512])
[utils/util.py::non_max_suppression] Conf threshold: 0.25, IoU threshold: 0.45
[utils/util.py::non_max_suppression] Number of classes: 1
[utils/util.py::non_max_suppression] Candidates per image: [0, 0, 0, 0, 0, 0, 0, 0]

--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([8, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: False
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([8, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Inference mode - processing...
[nets/tinysimov35.py::Head.forward] Box feature shape: torch.Size([8, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Cls feature shape: torch.Size([8, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Anchors shape: torch.Size([2, 512])
[nets/tinysimov35.py::Head.forward] Strides shape: torch.Size([1, 512])
[nets/tinysimov35.py::Head.forward] Combined features shape: torch.Size([8, 65, 16, 32])
[nets/tinysimov35.py::Head.forward] Combined flat shape: torch.Size([8, 65, 512])
[nets/tinysimov35.py::Head.forward] Expected self.no: 65
[nets/tinysimov35.py::Head.forward] Split - box shape: torch.Size([8, 64, 512]), cls shape: torch.Size([8, 1, 512])

--- [nets/tinysimov35.py::DFL.forward] PYTORCH DFL DEBUG ---
[nets/tinysimov35.py::DFL.forward] Input shape: torch.Size([8, 64, 512])
[nets/tinysimov35.py::DFL.forward] DFL channels (self.ch): 16
[nets/tinysimov35.py::DFL.forward] Parsed dimensions - batch: 8, channels: 64, anchors: 512
[nets/tinysimov35.py::DFL.forward] After view(b, 4, ch, a): torch.Size([8, 4, 16, 512])
[nets/tinysimov35.py::DFL.forward] After transpose(2, 1): torch.Size([8, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After softmax(1): torch.Size([8, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After conv: torch.Size([8, 1, 4, 512])
[nets/tinysimov35.py::DFL.forward] Final output shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL output shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL split - a shape: torch.Size([8, 2, 512]), b shape: torch.Size([8, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchors expanded shape: torch.Size([1, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchor adjusted - a: torch.Size([8, 2, 512]), b: torch.Size([8, 2, 512])
[nets/tinysimov35.py::Head.forward] Box coordinates shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] Scaled boxes shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] Sigmoid classes shape: torch.Size([8, 1, 512])
[nets/tinysimov35.py::Head.forward] Final output shape: torch.Size([8, 5, 512])
[main.py::test] Model outputs shape: torch.Size([8, 5, 512])

--- [utils/util.py::non_max_suppression] PYTORCH NMS DEBUG ---
[utils/util.py::non_max_suppression] Prediction shape: torch.Size([8, 5, 512])
[utils/util.py::non_max_suppression] Conf threshold: 0.25, IoU threshold: 0.45
[utils/util.py::non_max_suppression] Number of classes: 1
[utils/util.py::non_max_suppression] Candidates per image: [0, 0, 0, 0, 0, 0, 0, 0]

--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([8, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: False
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([8, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Inference mode - processing...
[nets/tinysimov35.py::Head.forward] Box feature shape: torch.Size([8, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Cls feature shape: torch.Size([8, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Anchors shape: torch.Size([2, 512])
[nets/tinysimov35.py::Head.forward] Strides shape: torch.Size([1, 512])
[nets/tinysimov35.py::Head.forward] Combined features shape: torch.Size([8, 65, 16, 32])
[nets/tinysimov35.py::Head.forward] Combined flat shape: torch.Size([8, 65, 512])
[nets/tinysimov35.py::Head.forward] Expected self.no: 65
[nets/tinysimov35.py::Head.forward] Split - box shape: torch.Size([8, 64, 512]), cls shape: torch.Size([8, 1, 512])

--- [nets/tinysimov35.py::DFL.forward] PYTORCH DFL DEBUG ---
[nets/tinysimov35.py::DFL.forward] Input shape: torch.Size([8, 64, 512])
[nets/tinysimov35.py::DFL.forward] DFL channels (self.ch): 16
[nets/tinysimov35.py::DFL.forward] Parsed dimensions - batch: 8, channels: 64, anchors: 512
[nets/tinysimov35.py::DFL.forward] After view(b, 4, ch, a): torch.Size([8, 4, 16, 512])
[nets/tinysimov35.py::DFL.forward] After transpose(2, 1): torch.Size([8, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After softmax(1): torch.Size([8, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After conv: torch.Size([8, 1, 4, 512])
[nets/tinysimov35.py::DFL.forward] Final output shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL output shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL split - a shape: torch.Size([8, 2, 512]), b shape: torch.Size([8, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchors expanded shape: torch.Size([1, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchor adjusted - a: torch.Size([8, 2, 512]), b: torch.Size([8, 2, 512])
[nets/tinysimov35.py::Head.forward] Box coordinates shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] Scaled boxes shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] Sigmoid classes shape: torch.Size([8, 1, 512])
[nets/tinysimov35.py::Head.forward] Final output shape: torch.Size([8, 5, 512])
[main.py::test] Model outputs shape: torch.Size([8, 5, 512])

--- [utils/util.py::non_max_suppression] PYTORCH NMS DEBUG ---
[utils/util.py::non_max_suppression] Prediction shape: torch.Size([8, 5, 512])
[utils/util.py::non_max_suppression] Conf threshold: 0.25, IoU threshold: 0.45
[utils/util.py::non_max_suppression] Number of classes: 1
[utils/util.py::non_max_suppression] Candidates per image: [0, 0, 0, 0, 0, 0, 0, 0]

--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([8, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: False
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([8, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Inference mode - processing...
[nets/tinysimov35.py::Head.forward] Box feature shape: torch.Size([8, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Cls feature shape: torch.Size([8, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Anchors shape: torch.Size([2, 512])
[nets/tinysimov35.py::Head.forward] Strides shape: torch.Size([1, 512])
[nets/tinysimov35.py::Head.forward] Combined features shape: torch.Size([8, 65, 16, 32])
[nets/tinysimov35.py::Head.forward] Combined flat shape: torch.Size([8, 65, 512])
[nets/tinysimov35.py::Head.forward] Expected self.no: 65
[nets/tinysimov35.py::Head.forward] Split - box shape: torch.Size([8, 64, 512]), cls shape: torch.Size([8, 1, 512])

--- [nets/tinysimov35.py::DFL.forward] PYTORCH DFL DEBUG ---
[nets/tinysimov35.py::DFL.forward] Input shape: torch.Size([8, 64, 512])
[nets/tinysimov35.py::DFL.forward] DFL channels (self.ch): 16
[nets/tinysimov35.py::DFL.forward] Parsed dimensions - batch: 8, channels: 64, anchors: 512
[nets/tinysimov35.py::DFL.forward] After view(b, 4, ch, a): torch.Size([8, 4, 16, 512])
[nets/tinysimov35.py::DFL.forward] After transpose(2, 1): torch.Size([8, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After softmax(1): torch.Size([8, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After conv: torch.Size([8, 1, 4, 512])
[nets/tinysimov35.py::DFL.forward] Final output shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL output shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL split - a shape: torch.Size([8, 2, 512]), b shape: torch.Size([8, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchors expanded shape: torch.Size([1, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchor adjusted - a: torch.Size([8, 2, 512]), b: torch.Size([8, 2, 512])
[nets/tinysimov35.py::Head.forward] Box coordinates shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] Scaled boxes shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] Sigmoid classes shape: torch.Size([8, 1, 512])
[nets/tinysimov35.py::Head.forward] Final output shape: torch.Size([8, 5, 512])
[main.py::test] Model outputs shape: torch.Size([8, 5, 512])

--- [utils/util.py::non_max_suppression] PYTORCH NMS DEBUG ---
[utils/util.py::non_max_suppression] Prediction shape: torch.Size([8, 5, 512])
[utils/util.py::non_max_suppression] Conf threshold: 0.25, IoU threshold: 0.45
[utils/util.py::non_max_suppression] Number of classes: 1
[utils/util.py::non_max_suppression] Candidates per image: [0, 0, 0, 0, 0, 0, 0, 0]

--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([8, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: False
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([8, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Inference mode - processing...
[nets/tinysimov35.py::Head.forward] Box feature shape: torch.Size([8, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Cls feature shape: torch.Size([8, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Anchors shape: torch.Size([2, 512])
[nets/tinysimov35.py::Head.forward] Strides shape: torch.Size([1, 512])
[nets/tinysimov35.py::Head.forward] Combined features shape: torch.Size([8, 65, 16, 32])
[nets/tinysimov35.py::Head.forward] Combined flat shape: torch.Size([8, 65, 512])
[nets/tinysimov35.py::Head.forward] Expected self.no: 65
[nets/tinysimov35.py::Head.forward] Split - box shape: torch.Size([8, 64, 512]), cls shape: torch.Size([8, 1, 512])

--- [nets/tinysimov35.py::DFL.forward] PYTORCH DFL DEBUG ---
[nets/tinysimov35.py::DFL.forward] Input shape: torch.Size([8, 64, 512])
[nets/tinysimov35.py::DFL.forward] DFL channels (self.ch): 16
[nets/tinysimov35.py::DFL.forward] Parsed dimensions - batch: 8, channels: 64, anchors: 512
[nets/tinysimov35.py::DFL.forward] After view(b, 4, ch, a): torch.Size([8, 4, 16, 512])
[nets/tinysimov35.py::DFL.forward] After transpose(2, 1): torch.Size([8, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After softmax(1): torch.Size([8, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After conv: torch.Size([8, 1, 4, 512])
[nets/tinysimov35.py::DFL.forward] Final output shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL output shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL split - a shape: torch.Size([8, 2, 512]), b shape: torch.Size([8, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchors expanded shape: torch.Size([1, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchor adjusted - a: torch.Size([8, 2, 512]), b: torch.Size([8, 2, 512])
[nets/tinysimov35.py::Head.forward] Box coordinates shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] Scaled boxes shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] Sigmoid classes shape: torch.Size([8, 1, 512])
[nets/tinysimov35.py::Head.forward] Final output shape: torch.Size([8, 5, 512])
[main.py::test] Model outputs shape: torch.Size([8, 5, 512])

--- [utils/util.py::non_max_suppression] PYTORCH NMS DEBUG ---
[utils/util.py::non_max_suppression] Prediction shape: torch.Size([8, 5, 512])
[utils/util.py::non_max_suppression] Conf threshold: 0.25, IoU threshold: 0.45
[utils/util.py::non_max_suppression] Number of classes: 1
[utils/util.py::non_max_suppression] Candidates per image: [0, 0, 0, 0, 0, 0, 0, 0]

--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([8, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: False
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([8, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Inference mode - processing...
[nets/tinysimov35.py::Head.forward] Box feature shape: torch.Size([8, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Cls feature shape: torch.Size([8, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Anchors shape: torch.Size([2, 512])
[nets/tinysimov35.py::Head.forward] Strides shape: torch.Size([1, 512])
[nets/tinysimov35.py::Head.forward] Combined features shape: torch.Size([8, 65, 16, 32])
[nets/tinysimov35.py::Head.forward] Combined flat shape: torch.Size([8, 65, 512])
[nets/tinysimov35.py::Head.forward] Expected self.no: 65
[nets/tinysimov35.py::Head.forward] Split - box shape: torch.Size([8, 64, 512]), cls shape: torch.Size([8, 1, 512])

--- [nets/tinysimov35.py::DFL.forward] PYTORCH DFL DEBUG ---
[nets/tinysimov35.py::DFL.forward] Input shape: torch.Size([8, 64, 512])
[nets/tinysimov35.py::DFL.forward] DFL channels (self.ch): 16
[nets/tinysimov35.py::DFL.forward] Parsed dimensions - batch: 8, channels: 64, anchors: 512
[nets/tinysimov35.py::DFL.forward] After view(b, 4, ch, a): torch.Size([8, 4, 16, 512])
[nets/tinysimov35.py::DFL.forward] After transpose(2, 1): torch.Size([8, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After softmax(1): torch.Size([8, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After conv: torch.Size([8, 1, 4, 512])
[nets/tinysimov35.py::DFL.forward] Final output shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL output shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL split - a shape: torch.Size([8, 2, 512]), b shape: torch.Size([8, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchors expanded shape: torch.Size([1, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchor adjusted - a: torch.Size([8, 2, 512]), b: torch.Size([8, 2, 512])
[nets/tinysimov35.py::Head.forward] Box coordinates shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] Scaled boxes shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] Sigmoid classes shape: torch.Size([8, 1, 512])
[nets/tinysimov35.py::Head.forward] Final output shape: torch.Size([8, 5, 512])
[main.py::test] Model outputs shape: torch.Size([8, 5, 512])

--- [utils/util.py::non_max_suppression] PYTORCH NMS DEBUG ---
[utils/util.py::non_max_suppression] Prediction shape: torch.Size([8, 5, 512])
[utils/util.py::non_max_suppression] Conf threshold: 0.25, IoU threshold: 0.45
[utils/util.py::non_max_suppression] Number of classes: 1
[utils/util.py::non_max_suppression] Candidates per image: [0, 0, 0, 0, 0, 0, 0, 0]

--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([8, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: False
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([8, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Inference mode - processing...
[nets/tinysimov35.py::Head.forward] Box feature shape: torch.Size([8, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Cls feature shape: torch.Size([8, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Anchors shape: torch.Size([2, 512])
[nets/tinysimov35.py::Head.forward] Strides shape: torch.Size([1, 512])
[nets/tinysimov35.py::Head.forward] Combined features shape: torch.Size([8, 65, 16, 32])
[nets/tinysimov35.py::Head.forward] Combined flat shape: torch.Size([8, 65, 512])
[nets/tinysimov35.py::Head.forward] Expected self.no: 65
[nets/tinysimov35.py::Head.forward] Split - box shape: torch.Size([8, 64, 512]), cls shape: torch.Size([8, 1, 512])

--- [nets/tinysimov35.py::DFL.forward] PYTORCH DFL DEBUG ---
[nets/tinysimov35.py::DFL.forward] Input shape: torch.Size([8, 64, 512])
[nets/tinysimov35.py::DFL.forward] DFL channels (self.ch): 16
[nets/tinysimov35.py::DFL.forward] Parsed dimensions - batch: 8, channels: 64, anchors: 512
[nets/tinysimov35.py::DFL.forward] After view(b, 4, ch, a): torch.Size([8, 4, 16, 512])
[nets/tinysimov35.py::DFL.forward] After transpose(2, 1): torch.Size([8, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After softmax(1): torch.Size([8, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After conv: torch.Size([8, 1, 4, 512])
[nets/tinysimov35.py::DFL.forward] Final output shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL output shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL split - a shape: torch.Size([8, 2, 512]), b shape: torch.Size([8, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchors expanded shape: torch.Size([1, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchor adjusted - a: torch.Size([8, 2, 512]), b: torch.Size([8, 2, 512])
[nets/tinysimov35.py::Head.forward] Box coordinates shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] Scaled boxes shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] Sigmoid classes shape: torch.Size([8, 1, 512])
[nets/tinysimov35.py::Head.forward] Final output shape: torch.Size([8, 5, 512])
[main.py::test] Model outputs shape: torch.Size([8, 5, 512])

--- [utils/util.py::non_max_suppression] PYTORCH NMS DEBUG ---
[utils/util.py::non_max_suppression] Prediction shape: torch.Size([8, 5, 512])
[utils/util.py::non_max_suppression] Conf threshold: 0.25, IoU threshold: 0.45
[utils/util.py::non_max_suppression] Number of classes: 1
[utils/util.py::non_max_suppression] Candidates per image: [0, 0, 0, 0, 0, 0, 0, 0]

--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([8, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: False
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([8, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Inference mode - processing...
[nets/tinysimov35.py::Head.forward] Box feature shape: torch.Size([8, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Cls feature shape: torch.Size([8, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Anchors shape: torch.Size([2, 512])
[nets/tinysimov35.py::Head.forward] Strides shape: torch.Size([1, 512])
[nets/tinysimov35.py::Head.forward] Combined features shape: torch.Size([8, 65, 16, 32])
[nets/tinysimov35.py::Head.forward] Combined flat shape: torch.Size([8, 65, 512])
[nets/tinysimov35.py::Head.forward] Expected self.no: 65
[nets/tinysimov35.py::Head.forward] Split - box shape: torch.Size([8, 64, 512]), cls shape: torch.Size([8, 1, 512])

--- [nets/tinysimov35.py::DFL.forward] PYTORCH DFL DEBUG ---
[nets/tinysimov35.py::DFL.forward] Input shape: torch.Size([8, 64, 512])
[nets/tinysimov35.py::DFL.forward] DFL channels (self.ch): 16
[nets/tinysimov35.py::DFL.forward] Parsed dimensions - batch: 8, channels: 64, anchors: 512
[nets/tinysimov35.py::DFL.forward] After view(b, 4, ch, a): torch.Size([8, 4, 16, 512])
[nets/tinysimov35.py::DFL.forward] After transpose(2, 1): torch.Size([8, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After softmax(1): torch.Size([8, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After conv: torch.Size([8, 1, 4, 512])
[nets/tinysimov35.py::DFL.forward] Final output shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL output shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL split - a shape: torch.Size([8, 2, 512]), b shape: torch.Size([8, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchors expanded shape: torch.Size([1, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchor adjusted - a: torch.Size([8, 2, 512]), b: torch.Size([8, 2, 512])
[nets/tinysimov35.py::Head.forward] Box coordinates shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] Scaled boxes shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] Sigmoid classes shape: torch.Size([8, 1, 512])
[nets/tinysimov35.py::Head.forward] Final output shape: torch.Size([8, 5, 512])
[main.py::test] Model outputs shape: torch.Size([8, 5, 512])

--- [utils/util.py::non_max_suppression] PYTORCH NMS DEBUG ---
[utils/util.py::non_max_suppression] Prediction shape: torch.Size([8, 5, 512])
[utils/util.py::non_max_suppression] Conf threshold: 0.25, IoU threshold: 0.45
[utils/util.py::non_max_suppression] Number of classes: 1
[utils/util.py::non_max_suppression] Candidates per image: [0, 0, 0, 0, 0, 0, 0, 0]

--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([8, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: False
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([8, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Inference mode - processing...
[nets/tinysimov35.py::Head.forward] Box feature shape: torch.Size([8, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Cls feature shape: torch.Size([8, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Anchors shape: torch.Size([2, 512])
[nets/tinysimov35.py::Head.forward] Strides shape: torch.Size([1, 512])
[nets/tinysimov35.py::Head.forward] Combined features shape: torch.Size([8, 65, 16, 32])
[nets/tinysimov35.py::Head.forward] Combined flat shape: torch.Size([8, 65, 512])
[nets/tinysimov35.py::Head.forward] Expected self.no: 65
[nets/tinysimov35.py::Head.forward] Split - box shape: torch.Size([8, 64, 512]), cls shape: torch.Size([8, 1, 512])

--- [nets/tinysimov35.py::DFL.forward] PYTORCH DFL DEBUG ---
[nets/tinysimov35.py::DFL.forward] Input shape: torch.Size([8, 64, 512])
[nets/tinysimov35.py::DFL.forward] DFL channels (self.ch): 16
[nets/tinysimov35.py::DFL.forward] Parsed dimensions - batch: 8, channels: 64, anchors: 512
[nets/tinysimov35.py::DFL.forward] After view(b, 4, ch, a): torch.Size([8, 4, 16, 512])
[nets/tinysimov35.py::DFL.forward] After transpose(2, 1): torch.Size([8, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After softmax(1): torch.Size([8, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After conv: torch.Size([8, 1, 4, 512])
[nets/tinysimov35.py::DFL.forward] Final output shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL output shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL split - a shape: torch.Size([8, 2, 512]), b shape: torch.Size([8, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchors expanded shape: torch.Size([1, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchor adjusted - a: torch.Size([8, 2, 512]), b: torch.Size([8, 2, 512])
[nets/tinysimov35.py::Head.forward] Box coordinates shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] Scaled boxes shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] Sigmoid classes shape: torch.Size([8, 1, 512])
[nets/tinysimov35.py::Head.forward] Final output shape: torch.Size([8, 5, 512])
[main.py::test] Model outputs shape: torch.Size([8, 5, 512])

--- [utils/util.py::non_max_suppression] PYTORCH NMS DEBUG ---
[utils/util.py::non_max_suppression] Prediction shape: torch.Size([8, 5, 512])
[utils/util.py::non_max_suppression] Conf threshold: 0.25, IoU threshold: 0.45
[utils/util.py::non_max_suppression] Number of classes: 1
[utils/util.py::non_max_suppression] Candidates per image: [0, 0, 0, 0, 0, 0, 0, 0]

--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([8, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: False
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([8, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Inference mode - processing...
[nets/tinysimov35.py::Head.forward] Box feature shape: torch.Size([8, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Cls feature shape: torch.Size([8, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Anchors shape: torch.Size([2, 512])
[nets/tinysimov35.py::Head.forward] Strides shape: torch.Size([1, 512])
[nets/tinysimov35.py::Head.forward] Combined features shape: torch.Size([8, 65, 16, 32])
[nets/tinysimov35.py::Head.forward] Combined flat shape: torch.Size([8, 65, 512])
[nets/tinysimov35.py::Head.forward] Expected self.no: 65
[nets/tinysimov35.py::Head.forward] Split - box shape: torch.Size([8, 64, 512]), cls shape: torch.Size([8, 1, 512])

--- [nets/tinysimov35.py::DFL.forward] PYTORCH DFL DEBUG ---
[nets/tinysimov35.py::DFL.forward] Input shape: torch.Size([8, 64, 512])
[nets/tinysimov35.py::DFL.forward] DFL channels (self.ch): 16
[nets/tinysimov35.py::DFL.forward] Parsed dimensions - batch: 8, channels: 64, anchors: 512
[nets/tinysimov35.py::DFL.forward] After view(b, 4, ch, a): torch.Size([8, 4, 16, 512])
[nets/tinysimov35.py::DFL.forward] After transpose(2, 1): torch.Size([8, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After softmax(1): torch.Size([8, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After conv: torch.Size([8, 1, 4, 512])
[nets/tinysimov35.py::DFL.forward] Final output shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL output shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL split - a shape: torch.Size([8, 2, 512]), b shape: torch.Size([8, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchors expanded shape: torch.Size([1, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchor adjusted - a: torch.Size([8, 2, 512]), b: torch.Size([8, 2, 512])
[nets/tinysimov35.py::Head.forward] Box coordinates shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] Scaled boxes shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] Sigmoid classes shape: torch.Size([8, 1, 512])
[nets/tinysimov35.py::Head.forward] Final output shape: torch.Size([8, 5, 512])
[main.py::test] Model outputs shape: torch.Size([8, 5, 512])

--- [utils/util.py::non_max_suppression] PYTORCH NMS DEBUG ---
[utils/util.py::non_max_suppression] Prediction shape: torch.Size([8, 5, 512])
[utils/util.py::non_max_suppression] Conf threshold: 0.25, IoU threshold: 0.45
[utils/util.py::non_max_suppression] Number of classes: 1
[utils/util.py::non_max_suppression] Candidates per image: [0, 0, 0, 0, 0, 0, 0, 0]

--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([8, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: False
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([8, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Inference mode - processing...
[nets/tinysimov35.py::Head.forward] Box feature shape: torch.Size([8, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Cls feature shape: torch.Size([8, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Anchors shape: torch.Size([2, 512])
[nets/tinysimov35.py::Head.forward] Strides shape: torch.Size([1, 512])
[nets/tinysimov35.py::Head.forward] Combined features shape: torch.Size([8, 65, 16, 32])
[nets/tinysimov35.py::Head.forward] Combined flat shape: torch.Size([8, 65, 512])
[nets/tinysimov35.py::Head.forward] Expected self.no: 65
[nets/tinysimov35.py::Head.forward] Split - box shape: torch.Size([8, 64, 512]), cls shape: torch.Size([8, 1, 512])

--- [nets/tinysimov35.py::DFL.forward] PYTORCH DFL DEBUG ---
[nets/tinysimov35.py::DFL.forward] Input shape: torch.Size([8, 64, 512])
[nets/tinysimov35.py::DFL.forward] DFL channels (self.ch): 16
[nets/tinysimov35.py::DFL.forward] Parsed dimensions - batch: 8, channels: 64, anchors: 512
[nets/tinysimov35.py::DFL.forward] After view(b, 4, ch, a): torch.Size([8, 4, 16, 512])
[nets/tinysimov35.py::DFL.forward] After transpose(2, 1): torch.Size([8, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After softmax(1): torch.Size([8, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After conv: torch.Size([8, 1, 4, 512])
[nets/tinysimov35.py::DFL.forward] Final output shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL output shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL split - a shape: torch.Size([8, 2, 512]), b shape: torch.Size([8, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchors expanded shape: torch.Size([1, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchor adjusted - a: torch.Size([8, 2, 512]), b: torch.Size([8, 2, 512])
[nets/tinysimov35.py::Head.forward] Box coordinates shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] Scaled boxes shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] Sigmoid classes shape: torch.Size([8, 1, 512])
[nets/tinysimov35.py::Head.forward] Final output shape: torch.Size([8, 5, 512])
[main.py::test] Model outputs shape: torch.Size([8, 5, 512])

--- [utils/util.py::non_max_suppression] PYTORCH NMS DEBUG ---
[utils/util.py::non_max_suppression] Prediction shape: torch.Size([8, 5, 512])
[utils/util.py::non_max_suppression] Conf threshold: 0.25, IoU threshold: 0.45
[utils/util.py::non_max_suppression] Number of classes: 1
[utils/util.py::non_max_suppression] Candidates per image: [0, 0, 0, 0, 0, 0, 0, 0]

--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([8, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: False
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([8, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Inference mode - processing...
[nets/tinysimov35.py::Head.forward] Box feature shape: torch.Size([8, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Cls feature shape: torch.Size([8, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Anchors shape: torch.Size([2, 512])
[nets/tinysimov35.py::Head.forward] Strides shape: torch.Size([1, 512])
[nets/tinysimov35.py::Head.forward] Combined features shape: torch.Size([8, 65, 16, 32])
[nets/tinysimov35.py::Head.forward] Combined flat shape: torch.Size([8, 65, 512])
[nets/tinysimov35.py::Head.forward] Expected self.no: 65
[nets/tinysimov35.py::Head.forward] Split - box shape: torch.Size([8, 64, 512]), cls shape: torch.Size([8, 1, 512])

--- [nets/tinysimov35.py::DFL.forward] PYTORCH DFL DEBUG ---
[nets/tinysimov35.py::DFL.forward] Input shape: torch.Size([8, 64, 512])
[nets/tinysimov35.py::DFL.forward] DFL channels (self.ch): 16
[nets/tinysimov35.py::DFL.forward] Parsed dimensions - batch: 8, channels: 64, anchors: 512
[nets/tinysimov35.py::DFL.forward] After view(b, 4, ch, a): torch.Size([8, 4, 16, 512])
[nets/tinysimov35.py::DFL.forward] After transpose(2, 1): torch.Size([8, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After softmax(1): torch.Size([8, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After conv: torch.Size([8, 1, 4, 512])
[nets/tinysimov35.py::DFL.forward] Final output shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL output shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL split - a shape: torch.Size([8, 2, 512]), b shape: torch.Size([8, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchors expanded shape: torch.Size([1, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchor adjusted - a: torch.Size([8, 2, 512]), b: torch.Size([8, 2, 512])
[nets/tinysimov35.py::Head.forward] Box coordinates shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] Scaled boxes shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] Sigmoid classes shape: torch.Size([8, 1, 512])
[nets/tinysimov35.py::Head.forward] Final output shape: torch.Size([8, 5, 512])
[main.py::test] Model outputs shape: torch.Size([8, 5, 512])

--- [utils/util.py::non_max_suppression] PYTORCH NMS DEBUG ---
[utils/util.py::non_max_suppression] Prediction shape: torch.Size([8, 5, 512])
[utils/util.py::non_max_suppression] Conf threshold: 0.25, IoU threshold: 0.45
[utils/util.py::non_max_suppression] Number of classes: 1
[utils/util.py::non_max_suppression] Candidates per image: [0, 0, 0, 0, 0, 0, 0, 0]

--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([8, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: False
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([8, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Inference mode - processing...
[nets/tinysimov35.py::Head.forward] Box feature shape: torch.Size([8, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Cls feature shape: torch.Size([8, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Anchors shape: torch.Size([2, 512])
[nets/tinysimov35.py::Head.forward] Strides shape: torch.Size([1, 512])
[nets/tinysimov35.py::Head.forward] Combined features shape: torch.Size([8, 65, 16, 32])
[nets/tinysimov35.py::Head.forward] Combined flat shape: torch.Size([8, 65, 512])
[nets/tinysimov35.py::Head.forward] Expected self.no: 65
[nets/tinysimov35.py::Head.forward] Split - box shape: torch.Size([8, 64, 512]), cls shape: torch.Size([8, 1, 512])

--- [nets/tinysimov35.py::DFL.forward] PYTORCH DFL DEBUG ---
[nets/tinysimov35.py::DFL.forward] Input shape: torch.Size([8, 64, 512])
[nets/tinysimov35.py::DFL.forward] DFL channels (self.ch): 16
[nets/tinysimov35.py::DFL.forward] Parsed dimensions - batch: 8, channels: 64, anchors: 512
[nets/tinysimov35.py::DFL.forward] After view(b, 4, ch, a): torch.Size([8, 4, 16, 512])
[nets/tinysimov35.py::DFL.forward] After transpose(2, 1): torch.Size([8, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After softmax(1): torch.Size([8, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After conv: torch.Size([8, 1, 4, 512])
[nets/tinysimov35.py::DFL.forward] Final output shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL output shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL split - a shape: torch.Size([8, 2, 512]), b shape: torch.Size([8, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchors expanded shape: torch.Size([1, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchor adjusted - a: torch.Size([8, 2, 512]), b: torch.Size([8, 2, 512])
[nets/tinysimov35.py::Head.forward] Box coordinates shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] Scaled boxes shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] Sigmoid classes shape: torch.Size([8, 1, 512])
[nets/tinysimov35.py::Head.forward] Final output shape: torch.Size([8, 5, 512])
[main.py::test] Model outputs shape: torch.Size([8, 5, 512])

--- [utils/util.py::non_max_suppression] PYTORCH NMS DEBUG ---
[utils/util.py::non_max_suppression] Prediction shape: torch.Size([8, 5, 512])
[utils/util.py::non_max_suppression] Conf threshold: 0.25, IoU threshold: 0.45
[utils/util.py::non_max_suppression] Number of classes: 1
[utils/util.py::non_max_suppression] Candidates per image: [0, 0, 0, 0, 0, 0, 0, 0]

--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([8, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: False
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([8, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Inference mode - processing...
[nets/tinysimov35.py::Head.forward] Box feature shape: torch.Size([8, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Cls feature shape: torch.Size([8, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Anchors shape: torch.Size([2, 512])
[nets/tinysimov35.py::Head.forward] Strides shape: torch.Size([1, 512])
[nets/tinysimov35.py::Head.forward] Combined features shape: torch.Size([8, 65, 16, 32])
[nets/tinysimov35.py::Head.forward] Combined flat shape: torch.Size([8, 65, 512])
[nets/tinysimov35.py::Head.forward] Expected self.no: 65
[nets/tinysimov35.py::Head.forward] Split - box shape: torch.Size([8, 64, 512]), cls shape: torch.Size([8, 1, 512])

--- [nets/tinysimov35.py::DFL.forward] PYTORCH DFL DEBUG ---
[nets/tinysimov35.py::DFL.forward] Input shape: torch.Size([8, 64, 512])
[nets/tinysimov35.py::DFL.forward] DFL channels (self.ch): 16
[nets/tinysimov35.py::DFL.forward] Parsed dimensions - batch: 8, channels: 64, anchors: 512
[nets/tinysimov35.py::DFL.forward] After view(b, 4, ch, a): torch.Size([8, 4, 16, 512])
[nets/tinysimov35.py::DFL.forward] After transpose(2, 1): torch.Size([8, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After softmax(1): torch.Size([8, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After conv: torch.Size([8, 1, 4, 512])
[nets/tinysimov35.py::DFL.forward] Final output shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL output shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL split - a shape: torch.Size([8, 2, 512]), b shape: torch.Size([8, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchors expanded shape: torch.Size([1, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchor adjusted - a: torch.Size([8, 2, 512]), b: torch.Size([8, 2, 512])
[nets/tinysimov35.py::Head.forward] Box coordinates shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] Scaled boxes shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] Sigmoid classes shape: torch.Size([8, 1, 512])
[nets/tinysimov35.py::Head.forward] Final output shape: torch.Size([8, 5, 512])
[main.py::test] Model outputs shape: torch.Size([8, 5, 512])

--- [utils/util.py::non_max_suppression] PYTORCH NMS DEBUG ---
[utils/util.py::non_max_suppression] Prediction shape: torch.Size([8, 5, 512])
[utils/util.py::non_max_suppression] Conf threshold: 0.25, IoU threshold: 0.45
[utils/util.py::non_max_suppression] Number of classes: 1
[utils/util.py::non_max_suppression] Candidates per image: [0, 0, 0, 0, 0, 0, 0, 0]

--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([8, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: False
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([8, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Inference mode - processing...
[nets/tinysimov35.py::Head.forward] Box feature shape: torch.Size([8, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Cls feature shape: torch.Size([8, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Anchors shape: torch.Size([2, 512])
[nets/tinysimov35.py::Head.forward] Strides shape: torch.Size([1, 512])
[nets/tinysimov35.py::Head.forward] Combined features shape: torch.Size([8, 65, 16, 32])
[nets/tinysimov35.py::Head.forward] Combined flat shape: torch.Size([8, 65, 512])
[nets/tinysimov35.py::Head.forward] Expected self.no: 65
[nets/tinysimov35.py::Head.forward] Split - box shape: torch.Size([8, 64, 512]), cls shape: torch.Size([8, 1, 512])

--- [nets/tinysimov35.py::DFL.forward] PYTORCH DFL DEBUG ---
[nets/tinysimov35.py::DFL.forward] Input shape: torch.Size([8, 64, 512])
[nets/tinysimov35.py::DFL.forward] DFL channels (self.ch): 16
[nets/tinysimov35.py::DFL.forward] Parsed dimensions - batch: 8, channels: 64, anchors: 512
[nets/tinysimov35.py::DFL.forward] After view(b, 4, ch, a): torch.Size([8, 4, 16, 512])
[nets/tinysimov35.py::DFL.forward] After transpose(2, 1): torch.Size([8, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After softmax(1): torch.Size([8, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After conv: torch.Size([8, 1, 4, 512])
[nets/tinysimov35.py::DFL.forward] Final output shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL output shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL split - a shape: torch.Size([8, 2, 512]), b shape: torch.Size([8, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchors expanded shape: torch.Size([1, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchor adjusted - a: torch.Size([8, 2, 512]), b: torch.Size([8, 2, 512])
[nets/tinysimov35.py::Head.forward] Box coordinates shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] Scaled boxes shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] Sigmoid classes shape: torch.Size([8, 1, 512])
[nets/tinysimov35.py::Head.forward] Final output shape: torch.Size([8, 5, 512])
[main.py::test] Model outputs shape: torch.Size([8, 5, 512])

--- [utils/util.py::non_max_suppression] PYTORCH NMS DEBUG ---
[utils/util.py::non_max_suppression] Prediction shape: torch.Size([8, 5, 512])
[utils/util.py::non_max_suppression] Conf threshold: 0.25, IoU threshold: 0.45
[utils/util.py::non_max_suppression] Number of classes: 1
[utils/util.py::non_max_suppression] Candidates per image: [0, 0, 0, 0, 0, 0, 0, 0]

--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([8, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: False
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([8, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Inference mode - processing...
[nets/tinysimov35.py::Head.forward] Box feature shape: torch.Size([8, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Cls feature shape: torch.Size([8, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Anchors shape: torch.Size([2, 512])
[nets/tinysimov35.py::Head.forward] Strides shape: torch.Size([1, 512])
[nets/tinysimov35.py::Head.forward] Combined features shape: torch.Size([8, 65, 16, 32])
[nets/tinysimov35.py::Head.forward] Combined flat shape: torch.Size([8, 65, 512])
[nets/tinysimov35.py::Head.forward] Expected self.no: 65
[nets/tinysimov35.py::Head.forward] Split - box shape: torch.Size([8, 64, 512]), cls shape: torch.Size([8, 1, 512])

--- [nets/tinysimov35.py::DFL.forward] PYTORCH DFL DEBUG ---
[nets/tinysimov35.py::DFL.forward] Input shape: torch.Size([8, 64, 512])
[nets/tinysimov35.py::DFL.forward] DFL channels (self.ch): 16
[nets/tinysimov35.py::DFL.forward] Parsed dimensions - batch: 8, channels: 64, anchors: 512
[nets/tinysimov35.py::DFL.forward] After view(b, 4, ch, a): torch.Size([8, 4, 16, 512])
[nets/tinysimov35.py::DFL.forward] After transpose(2, 1): torch.Size([8, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After softmax(1): torch.Size([8, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After conv: torch.Size([8, 1, 4, 512])
[nets/tinysimov35.py::DFL.forward] Final output shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL output shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL split - a shape: torch.Size([8, 2, 512]), b shape: torch.Size([8, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchors expanded shape: torch.Size([1, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchor adjusted - a: torch.Size([8, 2, 512]), b: torch.Size([8, 2, 512])
[nets/tinysimov35.py::Head.forward] Box coordinates shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] Scaled boxes shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] Sigmoid classes shape: torch.Size([8, 1, 512])
[nets/tinysimov35.py::Head.forward] Final output shape: torch.Size([8, 5, 512])
[main.py::test] Model outputs shape: torch.Size([8, 5, 512])

--- [utils/util.py::non_max_suppression] PYTORCH NMS DEBUG ---
[utils/util.py::non_max_suppression] Prediction shape: torch.Size([8, 5, 512])
[utils/util.py::non_max_suppression] Conf threshold: 0.25, IoU threshold: 0.45
[utils/util.py::non_max_suppression] Number of classes: 1
[utils/util.py::non_max_suppression] Candidates per image: [0, 0, 0, 0, 0, 0, 0, 0]

--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([8, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: False
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([8, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Inference mode - processing...
[nets/tinysimov35.py::Head.forward] Box feature shape: torch.Size([8, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Cls feature shape: torch.Size([8, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Anchors shape: torch.Size([2, 512])
[nets/tinysimov35.py::Head.forward] Strides shape: torch.Size([1, 512])
[nets/tinysimov35.py::Head.forward] Combined features shape: torch.Size([8, 65, 16, 32])
[nets/tinysimov35.py::Head.forward] Combined flat shape: torch.Size([8, 65, 512])
[nets/tinysimov35.py::Head.forward] Expected self.no: 65
[nets/tinysimov35.py::Head.forward] Split - box shape: torch.Size([8, 64, 512]), cls shape: torch.Size([8, 1, 512])

--- [nets/tinysimov35.py::DFL.forward] PYTORCH DFL DEBUG ---
[nets/tinysimov35.py::DFL.forward] Input shape: torch.Size([8, 64, 512])
[nets/tinysimov35.py::DFL.forward] DFL channels (self.ch): 16
[nets/tinysimov35.py::DFL.forward] Parsed dimensions - batch: 8, channels: 64, anchors: 512
[nets/tinysimov35.py::DFL.forward] After view(b, 4, ch, a): torch.Size([8, 4, 16, 512])
[nets/tinysimov35.py::DFL.forward] After transpose(2, 1): torch.Size([8, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After softmax(1): torch.Size([8, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After conv: torch.Size([8, 1, 4, 512])
[nets/tinysimov35.py::DFL.forward] Final output shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL output shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL split - a shape: torch.Size([8, 2, 512]), b shape: torch.Size([8, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchors expanded shape: torch.Size([1, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchor adjusted - a: torch.Size([8, 2, 512]), b: torch.Size([8, 2, 512])
[nets/tinysimov35.py::Head.forward] Box coordinates shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] Scaled boxes shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] Sigmoid classes shape: torch.Size([8, 1, 512])
[nets/tinysimov35.py::Head.forward] Final output shape: torch.Size([8, 5, 512])
[main.py::test] Model outputs shape: torch.Size([8, 5, 512])

--- [utils/util.py::non_max_suppression] PYTORCH NMS DEBUG ---
[utils/util.py::non_max_suppression] Prediction shape: torch.Size([8, 5, 512])
[utils/util.py::non_max_suppression] Conf threshold: 0.25, IoU threshold: 0.45
[utils/util.py::non_max_suppression] Number of classes: 1
[utils/util.py::non_max_suppression] Candidates per image: [0, 0, 0, 0, 0, 0, 0, 0]

--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([8, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: False
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([8, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Inference mode - processing...
[nets/tinysimov35.py::Head.forward] Box feature shape: torch.Size([8, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Cls feature shape: torch.Size([8, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Anchors shape: torch.Size([2, 512])
[nets/tinysimov35.py::Head.forward] Strides shape: torch.Size([1, 512])
[nets/tinysimov35.py::Head.forward] Combined features shape: torch.Size([8, 65, 16, 32])
[nets/tinysimov35.py::Head.forward] Combined flat shape: torch.Size([8, 65, 512])
[nets/tinysimov35.py::Head.forward] Expected self.no: 65
[nets/tinysimov35.py::Head.forward] Split - box shape: torch.Size([8, 64, 512]), cls shape: torch.Size([8, 1, 512])

--- [nets/tinysimov35.py::DFL.forward] PYTORCH DFL DEBUG ---
[nets/tinysimov35.py::DFL.forward] Input shape: torch.Size([8, 64, 512])
[nets/tinysimov35.py::DFL.forward] DFL channels (self.ch): 16
[nets/tinysimov35.py::DFL.forward] Parsed dimensions - batch: 8, channels: 64, anchors: 512
[nets/tinysimov35.py::DFL.forward] After view(b, 4, ch, a): torch.Size([8, 4, 16, 512])
[nets/tinysimov35.py::DFL.forward] After transpose(2, 1): torch.Size([8, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After softmax(1): torch.Size([8, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After conv: torch.Size([8, 1, 4, 512])
[nets/tinysimov35.py::DFL.forward] Final output shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL output shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL split - a shape: torch.Size([8, 2, 512]), b shape: torch.Size([8, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchors expanded shape: torch.Size([1, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchor adjusted - a: torch.Size([8, 2, 512]), b: torch.Size([8, 2, 512])
[nets/tinysimov35.py::Head.forward] Box coordinates shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] Scaled boxes shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] Sigmoid classes shape: torch.Size([8, 1, 512])
[nets/tinysimov35.py::Head.forward] Final output shape: torch.Size([8, 5, 512])
[main.py::test] Model outputs shape: torch.Size([8, 5, 512])

--- [utils/util.py::non_max_suppression] PYTORCH NMS DEBUG ---
[utils/util.py::non_max_suppression] Prediction shape: torch.Size([8, 5, 512])
[utils/util.py::non_max_suppression] Conf threshold: 0.25, IoU threshold: 0.45
[utils/util.py::non_max_suppression] Number of classes: 1
[utils/util.py::non_max_suppression] Candidates per image: [0, 0, 0, 0, 0, 0, 0, 0]

--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([8, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: False
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([8, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Inference mode - processing...
[nets/tinysimov35.py::Head.forward] Box feature shape: torch.Size([8, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Cls feature shape: torch.Size([8, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Anchors shape: torch.Size([2, 512])
[nets/tinysimov35.py::Head.forward] Strides shape: torch.Size([1, 512])
[nets/tinysimov35.py::Head.forward] Combined features shape: torch.Size([8, 65, 16, 32])
[nets/tinysimov35.py::Head.forward] Combined flat shape: torch.Size([8, 65, 512])
[nets/tinysimov35.py::Head.forward] Expected self.no: 65
[nets/tinysimov35.py::Head.forward] Split - box shape: torch.Size([8, 64, 512]), cls shape: torch.Size([8, 1, 512])

--- [nets/tinysimov35.py::DFL.forward] PYTORCH DFL DEBUG ---
[nets/tinysimov35.py::DFL.forward] Input shape: torch.Size([8, 64, 512])
[nets/tinysimov35.py::DFL.forward] DFL channels (self.ch): 16
[nets/tinysimov35.py::DFL.forward] Parsed dimensions - batch: 8, channels: 64, anchors: 512
[nets/tinysimov35.py::DFL.forward] After view(b, 4, ch, a): torch.Size([8, 4, 16, 512])
[nets/tinysimov35.py::DFL.forward] After transpose(2, 1): torch.Size([8, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After softmax(1): torch.Size([8, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After conv: torch.Size([8, 1, 4, 512])
[nets/tinysimov35.py::DFL.forward] Final output shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL output shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL split - a shape: torch.Size([8, 2, 512]), b shape: torch.Size([8, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchors expanded shape: torch.Size([1, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchor adjusted - a: torch.Size([8, 2, 512]), b: torch.Size([8, 2, 512])
[nets/tinysimov35.py::Head.forward] Box coordinates shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] Scaled boxes shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] Sigmoid classes shape: torch.Size([8, 1, 512])
[nets/tinysimov35.py::Head.forward] Final output shape: torch.Size([8, 5, 512])
[main.py::test] Model outputs shape: torch.Size([8, 5, 512])

--- [utils/util.py::non_max_suppression] PYTORCH NMS DEBUG ---
[utils/util.py::non_max_suppression] Prediction shape: torch.Size([8, 5, 512])
[utils/util.py::non_max_suppression] Conf threshold: 0.25, IoU threshold: 0.45
[utils/util.py::non_max_suppression] Number of classes: 1
[utils/util.py::non_max_suppression] Candidates per image: [0, 0, 0, 0, 0, 0, 0, 0]

--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([4, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: False
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([4, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Inference mode - processing...
[nets/tinysimov35.py::Head.forward] Box feature shape: torch.Size([4, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Cls feature shape: torch.Size([4, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Anchors shape: torch.Size([2, 512])
[nets/tinysimov35.py::Head.forward] Strides shape: torch.Size([1, 512])
[nets/tinysimov35.py::Head.forward] Combined features shape: torch.Size([4, 65, 16, 32])
[nets/tinysimov35.py::Head.forward] Combined flat shape: torch.Size([4, 65, 512])
[nets/tinysimov35.py::Head.forward] Expected self.no: 65
[nets/tinysimov35.py::Head.forward] Split - box shape: torch.Size([4, 64, 512]), cls shape: torch.Size([4, 1, 512])

--- [nets/tinysimov35.py::DFL.forward] PYTORCH DFL DEBUG ---
[nets/tinysimov35.py::DFL.forward] Input shape: torch.Size([4, 64, 512])
[nets/tinysimov35.py::DFL.forward] DFL channels (self.ch): 16
[nets/tinysimov35.py::DFL.forward] Parsed dimensions - batch: 4, channels: 64, anchors: 512
[nets/tinysimov35.py::DFL.forward] After view(b, 4, ch, a): torch.Size([4, 4, 16, 512])
[nets/tinysimov35.py::DFL.forward] After transpose(2, 1): torch.Size([4, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After softmax(1): torch.Size([4, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After conv: torch.Size([4, 1, 4, 512])
[nets/tinysimov35.py::DFL.forward] Final output shape: torch.Size([4, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL output shape: torch.Size([4, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL split - a shape: torch.Size([4, 2, 512]), b shape: torch.Size([4, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchors expanded shape: torch.Size([1, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchor adjusted - a: torch.Size([4, 2, 512]), b: torch.Size([4, 2, 512])
[nets/tinysimov35.py::Head.forward] Box coordinates shape: torch.Size([4, 4, 512])
[nets/tinysimov35.py::Head.forward] Scaled boxes shape: torch.Size([4, 4, 512])
[nets/tinysimov35.py::Head.forward] Sigmoid classes shape: torch.Size([4, 1, 512])
[nets/tinysimov35.py::Head.forward] Final output shape: torch.Size([4, 5, 512])
[main.py::test] Model outputs shape: torch.Size([4, 5, 512])

--- [utils/util.py::non_max_suppression] PYTORCH NMS DEBUG ---
[utils/util.py::non_max_suppression] Prediction shape: torch.Size([4, 5, 512])
[utils/util.py::non_max_suppression] Conf threshold: 0.25, IoU threshold: 0.45
[utils/util.py::non_max_suppression] Number of classes: 1
[utils/util.py::non_max_suppression] Candidates per image: [0, 0, 0, 0]

--- [utils/util.py::compute_ap] PYTORCH COMPUTE_AP DEBUG ---
[utils/util.py::compute_ap] TP shape: (0, 10), dtype: bool
[utils/util.py::compute_ap] Conf shape: (0,), dtype: float32
[utils/util.py::compute_ap] Pred_cls shape: (0,), dtype: float32
[utils/util.py::compute_ap] Target_cls shape: (0,), dtype: float32
[utils/util.py::compute_ap] Conf array is empty - no predictions to evaluate
After sorting - first 5 conf: []
Unique classes: []
Class counts: []
Number of classes: 0
Precision: nan, Recall: nan, mAP50: nan, mAP: nan
Evaluating on validation data...

--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([8, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: False
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([8, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Inference mode - processing...
[nets/tinysimov35.py::Head.forward] Box feature shape: torch.Size([8, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Cls feature shape: torch.Size([8, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Anchors shape: torch.Size([2, 512])
[nets/tinysimov35.py::Head.forward] Strides shape: torch.Size([1, 512])
[nets/tinysimov35.py::Head.forward] Combined features shape: torch.Size([8, 65, 16, 32])
[nets/tinysimov35.py::Head.forward] Combined flat shape: torch.Size([8, 65, 512])
[nets/tinysimov35.py::Head.forward] Expected self.no: 65
[nets/tinysimov35.py::Head.forward] Split - box shape: torch.Size([8, 64, 512]), cls shape: torch.Size([8, 1, 512])

--- [nets/tinysimov35.py::DFL.forward] PYTORCH DFL DEBUG ---
[nets/tinysimov35.py::DFL.forward] Input shape: torch.Size([8, 64, 512])
[nets/tinysimov35.py::DFL.forward] DFL channels (self.ch): 16
[nets/tinysimov35.py::DFL.forward] Parsed dimensions - batch: 8, channels: 64, anchors: 512
[nets/tinysimov35.py::DFL.forward] After view(b, 4, ch, a): torch.Size([8, 4, 16, 512])
[nets/tinysimov35.py::DFL.forward] After transpose(2, 1): torch.Size([8, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After softmax(1): torch.Size([8, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After conv: torch.Size([8, 1, 4, 512])
[nets/tinysimov35.py::DFL.forward] Final output shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL output shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL split - a shape: torch.Size([8, 2, 512]), b shape: torch.Size([8, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchors expanded shape: torch.Size([1, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchor adjusted - a: torch.Size([8, 2, 512]), b: torch.Size([8, 2, 512])
[nets/tinysimov35.py::Head.forward] Box coordinates shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] Scaled boxes shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] Sigmoid classes shape: torch.Size([8, 1, 512])
[nets/tinysimov35.py::Head.forward] Final output shape: torch.Size([8, 5, 512])
[main.py::test] Model outputs shape: torch.Size([8, 5, 512])

--- [utils/util.py::non_max_suppression] PYTORCH NMS DEBUG ---
[utils/util.py::non_max_suppression] Prediction shape: torch.Size([8, 5, 512])
[utils/util.py::non_max_suppression] Conf threshold: 0.25, IoU threshold: 0.45
[utils/util.py::non_max_suppression] Number of classes: 1
[utils/util.py::non_max_suppression] Candidates per image: [0, 0, 0, 0, 0, 0, 0, 0]

=== DEBUG: visualize_predictions input shapes (vis_count=0) ===
single_sample shape: torch.Size([1, 3, 128, 256])
single_sample dtype: torch.float16
single_sample min/max: 0.322/0.749
single_out type: <class 'list'>
single_out length: 1
single_out[0] shape: torch.Size([0, 6])
single_out[0] dtype: torch.float32
single_out[0]: empty tensor
single_gt shape: torch.Size([1, 6])
single_gt dtype: torch.float32
single_gt content (first few):
tensor([[ 0.0000,  0.0000, 18.0000, 17.3100, 24.0000, 23.3800]])
single_shapes: [([128, 256], [[1.0, 1.0], [0, 0]])]
single_shapes type: <class 'list'>
single_shapes[0]: ([128, 256], [[1.0, 1.0], [0, 0]])
=== END DEBUG ===

=== DEBUG: visualize_predictions input shapes (vis_count=1) ===
single_sample shape: torch.Size([1, 3, 128, 256])
single_sample dtype: torch.float16
single_sample min/max: 0.341/0.761
single_out type: <class 'list'>
single_out length: 1
single_out[0] shape: torch.Size([0, 6])
single_out[0] dtype: torch.float32
single_out[0]: empty tensor
single_gt shape: torch.Size([1, 6])
single_gt dtype: torch.float32
single_gt content (first few):
tensor([[  0.0000,   0.0000, 245.3500,  19.5000,  21.2900,  23.0000]])
single_shapes: [([128, 256], [[1.0, 1.0], [0, 0]])]
single_shapes type: <class 'list'>
single_shapes[0]: ([128, 256], [[1.0, 1.0], [0, 0]])
=== END DEBUG ===

=== DEBUG: visualize_predictions input shapes (vis_count=2) ===
single_sample shape: torch.Size([1, 3, 128, 256])
single_sample dtype: torch.float16
single_sample min/max: 0.396/0.792
single_out type: <class 'list'>
single_out length: 1
single_out[0] shape: torch.Size([0, 6])
single_out[0] dtype: torch.float32
single_out[0]: empty tensor
single_gt shape: torch.Size([1, 6])
single_gt dtype: torch.float32
single_gt content (first few):
tensor([[  0.0000,   0.0000, 127.9700,  43.3800,  26.0700,  27.5400]])
single_shapes: [([128, 256], [[1.0, 1.0], [0, 0]])]
single_shapes type: <class 'list'>
single_shapes[0]: ([128, 256], [[1.0, 1.0], [0, 0]])
=== END DEBUG ===

=== DEBUG: visualize_predictions input shapes (vis_count=3) ===
single_sample shape: torch.Size([1, 3, 128, 256])
single_sample dtype: torch.float16
single_sample min/max: 0.227/0.800
single_out type: <class 'list'>
single_out length: 1
single_out[0] shape: torch.Size([0, 6])
single_out[0] dtype: torch.float32
single_out[0]: empty tensor
single_gt shape: torch.Size([1, 6])
single_gt dtype: torch.float32
single_gt content (first few):
tensor([[  0.0000,   0.0000, 243.6200,  25.5000,  22.4400,  23.0000]])
single_shapes: [([128, 256], [[1.0, 1.0], [0, 0]])]
single_shapes type: <class 'list'>
single_shapes[0]: ([128, 256], [[1.0, 1.0], [0, 0]])
=== END DEBUG ===

=== DEBUG: visualize_predictions input shapes (vis_count=4) ===
single_sample shape: torch.Size([1, 3, 128, 256])
single_sample dtype: torch.float16
single_sample min/max: 0.027/0.749
single_out type: <class 'list'>
single_out length: 1
single_out[0] shape: torch.Size([0, 6])
single_out[0] dtype: torch.float32
single_out[0]: empty tensor
single_gt shape: torch.Size([1, 6])
single_gt dtype: torch.float32
single_gt content (first few):
tensor([[  0.0000,   0.0000, 235.0000,  44.6700,  20.6700,  21.3300]])
single_shapes: [([128, 256], [[1.0, 1.0], [0, 0]])]
single_shapes type: <class 'list'>
single_shapes[0]: ([128, 256], [[1.0, 1.0], [0, 0]])
=== END DEBUG ===

--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([8, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: False
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([8, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Inference mode - processing...
[nets/tinysimov35.py::Head.forward] Box feature shape: torch.Size([8, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Cls feature shape: torch.Size([8, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Anchors shape: torch.Size([2, 512])
[nets/tinysimov35.py::Head.forward] Strides shape: torch.Size([1, 512])
[nets/tinysimov35.py::Head.forward] Combined features shape: torch.Size([8, 65, 16, 32])
[nets/tinysimov35.py::Head.forward] Combined flat shape: torch.Size([8, 65, 512])
[nets/tinysimov35.py::Head.forward] Expected self.no: 65
[nets/tinysimov35.py::Head.forward] Split - box shape: torch.Size([8, 64, 512]), cls shape: torch.Size([8, 1, 512])

--- [nets/tinysimov35.py::DFL.forward] PYTORCH DFL DEBUG ---
[nets/tinysimov35.py::DFL.forward] Input shape: torch.Size([8, 64, 512])
[nets/tinysimov35.py::DFL.forward] DFL channels (self.ch): 16
[nets/tinysimov35.py::DFL.forward] Parsed dimensions - batch: 8, channels: 64, anchors: 512
[nets/tinysimov35.py::DFL.forward] After view(b, 4, ch, a): torch.Size([8, 4, 16, 512])
[nets/tinysimov35.py::DFL.forward] After transpose(2, 1): torch.Size([8, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After softmax(1): torch.Size([8, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After conv: torch.Size([8, 1, 4, 512])
[nets/tinysimov35.py::DFL.forward] Final output shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL output shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL split - a shape: torch.Size([8, 2, 512]), b shape: torch.Size([8, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchors expanded shape: torch.Size([1, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchor adjusted - a: torch.Size([8, 2, 512]), b: torch.Size([8, 2, 512])
[nets/tinysimov35.py::Head.forward] Box coordinates shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] Scaled boxes shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] Sigmoid classes shape: torch.Size([8, 1, 512])
[nets/tinysimov35.py::Head.forward] Final output shape: torch.Size([8, 5, 512])
[main.py::test] Model outputs shape: torch.Size([8, 5, 512])

--- [utils/util.py::non_max_suppression] PYTORCH NMS DEBUG ---
[utils/util.py::non_max_suppression] Prediction shape: torch.Size([8, 5, 512])
[utils/util.py::non_max_suppression] Conf threshold: 0.25, IoU threshold: 0.45
[utils/util.py::non_max_suppression] Number of classes: 1
[utils/util.py::non_max_suppression] Candidates per image: [0, 0, 0, 0, 0, 0, 0, 0]

--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([8, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: False
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([8, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Inference mode - processing...
[nets/tinysimov35.py::Head.forward] Box feature shape: torch.Size([8, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Cls feature shape: torch.Size([8, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Anchors shape: torch.Size([2, 512])
[nets/tinysimov35.py::Head.forward] Strides shape: torch.Size([1, 512])
[nets/tinysimov35.py::Head.forward] Combined features shape: torch.Size([8, 65, 16, 32])
[nets/tinysimov35.py::Head.forward] Combined flat shape: torch.Size([8, 65, 512])
[nets/tinysimov35.py::Head.forward] Expected self.no: 65
[nets/tinysimov35.py::Head.forward] Split - box shape: torch.Size([8, 64, 512]), cls shape: torch.Size([8, 1, 512])

--- [nets/tinysimov35.py::DFL.forward] PYTORCH DFL DEBUG ---
[nets/tinysimov35.py::DFL.forward] Input shape: torch.Size([8, 64, 512])
[nets/tinysimov35.py::DFL.forward] DFL channels (self.ch): 16
[nets/tinysimov35.py::DFL.forward] Parsed dimensions - batch: 8, channels: 64, anchors: 512
[nets/tinysimov35.py::DFL.forward] After view(b, 4, ch, a): torch.Size([8, 4, 16, 512])
[nets/tinysimov35.py::DFL.forward] After transpose(2, 1): torch.Size([8, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After softmax(1): torch.Size([8, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After conv: torch.Size([8, 1, 4, 512])
[nets/tinysimov35.py::DFL.forward] Final output shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL output shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL split - a shape: torch.Size([8, 2, 512]), b shape: torch.Size([8, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchors expanded shape: torch.Size([1, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchor adjusted - a: torch.Size([8, 2, 512]), b: torch.Size([8, 2, 512])
[nets/tinysimov35.py::Head.forward] Box coordinates shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] Scaled boxes shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] Sigmoid classes shape: torch.Size([8, 1, 512])
[nets/tinysimov35.py::Head.forward] Final output shape: torch.Size([8, 5, 512])
[main.py::test] Model outputs shape: torch.Size([8, 5, 512])

--- [utils/util.py::non_max_suppression] PYTORCH NMS DEBUG ---
[utils/util.py::non_max_suppression] Prediction shape: torch.Size([8, 5, 512])
[utils/util.py::non_max_suppression] Conf threshold: 0.25, IoU threshold: 0.45
[utils/util.py::non_max_suppression] Number of classes: 1
[utils/util.py::non_max_suppression] Candidates per image: [0, 0, 0, 0, 0, 0, 0, 0]

--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([8, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: False
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([8, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Inference mode - processing...
[nets/tinysimov35.py::Head.forward] Box feature shape: torch.Size([8, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Cls feature shape: torch.Size([8, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Anchors shape: torch.Size([2, 512])
[nets/tinysimov35.py::Head.forward] Strides shape: torch.Size([1, 512])
[nets/tinysimov35.py::Head.forward] Combined features shape: torch.Size([8, 65, 16, 32])
[nets/tinysimov35.py::Head.forward] Combined flat shape: torch.Size([8, 65, 512])
[nets/tinysimov35.py::Head.forward] Expected self.no: 65
[nets/tinysimov35.py::Head.forward] Split - box shape: torch.Size([8, 64, 512]), cls shape: torch.Size([8, 1, 512])

--- [nets/tinysimov35.py::DFL.forward] PYTORCH DFL DEBUG ---
[nets/tinysimov35.py::DFL.forward] Input shape: torch.Size([8, 64, 512])
[nets/tinysimov35.py::DFL.forward] DFL channels (self.ch): 16
[nets/tinysimov35.py::DFL.forward] Parsed dimensions - batch: 8, channels: 64, anchors: 512
[nets/tinysimov35.py::DFL.forward] After view(b, 4, ch, a): torch.Size([8, 4, 16, 512])
[nets/tinysimov35.py::DFL.forward] After transpose(2, 1): torch.Size([8, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After softmax(1): torch.Size([8, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After conv: torch.Size([8, 1, 4, 512])
[nets/tinysimov35.py::DFL.forward] Final output shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL output shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL split - a shape: torch.Size([8, 2, 512]), b shape: torch.Size([8, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchors expanded shape: torch.Size([1, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchor adjusted - a: torch.Size([8, 2, 512]), b: torch.Size([8, 2, 512])
[nets/tinysimov35.py::Head.forward] Box coordinates shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] Scaled boxes shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] Sigmoid classes shape: torch.Size([8, 1, 512])
[nets/tinysimov35.py::Head.forward] Final output shape: torch.Size([8, 5, 512])
[main.py::test] Model outputs shape: torch.Size([8, 5, 512])

--- [utils/util.py::non_max_suppression] PYTORCH NMS DEBUG ---
[utils/util.py::non_max_suppression] Prediction shape: torch.Size([8, 5, 512])
[utils/util.py::non_max_suppression] Conf threshold: 0.25, IoU threshold: 0.45
[utils/util.py::non_max_suppression] Number of classes: 1
[utils/util.py::non_max_suppression] Candidates per image: [0, 0, 0, 0, 0, 0, 0, 0]

--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([8, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: False
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([8, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Inference mode - processing...
[nets/tinysimov35.py::Head.forward] Box feature shape: torch.Size([8, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Cls feature shape: torch.Size([8, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Anchors shape: torch.Size([2, 512])
[nets/tinysimov35.py::Head.forward] Strides shape: torch.Size([1, 512])
[nets/tinysimov35.py::Head.forward] Combined features shape: torch.Size([8, 65, 16, 32])
[nets/tinysimov35.py::Head.forward] Combined flat shape: torch.Size([8, 65, 512])
[nets/tinysimov35.py::Head.forward] Expected self.no: 65
[nets/tinysimov35.py::Head.forward] Split - box shape: torch.Size([8, 64, 512]), cls shape: torch.Size([8, 1, 512])

--- [nets/tinysimov35.py::DFL.forward] PYTORCH DFL DEBUG ---
[nets/tinysimov35.py::DFL.forward] Input shape: torch.Size([8, 64, 512])
[nets/tinysimov35.py::DFL.forward] DFL channels (self.ch): 16
[nets/tinysimov35.py::DFL.forward] Parsed dimensions - batch: 8, channels: 64, anchors: 512
[nets/tinysimov35.py::DFL.forward] After view(b, 4, ch, a): torch.Size([8, 4, 16, 512])
[nets/tinysimov35.py::DFL.forward] After transpose(2, 1): torch.Size([8, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After softmax(1): torch.Size([8, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After conv: torch.Size([8, 1, 4, 512])
[nets/tinysimov35.py::DFL.forward] Final output shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL output shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL split - a shape: torch.Size([8, 2, 512]), b shape: torch.Size([8, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchors expanded shape: torch.Size([1, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchor adjusted - a: torch.Size([8, 2, 512]), b: torch.Size([8, 2, 512])
[nets/tinysimov35.py::Head.forward] Box coordinates shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] Scaled boxes shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] Sigmoid classes shape: torch.Size([8, 1, 512])
[nets/tinysimov35.py::Head.forward] Final output shape: torch.Size([8, 5, 512])
[main.py::test] Model outputs shape: torch.Size([8, 5, 512])

--- [utils/util.py::non_max_suppression] PYTORCH NMS DEBUG ---
[utils/util.py::non_max_suppression] Prediction shape: torch.Size([8, 5, 512])
[utils/util.py::non_max_suppression] Conf threshold: 0.25, IoU threshold: 0.45
[utils/util.py::non_max_suppression] Number of classes: 1
[utils/util.py::non_max_suppression] Candidates per image: [0, 0, 0, 0, 0, 0, 0, 0]

--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([8, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: False
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([8, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Inference mode - processing...
[nets/tinysimov35.py::Head.forward] Box feature shape: torch.Size([8, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Cls feature shape: torch.Size([8, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Anchors shape: torch.Size([2, 512])
[nets/tinysimov35.py::Head.forward] Strides shape: torch.Size([1, 512])
[nets/tinysimov35.py::Head.forward] Combined features shape: torch.Size([8, 65, 16, 32])
[nets/tinysimov35.py::Head.forward] Combined flat shape: torch.Size([8, 65, 512])
[nets/tinysimov35.py::Head.forward] Expected self.no: 65
[nets/tinysimov35.py::Head.forward] Split - box shape: torch.Size([8, 64, 512]), cls shape: torch.Size([8, 1, 512])

--- [nets/tinysimov35.py::DFL.forward] PYTORCH DFL DEBUG ---
[nets/tinysimov35.py::DFL.forward] Input shape: torch.Size([8, 64, 512])
[nets/tinysimov35.py::DFL.forward] DFL channels (self.ch): 16
[nets/tinysimov35.py::DFL.forward] Parsed dimensions - batch: 8, channels: 64, anchors: 512
[nets/tinysimov35.py::DFL.forward] After view(b, 4, ch, a): torch.Size([8, 4, 16, 512])
[nets/tinysimov35.py::DFL.forward] After transpose(2, 1): torch.Size([8, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After softmax(1): torch.Size([8, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After conv: torch.Size([8, 1, 4, 512])
[nets/tinysimov35.py::DFL.forward] Final output shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL output shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL split - a shape: torch.Size([8, 2, 512]), b shape: torch.Size([8, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchors expanded shape: torch.Size([1, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchor adjusted - a: torch.Size([8, 2, 512]), b: torch.Size([8, 2, 512])
[nets/tinysimov35.py::Head.forward] Box coordinates shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] Scaled boxes shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] Sigmoid classes shape: torch.Size([8, 1, 512])
[nets/tinysimov35.py::Head.forward] Final output shape: torch.Size([8, 5, 512])
[main.py::test] Model outputs shape: torch.Size([8, 5, 512])

--- [utils/util.py::non_max_suppression] PYTORCH NMS DEBUG ---
[utils/util.py::non_max_suppression] Prediction shape: torch.Size([8, 5, 512])
[utils/util.py::non_max_suppression] Conf threshold: 0.25, IoU threshold: 0.45
[utils/util.py::non_max_suppression] Number of classes: 1
[utils/util.py::non_max_suppression] Candidates per image: [0, 0, 0, 0, 0, 0, 0, 0]

--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([1, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: False
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([1, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Inference mode - processing...
[nets/tinysimov35.py::Head.forward] Box feature shape: torch.Size([1, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Cls feature shape: torch.Size([1, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Anchors shape: torch.Size([2, 512])
[nets/tinysimov35.py::Head.forward] Strides shape: torch.Size([1, 512])
[nets/tinysimov35.py::Head.forward] Combined features shape: torch.Size([1, 65, 16, 32])
[nets/tinysimov35.py::Head.forward] Combined flat shape: torch.Size([1, 65, 512])
[nets/tinysimov35.py::Head.forward] Expected self.no: 65
[nets/tinysimov35.py::Head.forward] Split - box shape: torch.Size([1, 64, 512]), cls shape: torch.Size([1, 1, 512])

--- [nets/tinysimov35.py::DFL.forward] PYTORCH DFL DEBUG ---
[nets/tinysimov35.py::DFL.forward] Input shape: torch.Size([1, 64, 512])
[nets/tinysimov35.py::DFL.forward] DFL channels (self.ch): 16
[nets/tinysimov35.py::DFL.forward] Parsed dimensions - batch: 1, channels: 64, anchors: 512
[nets/tinysimov35.py::DFL.forward] After view(b, 4, ch, a): torch.Size([1, 4, 16, 512])
[nets/tinysimov35.py::DFL.forward] After transpose(2, 1): torch.Size([1, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After softmax(1): torch.Size([1, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After conv: torch.Size([1, 1, 4, 512])
[nets/tinysimov35.py::DFL.forward] Final output shape: torch.Size([1, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL output shape: torch.Size([1, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL split - a shape: torch.Size([1, 2, 512]), b shape: torch.Size([1, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchors expanded shape: torch.Size([1, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchor adjusted - a: torch.Size([1, 2, 512]), b: torch.Size([1, 2, 512])
[nets/tinysimov35.py::Head.forward] Box coordinates shape: torch.Size([1, 4, 512])
[nets/tinysimov35.py::Head.forward] Scaled boxes shape: torch.Size([1, 4, 512])
[nets/tinysimov35.py::Head.forward] Sigmoid classes shape: torch.Size([1, 1, 512])
[nets/tinysimov35.py::Head.forward] Final output shape: torch.Size([1, 5, 512])
[main.py::test] Model outputs shape: torch.Size([1, 5, 512])

--- [utils/util.py::non_max_suppression] PYTORCH NMS DEBUG ---
[utils/util.py::non_max_suppression] Prediction shape: torch.Size([1, 5, 512])
[utils/util.py::non_max_suppression] Conf threshold: 0.25, IoU threshold: 0.45
[utils/util.py::non_max_suppression] Number of classes: 1
[utils/util.py::non_max_suppression] Candidates per image: [0]

--- [utils/util.py::compute_ap] PYTORCH COMPUTE_AP DEBUG ---
[utils/util.py::compute_ap] TP shape: (0, 10), dtype: bool
[utils/util.py::compute_ap] Conf shape: (0,), dtype: float32
[utils/util.py::compute_ap] Pred_cls shape: (0,), dtype: float32
[utils/util.py::compute_ap] Target_cls shape: (0,), dtype: float32
[utils/util.py::compute_ap] Conf array is empty - no predictions to evaluate
After sorting - first 5 conf: []
Unique classes: []
Class counts: []
Number of classes: 0
Precision: nan, Recall: nan, mAP50: nan, mAP: nan

     epoch    memory      loss

--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([4, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: True
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([4, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - box shape: torch.Size([4, 64, 16, 32]), cls shape: torch.Size([4, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - final concat shape: torch.Size([4, 65, 16, 32])

--- [utils/util.py::ComputeLoss.__call__] PYTORCH LOSS COMPUTATION DEBUG ---
[utils/util.py::ComputeLoss.__call__] Outputs type: <class 'list'>
[utils/util.py::ComputeLoss.__call__] x type: <class 'list'>, len: 1
[utils/util.py::ComputeLoss.__call__] x[0] shape: torch.Size([4, 65, 16, 32])
[utils/util.py::ComputeLoss.__call__] Concatenated output shape: torch.Size([4, 65, 512])
[utils/util.py::ComputeLoss.__call__] self.no: 65, self.dfl_ch: 16, self.nc: 1
[utils/util.py::ComputeLoss.__call__] pred_output shape: torch.Size([4, 64, 512])
[utils/util.py::ComputeLoss.__call__] pred_scores shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.__call__] After permute - pred_output shape: torch.Size([4, 512, 64])
[utils/util.py::ComputeLoss.__call__] After permute - pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Size tensor: tensor([128., 256.], device='cuda:0', dtype=torch.float16)
[utils/util.py::ComputeLoss.__call__] Stride: tensor([8.])
[utils/util.py::ComputeLoss.__call__] Anchor points shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.__call__] Stride tensor shape: torch.Size([512, 1])

--- [utils/util.py::ComputeLoss.__call__] TARGET PROCESSING ---
[utils/util.py::ComputeLoss.__call__] Targets shape: torch.Size([6, 6])
[utils/util.py::ComputeLoss.__call__] Targets dtype: torch.float32
[utils/util.py::ComputeLoss.__call__] First few targets: tensor([[0.0000, 0.0000, 0.5903, 0.9849, 0.1256, 0.0302],
        [1.0000, 0.0000, 0.1812, 0.1618, 0.0521, 0.1163],
        [1.0000, 0.0000, 0.6876, 0.1339, 0.0535, 0.1070],
        [1.0000, 0.0000, 0.3636, 0.7294, 0.0502, 0.1070],
        [1.0000, 0.0000, 0.7890, 0.7294, 0.0508, 0.1070]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Image indices: tensor([0., 1., 1., 1., 1., 2.], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Counts per image: tensor([1, 4, 1], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT tensor shape: torch.Size([4, 4, 5])
[utils/util.py::ComputeLoss.__call__] Image 0: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 1: 4 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 2: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] GT before coordinate conversion: tensor([[[0.0000, 0.5903, 0.9849, 0.1256, 0.0302],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.1812, 0.1618, 0.0521, 0.1163],
         [0.0000, 0.6876, 0.1339, 0.0535, 0.1070],
         [0.0000, 0.3636, 0.7294, 0.0502, 0.1070],
         [0.0000, 0.7890, 0.7294, 0.0508, 0.1070]],

        [[0.0000, 0.4518, 0.9214, 0.1350, 0.1571],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT after coordinate conversion: tensor([[[  0.0000, 135.0338, 124.1363, 167.1851, 127.9990],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000,  39.7290,  13.2666,  53.0563,  28.1542],
         [  0.0000, 169.1791,  10.2891, 182.8757,  23.9857],
         [  0.0000,  86.6664,  86.5134,  99.5054, 100.2099],
         [  0.0000, 195.4795,  86.5134, 208.4793, 100.2099]],

        [[  0.0000,  98.3802, 107.8920, 132.9299, 127.9990],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT labels shape: torch.Size([4, 4, 1])
[utils/util.py::ComputeLoss.__call__] GT bboxes shape: torch.Size([4, 4, 4])
[utils/util.py::ComputeLoss.__call__] GT mask shape: torch.Size([4, 4, 1])
[utils/util.py::ComputeLoss.__call__] Pred output dimensions - b: 4, a: 512, c: 64
[utils/util.py::ComputeLoss.__call__] Pred bboxes after softmax shape: torch.Size([4, 512, 4, 16])
[utils/util.py::ComputeLoss.__call__] Pred bboxes after matmul shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Final pred bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.__call__] ASSIGNMENT PHASE ---

--- [utils/util.py::ComputeLoss.assign] PYTORCH ASSIGNMENT DEBUG ---
[utils/util.py::ComputeLoss.assign] pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] true_labels shape: torch.Size([4, 4, 1])
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 4, 4])
[utils/util.py::ComputeLoss.assign] true_mask shape: torch.Size([4, 4, 1])
[utils/util.py::ComputeLoss.assign] anchors shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.assign] Batch size: 4, Max boxes: 4
[utils/util.py::ComputeLoss.assign] Created indices tensor with shape: torch.Size([2, 4, 4])

--- [utils/util.py::ComputeLoss.assign] IOUs DEBUG ---
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 4, 4])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([4, 4, 1, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([4, 1, 512, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([4, 4, 1, 1]), h: torch.Size([4, 4, 1, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([4, 1, 512, 1]), h: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([4, 4, 512, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([4, 4, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([4, 4, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.000000, max: 0.515106
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([4, 4, 512, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([4, 4, 512, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([4, 4, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([4, 4, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: -0.939027, max: 0.512285
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.assign] overlaps shape: torch.Size([4, 4, 512])
[utils/util.py::ComputeLoss.assign] overlaps min: 0.0, max: 0.5122845768928528
[utils/util.py::ComputeLoss.assign] align_metric shape: torch.Size([4, 4, 512])
[utils/util.py::ComputeLoss.assign] align_metric min: 0.0, max: 0.0011936444789171219
[utils/util.py::ComputeLoss.assign] mask_in_gts shape: torch.Size([4, 4, 512])
[utils/util.py::ComputeLoss.assign] mask_in_gts sum: 29.0
[utils/util.py::ComputeLoss.assign] metrics shape: torch.Size([4, 4, 512])
[utils/util.py::ComputeLoss.assign] top_k_mask shape: torch.Size([4, 4, 10])
[utils/util.py::ComputeLoss.assign] top_k_metrics shape: torch.Size([4, 4, 10])
[utils/util.py::ComputeLoss.assign] top_k_indices shape: torch.Size([4, 4, 10])
[utils/util.py::ComputeLoss.assign] is_in_top_k shape: torch.Size([4, 4, 512])
[utils/util.py::ComputeLoss.assign] mask_top_k shape: torch.Size([4, 4, 512])
[utils/util.py::ComputeLoss.assign] mask_pos shape: torch.Size([4, 4, 512])
[utils/util.py::ComputeLoss.assign] fg_mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] fg_mask sum: 24.0
[utils/util.py::ComputeLoss.assign] target_gt_idx shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_labels shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] Normalized target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] target_scores sum: 1.7415564060211182
--- [utils/util.py::ComputeLoss.assign] END PYTORCH ASSIGNMENT DEBUG ---

[utils/util.py::ComputeLoss.__call__] Target bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Target scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] FG mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.__call__] Target scores sum: 1.741556
[utils/util.py::ComputeLoss.__call__] Classification loss computed: 6.701979
[utils/util.py::ComputeLoss.__call__] Foreground count: 24
[utils/util.py::ComputeLoss.__call__] Weight shape: torch.Size([24, 1])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([24, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([24, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([24, 1]), h: torch.Size([24, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([24, 1]), h: torch.Size([24, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([24, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([24, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([24, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.100142, max: 0.515204
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([24, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([24, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([24, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([24, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: 0.057140, max: 0.512375
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.__call__] IoU values shape: torch.Size([24, 1])
[utils/util.py::ComputeLoss.__call__] Box loss computed: 0.740370
[utils/util.py::ComputeLoss.__call__] Target LT-RB shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.df_loss] PYTORCH DFL LOSS DEBUG ---
[utils/util.py::ComputeLoss.df_loss] pred_dist shape: torch.Size([96, 16])
[utils/util.py::ComputeLoss.df_loss] target shape: torch.Size([24, 4])
[utils/util.py::ComputeLoss.df_loss] DFL loss shape: torch.Size([24, 1])
[utils/util.py::ComputeLoss.df_loss] DFL loss mean: 1.708235
--- [utils/util.py::ComputeLoss.df_loss] END PYTORCH DFL LOSS DEBUG ---

[utils/util.py::ComputeLoss.__call__] DFL loss before weighting: 1.708235
[utils/util.py::ComputeLoss.__call__] DFL loss computed: 1.540813

--- [utils/util.py::ComputeLoss.__call__] LOSS COMPONENTS DEBUG ---
[utils/util.py::ComputeLoss.__call__] Raw loss_cls: 6.701979
[utils/util.py::ComputeLoss.__call__] Raw loss_box: 0.740370
[utils/util.py::ComputeLoss.__call__] Raw loss_dfl: 1.540813
[utils/util.py::ComputeLoss.__call__] Loss weights - cls: 0.5, box: 7.5, dfl: 1.5
[utils/util.py::ComputeLoss.__call__] target_scores_sum: 1.741556
[utils/util.py::ComputeLoss.__call__] fg_mask sum: 24
[utils/util.py::ComputeLoss.__call__] Weighted loss_cls: 3.350990
[utils/util.py::ComputeLoss.__call__] Weighted loss_box: 5.552777
[utils/util.py::ComputeLoss.__call__] Weighted loss_dfl: 2.311220
[utils/util.py::ComputeLoss.__call__] Total loss: 11.214987
--- [utils/util.py::ComputeLoss.__call__] END PYTORCH LOSS COMPUTATION DEBUG ---


--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([4, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: True
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([4, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - box shape: torch.Size([4, 64, 16, 32]), cls shape: torch.Size([4, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - final concat shape: torch.Size([4, 65, 16, 32])

--- [utils/util.py::ComputeLoss.__call__] PYTORCH LOSS COMPUTATION DEBUG ---
[utils/util.py::ComputeLoss.__call__] Outputs type: <class 'list'>
[utils/util.py::ComputeLoss.__call__] x type: <class 'list'>, len: 1
[utils/util.py::ComputeLoss.__call__] x[0] shape: torch.Size([4, 65, 16, 32])
[utils/util.py::ComputeLoss.__call__] Concatenated output shape: torch.Size([4, 65, 512])
[utils/util.py::ComputeLoss.__call__] self.no: 65, self.dfl_ch: 16, self.nc: 1
[utils/util.py::ComputeLoss.__call__] pred_output shape: torch.Size([4, 64, 512])
[utils/util.py::ComputeLoss.__call__] pred_scores shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.__call__] After permute - pred_output shape: torch.Size([4, 512, 64])
[utils/util.py::ComputeLoss.__call__] After permute - pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Size tensor: tensor([128., 256.], device='cuda:0', dtype=torch.float16)
[utils/util.py::ComputeLoss.__call__] Stride: tensor([8.])
[utils/util.py::ComputeLoss.__call__] Anchor points shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.__call__] Stride tensor shape: torch.Size([512, 1])

--- [utils/util.py::ComputeLoss.__call__] TARGET PROCESSING ---
[utils/util.py::ComputeLoss.__call__] Targets shape: torch.Size([8, 6])
[utils/util.py::ComputeLoss.__call__] Targets dtype: torch.float32
[utils/util.py::ComputeLoss.__call__] First few targets: tensor([[0.0000, 0.0000, 0.3950, 0.3535, 0.0589, 0.1113],
        [1.0000, 0.0000, 0.8065, 0.1575, 0.0529, 0.1057],
        [1.0000, 0.0000, 0.3434, 0.3224, 0.0504, 0.1047],
        [1.0000, 0.0000, 0.8525, 0.7412, 0.0529, 0.1057],
        [1.0000, 0.0000, 0.5145, 0.9357, 0.0619, 0.1179]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Image indices: tensor([0., 1., 1., 1., 1., 2., 2., 3.], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Counts per image: tensor([1, 4, 2, 1], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT tensor shape: torch.Size([4, 4, 5])
[utils/util.py::ComputeLoss.__call__] Image 0: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 1: 4 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 2: 2 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 3: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] GT before coordinate conversion: tensor([[[0.0000, 0.3950, 0.3535, 0.0589, 0.1113],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.8065, 0.1575, 0.0529, 0.1057],
         [0.0000, 0.3434, 0.3224, 0.0504, 0.1047],
         [0.0000, 0.8525, 0.7412, 0.0529, 0.1057],
         [0.0000, 0.5145, 0.9357, 0.0619, 0.1179]],

        [[0.0000, 0.2106, 0.2978, 0.1257, 0.2636],
         [0.0000, 0.9900, 0.2925, 0.0200, 0.2320],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.3181, 0.2219, 0.1091, 0.2299],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT after coordinate conversion: tensor([[[  0.0000,  93.5786,  38.1245, 108.6637,  52.3767],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000, 199.7053,  13.3918, 213.2359,  26.9224],
         [  0.0000,  81.4444,  34.5731,  94.3573,  47.9685],
         [  0.0000, 211.4711,  88.1046, 225.0018, 101.6352],
         [  0.0000, 123.7953, 112.2244, 139.6380, 127.3200]],

        [[  0.0000,  37.8266,  21.2414,  69.9932,  54.9872],
         [  0.0000, 250.8777,  22.5912, 255.9990,  52.2876],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000,  67.4666,  13.6846,  95.4020,  43.1172],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT labels shape: torch.Size([4, 4, 1])
[utils/util.py::ComputeLoss.__call__] GT bboxes shape: torch.Size([4, 4, 4])
[utils/util.py::ComputeLoss.__call__] GT mask shape: torch.Size([4, 4, 1])
[utils/util.py::ComputeLoss.__call__] Pred output dimensions - b: 4, a: 512, c: 64
[utils/util.py::ComputeLoss.__call__] Pred bboxes after softmax shape: torch.Size([4, 512, 4, 16])
[utils/util.py::ComputeLoss.__call__] Pred bboxes after matmul shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Final pred bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.__call__] ASSIGNMENT PHASE ---

--- [utils/util.py::ComputeLoss.assign] PYTORCH ASSIGNMENT DEBUG ---
[utils/util.py::ComputeLoss.assign] pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] true_labels shape: torch.Size([4, 4, 1])
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 4, 4])
[utils/util.py::ComputeLoss.assign] true_mask shape: torch.Size([4, 4, 1])
[utils/util.py::ComputeLoss.assign] anchors shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.assign] Batch size: 4, Max boxes: 4
[utils/util.py::ComputeLoss.assign] Created indices tensor with shape: torch.Size([2, 4, 4])

--- [utils/util.py::ComputeLoss.assign] IOUs DEBUG ---
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 4, 4])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([4, 4, 1, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([4, 1, 512, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([4, 4, 1, 1]), h: torch.Size([4, 4, 1, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([4, 1, 512, 1]), h: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([4, 4, 512, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([4, 4, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([4, 4, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.000000, max: 0.849978
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([4, 4, 512, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([4, 4, 512, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([4, 4, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([4, 4, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: -0.912512, max: 0.849481
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.assign] overlaps shape: torch.Size([4, 4, 512])
[utils/util.py::ComputeLoss.assign] overlaps min: 0.0, max: 0.8494806885719299
[utils/util.py::ComputeLoss.assign] align_metric shape: torch.Size([4, 4, 512])
[utils/util.py::ComputeLoss.assign] align_metric min: 0.0, max: 0.026054304093122482
[utils/util.py::ComputeLoss.assign] mask_in_gts shape: torch.Size([4, 4, 512])
[utils/util.py::ComputeLoss.assign] mask_in_gts sum: 50.0
[utils/util.py::ComputeLoss.assign] metrics shape: torch.Size([4, 4, 512])
[utils/util.py::ComputeLoss.assign] top_k_mask shape: torch.Size([4, 4, 10])
[utils/util.py::ComputeLoss.assign] top_k_metrics shape: torch.Size([4, 4, 10])
[utils/util.py::ComputeLoss.assign] top_k_indices shape: torch.Size([4, 4, 10])
[utils/util.py::ComputeLoss.assign] is_in_top_k shape: torch.Size([4, 4, 512])
[utils/util.py::ComputeLoss.assign] mask_top_k shape: torch.Size([4, 4, 512])
[utils/util.py::ComputeLoss.assign] mask_pos shape: torch.Size([4, 4, 512])
[utils/util.py::ComputeLoss.assign] fg_mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] fg_mask sum: 41.0
[utils/util.py::ComputeLoss.assign] target_gt_idx shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_labels shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] Normalized target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] target_scores sum: 3.5891547203063965
--- [utils/util.py::ComputeLoss.assign] END PYTORCH ASSIGNMENT DEBUG ---

[utils/util.py::ComputeLoss.__call__] Target bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Target scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] FG mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.__call__] Target scores sum: 3.589155
[utils/util.py::ComputeLoss.__call__] Classification loss computed: 6.364660
[utils/util.py::ComputeLoss.__call__] Foreground count: 41
[utils/util.py::ComputeLoss.__call__] Weight shape: torch.Size([41, 1])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([41, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([41, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([41, 1]), h: torch.Size([41, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([41, 1]), h: torch.Size([41, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([41, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([41, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([41, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.078742, max: 0.850327
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([41, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([41, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([41, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([41, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: 0.038439, max: 0.849830
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.__call__] IoU values shape: torch.Size([41, 1])
[utils/util.py::ComputeLoss.__call__] Box loss computed: 0.536459
[utils/util.py::ComputeLoss.__call__] Target LT-RB shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.df_loss] PYTORCH DFL LOSS DEBUG ---
[utils/util.py::ComputeLoss.df_loss] pred_dist shape: torch.Size([164, 16])
[utils/util.py::ComputeLoss.df_loss] target shape: torch.Size([41, 4])
[utils/util.py::ComputeLoss.df_loss] DFL loss shape: torch.Size([41, 1])
[utils/util.py::ComputeLoss.df_loss] DFL loss mean: 1.677131
--- [utils/util.py::ComputeLoss.df_loss] END PYTORCH DFL LOSS DEBUG ---

[utils/util.py::ComputeLoss.__call__] DFL loss before weighting: 1.677131
[utils/util.py::ComputeLoss.__call__] DFL loss computed: 1.549991

--- [utils/util.py::ComputeLoss.__call__] LOSS COMPONENTS DEBUG ---
[utils/util.py::ComputeLoss.__call__] Raw loss_cls: 6.364660
[utils/util.py::ComputeLoss.__call__] Raw loss_box: 0.536459
[utils/util.py::ComputeLoss.__call__] Raw loss_dfl: 1.549991
[utils/util.py::ComputeLoss.__call__] Loss weights - cls: 0.5, box: 7.5, dfl: 1.5
[utils/util.py::ComputeLoss.__call__] target_scores_sum: 3.589155
[utils/util.py::ComputeLoss.__call__] fg_mask sum: 41
[utils/util.py::ComputeLoss.__call__] Weighted loss_cls: 3.182330
[utils/util.py::ComputeLoss.__call__] Weighted loss_box: 4.023439
[utils/util.py::ComputeLoss.__call__] Weighted loss_dfl: 2.324986
[utils/util.py::ComputeLoss.__call__] Total loss: 9.530756
--- [utils/util.py::ComputeLoss.__call__] END PYTORCH LOSS COMPUTATION DEBUG ---


--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([4, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: True
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([4, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - box shape: torch.Size([4, 64, 16, 32]), cls shape: torch.Size([4, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - final concat shape: torch.Size([4, 65, 16, 32])

--- [utils/util.py::ComputeLoss.__call__] PYTORCH LOSS COMPUTATION DEBUG ---
[utils/util.py::ComputeLoss.__call__] Outputs type: <class 'list'>
[utils/util.py::ComputeLoss.__call__] x type: <class 'list'>, len: 1
[utils/util.py::ComputeLoss.__call__] x[0] shape: torch.Size([4, 65, 16, 32])
[utils/util.py::ComputeLoss.__call__] Concatenated output shape: torch.Size([4, 65, 512])
[utils/util.py::ComputeLoss.__call__] self.no: 65, self.dfl_ch: 16, self.nc: 1
[utils/util.py::ComputeLoss.__call__] pred_output shape: torch.Size([4, 64, 512])
[utils/util.py::ComputeLoss.__call__] pred_scores shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.__call__] After permute - pred_output shape: torch.Size([4, 512, 64])
[utils/util.py::ComputeLoss.__call__] After permute - pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Size tensor: tensor([128., 256.], device='cuda:0', dtype=torch.float16)
[utils/util.py::ComputeLoss.__call__] Stride: tensor([8.])
[utils/util.py::ComputeLoss.__call__] Anchor points shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.__call__] Stride tensor shape: torch.Size([512, 1])

--- [utils/util.py::ComputeLoss.__call__] TARGET PROCESSING ---
[utils/util.py::ComputeLoss.__call__] Targets shape: torch.Size([6, 6])
[utils/util.py::ComputeLoss.__call__] Targets dtype: torch.float32
[utils/util.py::ComputeLoss.__call__] First few targets: tensor([[0.0000, 0.0000, 0.5049, 0.0779, 0.0490, 0.0953],
        [0.0000, 0.0000, 0.8410, 0.0403, 0.0478, 0.0806],
        [0.0000, 0.0000, 0.4046, 0.6211, 0.0582, 0.1092],
        [2.0000, 0.0000, 0.2528, 0.3621, 0.0876, 0.1835],
        [3.0000, 0.0000, 0.0271, 0.0785, 0.0542, 0.1571]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Image indices: tensor([0., 0., 0., 2., 3., 3.], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Counts per image: tensor([3, 1, 2], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT tensor shape: torch.Size([4, 3, 5])
[utils/util.py::ComputeLoss.__call__] Image 0: 3 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 2: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 3: 2 targets assigned
[utils/util.py::ComputeLoss.__call__] GT before coordinate conversion: tensor([[[0.0000, 0.5049, 0.0779, 0.0490, 0.0953],
         [0.0000, 0.8410, 0.0403, 0.0478, 0.0806],
         [0.0000, 0.4046, 0.6211, 0.0582, 0.1092]],

        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.2528, 0.3621, 0.0876, 0.1835],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.0271, 0.0785, 0.0542, 0.1571],
         [0.0000, 0.8080, 0.0499, 0.0879, 0.0998],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT after coordinate conversion: tensor([[[  0.0000, 122.9802,   3.8678, 135.5363,  16.0692],
         [  0.0000, 209.1717,   0.0000, 221.4106,  10.3179],
         [  0.0000,  96.1264,  72.5071, 111.0260,  86.4822]],

        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000,  53.5110,  34.5981,  75.9376,  58.0919],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000,   0.0000,   0.0000,  13.8747,  20.1041],
         [  0.0000, 195.6093,   0.0000, 218.1061,  12.7779],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT labels shape: torch.Size([4, 3, 1])
[utils/util.py::ComputeLoss.__call__] GT bboxes shape: torch.Size([4, 3, 4])
[utils/util.py::ComputeLoss.__call__] GT mask shape: torch.Size([4, 3, 1])
[utils/util.py::ComputeLoss.__call__] Pred output dimensions - b: 4, a: 512, c: 64
[utils/util.py::ComputeLoss.__call__] Pred bboxes after softmax shape: torch.Size([4, 512, 4, 16])
[utils/util.py::ComputeLoss.__call__] Pred bboxes after matmul shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Final pred bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.__call__] ASSIGNMENT PHASE ---

--- [utils/util.py::ComputeLoss.assign] PYTORCH ASSIGNMENT DEBUG ---
[utils/util.py::ComputeLoss.assign] pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] true_labels shape: torch.Size([4, 3, 1])
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 3, 4])
[utils/util.py::ComputeLoss.assign] true_mask shape: torch.Size([4, 3, 1])
[utils/util.py::ComputeLoss.assign] anchors shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.assign] Batch size: 4, Max boxes: 3
[utils/util.py::ComputeLoss.assign] Created indices tensor with shape: torch.Size([2, 4, 3])

--- [utils/util.py::ComputeLoss.assign] IOUs DEBUG ---
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 3, 4])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([4, 3, 1, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([4, 1, 512, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([4, 3, 1, 1]), h: torch.Size([4, 3, 1, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([4, 1, 512, 1]), h: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.000000, max: 0.444320
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: -0.957362, max: 0.443616
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.assign] overlaps shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] overlaps min: 0.0, max: 0.4436163008213043
[utils/util.py::ComputeLoss.assign] align_metric shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] align_metric min: 0.0, max: 0.0006359069375321269
[utils/util.py::ComputeLoss.assign] mask_in_gts shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] mask_in_gts sum: 28.0
[utils/util.py::ComputeLoss.assign] metrics shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] top_k_mask shape: torch.Size([4, 3, 10])
[utils/util.py::ComputeLoss.assign] top_k_metrics shape: torch.Size([4, 3, 10])
[utils/util.py::ComputeLoss.assign] top_k_indices shape: torch.Size([4, 3, 10])
[utils/util.py::ComputeLoss.assign] is_in_top_k shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] mask_top_k shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] mask_pos shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] fg_mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] fg_mask sum: 28.0
[utils/util.py::ComputeLoss.assign] target_gt_idx shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_labels shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] Normalized target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] target_scores sum: 2.42742919921875
--- [utils/util.py::ComputeLoss.assign] END PYTORCH ASSIGNMENT DEBUG ---

[utils/util.py::ComputeLoss.__call__] Target bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Target scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] FG mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.__call__] Target scores sum: 2.427429
[utils/util.py::ComputeLoss.__call__] Classification loss computed: 6.507656
[utils/util.py::ComputeLoss.__call__] Foreground count: 28
[utils/util.py::ComputeLoss.__call__] Weight shape: torch.Size([28, 1])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([28, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([28, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([28, 1]), h: torch.Size([28, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([28, 1]), h: torch.Size([28, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([28, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([28, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([28, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.084809, max: 0.444257
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([28, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([28, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([28, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([28, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: 0.068247, max: 0.443553
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.__call__] IoU values shape: torch.Size([28, 1])
[utils/util.py::ComputeLoss.__call__] Box loss computed: 0.768268
[utils/util.py::ComputeLoss.__call__] Target LT-RB shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.df_loss] PYTORCH DFL LOSS DEBUG ---
[utils/util.py::ComputeLoss.df_loss] pred_dist shape: torch.Size([112, 16])
[utils/util.py::ComputeLoss.df_loss] target shape: torch.Size([28, 4])
[utils/util.py::ComputeLoss.df_loss] DFL loss shape: torch.Size([28, 1])
[utils/util.py::ComputeLoss.df_loss] DFL loss mean: 1.620212
--- [utils/util.py::ComputeLoss.df_loss] END PYTORCH DFL LOSS DEBUG ---

[utils/util.py::ComputeLoss.__call__] DFL loss before weighting: 1.620212
[utils/util.py::ComputeLoss.__call__] DFL loss computed: 1.415143

--- [utils/util.py::ComputeLoss.__call__] LOSS COMPONENTS DEBUG ---
[utils/util.py::ComputeLoss.__call__] Raw loss_cls: 6.507656
[utils/util.py::ComputeLoss.__call__] Raw loss_box: 0.768268
[utils/util.py::ComputeLoss.__call__] Raw loss_dfl: 1.415143
[utils/util.py::ComputeLoss.__call__] Loss weights - cls: 0.5, box: 7.5, dfl: 1.5
[utils/util.py::ComputeLoss.__call__] target_scores_sum: 2.427429
[utils/util.py::ComputeLoss.__call__] fg_mask sum: 28
[utils/util.py::ComputeLoss.__call__] Weighted loss_cls: 3.253828
[utils/util.py::ComputeLoss.__call__] Weighted loss_box: 5.762010
[utils/util.py::ComputeLoss.__call__] Weighted loss_dfl: 2.122715
[utils/util.py::ComputeLoss.__call__] Total loss: 11.138554
--- [utils/util.py::ComputeLoss.__call__] END PYTORCH LOSS COMPUTATION DEBUG ---


--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([4, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: True
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([4, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - box shape: torch.Size([4, 64, 16, 32]), cls shape: torch.Size([4, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - final concat shape: torch.Size([4, 65, 16, 32])

--- [utils/util.py::ComputeLoss.__call__] PYTORCH LOSS COMPUTATION DEBUG ---
[utils/util.py::ComputeLoss.__call__] Outputs type: <class 'list'>
[utils/util.py::ComputeLoss.__call__] x type: <class 'list'>, len: 1
[utils/util.py::ComputeLoss.__call__] x[0] shape: torch.Size([4, 65, 16, 32])
[utils/util.py::ComputeLoss.__call__] Concatenated output shape: torch.Size([4, 65, 512])
[utils/util.py::ComputeLoss.__call__] self.no: 65, self.dfl_ch: 16, self.nc: 1
[utils/util.py::ComputeLoss.__call__] pred_output shape: torch.Size([4, 64, 512])
[utils/util.py::ComputeLoss.__call__] pred_scores shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.__call__] After permute - pred_output shape: torch.Size([4, 512, 64])
[utils/util.py::ComputeLoss.__call__] After permute - pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Size tensor: tensor([128., 256.], device='cuda:0', dtype=torch.float16)
[utils/util.py::ComputeLoss.__call__] Stride: tensor([8.])
[utils/util.py::ComputeLoss.__call__] Anchor points shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.__call__] Stride tensor shape: torch.Size([512, 1])

--- [utils/util.py::ComputeLoss.__call__] TARGET PROCESSING ---
[utils/util.py::ComputeLoss.__call__] Targets shape: torch.Size([7, 6])
[utils/util.py::ComputeLoss.__call__] Targets dtype: torch.float32
[utils/util.py::ComputeLoss.__call__] First few targets: tensor([[0.0000, 0.0000, 0.0158, 0.0845, 0.0317, 0.1690],
        [0.0000, 0.0000, 0.8909, 0.9782, 0.1121, 0.0435],
        [1.0000, 0.0000, 0.7747, 0.2672, 0.0595, 0.1200],
        [1.0000, 0.0000, 0.1247, 0.2569, 0.0505, 0.1138],
        [1.0000, 0.0000, 0.2968, 0.8158, 0.0597, 0.1175]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Image indices: tensor([0., 0., 1., 1., 1., 2., 3.], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Counts per image: tensor([2, 3, 1, 1], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT tensor shape: torch.Size([4, 3, 5])
[utils/util.py::ComputeLoss.__call__] Image 0: 2 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 1: 3 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 2: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 3: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] GT before coordinate conversion: tensor([[[0.0000, 0.0158, 0.0845, 0.0317, 0.1690],
         [0.0000, 0.8909, 0.9782, 0.1121, 0.0435],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.7747, 0.2672, 0.0595, 0.1200],
         [0.0000, 0.1247, 0.2569, 0.0505, 0.1138],
         [0.0000, 0.2968, 0.8158, 0.0597, 0.1175]],

        [[0.0000, 0.2979, 0.8737, 0.1129, 0.2245],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.0871, 0.8597, 0.0917, 0.1964],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT after coordinate conversion: tensor([[[0.0000e+00, 9.9945e-04, 0.0000e+00, 8.1137e+00, 2.1637e+01],
         [0.0000e+00, 2.1372e+02, 1.2243e+02, 2.4243e+02, 1.2800e+02],
         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],

        [[0.0000e+00, 1.9071e+02, 2.6527e+01, 2.0594e+02, 4.1884e+01],
         [0.0000e+00, 2.5472e+01, 2.5601e+01, 3.8399e+01, 4.0170e+01],
         [0.0000e+00, 6.8321e+01, 9.6900e+01, 8.3617e+01, 1.1194e+02]],

        [[0.0000e+00, 6.1813e+01, 9.7463e+01, 9.0718e+01, 1.2620e+02],
         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],

        [[0.0000e+00, 1.0554e+01, 9.7466e+01, 3.4023e+01, 1.2261e+02],
         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]]],
       device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT labels shape: torch.Size([4, 3, 1])
[utils/util.py::ComputeLoss.__call__] GT bboxes shape: torch.Size([4, 3, 4])
[utils/util.py::ComputeLoss.__call__] GT mask shape: torch.Size([4, 3, 1])
[utils/util.py::ComputeLoss.__call__] Pred output dimensions - b: 4, a: 512, c: 64
[utils/util.py::ComputeLoss.__call__] Pred bboxes after softmax shape: torch.Size([4, 512, 4, 16])
[utils/util.py::ComputeLoss.__call__] Pred bboxes after matmul shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Final pred bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.__call__] ASSIGNMENT PHASE ---

--- [utils/util.py::ComputeLoss.assign] PYTORCH ASSIGNMENT DEBUG ---
[utils/util.py::ComputeLoss.assign] pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] true_labels shape: torch.Size([4, 3, 1])
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 3, 4])
[utils/util.py::ComputeLoss.assign] true_mask shape: torch.Size([4, 3, 1])
[utils/util.py::ComputeLoss.assign] anchors shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.assign] Batch size: 4, Max boxes: 3
[utils/util.py::ComputeLoss.assign] Created indices tensor with shape: torch.Size([2, 4, 3])

--- [utils/util.py::ComputeLoss.assign] IOUs DEBUG ---
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 3, 4])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([4, 3, 1, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([4, 1, 512, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([4, 3, 1, 1]), h: torch.Size([4, 3, 1, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([4, 1, 512, 1]), h: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.000000, max: 0.683317
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: -0.923487, max: 0.681382
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.assign] overlaps shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] overlaps min: 0.0, max: 0.6813821792602539
[utils/util.py::ComputeLoss.assign] align_metric shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] align_metric min: 0.0, max: 0.0059892479330301285
[utils/util.py::ComputeLoss.assign] mask_in_gts shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] mask_in_gts sum: 37.0
[utils/util.py::ComputeLoss.assign] metrics shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] top_k_mask shape: torch.Size([4, 3, 10])
[utils/util.py::ComputeLoss.assign] top_k_metrics shape: torch.Size([4, 3, 10])
[utils/util.py::ComputeLoss.assign] top_k_indices shape: torch.Size([4, 3, 10])
[utils/util.py::ComputeLoss.assign] is_in_top_k shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] mask_top_k shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] mask_pos shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] fg_mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] fg_mask sum: 35.0
[utils/util.py::ComputeLoss.assign] target_gt_idx shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_labels shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] Normalized target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] target_scores sum: 3.9140334129333496
--- [utils/util.py::ComputeLoss.assign] END PYTORCH ASSIGNMENT DEBUG ---

[utils/util.py::ComputeLoss.__call__] Target bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Target scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] FG mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.__call__] Target scores sum: 3.914033
[utils/util.py::ComputeLoss.__call__] Classification loss computed: 6.455138
[utils/util.py::ComputeLoss.__call__] Foreground count: 35
[utils/util.py::ComputeLoss.__call__] Weight shape: torch.Size([35, 1])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([35, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([35, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([35, 1]), h: torch.Size([35, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([35, 1]), h: torch.Size([35, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([35, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([35, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([35, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.089280, max: 0.683036
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([35, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([35, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([35, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([35, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: 0.048613, max: 0.681101
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.__call__] IoU values shape: torch.Size([35, 1])
[utils/util.py::ComputeLoss.__call__] Box loss computed: 0.637365
[utils/util.py::ComputeLoss.__call__] Target LT-RB shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.df_loss] PYTORCH DFL LOSS DEBUG ---
[utils/util.py::ComputeLoss.df_loss] pred_dist shape: torch.Size([140, 16])
[utils/util.py::ComputeLoss.df_loss] target shape: torch.Size([35, 4])
[utils/util.py::ComputeLoss.df_loss] DFL loss shape: torch.Size([35, 1])
[utils/util.py::ComputeLoss.df_loss] DFL loss mean: 1.698039
--- [utils/util.py::ComputeLoss.df_loss] END PYTORCH DFL LOSS DEBUG ---

[utils/util.py::ComputeLoss.__call__] DFL loss before weighting: 1.698039
[utils/util.py::ComputeLoss.__call__] DFL loss computed: 1.447858

--- [utils/util.py::ComputeLoss.__call__] LOSS COMPONENTS DEBUG ---
[utils/util.py::ComputeLoss.__call__] Raw loss_cls: 6.455138
[utils/util.py::ComputeLoss.__call__] Raw loss_box: 0.637365
[utils/util.py::ComputeLoss.__call__] Raw loss_dfl: 1.447858
[utils/util.py::ComputeLoss.__call__] Loss weights - cls: 0.5, box: 7.5, dfl: 1.5
[utils/util.py::ComputeLoss.__call__] target_scores_sum: 3.914033
[utils/util.py::ComputeLoss.__call__] fg_mask sum: 35
[utils/util.py::ComputeLoss.__call__] Weighted loss_cls: 3.227569
[utils/util.py::ComputeLoss.__call__] Weighted loss_box: 4.780234
[utils/util.py::ComputeLoss.__call__] Weighted loss_dfl: 2.171787
[utils/util.py::ComputeLoss.__call__] Total loss: 10.179590
--- [utils/util.py::ComputeLoss.__call__] END PYTORCH LOSS COMPUTATION DEBUG ---


--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([4, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: True
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([4, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - box shape: torch.Size([4, 64, 16, 32]), cls shape: torch.Size([4, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - final concat shape: torch.Size([4, 65, 16, 32])

--- [utils/util.py::ComputeLoss.__call__] PYTORCH LOSS COMPUTATION DEBUG ---
[utils/util.py::ComputeLoss.__call__] Outputs type: <class 'list'>
[utils/util.py::ComputeLoss.__call__] x type: <class 'list'>, len: 1
[utils/util.py::ComputeLoss.__call__] x[0] shape: torch.Size([4, 65, 16, 32])
[utils/util.py::ComputeLoss.__call__] Concatenated output shape: torch.Size([4, 65, 512])
[utils/util.py::ComputeLoss.__call__] self.no: 65, self.dfl_ch: 16, self.nc: 1
[utils/util.py::ComputeLoss.__call__] pred_output shape: torch.Size([4, 64, 512])
[utils/util.py::ComputeLoss.__call__] pred_scores shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.__call__] After permute - pred_output shape: torch.Size([4, 512, 64])
[utils/util.py::ComputeLoss.__call__] After permute - pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Size tensor: tensor([128., 256.], device='cuda:0', dtype=torch.float16)
[utils/util.py::ComputeLoss.__call__] Stride: tensor([8.])
[utils/util.py::ComputeLoss.__call__] Anchor points shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.__call__] Stride tensor shape: torch.Size([512, 1])

--- [utils/util.py::ComputeLoss.__call__] TARGET PROCESSING ---
[utils/util.py::ComputeLoss.__call__] Targets shape: torch.Size([3, 6])
[utils/util.py::ComputeLoss.__call__] Targets dtype: torch.float32
[utils/util.py::ComputeLoss.__call__] First few targets: tensor([[0.0000, 0.0000, 0.9481, 0.9035, 0.1038, 0.1930],
        [2.0000, 0.0000, 0.5040, 0.7045, 0.0862, 0.1777],
        [3.0000, 0.0000, 0.5419, 0.9239, 0.1158, 0.1523]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Image indices: tensor([0., 2., 3.], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Counts per image: tensor([1, 1, 1], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT tensor shape: torch.Size([4, 1, 5])
[utils/util.py::ComputeLoss.__call__] Image 0: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 2: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 3: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] GT before coordinate conversion: tensor([[[0.0000, 0.9481, 0.9035, 0.1038, 0.1930]],

        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.5040, 0.7045, 0.0862, 0.1777]],

        [[0.0000, 0.5419, 0.9239, 0.1158, 0.1523]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT after coordinate conversion: tensor([[[  0.0000, 229.4239, 103.2922, 256.0000, 127.9990]],

        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000, 117.9929,  78.8031, 140.0595, 101.5432]],

        [[  0.0000, 123.9093, 108.5098, 153.5472, 127.9990]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT labels shape: torch.Size([4, 1, 1])
[utils/util.py::ComputeLoss.__call__] GT bboxes shape: torch.Size([4, 1, 4])
[utils/util.py::ComputeLoss.__call__] GT mask shape: torch.Size([4, 1, 1])
[utils/util.py::ComputeLoss.__call__] Pred output dimensions - b: 4, a: 512, c: 64
[utils/util.py::ComputeLoss.__call__] Pred bboxes after softmax shape: torch.Size([4, 512, 4, 16])
[utils/util.py::ComputeLoss.__call__] Pred bboxes after matmul shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Final pred bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.__call__] ASSIGNMENT PHASE ---

--- [utils/util.py::ComputeLoss.assign] PYTORCH ASSIGNMENT DEBUG ---
[utils/util.py::ComputeLoss.assign] pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] true_labels shape: torch.Size([4, 1, 1])
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 1, 4])
[utils/util.py::ComputeLoss.assign] true_mask shape: torch.Size([4, 1, 1])
[utils/util.py::ComputeLoss.assign] anchors shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.assign] Batch size: 4, Max boxes: 1
[utils/util.py::ComputeLoss.assign] Created indices tensor with shape: torch.Size([2, 4, 1])

--- [utils/util.py::ComputeLoss.assign] IOUs DEBUG ---
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 1, 4])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([4, 1, 1, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([4, 1, 512, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([4, 1, 1, 1]), h: torch.Size([4, 1, 1, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([4, 1, 512, 1]), h: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.000000, max: 0.719782
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: -0.921801, max: 0.716818
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.assign] overlaps shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.assign] overlaps min: 0.0, max: 0.7168176174163818
[utils/util.py::ComputeLoss.assign] align_metric shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.assign] align_metric min: 0.0, max: 0.010350042022764683
[utils/util.py::ComputeLoss.assign] mask_in_gts shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.assign] mask_in_gts sum: 26.0
[utils/util.py::ComputeLoss.assign] metrics shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.assign] top_k_mask shape: torch.Size([4, 1, 10])
[utils/util.py::ComputeLoss.assign] top_k_metrics shape: torch.Size([4, 1, 10])
[utils/util.py::ComputeLoss.assign] top_k_indices shape: torch.Size([4, 1, 10])
[utils/util.py::ComputeLoss.assign] is_in_top_k shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.assign] mask_top_k shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.assign] mask_pos shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.assign] fg_mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] fg_mask sum: 26.0
[utils/util.py::ComputeLoss.assign] target_gt_idx shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_labels shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] Normalized target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] target_scores sum: 2.597407102584839
--- [utils/util.py::ComputeLoss.assign] END PYTORCH ASSIGNMENT DEBUG ---

[utils/util.py::ComputeLoss.__call__] Target bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Target scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] FG mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.__call__] Target scores sum: 2.597407
[utils/util.py::ComputeLoss.__call__] Classification loss computed: 5.958466
[utils/util.py::ComputeLoss.__call__] Foreground count: 26
[utils/util.py::ComputeLoss.__call__] Weight shape: torch.Size([26, 1])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([26, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([26, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([26, 1]), h: torch.Size([26, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([26, 1]), h: torch.Size([26, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([26, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([26, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([26, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.195640, max: 0.719967
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([26, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([26, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([26, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([26, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: 0.121309, max: 0.717003
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.__call__] IoU values shape: torch.Size([26, 1])
[utils/util.py::ComputeLoss.__call__] Box loss computed: 0.455757
[utils/util.py::ComputeLoss.__call__] Target LT-RB shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.df_loss] PYTORCH DFL LOSS DEBUG ---
[utils/util.py::ComputeLoss.df_loss] pred_dist shape: torch.Size([104, 16])
[utils/util.py::ComputeLoss.df_loss] target shape: torch.Size([26, 4])
[utils/util.py::ComputeLoss.df_loss] DFL loss shape: torch.Size([26, 1])
[utils/util.py::ComputeLoss.df_loss] DFL loss mean: 1.688113
--- [utils/util.py::ComputeLoss.df_loss] END PYTORCH DFL LOSS DEBUG ---

[utils/util.py::ComputeLoss.__call__] DFL loss before weighting: 1.688113
[utils/util.py::ComputeLoss.__call__] DFL loss computed: 1.350159

--- [utils/util.py::ComputeLoss.__call__] LOSS COMPONENTS DEBUG ---
[utils/util.py::ComputeLoss.__call__] Raw loss_cls: 5.958466
[utils/util.py::ComputeLoss.__call__] Raw loss_box: 0.455757
[utils/util.py::ComputeLoss.__call__] Raw loss_dfl: 1.350159
[utils/util.py::ComputeLoss.__call__] Loss weights - cls: 0.5, box: 7.5, dfl: 1.5
[utils/util.py::ComputeLoss.__call__] target_scores_sum: 2.597407
[utils/util.py::ComputeLoss.__call__] fg_mask sum: 26
[utils/util.py::ComputeLoss.__call__] Weighted loss_cls: 2.979233
[utils/util.py::ComputeLoss.__call__] Weighted loss_box: 3.418174
[utils/util.py::ComputeLoss.__call__] Weighted loss_dfl: 2.025239
[utils/util.py::ComputeLoss.__call__] Total loss: 8.422646
--- [utils/util.py::ComputeLoss.__call__] END PYTORCH LOSS COMPUTATION DEBUG ---


--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([4, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: True
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([4, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - box shape: torch.Size([4, 64, 16, 32]), cls shape: torch.Size([4, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - final concat shape: torch.Size([4, 65, 16, 32])

--- [utils/util.py::ComputeLoss.__call__] PYTORCH LOSS COMPUTATION DEBUG ---
[utils/util.py::ComputeLoss.__call__] Outputs type: <class 'list'>
[utils/util.py::ComputeLoss.__call__] x type: <class 'list'>, len: 1
[utils/util.py::ComputeLoss.__call__] x[0] shape: torch.Size([4, 65, 16, 32])
[utils/util.py::ComputeLoss.__call__] Concatenated output shape: torch.Size([4, 65, 512])
[utils/util.py::ComputeLoss.__call__] self.no: 65, self.dfl_ch: 16, self.nc: 1
[utils/util.py::ComputeLoss.__call__] pred_output shape: torch.Size([4, 64, 512])
[utils/util.py::ComputeLoss.__call__] pred_scores shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.__call__] After permute - pred_output shape: torch.Size([4, 512, 64])
[utils/util.py::ComputeLoss.__call__] After permute - pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Size tensor: tensor([128., 256.], device='cuda:0', dtype=torch.float16)
[utils/util.py::ComputeLoss.__call__] Stride: tensor([8.])
[utils/util.py::ComputeLoss.__call__] Anchor points shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.__call__] Stride tensor shape: torch.Size([512, 1])

--- [utils/util.py::ComputeLoss.__call__] TARGET PROCESSING ---
[utils/util.py::ComputeLoss.__call__] Targets shape: torch.Size([7, 6])
[utils/util.py::ComputeLoss.__call__] Targets dtype: torch.float32
[utils/util.py::ComputeLoss.__call__] First few targets: tensor([[0.0000, 0.0000, 0.9404, 0.0719, 0.0560, 0.1221],
        [0.0000, 0.0000, 0.5308, 0.0595, 0.0623, 0.1187],
        [0.0000, 0.0000, 0.2303, 0.7516, 0.0590, 0.1221],
        [1.0000, 0.0000, 0.5232, 0.9152, 0.1548, 0.1696],
        [1.0000, 0.0000, 0.2190, 0.6749, 0.1279, 0.2505]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Image indices: tensor([0., 0., 0., 1., 1., 2., 3.], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Counts per image: tensor([3, 2, 1, 1], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT tensor shape: torch.Size([4, 3, 5])
[utils/util.py::ComputeLoss.__call__] Image 0: 3 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 1: 2 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 2: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 3: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] GT before coordinate conversion: tensor([[[0.0000, 0.9404, 0.0719, 0.0560, 0.1221],
         [0.0000, 0.5308, 0.0595, 0.0623, 0.1187],
         [0.0000, 0.2303, 0.7516, 0.0590, 0.1221]],

        [[0.0000, 0.5232, 0.9152, 0.1548, 0.1696],
         [0.0000, 0.2190, 0.6749, 0.1279, 0.2505],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.9653, 0.5844, 0.0695, 0.2408],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.1636, 0.9183, 0.1145, 0.1633],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT after coordinate conversion: tensor([[[0.0000e+00, 2.3357e+02, 1.3854e+00, 2.4789e+02, 1.7018e+01],
         [0.0000e+00, 1.2790e+02, 2.2631e-02, 1.4385e+02, 1.5214e+01],
         [0.0000e+00, 5.1409e+01, 8.8386e+01, 6.6512e+01, 1.0402e+02]],

        [[0.0000e+00, 1.1412e+02, 1.0630e+02, 1.5377e+02, 1.2800e+02],
         [0.0000e+00, 3.9689e+01, 7.0350e+01, 7.2428e+01, 1.0241e+02],
         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],

        [[0.0000e+00, 2.3822e+02, 5.9398e+01, 2.5600e+02, 9.0216e+01],
         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],

        [[0.0000e+00, 2.7237e+01, 1.0710e+02, 5.6538e+01, 1.2800e+02],
         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]]],
       device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT labels shape: torch.Size([4, 3, 1])
[utils/util.py::ComputeLoss.__call__] GT bboxes shape: torch.Size([4, 3, 4])
[utils/util.py::ComputeLoss.__call__] GT mask shape: torch.Size([4, 3, 1])
[utils/util.py::ComputeLoss.__call__] Pred output dimensions - b: 4, a: 512, c: 64
[utils/util.py::ComputeLoss.__call__] Pred bboxes after softmax shape: torch.Size([4, 512, 4, 16])
[utils/util.py::ComputeLoss.__call__] Pred bboxes after matmul shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Final pred bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.__call__] ASSIGNMENT PHASE ---

--- [utils/util.py::ComputeLoss.assign] PYTORCH ASSIGNMENT DEBUG ---
[utils/util.py::ComputeLoss.assign] pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] true_labels shape: torch.Size([4, 3, 1])
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 3, 4])
[utils/util.py::ComputeLoss.assign] true_mask shape: torch.Size([4, 3, 1])
[utils/util.py::ComputeLoss.assign] anchors shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.assign] Batch size: 4, Max boxes: 3
[utils/util.py::ComputeLoss.assign] Created indices tensor with shape: torch.Size([2, 4, 3])

--- [utils/util.py::ComputeLoss.assign] IOUs DEBUG ---
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 3, 4])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([4, 3, 1, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([4, 1, 512, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([4, 3, 1, 1]), h: torch.Size([4, 3, 1, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([4, 1, 512, 1]), h: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.000000, max: 0.780303
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: -0.928868, max: 0.778784
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.assign] overlaps shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] overlaps min: 0.0, max: 0.7787840962409973
[utils/util.py::ComputeLoss.assign] align_metric shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] align_metric min: 0.0, max: 0.014978737570345402
[utils/util.py::ComputeLoss.assign] mask_in_gts shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] mask_in_gts sum: 63.0
[utils/util.py::ComputeLoss.assign] metrics shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] top_k_mask shape: torch.Size([4, 3, 10])
[utils/util.py::ComputeLoss.assign] top_k_metrics shape: torch.Size([4, 3, 10])
[utils/util.py::ComputeLoss.assign] top_k_indices shape: torch.Size([4, 3, 10])
[utils/util.py::ComputeLoss.assign] is_in_top_k shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] mask_top_k shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] mask_pos shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] fg_mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] fg_mask sum: 50.0
[utils/util.py::ComputeLoss.assign] target_gt_idx shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_labels shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] Normalized target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] target_scores sum: 6.408239841461182
--- [utils/util.py::ComputeLoss.assign] END PYTORCH ASSIGNMENT DEBUG ---

[utils/util.py::ComputeLoss.__call__] Target bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Target scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] FG mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.__call__] Target scores sum: 6.408240
[utils/util.py::ComputeLoss.__call__] Classification loss computed: 6.402889
[utils/util.py::ComputeLoss.__call__] Foreground count: 50
[utils/util.py::ComputeLoss.__call__] Weight shape: torch.Size([50, 1])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([50, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([50, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([50, 1]), h: torch.Size([50, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([50, 1]), h: torch.Size([50, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([50, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([50, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([50, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.171506, max: 0.780228
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([50, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([50, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([50, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([50, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: 0.134952, max: 0.778711
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.__call__] IoU values shape: torch.Size([50, 1])
[utils/util.py::ComputeLoss.__call__] Box loss computed: 0.510292
[utils/util.py::ComputeLoss.__call__] Target LT-RB shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.df_loss] PYTORCH DFL LOSS DEBUG ---
[utils/util.py::ComputeLoss.df_loss] pred_dist shape: torch.Size([200, 16])
[utils/util.py::ComputeLoss.df_loss] target shape: torch.Size([50, 4])
[utils/util.py::ComputeLoss.df_loss] DFL loss shape: torch.Size([50, 1])
[utils/util.py::ComputeLoss.df_loss] DFL loss mean: 1.746066
--- [utils/util.py::ComputeLoss.df_loss] END PYTORCH DFL LOSS DEBUG ---

[utils/util.py::ComputeLoss.__call__] DFL loss before weighting: 1.746066
[utils/util.py::ComputeLoss.__call__] DFL loss computed: 1.677187

--- [utils/util.py::ComputeLoss.__call__] LOSS COMPONENTS DEBUG ---
[utils/util.py::ComputeLoss.__call__] Raw loss_cls: 6.402889
[utils/util.py::ComputeLoss.__call__] Raw loss_box: 0.510292
[utils/util.py::ComputeLoss.__call__] Raw loss_dfl: 1.677187
[utils/util.py::ComputeLoss.__call__] Loss weights - cls: 0.5, box: 7.5, dfl: 1.5
[utils/util.py::ComputeLoss.__call__] target_scores_sum: 6.408240
[utils/util.py::ComputeLoss.__call__] fg_mask sum: 50
[utils/util.py::ComputeLoss.__call__] Weighted loss_cls: 3.201445
[utils/util.py::ComputeLoss.__call__] Weighted loss_box: 3.827192
[utils/util.py::ComputeLoss.__call__] Weighted loss_dfl: 2.515780
[utils/util.py::ComputeLoss.__call__] Total loss: 9.544416
--- [utils/util.py::ComputeLoss.__call__] END PYTORCH LOSS COMPUTATION DEBUG ---


--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([4, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: True
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([4, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - box shape: torch.Size([4, 64, 16, 32]), cls shape: torch.Size([4, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - final concat shape: torch.Size([4, 65, 16, 32])

--- [utils/util.py::ComputeLoss.__call__] PYTORCH LOSS COMPUTATION DEBUG ---
[utils/util.py::ComputeLoss.__call__] Outputs type: <class 'list'>
[utils/util.py::ComputeLoss.__call__] x type: <class 'list'>, len: 1
[utils/util.py::ComputeLoss.__call__] x[0] shape: torch.Size([4, 65, 16, 32])
[utils/util.py::ComputeLoss.__call__] Concatenated output shape: torch.Size([4, 65, 512])
[utils/util.py::ComputeLoss.__call__] self.no: 65, self.dfl_ch: 16, self.nc: 1
[utils/util.py::ComputeLoss.__call__] pred_output shape: torch.Size([4, 64, 512])
[utils/util.py::ComputeLoss.__call__] pred_scores shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.__call__] After permute - pred_output shape: torch.Size([4, 512, 64])
[utils/util.py::ComputeLoss.__call__] After permute - pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Size tensor: tensor([128., 256.], device='cuda:0', dtype=torch.float16)
[utils/util.py::ComputeLoss.__call__] Stride: tensor([8.])
[utils/util.py::ComputeLoss.__call__] Anchor points shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.__call__] Stride tensor shape: torch.Size([512, 1])

--- [utils/util.py::ComputeLoss.__call__] TARGET PROCESSING ---
[utils/util.py::ComputeLoss.__call__] Targets shape: torch.Size([7, 6])
[utils/util.py::ComputeLoss.__call__] Targets dtype: torch.float32
[utils/util.py::ComputeLoss.__call__] First few targets: tensor([[0.0000, 0.0000, 0.2177, 0.2734, 0.0744, 0.1513],
        [0.0000, 0.0000, 0.6788, 0.2189, 0.0577, 0.1173],
        [0.0000, 0.0000, 0.5259, 0.8332, 0.0636, 0.1141],
        [1.0000, 0.0000, 0.2505, 0.0991, 0.1611, 0.1981],
        [2.0000, 0.0000, 0.5911, 0.0571, 0.1265, 0.1143]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Image indices: tensor([0., 0., 0., 1., 2., 3., 3.], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Counts per image: tensor([3, 1, 1, 2], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT tensor shape: torch.Size([4, 3, 5])
[utils/util.py::ComputeLoss.__call__] Image 0: 3 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 1: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 2: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 3: 2 targets assigned
[utils/util.py::ComputeLoss.__call__] GT before coordinate conversion: tensor([[[0.0000, 0.2177, 0.2734, 0.0744, 0.1513],
         [0.0000, 0.6788, 0.2189, 0.0577, 0.1173],
         [0.0000, 0.5259, 0.8332, 0.0636, 0.1141]],

        [[0.0000, 0.2505, 0.0991, 0.1611, 0.1981],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.5911, 0.0571, 0.1265, 0.1143],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.0234, 0.0773, 0.0469, 0.1546],
         [0.0000, 0.1634, 0.9758, 0.0902, 0.0484],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT after coordinate conversion: tensor([[[  0.0000,  46.2047,  25.3051,  65.2483,  44.6739],
         [  0.0000, 166.3894,  20.5131, 181.1564,  35.5292],
         [  0.0000, 126.4893,  99.3410, 142.7649, 113.9489]],

        [[  0.0000,  43.5139,   0.0000,  84.7618,  25.3620],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000, 135.1434,   0.0000, 167.5148,  14.6243],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000,   0.0000,   0.0000,  12.0062,  19.7831],
         [  0.0000,  30.2931, 121.8045,  53.3923, 127.9990],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT labels shape: torch.Size([4, 3, 1])
[utils/util.py::ComputeLoss.__call__] GT bboxes shape: torch.Size([4, 3, 4])
[utils/util.py::ComputeLoss.__call__] GT mask shape: torch.Size([4, 3, 1])
[utils/util.py::ComputeLoss.__call__] Pred output dimensions - b: 4, a: 512, c: 64
[utils/util.py::ComputeLoss.__call__] Pred bboxes after softmax shape: torch.Size([4, 512, 4, 16])
[utils/util.py::ComputeLoss.__call__] Pred bboxes after matmul shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Final pred bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.__call__] ASSIGNMENT PHASE ---

--- [utils/util.py::ComputeLoss.assign] PYTORCH ASSIGNMENT DEBUG ---
[utils/util.py::ComputeLoss.assign] pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] true_labels shape: torch.Size([4, 3, 1])
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 3, 4])
[utils/util.py::ComputeLoss.assign] true_mask shape: torch.Size([4, 3, 1])
[utils/util.py::ComputeLoss.assign] anchors shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.assign] Batch size: 4, Max boxes: 3
[utils/util.py::ComputeLoss.assign] Created indices tensor with shape: torch.Size([2, 4, 3])

--- [utils/util.py::ComputeLoss.assign] IOUs DEBUG ---
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 3, 4])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([4, 3, 1, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([4, 1, 512, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([4, 3, 1, 1]), h: torch.Size([4, 3, 1, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([4, 1, 512, 1]), h: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.000000, max: 0.715059
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: -0.937215, max: 0.714323
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.assign] overlaps shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] overlaps min: 0.0, max: 0.7143227458000183
[utils/util.py::ComputeLoss.assign] align_metric shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] align_metric min: 0.0, max: 0.003409674623981118
[utils/util.py::ComputeLoss.assign] mask_in_gts shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] mask_in_gts sum: 45.0
[utils/util.py::ComputeLoss.assign] metrics shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] top_k_mask shape: torch.Size([4, 3, 10])
[utils/util.py::ComputeLoss.assign] top_k_metrics shape: torch.Size([4, 3, 10])
[utils/util.py::ComputeLoss.assign] top_k_indices shape: torch.Size([4, 3, 10])
[utils/util.py::ComputeLoss.assign] is_in_top_k shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] mask_top_k shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] mask_pos shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] fg_mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] fg_mask sum: 37.0
[utils/util.py::ComputeLoss.assign] target_gt_idx shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_labels shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] Normalized target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] target_scores sum: 3.953946590423584
--- [utils/util.py::ComputeLoss.assign] END PYTORCH ASSIGNMENT DEBUG ---

[utils/util.py::ComputeLoss.__call__] Target bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Target scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] FG mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.__call__] Target scores sum: 3.953947
[utils/util.py::ComputeLoss.__call__] Classification loss computed: 6.781199
[utils/util.py::ComputeLoss.__call__] Foreground count: 37
[utils/util.py::ComputeLoss.__call__] Weight shape: torch.Size([37, 1])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([37, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([37, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([37, 1]), h: torch.Size([37, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([37, 1]), h: torch.Size([37, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([37, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([37, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([37, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.098691, max: 0.715362
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([37, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([37, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([37, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([37, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: 0.054137, max: 0.714625
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.__call__] IoU values shape: torch.Size([37, 1])
[utils/util.py::ComputeLoss.__call__] Box loss computed: 0.605446
[utils/util.py::ComputeLoss.__call__] Target LT-RB shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.df_loss] PYTORCH DFL LOSS DEBUG ---
[utils/util.py::ComputeLoss.df_loss] pred_dist shape: torch.Size([148, 16])
[utils/util.py::ComputeLoss.df_loss] target shape: torch.Size([37, 4])
[utils/util.py::ComputeLoss.df_loss] DFL loss shape: torch.Size([37, 1])
[utils/util.py::ComputeLoss.df_loss] DFL loss mean: 1.770763
--- [utils/util.py::ComputeLoss.df_loss] END PYTORCH DFL LOSS DEBUG ---

[utils/util.py::ComputeLoss.__call__] DFL loss before weighting: 1.770763
[utils/util.py::ComputeLoss.__call__] DFL loss computed: 1.569013

--- [utils/util.py::ComputeLoss.__call__] LOSS COMPONENTS DEBUG ---
[utils/util.py::ComputeLoss.__call__] Raw loss_cls: 6.781199
[utils/util.py::ComputeLoss.__call__] Raw loss_box: 0.605446
[utils/util.py::ComputeLoss.__call__] Raw loss_dfl: 1.569013
[utils/util.py::ComputeLoss.__call__] Loss weights - cls: 0.5, box: 7.5, dfl: 1.5
[utils/util.py::ComputeLoss.__call__] target_scores_sum: 3.953947
[utils/util.py::ComputeLoss.__call__] fg_mask sum: 37
[utils/util.py::ComputeLoss.__call__] Weighted loss_cls: 3.390600
[utils/util.py::ComputeLoss.__call__] Weighted loss_box: 4.540847
[utils/util.py::ComputeLoss.__call__] Weighted loss_dfl: 2.353520
[utils/util.py::ComputeLoss.__call__] Total loss: 10.284967
--- [utils/util.py::ComputeLoss.__call__] END PYTORCH LOSS COMPUTATION DEBUG ---


--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([4, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: True
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([4, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - box shape: torch.Size([4, 64, 16, 32]), cls shape: torch.Size([4, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - final concat shape: torch.Size([4, 65, 16, 32])

--- [utils/util.py::ComputeLoss.__call__] PYTORCH LOSS COMPUTATION DEBUG ---
[utils/util.py::ComputeLoss.__call__] Outputs type: <class 'list'>
[utils/util.py::ComputeLoss.__call__] x type: <class 'list'>, len: 1
[utils/util.py::ComputeLoss.__call__] x[0] shape: torch.Size([4, 65, 16, 32])
[utils/util.py::ComputeLoss.__call__] Concatenated output shape: torch.Size([4, 65, 512])
[utils/util.py::ComputeLoss.__call__] self.no: 65, self.dfl_ch: 16, self.nc: 1
[utils/util.py::ComputeLoss.__call__] pred_output shape: torch.Size([4, 64, 512])
[utils/util.py::ComputeLoss.__call__] pred_scores shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.__call__] After permute - pred_output shape: torch.Size([4, 512, 64])
[utils/util.py::ComputeLoss.__call__] After permute - pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Size tensor: tensor([128., 256.], device='cuda:0', dtype=torch.float16)
[utils/util.py::ComputeLoss.__call__] Stride: tensor([8.])
[utils/util.py::ComputeLoss.__call__] Anchor points shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.__call__] Stride tensor shape: torch.Size([512, 1])

--- [utils/util.py::ComputeLoss.__call__] TARGET PROCESSING ---
[utils/util.py::ComputeLoss.__call__] Targets shape: torch.Size([6, 6])
[utils/util.py::ComputeLoss.__call__] Targets dtype: torch.float32
[utils/util.py::ComputeLoss.__call__] First few targets: tensor([[0.0000, 0.0000, 0.0165, 0.9324, 0.0329, 0.1351],
        [2.0000, 0.0000, 0.9874, 0.2233, 0.0253, 0.1528],
        [2.0000, 0.0000, 0.6011, 0.3089, 0.0719, 0.1528],
        [2.0000, 0.0000, 0.8000, 0.9678, 0.0846, 0.0645],
        [3.0000, 0.0000, 0.1989, 0.0608, 0.0638, 0.1216]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Image indices: tensor([0., 2., 2., 2., 3., 3.], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Counts per image: tensor([1, 3, 2], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT tensor shape: torch.Size([4, 3, 5])
[utils/util.py::ComputeLoss.__call__] Image 0: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 2: 3 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 3: 2 targets assigned
[utils/util.py::ComputeLoss.__call__] GT before coordinate conversion: tensor([[[0.0000, 0.0165, 0.9324, 0.0329, 0.1351],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.9874, 0.2233, 0.0253, 0.1528],
         [0.0000, 0.6011, 0.3089, 0.0719, 0.1528],
         [0.0000, 0.8000, 0.9678, 0.0846, 0.0645]],

        [[0.0000, 0.1989, 0.0608, 0.0638, 0.1216],
         [0.0000, 0.3726, 0.7888, 0.0692, 0.1426],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT after coordinate conversion: tensor([[[0.0000e+00, 9.9945e-04, 1.1070e+02, 8.4224e+00, 1.2800e+02],
         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],

        [[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],

        [[0.0000e+00, 2.4953e+02, 1.8803e+01, 2.5600e+02, 3.8366e+01],
         [0.0000e+00, 1.4468e+02, 2.9758e+01, 1.6307e+02, 4.9321e+01],
         [0.0000e+00, 1.9397e+02, 1.1975e+02, 2.1562e+02, 1.2800e+02]],

        [[0.0000e+00, 4.2754e+01, 0.0000e+00, 5.9078e+01, 1.5570e+01],
         [0.0000e+00, 8.6523e+01, 9.1838e+01, 1.0424e+02, 1.1009e+02],
         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]]],
       device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT labels shape: torch.Size([4, 3, 1])
[utils/util.py::ComputeLoss.__call__] GT bboxes shape: torch.Size([4, 3, 4])
[utils/util.py::ComputeLoss.__call__] GT mask shape: torch.Size([4, 3, 1])
[utils/util.py::ComputeLoss.__call__] Pred output dimensions - b: 4, a: 512, c: 64
[utils/util.py::ComputeLoss.__call__] Pred bboxes after softmax shape: torch.Size([4, 512, 4, 16])
[utils/util.py::ComputeLoss.__call__] Pred bboxes after matmul shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Final pred bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.__call__] ASSIGNMENT PHASE ---

--- [utils/util.py::ComputeLoss.assign] PYTORCH ASSIGNMENT DEBUG ---
[utils/util.py::ComputeLoss.assign] pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] true_labels shape: torch.Size([4, 3, 1])
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 3, 4])
[utils/util.py::ComputeLoss.assign] true_mask shape: torch.Size([4, 3, 1])
[utils/util.py::ComputeLoss.assign] anchors shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.assign] Batch size: 4, Max boxes: 3
[utils/util.py::ComputeLoss.assign] Created indices tensor with shape: torch.Size([2, 4, 3])

--- [utils/util.py::ComputeLoss.assign] IOUs DEBUG ---
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 3, 4])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([4, 3, 1, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([4, 1, 512, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([4, 3, 1, 1]), h: torch.Size([4, 3, 1, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([4, 1, 512, 1]), h: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.000000, max: 0.335711
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: -0.950816, max: 0.328552
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.assign] overlaps shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] overlaps min: 0.0, max: 0.32855165004730225
[utils/util.py::ComputeLoss.assign] align_metric shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] align_metric min: 0.0, max: 7.308679778361693e-05
[utils/util.py::ComputeLoss.assign] mask_in_gts shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] mask_in_gts sum: 22.0
[utils/util.py::ComputeLoss.assign] metrics shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] top_k_mask shape: torch.Size([4, 3, 10])
[utils/util.py::ComputeLoss.assign] top_k_metrics shape: torch.Size([4, 3, 10])
[utils/util.py::ComputeLoss.assign] top_k_indices shape: torch.Size([4, 3, 10])
[utils/util.py::ComputeLoss.assign] is_in_top_k shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] mask_top_k shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] mask_pos shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] fg_mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] fg_mask sum: 22.0
[utils/util.py::ComputeLoss.assign] target_gt_idx shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_labels shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] Normalized target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] target_scores sum: 2.289151191711426
--- [utils/util.py::ComputeLoss.assign] END PYTORCH ASSIGNMENT DEBUG ---

[utils/util.py::ComputeLoss.__call__] Target bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Target scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] FG mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.__call__] Target scores sum: 2.289151
[utils/util.py::ComputeLoss.__call__] Classification loss computed: 6.856390
[utils/util.py::ComputeLoss.__call__] Foreground count: 22
[utils/util.py::ComputeLoss.__call__] Weight shape: torch.Size([22, 1])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([22, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([22, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([22, 1]), h: torch.Size([22, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([22, 1]), h: torch.Size([22, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([22, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([22, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([22, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.093341, max: 0.335776
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([22, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([22, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([22, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([22, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: 0.045605, max: 0.328617
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.__call__] IoU values shape: torch.Size([22, 1])
[utils/util.py::ComputeLoss.__call__] Box loss computed: 0.764946
[utils/util.py::ComputeLoss.__call__] Target LT-RB shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.df_loss] PYTORCH DFL LOSS DEBUG ---
[utils/util.py::ComputeLoss.df_loss] pred_dist shape: torch.Size([88, 16])
[utils/util.py::ComputeLoss.df_loss] target shape: torch.Size([22, 4])
[utils/util.py::ComputeLoss.df_loss] DFL loss shape: torch.Size([22, 1])
[utils/util.py::ComputeLoss.df_loss] DFL loss mean: 1.571610
--- [utils/util.py::ComputeLoss.df_loss] END PYTORCH DFL LOSS DEBUG ---

[utils/util.py::ComputeLoss.__call__] DFL loss before weighting: 1.571610
[utils/util.py::ComputeLoss.__call__] DFL loss computed: 1.349916

--- [utils/util.py::ComputeLoss.__call__] LOSS COMPONENTS DEBUG ---
[utils/util.py::ComputeLoss.__call__] Raw loss_cls: 6.856390
[utils/util.py::ComputeLoss.__call__] Raw loss_box: 0.764946
[utils/util.py::ComputeLoss.__call__] Raw loss_dfl: 1.349916
[utils/util.py::ComputeLoss.__call__] Loss weights - cls: 0.5, box: 7.5, dfl: 1.5
[utils/util.py::ComputeLoss.__call__] target_scores_sum: 2.289151
[utils/util.py::ComputeLoss.__call__] fg_mask sum: 22
[utils/util.py::ComputeLoss.__call__] Weighted loss_cls: 3.428195
[utils/util.py::ComputeLoss.__call__] Weighted loss_box: 5.737091
[utils/util.py::ComputeLoss.__call__] Weighted loss_dfl: 2.024875
[utils/util.py::ComputeLoss.__call__] Total loss: 11.190161
--- [utils/util.py::ComputeLoss.__call__] END PYTORCH LOSS COMPUTATION DEBUG ---


--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([4, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: True
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([4, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - box shape: torch.Size([4, 64, 16, 32]), cls shape: torch.Size([4, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - final concat shape: torch.Size([4, 65, 16, 32])

--- [utils/util.py::ComputeLoss.__call__] PYTORCH LOSS COMPUTATION DEBUG ---
[utils/util.py::ComputeLoss.__call__] Outputs type: <class 'list'>
[utils/util.py::ComputeLoss.__call__] x type: <class 'list'>, len: 1
[utils/util.py::ComputeLoss.__call__] x[0] shape: torch.Size([4, 65, 16, 32])
[utils/util.py::ComputeLoss.__call__] Concatenated output shape: torch.Size([4, 65, 512])
[utils/util.py::ComputeLoss.__call__] self.no: 65, self.dfl_ch: 16, self.nc: 1
[utils/util.py::ComputeLoss.__call__] pred_output shape: torch.Size([4, 64, 512])
[utils/util.py::ComputeLoss.__call__] pred_scores shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.__call__] After permute - pred_output shape: torch.Size([4, 512, 64])
[utils/util.py::ComputeLoss.__call__] After permute - pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Size tensor: tensor([128., 256.], device='cuda:0', dtype=torch.float16)
[utils/util.py::ComputeLoss.__call__] Stride: tensor([8.])
[utils/util.py::ComputeLoss.__call__] Anchor points shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.__call__] Stride tensor shape: torch.Size([512, 1])

--- [utils/util.py::ComputeLoss.__call__] TARGET PROCESSING ---
[utils/util.py::ComputeLoss.__call__] Targets shape: torch.Size([3, 6])
[utils/util.py::ComputeLoss.__call__] Targets dtype: torch.float32
[utils/util.py::ComputeLoss.__call__] First few targets: tensor([[0.0000, 0.0000, 0.4868, 0.9760, 0.1327, 0.0479],
        [2.0000, 0.0000, 0.9619, 0.0723, 0.0761, 0.1447],
        [3.0000, 0.0000, 0.7271, 0.9734, 0.1512, 0.0533]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Image indices: tensor([0., 2., 3.], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Counts per image: tensor([1, 1, 1], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT tensor shape: torch.Size([4, 1, 5])
[utils/util.py::ComputeLoss.__call__] Image 0: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 2: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 3: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] GT before coordinate conversion: tensor([[[0.0000, 0.4868, 0.9760, 0.1327, 0.0479]],

        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.9619, 0.0723, 0.0761, 0.1447]],

        [[0.0000, 0.7271, 0.9734, 0.1512, 0.0533]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT after coordinate conversion: tensor([[[  0.0000, 107.6322, 121.8695, 141.6114, 127.9990]],

        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000, 236.5069,   0.0000, 255.9990,  18.5191]],

        [[  0.0000, 166.7774, 121.1799, 205.4816, 127.9990]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT labels shape: torch.Size([4, 1, 1])
[utils/util.py::ComputeLoss.__call__] GT bboxes shape: torch.Size([4, 1, 4])
[utils/util.py::ComputeLoss.__call__] GT mask shape: torch.Size([4, 1, 1])
[utils/util.py::ComputeLoss.__call__] Pred output dimensions - b: 4, a: 512, c: 64
[utils/util.py::ComputeLoss.__call__] Pred bboxes after softmax shape: torch.Size([4, 512, 4, 16])
[utils/util.py::ComputeLoss.__call__] Pred bboxes after matmul shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Final pred bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.__call__] ASSIGNMENT PHASE ---

--- [utils/util.py::ComputeLoss.assign] PYTORCH ASSIGNMENT DEBUG ---
[utils/util.py::ComputeLoss.assign] pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] true_labels shape: torch.Size([4, 1, 1])
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 1, 4])
[utils/util.py::ComputeLoss.assign] true_mask shape: torch.Size([4, 1, 1])
[utils/util.py::ComputeLoss.assign] anchors shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.assign] Batch size: 4, Max boxes: 1
[utils/util.py::ComputeLoss.assign] Created indices tensor with shape: torch.Size([2, 4, 1])

--- [utils/util.py::ComputeLoss.assign] IOUs DEBUG ---
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 1, 4])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([4, 1, 1, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([4, 1, 512, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([4, 1, 1, 1]), h: torch.Size([4, 1, 1, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([4, 1, 512, 1]), h: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.000000, max: 0.447073
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: -0.951148, max: 0.423322
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.assign] overlaps shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.assign] overlaps min: 0.0, max: 0.4233216643333435
[utils/util.py::ComputeLoss.assign] align_metric shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.assign] align_metric min: 0.0, max: 0.00024867738829925656
[utils/util.py::ComputeLoss.assign] mask_in_gts shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.assign] mask_in_gts sum: 14.0
[utils/util.py::ComputeLoss.assign] metrics shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.assign] top_k_mask shape: torch.Size([4, 1, 10])
[utils/util.py::ComputeLoss.assign] top_k_metrics shape: torch.Size([4, 1, 10])
[utils/util.py::ComputeLoss.assign] top_k_indices shape: torch.Size([4, 1, 10])
[utils/util.py::ComputeLoss.assign] is_in_top_k shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.assign] mask_top_k shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.assign] mask_pos shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.assign] fg_mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] fg_mask sum: 14.0
[utils/util.py::ComputeLoss.assign] target_gt_idx shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_labels shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] Normalized target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] target_scores sum: 1.306746244430542
--- [utils/util.py::ComputeLoss.assign] END PYTORCH ASSIGNMENT DEBUG ---

[utils/util.py::ComputeLoss.__call__] Target bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Target scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] FG mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.__call__] Target scores sum: 1.306746
[utils/util.py::ComputeLoss.__call__] Classification loss computed: 6.935164
[utils/util.py::ComputeLoss.__call__] Foreground count: 14
[utils/util.py::ComputeLoss.__call__] Weight shape: torch.Size([14, 1])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([14, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([14, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([14, 1]), h: torch.Size([14, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([14, 1]), h: torch.Size([14, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([14, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([14, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([14, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.102185, max: 0.447307
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([14, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([14, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([14, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([14, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: 0.000320, max: 0.423555
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.__call__] IoU values shape: torch.Size([14, 1])
[utils/util.py::ComputeLoss.__call__] Box loss computed: 0.674069
[utils/util.py::ComputeLoss.__call__] Target LT-RB shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.df_loss] PYTORCH DFL LOSS DEBUG ---
[utils/util.py::ComputeLoss.df_loss] pred_dist shape: torch.Size([56, 16])
[utils/util.py::ComputeLoss.df_loss] target shape: torch.Size([14, 4])
[utils/util.py::ComputeLoss.df_loss] DFL loss shape: torch.Size([14, 1])
[utils/util.py::ComputeLoss.df_loss] DFL loss mean: 2.123896
--- [utils/util.py::ComputeLoss.df_loss] END PYTORCH DFL LOSS DEBUG ---

[utils/util.py::ComputeLoss.__call__] DFL loss before weighting: 2.123896
[utils/util.py::ComputeLoss.__call__] DFL loss computed: 1.644116

--- [utils/util.py::ComputeLoss.__call__] LOSS COMPONENTS DEBUG ---
[utils/util.py::ComputeLoss.__call__] Raw loss_cls: 6.935164
[utils/util.py::ComputeLoss.__call__] Raw loss_box: 0.674069
[utils/util.py::ComputeLoss.__call__] Raw loss_dfl: 1.644116
[utils/util.py::ComputeLoss.__call__] Loss weights - cls: 0.5, box: 7.5, dfl: 1.5
[utils/util.py::ComputeLoss.__call__] target_scores_sum: 1.306746
[utils/util.py::ComputeLoss.__call__] fg_mask sum: 14
[utils/util.py::ComputeLoss.__call__] Weighted loss_cls: 3.467582
[utils/util.py::ComputeLoss.__call__] Weighted loss_box: 5.055515
[utils/util.py::ComputeLoss.__call__] Weighted loss_dfl: 2.466175
[utils/util.py::ComputeLoss.__call__] Total loss: 10.989271
--- [utils/util.py::ComputeLoss.__call__] END PYTORCH LOSS COMPUTATION DEBUG ---


--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([4, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: True
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([4, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - box shape: torch.Size([4, 64, 16, 32]), cls shape: torch.Size([4, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - final concat shape: torch.Size([4, 65, 16, 32])

--- [utils/util.py::ComputeLoss.__call__] PYTORCH LOSS COMPUTATION DEBUG ---
[utils/util.py::ComputeLoss.__call__] Outputs type: <class 'list'>
[utils/util.py::ComputeLoss.__call__] x type: <class 'list'>, len: 1
[utils/util.py::ComputeLoss.__call__] x[0] shape: torch.Size([4, 65, 16, 32])
[utils/util.py::ComputeLoss.__call__] Concatenated output shape: torch.Size([4, 65, 512])
[utils/util.py::ComputeLoss.__call__] self.no: 65, self.dfl_ch: 16, self.nc: 1
[utils/util.py::ComputeLoss.__call__] pred_output shape: torch.Size([4, 64, 512])
[utils/util.py::ComputeLoss.__call__] pred_scores shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.__call__] After permute - pred_output shape: torch.Size([4, 512, 64])
[utils/util.py::ComputeLoss.__call__] After permute - pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Size tensor: tensor([128., 256.], device='cuda:0', dtype=torch.float16)
[utils/util.py::ComputeLoss.__call__] Stride: tensor([8.])
[utils/util.py::ComputeLoss.__call__] Anchor points shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.__call__] Stride tensor shape: torch.Size([512, 1])

--- [utils/util.py::ComputeLoss.__call__] TARGET PROCESSING ---
[utils/util.py::ComputeLoss.__call__] Targets shape: torch.Size([7, 6])
[utils/util.py::ComputeLoss.__call__] Targets dtype: torch.float32
[utils/util.py::ComputeLoss.__call__] First few targets: tensor([[0.0000, 0.0000, 0.8863, 0.6394, 0.1176, 0.2371],
        [1.0000, 0.0000, 0.5353, 0.3025, 0.0749, 0.1456],
        [2.0000, 0.0000, 0.7607, 0.2090, 0.0459, 0.1036],
        [2.0000, 0.0000, 0.3161, 0.3126, 0.0624, 0.1217],
        [2.0000, 0.0000, 0.7236, 0.9145, 0.0466, 0.0943]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Image indices: tensor([0., 1., 2., 2., 2., 2., 3.], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Counts per image: tensor([1, 1, 4, 1], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT tensor shape: torch.Size([4, 4, 5])
[utils/util.py::ComputeLoss.__call__] Image 0: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 1: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 2: 4 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 3: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] GT before coordinate conversion: tensor([[[0.0000, 0.8863, 0.6394, 0.1176, 0.2371],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.5353, 0.3025, 0.0749, 0.1456],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.7607, 0.2090, 0.0459, 0.1036],
         [0.0000, 0.3161, 0.3126, 0.0624, 0.1217],
         [0.0000, 0.7236, 0.9145, 0.0466, 0.0943],
         [0.0000, 0.5095, 0.7880, 0.0483, 0.0991]],

        [[0.0000, 0.4318, 0.6473, 0.0909, 0.1828],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT after coordinate conversion: tensor([[[  0.0000, 211.8551,  66.6702, 241.9513,  97.0210],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000, 127.4636,  29.3939, 146.6346,  48.0367],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000, 188.8575,  20.1201, 200.6122,  33.3859],
         [  0.0000,  72.9284,  32.2324,  88.9109,  47.8053],
         [  0.0000, 179.2773, 111.0257, 191.2165, 123.0919],
         [  0.0000, 124.2557,  94.5242, 136.6275, 107.2132]],

        [[  0.0000,  98.8931,  71.1582, 122.1675,  94.5538],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT labels shape: torch.Size([4, 4, 1])
[utils/util.py::ComputeLoss.__call__] GT bboxes shape: torch.Size([4, 4, 4])
[utils/util.py::ComputeLoss.__call__] GT mask shape: torch.Size([4, 4, 1])
[utils/util.py::ComputeLoss.__call__] Pred output dimensions - b: 4, a: 512, c: 64
[utils/util.py::ComputeLoss.__call__] Pred bboxes after softmax shape: torch.Size([4, 512, 4, 16])
[utils/util.py::ComputeLoss.__call__] Pred bboxes after matmul shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Final pred bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.__call__] ASSIGNMENT PHASE ---

--- [utils/util.py::ComputeLoss.assign] PYTORCH ASSIGNMENT DEBUG ---
[utils/util.py::ComputeLoss.assign] pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] true_labels shape: torch.Size([4, 4, 1])
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 4, 4])
[utils/util.py::ComputeLoss.assign] true_mask shape: torch.Size([4, 4, 1])
[utils/util.py::ComputeLoss.assign] anchors shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.assign] Batch size: 4, Max boxes: 4
[utils/util.py::ComputeLoss.assign] Created indices tensor with shape: torch.Size([2, 4, 4])

--- [utils/util.py::ComputeLoss.assign] IOUs DEBUG ---
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 4, 4])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([4, 4, 1, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([4, 1, 512, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([4, 4, 1, 1]), h: torch.Size([4, 4, 1, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([4, 1, 512, 1]), h: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([4, 4, 512, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([4, 4, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([4, 4, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.000000, max: 0.756058
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([4, 4, 512, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([4, 4, 512, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([4, 4, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([4, 4, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: -0.942260, max: 0.749138
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.assign] overlaps shape: torch.Size([4, 4, 512])
[utils/util.py::ComputeLoss.assign] overlaps min: 0.0, max: 0.7491379380226135
[utils/util.py::ComputeLoss.assign] align_metric shape: torch.Size([4, 4, 512])
[utils/util.py::ComputeLoss.assign] align_metric min: 0.0, max: 0.012600670568645
[utils/util.py::ComputeLoss.assign] mask_in_gts shape: torch.Size([4, 4, 512])
[utils/util.py::ComputeLoss.assign] mask_in_gts sum: 37.0
[utils/util.py::ComputeLoss.assign] metrics shape: torch.Size([4, 4, 512])
[utils/util.py::ComputeLoss.assign] top_k_mask shape: torch.Size([4, 4, 10])
[utils/util.py::ComputeLoss.assign] top_k_metrics shape: torch.Size([4, 4, 10])
[utils/util.py::ComputeLoss.assign] top_k_indices shape: torch.Size([4, 4, 10])
[utils/util.py::ComputeLoss.assign] is_in_top_k shape: torch.Size([4, 4, 512])
[utils/util.py::ComputeLoss.assign] mask_top_k shape: torch.Size([4, 4, 512])
[utils/util.py::ComputeLoss.assign] mask_pos shape: torch.Size([4, 4, 512])
[utils/util.py::ComputeLoss.assign] fg_mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] fg_mask sum: 31.0
[utils/util.py::ComputeLoss.assign] target_gt_idx shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_labels shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] Normalized target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] target_scores sum: 4.320817947387695
--- [utils/util.py::ComputeLoss.assign] END PYTORCH ASSIGNMENT DEBUG ---

[utils/util.py::ComputeLoss.__call__] Target bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Target scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] FG mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.__call__] Target scores sum: 4.320818
[utils/util.py::ComputeLoss.__call__] Classification loss computed: 6.259665
[utils/util.py::ComputeLoss.__call__] Foreground count: 31
[utils/util.py::ComputeLoss.__call__] Weight shape: torch.Size([31, 1])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([31, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([31, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([31, 1]), h: torch.Size([31, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([31, 1]), h: torch.Size([31, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([31, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([31, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([31, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.132045, max: 0.755905
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([31, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([31, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([31, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([31, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: 0.104771, max: 0.748985
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.__call__] IoU values shape: torch.Size([31, 1])
[utils/util.py::ComputeLoss.__call__] Box loss computed: 0.523217
[utils/util.py::ComputeLoss.__call__] Target LT-RB shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.df_loss] PYTORCH DFL LOSS DEBUG ---
[utils/util.py::ComputeLoss.df_loss] pred_dist shape: torch.Size([124, 16])
[utils/util.py::ComputeLoss.df_loss] target shape: torch.Size([31, 4])
[utils/util.py::ComputeLoss.df_loss] DFL loss shape: torch.Size([31, 1])
[utils/util.py::ComputeLoss.df_loss] DFL loss mean: 1.561809
--- [utils/util.py::ComputeLoss.df_loss] END PYTORCH DFL LOSS DEBUG ---

[utils/util.py::ComputeLoss.__call__] DFL loss before weighting: 1.561809
[utils/util.py::ComputeLoss.__call__] DFL loss computed: 1.300629

--- [utils/util.py::ComputeLoss.__call__] LOSS COMPONENTS DEBUG ---
[utils/util.py::ComputeLoss.__call__] Raw loss_cls: 6.259665
[utils/util.py::ComputeLoss.__call__] Raw loss_box: 0.523217
[utils/util.py::ComputeLoss.__call__] Raw loss_dfl: 1.300629
[utils/util.py::ComputeLoss.__call__] Loss weights - cls: 0.5, box: 7.5, dfl: 1.5
[utils/util.py::ComputeLoss.__call__] target_scores_sum: 4.320818
[utils/util.py::ComputeLoss.__call__] fg_mask sum: 31
[utils/util.py::ComputeLoss.__call__] Weighted loss_cls: 3.129833
[utils/util.py::ComputeLoss.__call__] Weighted loss_box: 3.924125
[utils/util.py::ComputeLoss.__call__] Weighted loss_dfl: 1.950944
[utils/util.py::ComputeLoss.__call__] Total loss: 9.004902
--- [utils/util.py::ComputeLoss.__call__] END PYTORCH LOSS COMPUTATION DEBUG ---


--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([4, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: True
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([4, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - box shape: torch.Size([4, 64, 16, 32]), cls shape: torch.Size([4, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - final concat shape: torch.Size([4, 65, 16, 32])

--- [utils/util.py::ComputeLoss.__call__] PYTORCH LOSS COMPUTATION DEBUG ---
[utils/util.py::ComputeLoss.__call__] Outputs type: <class 'list'>
[utils/util.py::ComputeLoss.__call__] x type: <class 'list'>, len: 1
[utils/util.py::ComputeLoss.__call__] x[0] shape: torch.Size([4, 65, 16, 32])
[utils/util.py::ComputeLoss.__call__] Concatenated output shape: torch.Size([4, 65, 512])
[utils/util.py::ComputeLoss.__call__] self.no: 65, self.dfl_ch: 16, self.nc: 1
[utils/util.py::ComputeLoss.__call__] pred_output shape: torch.Size([4, 64, 512])
[utils/util.py::ComputeLoss.__call__] pred_scores shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.__call__] After permute - pred_output shape: torch.Size([4, 512, 64])
[utils/util.py::ComputeLoss.__call__] After permute - pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Size tensor: tensor([128., 256.], device='cuda:0', dtype=torch.float16)
[utils/util.py::ComputeLoss.__call__] Stride: tensor([8.])
[utils/util.py::ComputeLoss.__call__] Anchor points shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.__call__] Stride tensor shape: torch.Size([512, 1])

--- [utils/util.py::ComputeLoss.__call__] TARGET PROCESSING ---
[utils/util.py::ComputeLoss.__call__] Targets shape: torch.Size([4, 6])
[utils/util.py::ComputeLoss.__call__] Targets dtype: torch.float32
[utils/util.py::ComputeLoss.__call__] First few targets: tensor([[0.0000, 0.0000, 0.7140, 0.8883, 0.1162, 0.2234],
        [1.0000, 0.0000, 0.9129, 0.6564, 0.0671, 0.1195],
        [1.0000, 0.0000, 0.0284, 0.6165, 0.0568, 0.1546],
        [2.0000, 0.0000, 0.0204, 0.8555, 0.0409, 0.1551]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Image indices: tensor([0., 1., 1., 2.], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Counts per image: tensor([1, 2, 1], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT tensor shape: torch.Size([4, 2, 5])
[utils/util.py::ComputeLoss.__call__] Image 0: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 1: 2 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 2: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] GT before coordinate conversion: tensor([[[0.0000, 0.7140, 0.8883, 0.1162, 0.2234],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.9129, 0.6564, 0.0671, 0.1195],
         [0.0000, 0.0284, 0.6165, 0.0568, 0.1546]],

        [[0.0000, 0.0204, 0.8555, 0.0409, 0.1551],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT after coordinate conversion: tensor([[[0.0000e+00, 1.6790e+02, 9.9408e+01, 1.9765e+02, 1.2800e+02],
         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],

        [[0.0000e+00, 2.2511e+02, 7.6377e+01, 2.4228e+02, 9.1668e+01],
         [0.0000e+00, 1.0071e-03, 6.9011e+01, 1.4532e+01, 8.8803e+01]],

        [[0.0000e+00, 1.0071e-03, 9.9575e+01, 1.0467e+01, 1.1943e+02],
         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],

        [[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]]],
       device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT labels shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.__call__] GT bboxes shape: torch.Size([4, 2, 4])
[utils/util.py::ComputeLoss.__call__] GT mask shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.__call__] Pred output dimensions - b: 4, a: 512, c: 64
[utils/util.py::ComputeLoss.__call__] Pred bboxes after softmax shape: torch.Size([4, 512, 4, 16])
[utils/util.py::ComputeLoss.__call__] Pred bboxes after matmul shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Final pred bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.__call__] ASSIGNMENT PHASE ---

--- [utils/util.py::ComputeLoss.assign] PYTORCH ASSIGNMENT DEBUG ---
[utils/util.py::ComputeLoss.assign] pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] true_labels shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 2, 4])
[utils/util.py::ComputeLoss.assign] true_mask shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.assign] anchors shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.assign] Batch size: 4, Max boxes: 2
[utils/util.py::ComputeLoss.assign] Created indices tensor with shape: torch.Size([2, 4, 2])

--- [utils/util.py::ComputeLoss.assign] IOUs DEBUG ---
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 2, 4])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([4, 2, 1, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([4, 1, 512, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([4, 2, 1, 1]), h: torch.Size([4, 2, 1, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([4, 1, 512, 1]), h: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.000000, max: 0.643784
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: -1.005912, max: 0.633028
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.assign] overlaps shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] overlaps min: 0.0, max: 0.6330280900001526
[utils/util.py::ComputeLoss.assign] align_metric shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] align_metric min: 0.0, max: 0.0036172422114759684
[utils/util.py::ComputeLoss.assign] mask_in_gts shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] mask_in_gts sum: 25.0
[utils/util.py::ComputeLoss.assign] metrics shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] top_k_mask shape: torch.Size([4, 2, 10])
[utils/util.py::ComputeLoss.assign] top_k_metrics shape: torch.Size([4, 2, 10])
[utils/util.py::ComputeLoss.assign] top_k_indices shape: torch.Size([4, 2, 10])
[utils/util.py::ComputeLoss.assign] is_in_top_k shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] mask_top_k shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] mask_pos shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] fg_mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] fg_mask sum: 19.0
[utils/util.py::ComputeLoss.assign] target_gt_idx shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_labels shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] Normalized target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] target_scores sum: 3.0578606128692627
--- [utils/util.py::ComputeLoss.assign] END PYTORCH ASSIGNMENT DEBUG ---

[utils/util.py::ComputeLoss.__call__] Target bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Target scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] FG mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.__call__] Target scores sum: 3.057861
[utils/util.py::ComputeLoss.__call__] Classification loss computed: 6.152177
[utils/util.py::ComputeLoss.__call__] Foreground count: 19
[utils/util.py::ComputeLoss.__call__] Weight shape: torch.Size([19, 1])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([19, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([19, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([19, 1]), h: torch.Size([19, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([19, 1]), h: torch.Size([19, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([19, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([19, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([19, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.145380, max: 0.643910
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([19, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([19, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([19, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([19, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: 0.098609, max: 0.633155
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.__call__] IoU values shape: torch.Size([19, 1])
[utils/util.py::ComputeLoss.__call__] Box loss computed: 0.521998
[utils/util.py::ComputeLoss.__call__] Target LT-RB shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.df_loss] PYTORCH DFL LOSS DEBUG ---
[utils/util.py::ComputeLoss.df_loss] pred_dist shape: torch.Size([76, 16])
[utils/util.py::ComputeLoss.df_loss] target shape: torch.Size([19, 4])
[utils/util.py::ComputeLoss.df_loss] DFL loss shape: torch.Size([19, 1])
[utils/util.py::ComputeLoss.df_loss] DFL loss mean: 1.732746
--- [utils/util.py::ComputeLoss.df_loss] END PYTORCH DFL LOSS DEBUG ---

[utils/util.py::ComputeLoss.__call__] DFL loss before weighting: 1.732746
[utils/util.py::ComputeLoss.__call__] DFL loss computed: 1.431363

--- [utils/util.py::ComputeLoss.__call__] LOSS COMPONENTS DEBUG ---
[utils/util.py::ComputeLoss.__call__] Raw loss_cls: 6.152177
[utils/util.py::ComputeLoss.__call__] Raw loss_box: 0.521998
[utils/util.py::ComputeLoss.__call__] Raw loss_dfl: 1.431363
[utils/util.py::ComputeLoss.__call__] Loss weights - cls: 0.5, box: 7.5, dfl: 1.5
[utils/util.py::ComputeLoss.__call__] target_scores_sum: 3.057861
[utils/util.py::ComputeLoss.__call__] fg_mask sum: 19
[utils/util.py::ComputeLoss.__call__] Weighted loss_cls: 3.076088
[utils/util.py::ComputeLoss.__call__] Weighted loss_box: 3.914989
[utils/util.py::ComputeLoss.__call__] Weighted loss_dfl: 2.147044
[utils/util.py::ComputeLoss.__call__] Total loss: 9.138121
--- [utils/util.py::ComputeLoss.__call__] END PYTORCH LOSS COMPUTATION DEBUG ---


--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([4, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: True
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([4, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - box shape: torch.Size([4, 64, 16, 32]), cls shape: torch.Size([4, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - final concat shape: torch.Size([4, 65, 16, 32])

--- [utils/util.py::ComputeLoss.__call__] PYTORCH LOSS COMPUTATION DEBUG ---
[utils/util.py::ComputeLoss.__call__] Outputs type: <class 'list'>
[utils/util.py::ComputeLoss.__call__] x type: <class 'list'>, len: 1
[utils/util.py::ComputeLoss.__call__] x[0] shape: torch.Size([4, 65, 16, 32])
[utils/util.py::ComputeLoss.__call__] Concatenated output shape: torch.Size([4, 65, 512])
[utils/util.py::ComputeLoss.__call__] self.no: 65, self.dfl_ch: 16, self.nc: 1
[utils/util.py::ComputeLoss.__call__] pred_output shape: torch.Size([4, 64, 512])
[utils/util.py::ComputeLoss.__call__] pred_scores shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.__call__] After permute - pred_output shape: torch.Size([4, 512, 64])
[utils/util.py::ComputeLoss.__call__] After permute - pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Size tensor: tensor([128., 256.], device='cuda:0', dtype=torch.float16)
[utils/util.py::ComputeLoss.__call__] Stride: tensor([8.])
[utils/util.py::ComputeLoss.__call__] Anchor points shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.__call__] Stride tensor shape: torch.Size([512, 1])

--- [utils/util.py::ComputeLoss.__call__] TARGET PROCESSING ---
[utils/util.py::ComputeLoss.__call__] Targets shape: torch.Size([4, 6])
[utils/util.py::ComputeLoss.__call__] Targets dtype: torch.float32
[utils/util.py::ComputeLoss.__call__] First few targets: tensor([[0.0000, 0.0000, 0.9707, 0.5322, 0.0587, 0.2002],
        [2.0000, 0.0000, 0.2064, 0.9811, 0.1236, 0.0378],
        [3.0000, 0.0000, 0.2349, 0.2997, 0.0573, 0.1036],
        [3.0000, 0.0000, 0.1644, 0.9581, 0.0635, 0.0837]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Image indices: tensor([0., 2., 3., 3.], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Counts per image: tensor([1, 1, 2], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT tensor shape: torch.Size([4, 2, 5])
[utils/util.py::ComputeLoss.__call__] Image 0: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 2: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 3: 2 targets assigned
[utils/util.py::ComputeLoss.__call__] GT before coordinate conversion: tensor([[[0.0000, 0.9707, 0.5322, 0.0587, 0.2002],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.2064, 0.9811, 0.1236, 0.0378],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.2349, 0.2997, 0.0573, 0.1036],
         [0.0000, 0.1644, 0.9581, 0.0635, 0.0837]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT after coordinate conversion: tensor([[[  0.0000, 240.9759,  55.3107, 255.9990,  80.9364],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000,  37.0164, 123.1608,  68.6519, 127.9990],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000,  52.7893,  31.7308,  67.4599,  44.9855],
         [  0.0000,  33.9646, 117.2839,  50.2197, 127.9990]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT labels shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.__call__] GT bboxes shape: torch.Size([4, 2, 4])
[utils/util.py::ComputeLoss.__call__] GT mask shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.__call__] Pred output dimensions - b: 4, a: 512, c: 64
[utils/util.py::ComputeLoss.__call__] Pred bboxes after softmax shape: torch.Size([4, 512, 4, 16])
[utils/util.py::ComputeLoss.__call__] Pred bboxes after matmul shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Final pred bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.__call__] ASSIGNMENT PHASE ---

--- [utils/util.py::ComputeLoss.assign] PYTORCH ASSIGNMENT DEBUG ---
[utils/util.py::ComputeLoss.assign] pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] true_labels shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 2, 4])
[utils/util.py::ComputeLoss.assign] true_mask shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.assign] anchors shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.assign] Batch size: 4, Max boxes: 2
[utils/util.py::ComputeLoss.assign] Created indices tensor with shape: torch.Size([2, 4, 2])

--- [utils/util.py::ComputeLoss.assign] IOUs DEBUG ---
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 2, 4])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([4, 2, 1, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([4, 1, 512, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([4, 2, 1, 1]), h: torch.Size([4, 2, 1, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([4, 1, 512, 1]), h: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.000000, max: 0.458829
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: -0.960956, max: 0.430476
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.assign] overlaps shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] overlaps min: 0.0, max: 0.43047621846199036
[utils/util.py::ComputeLoss.assign] align_metric shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] align_metric min: 0.0, max: 0.0005433663609437644
[utils/util.py::ComputeLoss.assign] mask_in_gts shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] mask_in_gts sum: 14.0
[utils/util.py::ComputeLoss.assign] metrics shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] top_k_mask shape: torch.Size([4, 2, 10])
[utils/util.py::ComputeLoss.assign] top_k_metrics shape: torch.Size([4, 2, 10])
[utils/util.py::ComputeLoss.assign] top_k_indices shape: torch.Size([4, 2, 10])
[utils/util.py::ComputeLoss.assign] is_in_top_k shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] mask_top_k shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] mask_pos shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] fg_mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] fg_mask sum: 14.0
[utils/util.py::ComputeLoss.assign] target_gt_idx shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_labels shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] Normalized target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] target_scores sum: 1.1409374475479126
--- [utils/util.py::ComputeLoss.assign] END PYTORCH ASSIGNMENT DEBUG ---

[utils/util.py::ComputeLoss.__call__] Target bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Target scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] FG mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.__call__] Target scores sum: 1.140937
[utils/util.py::ComputeLoss.__call__] Classification loss computed: 6.854287
[utils/util.py::ComputeLoss.__call__] Foreground count: 14
[utils/util.py::ComputeLoss.__call__] Weight shape: torch.Size([14, 1])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([14, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([14, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([14, 1]), h: torch.Size([14, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([14, 1]), h: torch.Size([14, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([14, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([14, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([14, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.083879, max: 0.458706
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([14, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([14, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([14, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([14, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: 0.010170, max: 0.430353
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.__call__] IoU values shape: torch.Size([14, 1])
[utils/util.py::ComputeLoss.__call__] Box loss computed: 0.721899
[utils/util.py::ComputeLoss.__call__] Target LT-RB shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.df_loss] PYTORCH DFL LOSS DEBUG ---
[utils/util.py::ComputeLoss.df_loss] pred_dist shape: torch.Size([56, 16])
[utils/util.py::ComputeLoss.df_loss] target shape: torch.Size([14, 4])
[utils/util.py::ComputeLoss.df_loss] DFL loss shape: torch.Size([14, 1])
[utils/util.py::ComputeLoss.df_loss] DFL loss mean: 1.783001
--- [utils/util.py::ComputeLoss.df_loss] END PYTORCH DFL LOSS DEBUG ---

[utils/util.py::ComputeLoss.__call__] DFL loss before weighting: 1.783001
[utils/util.py::ComputeLoss.__call__] DFL loss computed: 1.427885

--- [utils/util.py::ComputeLoss.__call__] LOSS COMPONENTS DEBUG ---
[utils/util.py::ComputeLoss.__call__] Raw loss_cls: 6.854287
[utils/util.py::ComputeLoss.__call__] Raw loss_box: 0.721899
[utils/util.py::ComputeLoss.__call__] Raw loss_dfl: 1.427885
[utils/util.py::ComputeLoss.__call__] Loss weights - cls: 0.5, box: 7.5, dfl: 1.5
[utils/util.py::ComputeLoss.__call__] target_scores_sum: 1.140937
[utils/util.py::ComputeLoss.__call__] fg_mask sum: 14
[utils/util.py::ComputeLoss.__call__] Weighted loss_cls: 3.427143
[utils/util.py::ComputeLoss.__call__] Weighted loss_box: 5.414245
[utils/util.py::ComputeLoss.__call__] Weighted loss_dfl: 2.141828
[utils/util.py::ComputeLoss.__call__] Total loss: 10.983215
--- [utils/util.py::ComputeLoss.__call__] END PYTORCH LOSS COMPUTATION DEBUG ---


--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([4, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: True
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([4, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - box shape: torch.Size([4, 64, 16, 32]), cls shape: torch.Size([4, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - final concat shape: torch.Size([4, 65, 16, 32])

--- [utils/util.py::ComputeLoss.__call__] PYTORCH LOSS COMPUTATION DEBUG ---
[utils/util.py::ComputeLoss.__call__] Outputs type: <class 'list'>
[utils/util.py::ComputeLoss.__call__] x type: <class 'list'>, len: 1
[utils/util.py::ComputeLoss.__call__] x[0] shape: torch.Size([4, 65, 16, 32])
[utils/util.py::ComputeLoss.__call__] Concatenated output shape: torch.Size([4, 65, 512])
[utils/util.py::ComputeLoss.__call__] self.no: 65, self.dfl_ch: 16, self.nc: 1
[utils/util.py::ComputeLoss.__call__] pred_output shape: torch.Size([4, 64, 512])
[utils/util.py::ComputeLoss.__call__] pred_scores shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.__call__] After permute - pred_output shape: torch.Size([4, 512, 64])
[utils/util.py::ComputeLoss.__call__] After permute - pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Size tensor: tensor([128., 256.], device='cuda:0', dtype=torch.float16)
[utils/util.py::ComputeLoss.__call__] Stride: tensor([8.])
[utils/util.py::ComputeLoss.__call__] Anchor points shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.__call__] Stride tensor shape: torch.Size([512, 1])

--- [utils/util.py::ComputeLoss.__call__] TARGET PROCESSING ---
[utils/util.py::ComputeLoss.__call__] Targets shape: torch.Size([5, 6])
[utils/util.py::ComputeLoss.__call__] Targets dtype: torch.float32
[utils/util.py::ComputeLoss.__call__] First few targets: tensor([[0.0000, 0.0000, 0.6426, 0.9810, 0.1206, 0.0379],
        [1.0000, 0.0000, 0.4600, 0.0888, 0.0976, 0.1776],
        [2.0000, 0.0000, 0.0457, 0.2455, 0.0913, 0.2449],
        [3.0000, 0.0000, 0.8762, 0.6321, 0.0532, 0.1090],
        [3.0000, 0.0000, 0.0121, 0.7333, 0.0242, 0.1120]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Image indices: tensor([0., 1., 2., 3., 3.], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Counts per image: tensor([1, 1, 1, 2], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT tensor shape: torch.Size([4, 2, 5])
[utils/util.py::ComputeLoss.__call__] Image 0: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 1: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 2: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 3: 2 targets assigned
[utils/util.py::ComputeLoss.__call__] GT before coordinate conversion: tensor([[[0.0000, 0.6426, 0.9810, 0.1206, 0.0379],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.4600, 0.0888, 0.0976, 0.1776],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.0457, 0.2455, 0.0913, 0.2449],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.8762, 0.6321, 0.0532, 0.1090],
         [0.0000, 0.0121, 0.7333, 0.0242, 0.1120]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT after coordinate conversion: tensor([[[0.0000e+00, 1.4907e+02, 1.2314e+02, 1.7995e+02, 1.2800e+02],
         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],

        [[0.0000e+00, 1.0526e+02, 0.0000e+00, 1.3024e+02, 2.2739e+01],
         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],

        [[0.0000e+00, 0.0000e+00, 1.5751e+01, 2.3373e+01, 4.7093e+01],
         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],

        [[0.0000e+00, 2.1749e+02, 7.3926e+01, 2.3111e+02, 8.7884e+01],
         [0.0000e+00, 1.0071e-03, 8.6698e+01, 6.1965e+00, 1.0104e+02]]],
       device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT labels shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.__call__] GT bboxes shape: torch.Size([4, 2, 4])
[utils/util.py::ComputeLoss.__call__] GT mask shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.__call__] Pred output dimensions - b: 4, a: 512, c: 64
[utils/util.py::ComputeLoss.__call__] Pred bboxes after softmax shape: torch.Size([4, 512, 4, 16])
[utils/util.py::ComputeLoss.__call__] Pred bboxes after matmul shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Final pred bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.__call__] ASSIGNMENT PHASE ---

--- [utils/util.py::ComputeLoss.assign] PYTORCH ASSIGNMENT DEBUG ---
[utils/util.py::ComputeLoss.assign] pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] true_labels shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 2, 4])
[utils/util.py::ComputeLoss.assign] true_mask shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.assign] anchors shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.assign] Batch size: 4, Max boxes: 2
[utils/util.py::ComputeLoss.assign] Created indices tensor with shape: torch.Size([2, 4, 2])

--- [utils/util.py::ComputeLoss.assign] IOUs DEBUG ---
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 2, 4])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([4, 2, 1, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([4, 1, 512, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([4, 2, 1, 1]), h: torch.Size([4, 2, 1, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([4, 1, 512, 1]), h: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.000000, max: 0.672775
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: -0.979641, max: 0.666444
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.assign] overlaps shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] overlaps min: 0.0, max: 0.6664437651634216
[utils/util.py::ComputeLoss.assign] align_metric shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] align_metric min: 0.0, max: 0.0043395995162427425
[utils/util.py::ComputeLoss.assign] mask_in_gts shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] mask_in_gts sum: 30.0
[utils/util.py::ComputeLoss.assign] metrics shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] top_k_mask shape: torch.Size([4, 2, 10])
[utils/util.py::ComputeLoss.assign] top_k_metrics shape: torch.Size([4, 2, 10])
[utils/util.py::ComputeLoss.assign] top_k_indices shape: torch.Size([4, 2, 10])
[utils/util.py::ComputeLoss.assign] is_in_top_k shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] mask_top_k shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] mask_pos shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] fg_mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] fg_mask sum: 28.0
[utils/util.py::ComputeLoss.assign] target_gt_idx shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_labels shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] Normalized target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] target_scores sum: 3.2925422191619873
--- [utils/util.py::ComputeLoss.assign] END PYTORCH ASSIGNMENT DEBUG ---

[utils/util.py::ComputeLoss.__call__] Target bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Target scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] FG mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.__call__] Target scores sum: 3.292542
[utils/util.py::ComputeLoss.__call__] Classification loss computed: 6.491944
[utils/util.py::ComputeLoss.__call__] Foreground count: 28
[utils/util.py::ComputeLoss.__call__] Weight shape: torch.Size([28, 1])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([28, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([28, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([28, 1]), h: torch.Size([28, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([28, 1]), h: torch.Size([28, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([28, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([28, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([28, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.096987, max: 0.672722
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([28, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([28, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([28, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([28, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: 0.055367, max: 0.666388
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.__call__] IoU values shape: torch.Size([28, 1])
[utils/util.py::ComputeLoss.__call__] Box loss computed: 0.466720
[utils/util.py::ComputeLoss.__call__] Target LT-RB shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.df_loss] PYTORCH DFL LOSS DEBUG ---
[utils/util.py::ComputeLoss.df_loss] pred_dist shape: torch.Size([112, 16])
[utils/util.py::ComputeLoss.df_loss] target shape: torch.Size([28, 4])
[utils/util.py::ComputeLoss.df_loss] DFL loss shape: torch.Size([28, 1])
[utils/util.py::ComputeLoss.df_loss] DFL loss mean: 1.835847
--- [utils/util.py::ComputeLoss.df_loss] END PYTORCH DFL LOSS DEBUG ---

[utils/util.py::ComputeLoss.__call__] DFL loss before weighting: 1.835847
[utils/util.py::ComputeLoss.__call__] DFL loss computed: 1.431618

--- [utils/util.py::ComputeLoss.__call__] LOSS COMPONENTS DEBUG ---
[utils/util.py::ComputeLoss.__call__] Raw loss_cls: 6.491944
[utils/util.py::ComputeLoss.__call__] Raw loss_box: 0.466720
[utils/util.py::ComputeLoss.__call__] Raw loss_dfl: 1.431618
[utils/util.py::ComputeLoss.__call__] Loss weights - cls: 0.5, box: 7.5, dfl: 1.5
[utils/util.py::ComputeLoss.__call__] target_scores_sum: 3.292542
[utils/util.py::ComputeLoss.__call__] fg_mask sum: 28
[utils/util.py::ComputeLoss.__call__] Weighted loss_cls: 3.245972
[utils/util.py::ComputeLoss.__call__] Weighted loss_box: 3.500398
[utils/util.py::ComputeLoss.__call__] Weighted loss_dfl: 2.147427
[utils/util.py::ComputeLoss.__call__] Total loss: 8.893797
--- [utils/util.py::ComputeLoss.__call__] END PYTORCH LOSS COMPUTATION DEBUG ---


--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([4, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: True
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([4, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - box shape: torch.Size([4, 64, 16, 32]), cls shape: torch.Size([4, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - final concat shape: torch.Size([4, 65, 16, 32])

--- [utils/util.py::ComputeLoss.__call__] PYTORCH LOSS COMPUTATION DEBUG ---
[utils/util.py::ComputeLoss.__call__] Outputs type: <class 'list'>
[utils/util.py::ComputeLoss.__call__] x type: <class 'list'>, len: 1
[utils/util.py::ComputeLoss.__call__] x[0] shape: torch.Size([4, 65, 16, 32])
[utils/util.py::ComputeLoss.__call__] Concatenated output shape: torch.Size([4, 65, 512])
[utils/util.py::ComputeLoss.__call__] self.no: 65, self.dfl_ch: 16, self.nc: 1
[utils/util.py::ComputeLoss.__call__] pred_output shape: torch.Size([4, 64, 512])
[utils/util.py::ComputeLoss.__call__] pred_scores shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.__call__] After permute - pred_output shape: torch.Size([4, 512, 64])
[utils/util.py::ComputeLoss.__call__] After permute - pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Size tensor: tensor([128., 256.], device='cuda:0', dtype=torch.float16)
[utils/util.py::ComputeLoss.__call__] Stride: tensor([8.])
[utils/util.py::ComputeLoss.__call__] Anchor points shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.__call__] Stride tensor shape: torch.Size([512, 1])

--- [utils/util.py::ComputeLoss.__call__] TARGET PROCESSING ---
[utils/util.py::ComputeLoss.__call__] Targets shape: torch.Size([6, 6])
[utils/util.py::ComputeLoss.__call__] Targets dtype: torch.float32
[utils/util.py::ComputeLoss.__call__] First few targets: tensor([[0.0000, 0.0000, 0.5084, 0.2616, 0.0656, 0.1331],
        [0.0000, 0.0000, 0.7658, 0.9383, 0.0589, 0.1220],
        [1.0000, 0.0000, 0.0219, 0.0219, 0.0438, 0.0439],
        [1.0000, 0.0000, 0.1386, 0.7664, 0.0840, 0.1620],
        [2.0000, 0.0000, 0.6273, 0.1333, 0.1132, 0.2211]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Image indices: tensor([0., 0., 1., 1., 2., 3.], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Counts per image: tensor([2, 2, 1, 1], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT tensor shape: torch.Size([4, 2, 5])
[utils/util.py::ComputeLoss.__call__] Image 0: 2 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 1: 2 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 2: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 3: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] GT before coordinate conversion: tensor([[[0.0000, 0.5084, 0.2616, 0.0656, 0.1331],
         [0.0000, 0.7658, 0.9383, 0.0589, 0.1220]],

        [[0.0000, 0.0219, 0.0219, 0.0438, 0.0439],
         [0.0000, 0.1386, 0.7664, 0.0840, 0.1620]],

        [[0.0000, 0.6273, 0.1333, 0.1132, 0.2211],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.9609, 0.9388, 0.0783, 0.1224],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT after coordinate conversion: tensor([[[0.0000e+00, 1.2176e+02, 2.4967e+01, 1.3855e+02, 4.2005e+01],
         [0.0000e+00, 1.8849e+02, 1.1229e+02, 2.0358e+02, 1.2791e+02]],

        [[0.0000e+00, 1.0147e-03, 0.0000e+00, 1.1207e+01, 5.6175e+00],
         [0.0000e+00, 2.4722e+01, 8.7725e+01, 4.6219e+01, 1.0847e+02]],

        [[0.0000e+00, 1.4610e+02, 2.9064e+00, 1.7508e+02, 3.1213e+01],
         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],

        [[0.0000e+00, 2.3596e+02, 1.1233e+02, 2.5600e+02, 1.2800e+02],
         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]]],
       device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT labels shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.__call__] GT bboxes shape: torch.Size([4, 2, 4])
[utils/util.py::ComputeLoss.__call__] GT mask shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.__call__] Pred output dimensions - b: 4, a: 512, c: 64
[utils/util.py::ComputeLoss.__call__] Pred bboxes after softmax shape: torch.Size([4, 512, 4, 16])
[utils/util.py::ComputeLoss.__call__] Pred bboxes after matmul shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Final pred bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.__call__] ASSIGNMENT PHASE ---

--- [utils/util.py::ComputeLoss.assign] PYTORCH ASSIGNMENT DEBUG ---
[utils/util.py::ComputeLoss.assign] pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] true_labels shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 2, 4])
[utils/util.py::ComputeLoss.assign] true_mask shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.assign] anchors shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.assign] Batch size: 4, Max boxes: 2
[utils/util.py::ComputeLoss.assign] Created indices tensor with shape: torch.Size([2, 4, 2])

--- [utils/util.py::ComputeLoss.assign] IOUs DEBUG ---
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 2, 4])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([4, 2, 1, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([4, 1, 512, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([4, 2, 1, 1]), h: torch.Size([4, 2, 1, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([4, 1, 512, 1]), h: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.000000, max: 0.710425
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: -0.957534, max: 0.701722
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.assign] overlaps shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] overlaps min: 0.0, max: 0.7017219066619873
[utils/util.py::ComputeLoss.assign] align_metric shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] align_metric min: 0.0, max: 0.005418153014034033
[utils/util.py::ComputeLoss.assign] mask_in_gts shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] mask_in_gts sum: 38.0
[utils/util.py::ComputeLoss.assign] metrics shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] top_k_mask shape: torch.Size([4, 2, 10])
[utils/util.py::ComputeLoss.assign] top_k_metrics shape: torch.Size([4, 2, 10])
[utils/util.py::ComputeLoss.assign] top_k_indices shape: torch.Size([4, 2, 10])
[utils/util.py::ComputeLoss.assign] is_in_top_k shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] mask_top_k shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] mask_pos shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] fg_mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] fg_mask sum: 32.0
[utils/util.py::ComputeLoss.assign] target_gt_idx shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_labels shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] Normalized target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] target_scores sum: 4.293307304382324
--- [utils/util.py::ComputeLoss.assign] END PYTORCH ASSIGNMENT DEBUG ---

[utils/util.py::ComputeLoss.__call__] Target bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Target scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] FG mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.__call__] Target scores sum: 4.293307
[utils/util.py::ComputeLoss.__call__] Classification loss computed: 6.296137
[utils/util.py::ComputeLoss.__call__] Foreground count: 32
[utils/util.py::ComputeLoss.__call__] Weight shape: torch.Size([32, 1])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([32, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([32, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([32, 1]), h: torch.Size([32, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([32, 1]), h: torch.Size([32, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([32, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([32, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([32, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.072609, max: 0.710381
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([32, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([32, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([32, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([32, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: 0.058771, max: 0.701678
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.__call__] IoU values shape: torch.Size([32, 1])
[utils/util.py::ComputeLoss.__call__] Box loss computed: 0.524211
[utils/util.py::ComputeLoss.__call__] Target LT-RB shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.df_loss] PYTORCH DFL LOSS DEBUG ---
[utils/util.py::ComputeLoss.df_loss] pred_dist shape: torch.Size([128, 16])
[utils/util.py::ComputeLoss.df_loss] target shape: torch.Size([32, 4])
[utils/util.py::ComputeLoss.df_loss] DFL loss shape: torch.Size([32, 1])
[utils/util.py::ComputeLoss.df_loss] DFL loss mean: 1.690217
--- [utils/util.py::ComputeLoss.df_loss] END PYTORCH DFL LOSS DEBUG ---

[utils/util.py::ComputeLoss.__call__] DFL loss before weighting: 1.690217
[utils/util.py::ComputeLoss.__call__] DFL loss computed: 1.323416

--- [utils/util.py::ComputeLoss.__call__] LOSS COMPONENTS DEBUG ---
[utils/util.py::ComputeLoss.__call__] Raw loss_cls: 6.296137
[utils/util.py::ComputeLoss.__call__] Raw loss_box: 0.524211
[utils/util.py::ComputeLoss.__call__] Raw loss_dfl: 1.323416
[utils/util.py::ComputeLoss.__call__] Loss weights - cls: 0.5, box: 7.5, dfl: 1.5
[utils/util.py::ComputeLoss.__call__] target_scores_sum: 4.293307
[utils/util.py::ComputeLoss.__call__] fg_mask sum: 32
[utils/util.py::ComputeLoss.__call__] Weighted loss_cls: 3.148068
[utils/util.py::ComputeLoss.__call__] Weighted loss_box: 3.931586
[utils/util.py::ComputeLoss.__call__] Weighted loss_dfl: 1.985123
[utils/util.py::ComputeLoss.__call__] Total loss: 9.064778
--- [utils/util.py::ComputeLoss.__call__] END PYTORCH LOSS COMPUTATION DEBUG ---


--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([4, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: True
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([4, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - box shape: torch.Size([4, 64, 16, 32]), cls shape: torch.Size([4, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - final concat shape: torch.Size([4, 65, 16, 32])

--- [utils/util.py::ComputeLoss.__call__] PYTORCH LOSS COMPUTATION DEBUG ---
[utils/util.py::ComputeLoss.__call__] Outputs type: <class 'list'>
[utils/util.py::ComputeLoss.__call__] x type: <class 'list'>, len: 1
[utils/util.py::ComputeLoss.__call__] x[0] shape: torch.Size([4, 65, 16, 32])
[utils/util.py::ComputeLoss.__call__] Concatenated output shape: torch.Size([4, 65, 512])
[utils/util.py::ComputeLoss.__call__] self.no: 65, self.dfl_ch: 16, self.nc: 1
[utils/util.py::ComputeLoss.__call__] pred_output shape: torch.Size([4, 64, 512])
[utils/util.py::ComputeLoss.__call__] pred_scores shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.__call__] After permute - pred_output shape: torch.Size([4, 512, 64])
[utils/util.py::ComputeLoss.__call__] After permute - pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Size tensor: tensor([128., 256.], device='cuda:0', dtype=torch.float16)
[utils/util.py::ComputeLoss.__call__] Stride: tensor([8.])
[utils/util.py::ComputeLoss.__call__] Anchor points shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.__call__] Stride tensor shape: torch.Size([512, 1])

--- [utils/util.py::ComputeLoss.__call__] TARGET PROCESSING ---
[utils/util.py::ComputeLoss.__call__] Targets shape: torch.Size([6, 6])
[utils/util.py::ComputeLoss.__call__] Targets dtype: torch.float32
[utils/util.py::ComputeLoss.__call__] First few targets: tensor([[0.0000, 0.0000, 0.8856, 0.5428, 0.0488, 0.0899],
        [1.0000, 0.0000, 0.0197, 0.3240, 0.0394, 0.1487],
        [1.0000, 0.0000, 0.5723, 0.4752, 0.0877, 0.1769],
        [2.0000, 0.0000, 0.6650, 0.3067, 0.0871, 0.1614],
        [2.0000, 0.0000, 0.1765, 0.4581, 0.0883, 0.1673]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Image indices: tensor([0., 1., 1., 2., 2., 3.], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Counts per image: tensor([1, 2, 2, 1], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT tensor shape: torch.Size([4, 2, 5])
[utils/util.py::ComputeLoss.__call__] Image 0: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 1: 2 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 2: 2 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 3: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] GT before coordinate conversion: tensor([[[0.0000, 0.8856, 0.5428, 0.0488, 0.0899],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.0197, 0.3240, 0.0394, 0.1487],
         [0.0000, 0.5723, 0.4752, 0.0877, 0.1769]],

        [[0.0000, 0.6650, 0.3067, 0.0871, 0.1614],
         [0.0000, 0.1765, 0.4581, 0.0883, 0.1673]],

        [[0.0000, 0.1859, 0.6265, 0.0622, 0.1244],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT after coordinate conversion: tensor([[[  0.0000, 220.4638,  63.7289, 232.9553,  75.2350],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000,   0.0000,  31.9519,  10.0921,  50.9912],
         [  0.0000, 135.2893,  49.5018, 157.7393,  72.1417]],

        [[  0.0000, 159.0886,  28.9298, 181.3850,  49.5852],
         [  0.0000,  33.8832,  47.9346,  56.4814,  69.3445]],

        [[  0.0000,  39.6379,  72.2321,  55.5632,  88.1574],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT labels shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.__call__] GT bboxes shape: torch.Size([4, 2, 4])
[utils/util.py::ComputeLoss.__call__] GT mask shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.__call__] Pred output dimensions - b: 4, a: 512, c: 64
[utils/util.py::ComputeLoss.__call__] Pred bboxes after softmax shape: torch.Size([4, 512, 4, 16])
[utils/util.py::ComputeLoss.__call__] Pred bboxes after matmul shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Final pred bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.__call__] ASSIGNMENT PHASE ---

--- [utils/util.py::ComputeLoss.assign] PYTORCH ASSIGNMENT DEBUG ---
[utils/util.py::ComputeLoss.assign] pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] true_labels shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 2, 4])
[utils/util.py::ComputeLoss.assign] true_mask shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.assign] anchors shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.assign] Batch size: 4, Max boxes: 2
[utils/util.py::ComputeLoss.assign] Created indices tensor with shape: torch.Size([2, 4, 2])

--- [utils/util.py::ComputeLoss.assign] IOUs DEBUG ---
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 2, 4])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([4, 2, 1, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([4, 1, 512, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([4, 2, 1, 1]), h: torch.Size([4, 2, 1, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([4, 1, 512, 1]), h: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.000000, max: 0.799207
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: -1.034028, max: 0.798069
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.assign] overlaps shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] overlaps min: 0.0, max: 0.7980687022209167
[utils/util.py::ComputeLoss.assign] align_metric shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] align_metric min: 0.0, max: 0.0197908952832222
[utils/util.py::ComputeLoss.assign] mask_in_gts shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] mask_in_gts sum: 31.0
[utils/util.py::ComputeLoss.assign] metrics shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] top_k_mask shape: torch.Size([4, 2, 10])
[utils/util.py::ComputeLoss.assign] top_k_metrics shape: torch.Size([4, 2, 10])
[utils/util.py::ComputeLoss.assign] top_k_indices shape: torch.Size([4, 2, 10])
[utils/util.py::ComputeLoss.assign] is_in_top_k shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] mask_top_k shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] mask_pos shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] fg_mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] fg_mask sum: 31.0
[utils/util.py::ComputeLoss.assign] target_gt_idx shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_labels shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] Normalized target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] target_scores sum: 3.7828311920166016
--- [utils/util.py::ComputeLoss.assign] END PYTORCH ASSIGNMENT DEBUG ---

[utils/util.py::ComputeLoss.__call__] Target bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Target scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] FG mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.__call__] Target scores sum: 3.782831
[utils/util.py::ComputeLoss.__call__] Classification loss computed: 6.212278
[utils/util.py::ComputeLoss.__call__] Foreground count: 31
[utils/util.py::ComputeLoss.__call__] Weight shape: torch.Size([31, 1])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([31, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([31, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([31, 1]), h: torch.Size([31, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([31, 1]), h: torch.Size([31, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([31, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([31, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([31, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.174745, max: 0.799158
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([31, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([31, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([31, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([31, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: 0.173420, max: 0.798020
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.__call__] IoU values shape: torch.Size([31, 1])
[utils/util.py::ComputeLoss.__call__] Box loss computed: 0.474235
[utils/util.py::ComputeLoss.__call__] Target LT-RB shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.df_loss] PYTORCH DFL LOSS DEBUG ---
[utils/util.py::ComputeLoss.df_loss] pred_dist shape: torch.Size([124, 16])
[utils/util.py::ComputeLoss.df_loss] target shape: torch.Size([31, 4])
[utils/util.py::ComputeLoss.df_loss] DFL loss shape: torch.Size([31, 1])
[utils/util.py::ComputeLoss.df_loss] DFL loss mean: 1.631490
--- [utils/util.py::ComputeLoss.df_loss] END PYTORCH DFL LOSS DEBUG ---

[utils/util.py::ComputeLoss.__call__] DFL loss before weighting: 1.631490
[utils/util.py::ComputeLoss.__call__] DFL loss computed: 1.177570

--- [utils/util.py::ComputeLoss.__call__] LOSS COMPONENTS DEBUG ---
[utils/util.py::ComputeLoss.__call__] Raw loss_cls: 6.212278
[utils/util.py::ComputeLoss.__call__] Raw loss_box: 0.474235
[utils/util.py::ComputeLoss.__call__] Raw loss_dfl: 1.177570
[utils/util.py::ComputeLoss.__call__] Loss weights - cls: 0.5, box: 7.5, dfl: 1.5
[utils/util.py::ComputeLoss.__call__] target_scores_sum: 3.782831
[utils/util.py::ComputeLoss.__call__] fg_mask sum: 31
[utils/util.py::ComputeLoss.__call__] Weighted loss_cls: 3.106139
[utils/util.py::ComputeLoss.__call__] Weighted loss_box: 3.556760
[utils/util.py::ComputeLoss.__call__] Weighted loss_dfl: 1.766355
[utils/util.py::ComputeLoss.__call__] Total loss: 8.429255
--- [utils/util.py::ComputeLoss.__call__] END PYTORCH LOSS COMPUTATION DEBUG ---


--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([4, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: True
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([4, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - box shape: torch.Size([4, 64, 16, 32]), cls shape: torch.Size([4, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - final concat shape: torch.Size([4, 65, 16, 32])

--- [utils/util.py::ComputeLoss.__call__] PYTORCH LOSS COMPUTATION DEBUG ---
[utils/util.py::ComputeLoss.__call__] Outputs type: <class 'list'>
[utils/util.py::ComputeLoss.__call__] x type: <class 'list'>, len: 1
[utils/util.py::ComputeLoss.__call__] x[0] shape: torch.Size([4, 65, 16, 32])
[utils/util.py::ComputeLoss.__call__] Concatenated output shape: torch.Size([4, 65, 512])
[utils/util.py::ComputeLoss.__call__] self.no: 65, self.dfl_ch: 16, self.nc: 1
[utils/util.py::ComputeLoss.__call__] pred_output shape: torch.Size([4, 64, 512])
[utils/util.py::ComputeLoss.__call__] pred_scores shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.__call__] After permute - pred_output shape: torch.Size([4, 512, 64])
[utils/util.py::ComputeLoss.__call__] After permute - pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Size tensor: tensor([128., 256.], device='cuda:0', dtype=torch.float16)
[utils/util.py::ComputeLoss.__call__] Stride: tensor([8.])
[utils/util.py::ComputeLoss.__call__] Anchor points shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.__call__] Stride tensor shape: torch.Size([512, 1])

--- [utils/util.py::ComputeLoss.__call__] TARGET PROCESSING ---
[utils/util.py::ComputeLoss.__call__] Targets shape: torch.Size([3, 6])
[utils/util.py::ComputeLoss.__call__] Targets dtype: torch.float32
[utils/util.py::ComputeLoss.__call__] First few targets: tensor([[0.0000, 0.0000, 0.4620, 0.1594, 0.0788, 0.1576],
        [1.0000, 0.0000, 0.3546, 0.4614, 0.0911, 0.1951],
        [3.0000, 0.0000, 0.3578, 0.4215, 0.0828, 0.1732]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Image indices: tensor([0., 1., 3.], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Counts per image: tensor([1, 1, 1], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT tensor shape: torch.Size([4, 1, 5])
[utils/util.py::ComputeLoss.__call__] Image 0: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 1: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 3: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] GT before coordinate conversion: tensor([[[0.0000, 0.4620, 0.1594, 0.0788, 0.1576]],

        [[0.0000, 0.3546, 0.4614, 0.0911, 0.1951]],

        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.3578, 0.4215, 0.0828, 0.1732]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT after coordinate conversion: tensor([[[  0.0000, 108.1773,  10.3189, 128.3487,  30.4902]],

        [[  0.0000,  79.1169,  46.5676, 102.4353,  71.5462]],

        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000,  80.9910,  42.8737, 102.1916,  65.0380]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT labels shape: torch.Size([4, 1, 1])
[utils/util.py::ComputeLoss.__call__] GT bboxes shape: torch.Size([4, 1, 4])
[utils/util.py::ComputeLoss.__call__] GT mask shape: torch.Size([4, 1, 1])
[utils/util.py::ComputeLoss.__call__] Pred output dimensions - b: 4, a: 512, c: 64
[utils/util.py::ComputeLoss.__call__] Pred bboxes after softmax shape: torch.Size([4, 512, 4, 16])
[utils/util.py::ComputeLoss.__call__] Pred bboxes after matmul shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Final pred bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.__call__] ASSIGNMENT PHASE ---

--- [utils/util.py::ComputeLoss.assign] PYTORCH ASSIGNMENT DEBUG ---
[utils/util.py::ComputeLoss.assign] pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] true_labels shape: torch.Size([4, 1, 1])
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 1, 4])
[utils/util.py::ComputeLoss.assign] true_mask shape: torch.Size([4, 1, 1])
[utils/util.py::ComputeLoss.assign] anchors shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.assign] Batch size: 4, Max boxes: 1
[utils/util.py::ComputeLoss.assign] Created indices tensor with shape: torch.Size([2, 4, 1])

--- [utils/util.py::ComputeLoss.assign] IOUs DEBUG ---
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 1, 4])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([4, 1, 1, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([4, 1, 512, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([4, 1, 1, 1]), h: torch.Size([4, 1, 1, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([4, 1, 512, 1]), h: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.000000, max: 0.695035
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: -0.966818, max: 0.692250
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.assign] overlaps shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.assign] overlaps min: 0.0, max: 0.6922497153282166
[utils/util.py::ComputeLoss.assign] align_metric shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.assign] align_metric min: 0.0, max: 0.005003951024264097
[utils/util.py::ComputeLoss.assign] mask_in_gts shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.assign] mask_in_gts sum: 24.0
[utils/util.py::ComputeLoss.assign] metrics shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.assign] top_k_mask shape: torch.Size([4, 1, 10])
[utils/util.py::ComputeLoss.assign] top_k_metrics shape: torch.Size([4, 1, 10])
[utils/util.py::ComputeLoss.assign] top_k_indices shape: torch.Size([4, 1, 10])
[utils/util.py::ComputeLoss.assign] is_in_top_k shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.assign] mask_top_k shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.assign] mask_pos shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.assign] fg_mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] fg_mask sum: 24.0
[utils/util.py::ComputeLoss.assign] target_gt_idx shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_labels shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] Normalized target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] target_scores sum: 2.7240378856658936
--- [utils/util.py::ComputeLoss.assign] END PYTORCH ASSIGNMENT DEBUG ---

[utils/util.py::ComputeLoss.__call__] Target bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Target scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] FG mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.__call__] Target scores sum: 2.724038
[utils/util.py::ComputeLoss.__call__] Classification loss computed: 6.389871
[utils/util.py::ComputeLoss.__call__] Foreground count: 24
[utils/util.py::ComputeLoss.__call__] Weight shape: torch.Size([24, 1])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([24, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([24, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([24, 1]), h: torch.Size([24, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([24, 1]), h: torch.Size([24, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([24, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([24, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([24, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.230081, max: 0.694903
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([24, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([24, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([24, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([24, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: 0.153857, max: 0.692117
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.__call__] IoU values shape: torch.Size([24, 1])
[utils/util.py::ComputeLoss.__call__] Box loss computed: 0.450624
[utils/util.py::ComputeLoss.__call__] Target LT-RB shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.df_loss] PYTORCH DFL LOSS DEBUG ---
[utils/util.py::ComputeLoss.df_loss] pred_dist shape: torch.Size([96, 16])
[utils/util.py::ComputeLoss.df_loss] target shape: torch.Size([24, 4])
[utils/util.py::ComputeLoss.df_loss] DFL loss shape: torch.Size([24, 1])
[utils/util.py::ComputeLoss.df_loss] DFL loss mean: 1.706801
--- [utils/util.py::ComputeLoss.df_loss] END PYTORCH DFL LOSS DEBUG ---

[utils/util.py::ComputeLoss.__call__] DFL loss before weighting: 1.706801
[utils/util.py::ComputeLoss.__call__] DFL loss computed: 1.154815

--- [utils/util.py::ComputeLoss.__call__] LOSS COMPONENTS DEBUG ---
[utils/util.py::ComputeLoss.__call__] Raw loss_cls: 6.389871
[utils/util.py::ComputeLoss.__call__] Raw loss_box: 0.450624
[utils/util.py::ComputeLoss.__call__] Raw loss_dfl: 1.154815
[utils/util.py::ComputeLoss.__call__] Loss weights - cls: 0.5, box: 7.5, dfl: 1.5
[utils/util.py::ComputeLoss.__call__] target_scores_sum: 2.724038
[utils/util.py::ComputeLoss.__call__] fg_mask sum: 24
[utils/util.py::ComputeLoss.__call__] Weighted loss_cls: 3.194935
[utils/util.py::ComputeLoss.__call__] Weighted loss_box: 3.379682
[utils/util.py::ComputeLoss.__call__] Weighted loss_dfl: 1.732223
[utils/util.py::ComputeLoss.__call__] Total loss: 8.306841
--- [utils/util.py::ComputeLoss.__call__] END PYTORCH LOSS COMPUTATION DEBUG ---


--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([4, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: True
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([4, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - box shape: torch.Size([4, 64, 16, 32]), cls shape: torch.Size([4, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - final concat shape: torch.Size([4, 65, 16, 32])

--- [utils/util.py::ComputeLoss.__call__] PYTORCH LOSS COMPUTATION DEBUG ---
[utils/util.py::ComputeLoss.__call__] Outputs type: <class 'list'>
[utils/util.py::ComputeLoss.__call__] x type: <class 'list'>, len: 1
[utils/util.py::ComputeLoss.__call__] x[0] shape: torch.Size([4, 65, 16, 32])
[utils/util.py::ComputeLoss.__call__] Concatenated output shape: torch.Size([4, 65, 512])
[utils/util.py::ComputeLoss.__call__] self.no: 65, self.dfl_ch: 16, self.nc: 1
[utils/util.py::ComputeLoss.__call__] pred_output shape: torch.Size([4, 64, 512])
[utils/util.py::ComputeLoss.__call__] pred_scores shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.__call__] After permute - pred_output shape: torch.Size([4, 512, 64])
[utils/util.py::ComputeLoss.__call__] After permute - pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Size tensor: tensor([128., 256.], device='cuda:0', dtype=torch.float16)
[utils/util.py::ComputeLoss.__call__] Stride: tensor([8.])
[utils/util.py::ComputeLoss.__call__] Anchor points shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.__call__] Stride tensor shape: torch.Size([512, 1])

--- [utils/util.py::ComputeLoss.__call__] TARGET PROCESSING ---
[utils/util.py::ComputeLoss.__call__] Targets shape: torch.Size([5, 6])
[utils/util.py::ComputeLoss.__call__] Targets dtype: torch.float32
[utils/util.py::ComputeLoss.__call__] First few targets: tensor([[0.0000, 0.0000, 0.5919, 0.3011, 0.1150, 0.2241],
        [0.0000, 0.0000, 0.9505, 0.3670, 0.0991, 0.2840],
        [1.0000, 0.0000, 0.4164, 0.7088, 0.0675, 0.1446],
        [3.0000, 0.0000, 0.5884, 0.4435, 0.0481, 0.0963],
        [3.0000, 0.0000, 0.6920, 0.4848, 0.0447, 0.0891]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Image indices: tensor([0., 0., 1., 3., 3.], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Counts per image: tensor([2, 1, 2], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT tensor shape: torch.Size([4, 2, 5])
[utils/util.py::ComputeLoss.__call__] Image 0: 2 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 1: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 3: 2 targets assigned
[utils/util.py::ComputeLoss.__call__] GT before coordinate conversion: tensor([[[0.0000, 0.5919, 0.3011, 0.1150, 0.2241],
         [0.0000, 0.9505, 0.3670, 0.0991, 0.2840]],

        [[0.0000, 0.4164, 0.7088, 0.0675, 0.1446],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.5884, 0.4435, 0.0481, 0.0963],
         [0.0000, 0.6920, 0.4848, 0.0447, 0.0891]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT after coordinate conversion: tensor([[[  0.0000, 136.8136,  24.2052, 166.2646,  52.8878],
         [  0.0000, 230.6364,  28.7947, 255.9990,  65.1474]],

        [[  0.0000,  97.9487,  81.4755, 115.2225,  99.9875],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000, 144.4822,  50.6137, 156.8029,  62.9344],
         [  0.0000, 171.4271,  56.3562, 182.8586,  67.7556]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT labels shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.__call__] GT bboxes shape: torch.Size([4, 2, 4])
[utils/util.py::ComputeLoss.__call__] GT mask shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.__call__] Pred output dimensions - b: 4, a: 512, c: 64
[utils/util.py::ComputeLoss.__call__] Pred bboxes after softmax shape: torch.Size([4, 512, 4, 16])
[utils/util.py::ComputeLoss.__call__] Pred bboxes after matmul shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Final pred bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.__call__] ASSIGNMENT PHASE ---

--- [utils/util.py::ComputeLoss.assign] PYTORCH ASSIGNMENT DEBUG ---
[utils/util.py::ComputeLoss.assign] pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] true_labels shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 2, 4])
[utils/util.py::ComputeLoss.assign] true_mask shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.assign] anchors shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.assign] Batch size: 4, Max boxes: 2
[utils/util.py::ComputeLoss.assign] Created indices tensor with shape: torch.Size([2, 4, 2])

--- [utils/util.py::ComputeLoss.assign] IOUs DEBUG ---
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 2, 4])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([4, 2, 1, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([4, 1, 512, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([4, 2, 1, 1]), h: torch.Size([4, 2, 1, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([4, 1, 512, 1]), h: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.000000, max: 0.773740
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: -0.956564, max: 0.769910
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.assign] overlaps shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] overlaps min: 0.0, max: 0.7699100971221924
[utils/util.py::ComputeLoss.assign] align_metric shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] align_metric min: 0.0, max: 0.007360354531556368
[utils/util.py::ComputeLoss.assign] mask_in_gts shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] mask_in_gts sum: 38.0
[utils/util.py::ComputeLoss.assign] metrics shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] top_k_mask shape: torch.Size([4, 2, 10])
[utils/util.py::ComputeLoss.assign] top_k_metrics shape: torch.Size([4, 2, 10])
[utils/util.py::ComputeLoss.assign] top_k_indices shape: torch.Size([4, 2, 10])
[utils/util.py::ComputeLoss.assign] is_in_top_k shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] mask_top_k shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] mask_pos shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] fg_mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] fg_mask sum: 30.0
[utils/util.py::ComputeLoss.assign] target_gt_idx shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_labels shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] Normalized target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] target_scores sum: 3.42622709274292
--- [utils/util.py::ComputeLoss.assign] END PYTORCH ASSIGNMENT DEBUG ---

[utils/util.py::ComputeLoss.__call__] Target bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Target scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] FG mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.__call__] Target scores sum: 3.426227
[utils/util.py::ComputeLoss.__call__] Classification loss computed: 6.457541
[utils/util.py::ComputeLoss.__call__] Foreground count: 30
[utils/util.py::ComputeLoss.__call__] Weight shape: torch.Size([30, 1])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([30, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([30, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([30, 1]), h: torch.Size([30, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([30, 1]), h: torch.Size([30, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([30, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([30, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([30, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.159501, max: 0.773684
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([30, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([30, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([30, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([30, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: 0.133446, max: 0.769855
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.__call__] IoU values shape: torch.Size([30, 1])
[utils/util.py::ComputeLoss.__call__] Box loss computed: 0.449300
[utils/util.py::ComputeLoss.__call__] Target LT-RB shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.df_loss] PYTORCH DFL LOSS DEBUG ---
[utils/util.py::ComputeLoss.df_loss] pred_dist shape: torch.Size([120, 16])
[utils/util.py::ComputeLoss.df_loss] target shape: torch.Size([30, 4])
[utils/util.py::ComputeLoss.df_loss] DFL loss shape: torch.Size([30, 1])
[utils/util.py::ComputeLoss.df_loss] DFL loss mean: 1.810406
--- [utils/util.py::ComputeLoss.df_loss] END PYTORCH DFL LOSS DEBUG ---

[utils/util.py::ComputeLoss.__call__] DFL loss before weighting: 1.810406
[utils/util.py::ComputeLoss.__call__] DFL loss computed: 1.525077

--- [utils/util.py::ComputeLoss.__call__] LOSS COMPONENTS DEBUG ---
[utils/util.py::ComputeLoss.__call__] Raw loss_cls: 6.457541
[utils/util.py::ComputeLoss.__call__] Raw loss_box: 0.449300
[utils/util.py::ComputeLoss.__call__] Raw loss_dfl: 1.525077
[utils/util.py::ComputeLoss.__call__] Loss weights - cls: 0.5, box: 7.5, dfl: 1.5
[utils/util.py::ComputeLoss.__call__] target_scores_sum: 3.426227
[utils/util.py::ComputeLoss.__call__] fg_mask sum: 30
[utils/util.py::ComputeLoss.__call__] Weighted loss_cls: 3.228770
[utils/util.py::ComputeLoss.__call__] Weighted loss_box: 3.369750
[utils/util.py::ComputeLoss.__call__] Weighted loss_dfl: 2.287615
[utils/util.py::ComputeLoss.__call__] Total loss: 8.886135
--- [utils/util.py::ComputeLoss.__call__] END PYTORCH LOSS COMPUTATION DEBUG ---


--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([4, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: True
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([4, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - box shape: torch.Size([4, 64, 16, 32]), cls shape: torch.Size([4, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - final concat shape: torch.Size([4, 65, 16, 32])

--- [utils/util.py::ComputeLoss.__call__] PYTORCH LOSS COMPUTATION DEBUG ---
[utils/util.py::ComputeLoss.__call__] Outputs type: <class 'list'>
[utils/util.py::ComputeLoss.__call__] x type: <class 'list'>, len: 1
[utils/util.py::ComputeLoss.__call__] x[0] shape: torch.Size([4, 65, 16, 32])
[utils/util.py::ComputeLoss.__call__] Concatenated output shape: torch.Size([4, 65, 512])
[utils/util.py::ComputeLoss.__call__] self.no: 65, self.dfl_ch: 16, self.nc: 1
[utils/util.py::ComputeLoss.__call__] pred_output shape: torch.Size([4, 64, 512])
[utils/util.py::ComputeLoss.__call__] pred_scores shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.__call__] After permute - pred_output shape: torch.Size([4, 512, 64])
[utils/util.py::ComputeLoss.__call__] After permute - pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Size tensor: tensor([128., 256.], device='cuda:0', dtype=torch.float16)
[utils/util.py::ComputeLoss.__call__] Stride: tensor([8.])
[utils/util.py::ComputeLoss.__call__] Anchor points shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.__call__] Stride tensor shape: torch.Size([512, 1])

--- [utils/util.py::ComputeLoss.__call__] TARGET PROCESSING ---
[utils/util.py::ComputeLoss.__call__] Targets shape: torch.Size([6, 6])
[utils/util.py::ComputeLoss.__call__] Targets dtype: torch.float32
[utils/util.py::ComputeLoss.__call__] First few targets: tensor([[0.0000, 0.0000, 0.3227, 0.0872, 0.0736, 0.1570],
        [0.0000, 0.0000, 0.0626, 0.0483, 0.0595, 0.0967],
        [0.0000, 0.0000, 0.8936, 0.7521, 0.0771, 0.1600],
        [0.0000, 0.0000, 0.2270, 0.6693, 0.0593, 0.1282],
        [1.0000, 0.0000, 0.4188, 0.8427, 0.1180, 0.2352]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Image indices: tensor([0., 0., 0., 0., 1., 2.], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Counts per image: tensor([4, 1, 1], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT tensor shape: torch.Size([4, 4, 5])
[utils/util.py::ComputeLoss.__call__] Image 0: 4 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 1: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 2: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] GT before coordinate conversion: tensor([[[0.0000, 0.3227, 0.0872, 0.0736, 0.1570],
         [0.0000, 0.0626, 0.0483, 0.0595, 0.0967],
         [0.0000, 0.8936, 0.7521, 0.0771, 0.1600],
         [0.0000, 0.2270, 0.6693, 0.0593, 0.1282]],

        [[0.0000, 0.4188, 0.8427, 0.1180, 0.2352],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.3252, 0.0623, 0.0977, 0.1247],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT after coordinate conversion: tensor([[[  0.0000,  73.1855,   1.1112,  92.0382,  21.2056],
         [  0.0000,   8.3999,   0.0000,  23.6276,  12.3715],
         [  0.0000, 218.9051,  86.0269, 238.6427, 106.5066],
         [  0.0000,  50.5045,  77.4640,  65.6965,  93.8763]],

        [[  0.0000,  92.1134,  92.8154, 122.3214, 122.9193],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000,  70.7532,   0.0000,  95.7582,  15.9584],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT labels shape: torch.Size([4, 4, 1])
[utils/util.py::ComputeLoss.__call__] GT bboxes shape: torch.Size([4, 4, 4])
[utils/util.py::ComputeLoss.__call__] GT mask shape: torch.Size([4, 4, 1])
[utils/util.py::ComputeLoss.__call__] Pred output dimensions - b: 4, a: 512, c: 64
[utils/util.py::ComputeLoss.__call__] Pred bboxes after softmax shape: torch.Size([4, 512, 4, 16])
[utils/util.py::ComputeLoss.__call__] Pred bboxes after matmul shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Final pred bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.__call__] ASSIGNMENT PHASE ---

--- [utils/util.py::ComputeLoss.assign] PYTORCH ASSIGNMENT DEBUG ---
[utils/util.py::ComputeLoss.assign] pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] true_labels shape: torch.Size([4, 4, 1])
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 4, 4])
[utils/util.py::ComputeLoss.assign] true_mask shape: torch.Size([4, 4, 1])
[utils/util.py::ComputeLoss.assign] anchors shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.assign] Batch size: 4, Max boxes: 4
[utils/util.py::ComputeLoss.assign] Created indices tensor with shape: torch.Size([2, 4, 4])

--- [utils/util.py::ComputeLoss.assign] IOUs DEBUG ---
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 4, 4])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([4, 4, 1, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([4, 1, 512, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([4, 4, 1, 1]), h: torch.Size([4, 4, 1, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([4, 1, 512, 1]), h: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([4, 4, 512, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([4, 4, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([4, 4, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.000000, max: 0.574461
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([4, 4, 512, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([4, 4, 512, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([4, 4, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([4, 4, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: -0.983521, max: 0.569008
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.assign] overlaps shape: torch.Size([4, 4, 512])
[utils/util.py::ComputeLoss.assign] overlaps min: 0.0, max: 0.5690078735351562
[utils/util.py::ComputeLoss.assign] align_metric shape: torch.Size([4, 4, 512])
[utils/util.py::ComputeLoss.assign] align_metric min: 0.0, max: 0.002378108212724328
[utils/util.py::ComputeLoss.assign] mask_in_gts shape: torch.Size([4, 4, 512])
[utils/util.py::ComputeLoss.assign] mask_in_gts sum: 38.0
[utils/util.py::ComputeLoss.assign] metrics shape: torch.Size([4, 4, 512])
[utils/util.py::ComputeLoss.assign] top_k_mask shape: torch.Size([4, 4, 10])
[utils/util.py::ComputeLoss.assign] top_k_metrics shape: torch.Size([4, 4, 10])
[utils/util.py::ComputeLoss.assign] top_k_indices shape: torch.Size([4, 4, 10])
[utils/util.py::ComputeLoss.assign] is_in_top_k shape: torch.Size([4, 4, 512])
[utils/util.py::ComputeLoss.assign] mask_top_k shape: torch.Size([4, 4, 512])
[utils/util.py::ComputeLoss.assign] mask_pos shape: torch.Size([4, 4, 512])
[utils/util.py::ComputeLoss.assign] fg_mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] fg_mask sum: 38.0
[utils/util.py::ComputeLoss.assign] target_gt_idx shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_labels shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] Normalized target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] target_scores sum: 4.767001152038574
--- [utils/util.py::ComputeLoss.assign] END PYTORCH ASSIGNMENT DEBUG ---

[utils/util.py::ComputeLoss.__call__] Target bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Target scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] FG mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.__call__] Target scores sum: 4.767001
[utils/util.py::ComputeLoss.__call__] Classification loss computed: 6.181821
[utils/util.py::ComputeLoss.__call__] Foreground count: 38
[utils/util.py::ComputeLoss.__call__] Weight shape: torch.Size([38, 1])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([38, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([38, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([38, 1]), h: torch.Size([38, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([38, 1]), h: torch.Size([38, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([38, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([38, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([38, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.214375, max: 0.574424
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([38, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([38, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([38, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([38, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: 0.132233, max: 0.568971
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.__call__] IoU values shape: torch.Size([38, 1])
[utils/util.py::ComputeLoss.__call__] Box loss computed: 0.529329
[utils/util.py::ComputeLoss.__call__] Target LT-RB shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.df_loss] PYTORCH DFL LOSS DEBUG ---
[utils/util.py::ComputeLoss.df_loss] pred_dist shape: torch.Size([152, 16])
[utils/util.py::ComputeLoss.df_loss] target shape: torch.Size([38, 4])
[utils/util.py::ComputeLoss.df_loss] DFL loss shape: torch.Size([38, 1])
[utils/util.py::ComputeLoss.df_loss] DFL loss mean: 1.762846
--- [utils/util.py::ComputeLoss.df_loss] END PYTORCH DFL LOSS DEBUG ---

[utils/util.py::ComputeLoss.__call__] DFL loss before weighting: 1.762846
[utils/util.py::ComputeLoss.__call__] DFL loss computed: 1.482895

--- [utils/util.py::ComputeLoss.__call__] LOSS COMPONENTS DEBUG ---
[utils/util.py::ComputeLoss.__call__] Raw loss_cls: 6.181821
[utils/util.py::ComputeLoss.__call__] Raw loss_box: 0.529329
[utils/util.py::ComputeLoss.__call__] Raw loss_dfl: 1.482895
[utils/util.py::ComputeLoss.__call__] Loss weights - cls: 0.5, box: 7.5, dfl: 1.5
[utils/util.py::ComputeLoss.__call__] target_scores_sum: 4.767001
[utils/util.py::ComputeLoss.__call__] fg_mask sum: 38
[utils/util.py::ComputeLoss.__call__] Weighted loss_cls: 3.090911
[utils/util.py::ComputeLoss.__call__] Weighted loss_box: 3.969964
[utils/util.py::ComputeLoss.__call__] Weighted loss_dfl: 2.224343
[utils/util.py::ComputeLoss.__call__] Total loss: 9.285217
--- [utils/util.py::ComputeLoss.__call__] END PYTORCH LOSS COMPUTATION DEBUG ---


--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([4, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: True
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([4, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - box shape: torch.Size([4, 64, 16, 32]), cls shape: torch.Size([4, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - final concat shape: torch.Size([4, 65, 16, 32])

--- [utils/util.py::ComputeLoss.__call__] PYTORCH LOSS COMPUTATION DEBUG ---
[utils/util.py::ComputeLoss.__call__] Outputs type: <class 'list'>
[utils/util.py::ComputeLoss.__call__] x type: <class 'list'>, len: 1
[utils/util.py::ComputeLoss.__call__] x[0] shape: torch.Size([4, 65, 16, 32])
[utils/util.py::ComputeLoss.__call__] Concatenated output shape: torch.Size([4, 65, 512])
[utils/util.py::ComputeLoss.__call__] self.no: 65, self.dfl_ch: 16, self.nc: 1
[utils/util.py::ComputeLoss.__call__] pred_output shape: torch.Size([4, 64, 512])
[utils/util.py::ComputeLoss.__call__] pred_scores shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.__call__] After permute - pred_output shape: torch.Size([4, 512, 64])
[utils/util.py::ComputeLoss.__call__] After permute - pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Size tensor: tensor([128., 256.], device='cuda:0', dtype=torch.float16)
[utils/util.py::ComputeLoss.__call__] Stride: tensor([8.])
[utils/util.py::ComputeLoss.__call__] Anchor points shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.__call__] Stride tensor shape: torch.Size([512, 1])

--- [utils/util.py::ComputeLoss.__call__] TARGET PROCESSING ---
[utils/util.py::ComputeLoss.__call__] Targets shape: torch.Size([6, 6])
[utils/util.py::ComputeLoss.__call__] Targets dtype: torch.float32
[utils/util.py::ComputeLoss.__call__] First few targets: tensor([[0.0000, 0.0000, 0.4544, 0.0185, 0.0466, 0.0369],
        [0.0000, 0.0000, 0.4814, 0.7180, 0.0499, 0.0910],
        [1.0000, 0.0000, 0.8139, 0.3476, 0.1163, 0.2365],
        [3.0000, 0.0000, 0.4501, 0.0262, 0.0880, 0.0523],
        [3.0000, 0.0000, 0.2810, 0.7548, 0.0882, 0.1701]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Image indices: tensor([0., 0., 1., 3., 3., 3.], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Counts per image: tensor([2, 1, 3], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT tensor shape: torch.Size([4, 3, 5])
[utils/util.py::ComputeLoss.__call__] Image 0: 2 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 1: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 3: 3 targets assigned
[utils/util.py::ComputeLoss.__call__] GT before coordinate conversion: tensor([[[0.0000, 0.4544, 0.0185, 0.0466, 0.0369],
         [0.0000, 0.4814, 0.7180, 0.0499, 0.0910],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.8139, 0.3476, 0.1163, 0.2365],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.4501, 0.0262, 0.0880, 0.0523],
         [0.0000, 0.2810, 0.7548, 0.0882, 0.1701],
         [0.0000, 0.8201, 0.7093, 0.0724, 0.1422]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT after coordinate conversion: tensor([[[  0.0000, 110.3725,   0.0000, 122.2950,   4.7267],
         [  0.0000, 116.8368,  86.0863, 129.6155,  97.7305],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000, 193.4700,  29.3580, 223.2435,  59.6248],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000, 103.9596,   0.0000, 126.4811,   6.7006],
         [  0.0000,  60.6383,  85.7232,  83.2162, 107.4948],
         [  0.0000, 200.6616,  81.6915, 219.2077,  99.8990]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT labels shape: torch.Size([4, 3, 1])
[utils/util.py::ComputeLoss.__call__] GT bboxes shape: torch.Size([4, 3, 4])
[utils/util.py::ComputeLoss.__call__] GT mask shape: torch.Size([4, 3, 1])
[utils/util.py::ComputeLoss.__call__] Pred output dimensions - b: 4, a: 512, c: 64
[utils/util.py::ComputeLoss.__call__] Pred bboxes after softmax shape: torch.Size([4, 512, 4, 16])
[utils/util.py::ComputeLoss.__call__] Pred bboxes after matmul shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Final pred bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.__call__] ASSIGNMENT PHASE ---

--- [utils/util.py::ComputeLoss.assign] PYTORCH ASSIGNMENT DEBUG ---
[utils/util.py::ComputeLoss.assign] pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] true_labels shape: torch.Size([4, 3, 1])
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 3, 4])
[utils/util.py::ComputeLoss.assign] true_mask shape: torch.Size([4, 3, 1])
[utils/util.py::ComputeLoss.assign] anchors shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.assign] Batch size: 4, Max boxes: 3
[utils/util.py::ComputeLoss.assign] Created indices tensor with shape: torch.Size([2, 4, 3])

--- [utils/util.py::ComputeLoss.assign] IOUs DEBUG ---
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 3, 4])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([4, 3, 1, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([4, 1, 512, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([4, 3, 1, 1]), h: torch.Size([4, 3, 1, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([4, 1, 512, 1]), h: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.000000, max: 0.690760
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: -1.043878, max: 0.689431
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.assign] overlaps shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] overlaps min: 0.0, max: 0.6894313097000122
[utils/util.py::ComputeLoss.assign] align_metric shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] align_metric min: 0.0, max: 0.0060594468377530575
[utils/util.py::ComputeLoss.assign] mask_in_gts shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] mask_in_gts sum: 25.0
[utils/util.py::ComputeLoss.assign] metrics shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] top_k_mask shape: torch.Size([4, 3, 10])
[utils/util.py::ComputeLoss.assign] top_k_metrics shape: torch.Size([4, 3, 10])
[utils/util.py::ComputeLoss.assign] top_k_indices shape: torch.Size([4, 3, 10])
[utils/util.py::ComputeLoss.assign] is_in_top_k shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] mask_top_k shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] mask_pos shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] fg_mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] fg_mask sum: 23.0
[utils/util.py::ComputeLoss.assign] target_gt_idx shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_labels shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] Normalized target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] target_scores sum: 3.3673288822174072
--- [utils/util.py::ComputeLoss.assign] END PYTORCH ASSIGNMENT DEBUG ---

[utils/util.py::ComputeLoss.__call__] Target bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Target scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] FG mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.__call__] Target scores sum: 3.367329
[utils/util.py::ComputeLoss.__call__] Classification loss computed: 5.944066
[utils/util.py::ComputeLoss.__call__] Foreground count: 23
[utils/util.py::ComputeLoss.__call__] Weight shape: torch.Size([23, 1])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([23, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([23, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([23, 1]), h: torch.Size([23, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([23, 1]), h: torch.Size([23, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([23, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([23, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([23, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.074394, max: 0.690647
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([23, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([23, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([23, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([23, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: 0.057218, max: 0.689318
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.__call__] IoU values shape: torch.Size([23, 1])
[utils/util.py::ComputeLoss.__call__] Box loss computed: 0.456171
[utils/util.py::ComputeLoss.__call__] Target LT-RB shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.df_loss] PYTORCH DFL LOSS DEBUG ---
[utils/util.py::ComputeLoss.df_loss] pred_dist shape: torch.Size([92, 16])
[utils/util.py::ComputeLoss.df_loss] target shape: torch.Size([23, 4])
[utils/util.py::ComputeLoss.df_loss] DFL loss shape: torch.Size([23, 1])
[utils/util.py::ComputeLoss.df_loss] DFL loss mean: 1.724089
--- [utils/util.py::ComputeLoss.df_loss] END PYTORCH DFL LOSS DEBUG ---

[utils/util.py::ComputeLoss.__call__] DFL loss before weighting: 1.724089
[utils/util.py::ComputeLoss.__call__] DFL loss computed: 1.361361

--- [utils/util.py::ComputeLoss.__call__] LOSS COMPONENTS DEBUG ---
[utils/util.py::ComputeLoss.__call__] Raw loss_cls: 5.944066
[utils/util.py::ComputeLoss.__call__] Raw loss_box: 0.456171
[utils/util.py::ComputeLoss.__call__] Raw loss_dfl: 1.361361
[utils/util.py::ComputeLoss.__call__] Loss weights - cls: 0.5, box: 7.5, dfl: 1.5
[utils/util.py::ComputeLoss.__call__] target_scores_sum: 3.367329
[utils/util.py::ComputeLoss.__call__] fg_mask sum: 23
[utils/util.py::ComputeLoss.__call__] Weighted loss_cls: 2.972033
[utils/util.py::ComputeLoss.__call__] Weighted loss_box: 3.421283
[utils/util.py::ComputeLoss.__call__] Weighted loss_dfl: 2.042042
[utils/util.py::ComputeLoss.__call__] Total loss: 8.435358
--- [utils/util.py::ComputeLoss.__call__] END PYTORCH LOSS COMPUTATION DEBUG ---


--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([4, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: True
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([4, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - box shape: torch.Size([4, 64, 16, 32]), cls shape: torch.Size([4, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - final concat shape: torch.Size([4, 65, 16, 32])

--- [utils/util.py::ComputeLoss.__call__] PYTORCH LOSS COMPUTATION DEBUG ---
[utils/util.py::ComputeLoss.__call__] Outputs type: <class 'list'>
[utils/util.py::ComputeLoss.__call__] x type: <class 'list'>, len: 1
[utils/util.py::ComputeLoss.__call__] x[0] shape: torch.Size([4, 65, 16, 32])
[utils/util.py::ComputeLoss.__call__] Concatenated output shape: torch.Size([4, 65, 512])
[utils/util.py::ComputeLoss.__call__] self.no: 65, self.dfl_ch: 16, self.nc: 1
[utils/util.py::ComputeLoss.__call__] pred_output shape: torch.Size([4, 64, 512])
[utils/util.py::ComputeLoss.__call__] pred_scores shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.__call__] After permute - pred_output shape: torch.Size([4, 512, 64])
[utils/util.py::ComputeLoss.__call__] After permute - pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Size tensor: tensor([128., 256.], device='cuda:0', dtype=torch.float16)
[utils/util.py::ComputeLoss.__call__] Stride: tensor([8.])
[utils/util.py::ComputeLoss.__call__] Anchor points shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.__call__] Stride tensor shape: torch.Size([512, 1])

--- [utils/util.py::ComputeLoss.__call__] TARGET PROCESSING ---
[utils/util.py::ComputeLoss.__call__] Targets shape: torch.Size([5, 6])
[utils/util.py::ComputeLoss.__call__] Targets dtype: torch.float32
[utils/util.py::ComputeLoss.__call__] First few targets: tensor([[0.0000, 0.0000, 0.2247, 0.4589, 0.0557, 0.1256],
        [0.0000, 0.0000, 0.4269, 0.4751, 0.0666, 0.1259],
        [2.0000, 0.0000, 0.9653, 0.0777, 0.0695, 0.1555],
        [2.0000, 0.0000, 0.1471, 0.0767, 0.0728, 0.1450],
        [3.0000, 0.0000, 0.3043, 0.4850, 0.1074, 0.2223]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Image indices: tensor([0., 0., 2., 2., 3.], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Counts per image: tensor([2, 2, 1], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT tensor shape: torch.Size([4, 2, 5])
[utils/util.py::ComputeLoss.__call__] Image 0: 2 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 2: 2 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 3: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] GT before coordinate conversion: tensor([[[0.0000, 0.2247, 0.4589, 0.0557, 0.1256],
         [0.0000, 0.4269, 0.4751, 0.0666, 0.1259]],

        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.9653, 0.0777, 0.0695, 0.1555],
         [0.0000, 0.1471, 0.0767, 0.0728, 0.1450]],

        [[0.0000, 0.3043, 0.4850, 0.1074, 0.2223],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT after coordinate conversion: tensor([[[  0.0000,  50.4058,  50.6930,  64.6549,  66.7740],
         [  0.0000, 100.7567,  52.7520, 117.7956,  68.8680]],

        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000, 238.2137,   0.0000, 256.0000,  19.9024],
         [  0.0000,  28.3389,   0.5294,  46.9774,  19.0952]],

        [[  0.0000,  64.1613,  47.8541,  91.6500,  76.3078],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT labels shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.__call__] GT bboxes shape: torch.Size([4, 2, 4])
[utils/util.py::ComputeLoss.__call__] GT mask shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.__call__] Pred output dimensions - b: 4, a: 512, c: 64
[utils/util.py::ComputeLoss.__call__] Pred bboxes after softmax shape: torch.Size([4, 512, 4, 16])
[utils/util.py::ComputeLoss.__call__] Pred bboxes after matmul shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Final pred bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.__call__] ASSIGNMENT PHASE ---

--- [utils/util.py::ComputeLoss.assign] PYTORCH ASSIGNMENT DEBUG ---
[utils/util.py::ComputeLoss.assign] pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] true_labels shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 2, 4])
[utils/util.py::ComputeLoss.assign] true_mask shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.assign] anchors shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.assign] Batch size: 4, Max boxes: 2
[utils/util.py::ComputeLoss.assign] Created indices tensor with shape: torch.Size([2, 4, 2])

--- [utils/util.py::ComputeLoss.assign] IOUs DEBUG ---
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 2, 4])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([4, 2, 1, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([4, 1, 512, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([4, 2, 1, 1]), h: torch.Size([4, 2, 1, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([4, 1, 512, 1]), h: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.000000, max: 0.709808
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: -1.000288, max: 0.708069
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.assign] overlaps shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] overlaps min: 0.0, max: 0.7080693244934082
[utils/util.py::ComputeLoss.assign] align_metric shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] align_metric min: 0.0, max: 0.0106148486956954
[utils/util.py::ComputeLoss.assign] mask_in_gts shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] mask_in_gts sum: 28.0
[utils/util.py::ComputeLoss.assign] metrics shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] top_k_mask shape: torch.Size([4, 2, 10])
[utils/util.py::ComputeLoss.assign] top_k_metrics shape: torch.Size([4, 2, 10])
[utils/util.py::ComputeLoss.assign] top_k_indices shape: torch.Size([4, 2, 10])
[utils/util.py::ComputeLoss.assign] is_in_top_k shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] mask_top_k shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] mask_pos shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] fg_mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] fg_mask sum: 26.0
[utils/util.py::ComputeLoss.assign] target_gt_idx shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_labels shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] Normalized target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] target_scores sum: 3.8446407318115234
--- [utils/util.py::ComputeLoss.assign] END PYTORCH ASSIGNMENT DEBUG ---

[utils/util.py::ComputeLoss.__call__] Target bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Target scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] FG mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.__call__] Target scores sum: 3.844641
[utils/util.py::ComputeLoss.__call__] Classification loss computed: 5.953905
[utils/util.py::ComputeLoss.__call__] Foreground count: 26
[utils/util.py::ComputeLoss.__call__] Weight shape: torch.Size([26, 1])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([26, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([26, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([26, 1]), h: torch.Size([26, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([26, 1]), h: torch.Size([26, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([26, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([26, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([26, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.215585, max: 0.709971
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([26, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([26, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([26, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([26, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: 0.137092, max: 0.708232
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.__call__] IoU values shape: torch.Size([26, 1])
[utils/util.py::ComputeLoss.__call__] Box loss computed: 0.530560
[utils/util.py::ComputeLoss.__call__] Target LT-RB shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.df_loss] PYTORCH DFL LOSS DEBUG ---
[utils/util.py::ComputeLoss.df_loss] pred_dist shape: torch.Size([104, 16])
[utils/util.py::ComputeLoss.df_loss] target shape: torch.Size([26, 4])
[utils/util.py::ComputeLoss.df_loss] DFL loss shape: torch.Size([26, 1])
[utils/util.py::ComputeLoss.df_loss] DFL loss mean: 1.689330
--- [utils/util.py::ComputeLoss.df_loss] END PYTORCH DFL LOSS DEBUG ---

[utils/util.py::ComputeLoss.__call__] DFL loss before weighting: 1.689330
[utils/util.py::ComputeLoss.__call__] DFL loss computed: 1.276313

--- [utils/util.py::ComputeLoss.__call__] LOSS COMPONENTS DEBUG ---
[utils/util.py::ComputeLoss.__call__] Raw loss_cls: 5.953905
[utils/util.py::ComputeLoss.__call__] Raw loss_box: 0.530560
[utils/util.py::ComputeLoss.__call__] Raw loss_dfl: 1.276313
[utils/util.py::ComputeLoss.__call__] Loss weights - cls: 0.5, box: 7.5, dfl: 1.5
[utils/util.py::ComputeLoss.__call__] target_scores_sum: 3.844641
[utils/util.py::ComputeLoss.__call__] fg_mask sum: 26
[utils/util.py::ComputeLoss.__call__] Weighted loss_cls: 2.976952
[utils/util.py::ComputeLoss.__call__] Weighted loss_box: 3.979197
[utils/util.py::ComputeLoss.__call__] Weighted loss_dfl: 1.914470
[utils/util.py::ComputeLoss.__call__] Total loss: 8.870619
--- [utils/util.py::ComputeLoss.__call__] END PYTORCH LOSS COMPUTATION DEBUG ---


--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([4, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: True
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([4, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - box shape: torch.Size([4, 64, 16, 32]), cls shape: torch.Size([4, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - final concat shape: torch.Size([4, 65, 16, 32])

--- [utils/util.py::ComputeLoss.__call__] PYTORCH LOSS COMPUTATION DEBUG ---
[utils/util.py::ComputeLoss.__call__] Outputs type: <class 'list'>
[utils/util.py::ComputeLoss.__call__] x type: <class 'list'>, len: 1
[utils/util.py::ComputeLoss.__call__] x[0] shape: torch.Size([4, 65, 16, 32])
[utils/util.py::ComputeLoss.__call__] Concatenated output shape: torch.Size([4, 65, 512])
[utils/util.py::ComputeLoss.__call__] self.no: 65, self.dfl_ch: 16, self.nc: 1
[utils/util.py::ComputeLoss.__call__] pred_output shape: torch.Size([4, 64, 512])
[utils/util.py::ComputeLoss.__call__] pred_scores shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.__call__] After permute - pred_output shape: torch.Size([4, 512, 64])
[utils/util.py::ComputeLoss.__call__] After permute - pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Size tensor: tensor([128., 256.], device='cuda:0', dtype=torch.float16)
[utils/util.py::ComputeLoss.__call__] Stride: tensor([8.])
[utils/util.py::ComputeLoss.__call__] Anchor points shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.__call__] Stride tensor shape: torch.Size([512, 1])

--- [utils/util.py::ComputeLoss.__call__] TARGET PROCESSING ---
[utils/util.py::ComputeLoss.__call__] Targets shape: torch.Size([7, 6])
[utils/util.py::ComputeLoss.__call__] Targets dtype: torch.float32
[utils/util.py::ComputeLoss.__call__] First few targets: tensor([[0.0000, 0.0000, 0.0563, 0.2654, 0.0940, 0.2013],
        [0.0000, 0.0000, 0.8860, 0.2977, 0.1094, 0.2127],
        [2.0000, 0.0000, 0.2931, 0.0215, 0.0742, 0.0431],
        [2.0000, 0.0000, 0.8194, 0.8493, 0.0862, 0.1838],
        [3.0000, 0.0000, 0.2223, 0.2984, 0.0927, 0.1823]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Image indices: tensor([0., 0., 2., 2., 3., 3., 3.], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Counts per image: tensor([2, 2, 3], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT tensor shape: torch.Size([4, 3, 5])
[utils/util.py::ComputeLoss.__call__] Image 0: 2 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 2: 2 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 3: 3 targets assigned
[utils/util.py::ComputeLoss.__call__] GT before coordinate conversion: tensor([[[0.0000, 0.0563, 0.2654, 0.0940, 0.2013],
         [0.0000, 0.8860, 0.2977, 0.1094, 0.2127],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.2931, 0.0215, 0.0742, 0.0431],
         [0.0000, 0.8194, 0.8493, 0.0862, 0.1838],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.2223, 0.2984, 0.0927, 0.1823],
         [0.0000, 0.8923, 0.9606, 0.0741, 0.0788],
         [0.0000, 0.1880, 0.9673, 0.0713, 0.0654]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT after coordinate conversion: tensor([[[  0.0000,   2.3921,  21.0871,  26.4494,  46.8571],
         [  0.0000, 212.8111,  24.4899, 240.8269,  51.7117],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000,  65.5338,   0.0000,  84.5299,   5.5158],
         [  0.0000, 198.7409,  96.9422, 220.8112, 120.4661],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000,  45.0444,  26.5243,  68.7787,  49.8626],
         [  0.0000, 218.9372, 117.9106, 237.9109, 127.9990],
         [  0.0000,  39.0097, 119.6324,  57.2688, 127.9990]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT labels shape: torch.Size([4, 3, 1])
[utils/util.py::ComputeLoss.__call__] GT bboxes shape: torch.Size([4, 3, 4])
[utils/util.py::ComputeLoss.__call__] GT mask shape: torch.Size([4, 3, 1])
[utils/util.py::ComputeLoss.__call__] Pred output dimensions - b: 4, a: 512, c: 64
[utils/util.py::ComputeLoss.__call__] Pred bboxes after softmax shape: torch.Size([4, 512, 4, 16])
[utils/util.py::ComputeLoss.__call__] Pred bboxes after matmul shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Final pred bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.__call__] ASSIGNMENT PHASE ---

--- [utils/util.py::ComputeLoss.assign] PYTORCH ASSIGNMENT DEBUG ---
[utils/util.py::ComputeLoss.assign] pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] true_labels shape: torch.Size([4, 3, 1])
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 3, 4])
[utils/util.py::ComputeLoss.assign] true_mask shape: torch.Size([4, 3, 1])
[utils/util.py::ComputeLoss.assign] anchors shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.assign] Batch size: 4, Max boxes: 3
[utils/util.py::ComputeLoss.assign] Created indices tensor with shape: torch.Size([2, 4, 3])

--- [utils/util.py::ComputeLoss.assign] IOUs DEBUG ---
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 3, 4])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([4, 3, 1, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([4, 1, 512, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([4, 3, 1, 1]), h: torch.Size([4, 3, 1, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([4, 1, 512, 1]), h: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.000000, max: 0.796205
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: -1.021984, max: 0.794496
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.assign] overlaps shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] overlaps min: 0.0, max: 0.7944958806037903
[utils/util.py::ComputeLoss.assign] align_metric shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] align_metric min: 0.0, max: 0.016486719250679016
[utils/util.py::ComputeLoss.assign] mask_in_gts shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] mask_in_gts sum: 44.0
[utils/util.py::ComputeLoss.assign] metrics shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] top_k_mask shape: torch.Size([4, 3, 10])
[utils/util.py::ComputeLoss.assign] top_k_metrics shape: torch.Size([4, 3, 10])
[utils/util.py::ComputeLoss.assign] top_k_indices shape: torch.Size([4, 3, 10])
[utils/util.py::ComputeLoss.assign] is_in_top_k shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] mask_top_k shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] mask_pos shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] fg_mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] fg_mask sum: 44.0
[utils/util.py::ComputeLoss.assign] target_gt_idx shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_labels shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] Normalized target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] target_scores sum: 4.258657455444336
--- [utils/util.py::ComputeLoss.assign] END PYTORCH ASSIGNMENT DEBUG ---

[utils/util.py::ComputeLoss.__call__] Target bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Target scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] FG mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.__call__] Target scores sum: 4.258657
[utils/util.py::ComputeLoss.__call__] Classification loss computed: 6.101542
[utils/util.py::ComputeLoss.__call__] Foreground count: 44
[utils/util.py::ComputeLoss.__call__] Weight shape: torch.Size([44, 1])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([44, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([44, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([44, 1]), h: torch.Size([44, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([44, 1]), h: torch.Size([44, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([44, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([44, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([44, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.095967, max: 0.796434
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([44, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([44, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([44, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([44, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: 0.038535, max: 0.794724
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.__call__] IoU values shape: torch.Size([44, 1])
[utils/util.py::ComputeLoss.__call__] Box loss computed: 0.375401
[utils/util.py::ComputeLoss.__call__] Target LT-RB shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.df_loss] PYTORCH DFL LOSS DEBUG ---
[utils/util.py::ComputeLoss.df_loss] pred_dist shape: torch.Size([176, 16])
[utils/util.py::ComputeLoss.df_loss] target shape: torch.Size([44, 4])
[utils/util.py::ComputeLoss.df_loss] DFL loss shape: torch.Size([44, 1])
[utils/util.py::ComputeLoss.df_loss] DFL loss mean: 1.828108
--- [utils/util.py::ComputeLoss.df_loss] END PYTORCH DFL LOSS DEBUG ---

[utils/util.py::ComputeLoss.__call__] DFL loss before weighting: 1.828108
[utils/util.py::ComputeLoss.__call__] DFL loss computed: 1.234464

--- [utils/util.py::ComputeLoss.__call__] LOSS COMPONENTS DEBUG ---
[utils/util.py::ComputeLoss.__call__] Raw loss_cls: 6.101542
[utils/util.py::ComputeLoss.__call__] Raw loss_box: 0.375401
[utils/util.py::ComputeLoss.__call__] Raw loss_dfl: 1.234464
[utils/util.py::ComputeLoss.__call__] Loss weights - cls: 0.5, box: 7.5, dfl: 1.5
[utils/util.py::ComputeLoss.__call__] target_scores_sum: 4.258657
[utils/util.py::ComputeLoss.__call__] fg_mask sum: 44
[utils/util.py::ComputeLoss.__call__] Weighted loss_cls: 3.050771
[utils/util.py::ComputeLoss.__call__] Weighted loss_box: 2.815510
[utils/util.py::ComputeLoss.__call__] Weighted loss_dfl: 1.851696
[utils/util.py::ComputeLoss.__call__] Total loss: 7.717976
--- [utils/util.py::ComputeLoss.__call__] END PYTORCH LOSS COMPUTATION DEBUG ---


--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([4, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: True
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([4, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - box shape: torch.Size([4, 64, 16, 32]), cls shape: torch.Size([4, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - final concat shape: torch.Size([4, 65, 16, 32])

--- [utils/util.py::ComputeLoss.__call__] PYTORCH LOSS COMPUTATION DEBUG ---
[utils/util.py::ComputeLoss.__call__] Outputs type: <class 'list'>
[utils/util.py::ComputeLoss.__call__] x type: <class 'list'>, len: 1
[utils/util.py::ComputeLoss.__call__] x[0] shape: torch.Size([4, 65, 16, 32])
[utils/util.py::ComputeLoss.__call__] Concatenated output shape: torch.Size([4, 65, 512])
[utils/util.py::ComputeLoss.__call__] self.no: 65, self.dfl_ch: 16, self.nc: 1
[utils/util.py::ComputeLoss.__call__] pred_output shape: torch.Size([4, 64, 512])
[utils/util.py::ComputeLoss.__call__] pred_scores shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.__call__] After permute - pred_output shape: torch.Size([4, 512, 64])
[utils/util.py::ComputeLoss.__call__] After permute - pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Size tensor: tensor([128., 256.], device='cuda:0', dtype=torch.float16)
[utils/util.py::ComputeLoss.__call__] Stride: tensor([8.])
[utils/util.py::ComputeLoss.__call__] Anchor points shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.__call__] Stride tensor shape: torch.Size([512, 1])

--- [utils/util.py::ComputeLoss.__call__] TARGET PROCESSING ---
[utils/util.py::ComputeLoss.__call__] Targets shape: torch.Size([10, 6])
[utils/util.py::ComputeLoss.__call__] Targets dtype: torch.float32
[utils/util.py::ComputeLoss.__call__] First few targets: tensor([[0.0000, 0.0000, 0.9846, 0.0785, 0.0309, 0.1373],
        [0.0000, 0.0000, 0.3554, 0.1698, 0.0633, 0.1298],
        [0.0000, 0.0000, 0.7183, 0.8220, 0.0644, 0.1258],
        [0.0000, 0.0000, 0.0323, 0.9368, 0.0647, 0.1265],
        [1.0000, 0.0000, 0.1017, 0.5229, 0.0714, 0.1352]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Image indices: tensor([0., 0., 0., 0., 1., 2., 3., 3., 3., 3.], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Counts per image: tensor([4, 1, 1, 4], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT tensor shape: torch.Size([4, 4, 5])
[utils/util.py::ComputeLoss.__call__] Image 0: 4 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 1: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 2: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 3: 4 targets assigned
[utils/util.py::ComputeLoss.__call__] GT before coordinate conversion: tensor([[[0.0000, 0.9846, 0.0785, 0.0309, 0.1373],
         [0.0000, 0.3554, 0.1698, 0.0633, 0.1298],
         [0.0000, 0.7183, 0.8220, 0.0644, 0.1258],
         [0.0000, 0.0323, 0.9368, 0.0647, 0.1265]],

        [[0.0000, 0.1017, 0.5229, 0.0714, 0.1352],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.5726, 0.7820, 0.1083, 0.2043],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.5069, 0.1072, 0.0542, 0.0964],
         [0.0000, 0.0088, 0.0838, 0.0175, 0.1223],
         [0.0000, 0.4456, 0.5784, 0.0555, 0.1083],
         [0.0000, 0.2254, 0.5460, 0.0554, 0.1087]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT after coordinate conversion: tensor([[[0.0000e+00, 2.4810e+02, 1.2677e+00, 2.5600e+02, 1.8837e+01],
         [0.0000e+00, 8.2872e+01, 1.3420e+01, 9.9087e+01, 3.0038e+01],
         [0.0000e+00, 1.7564e+02, 9.7168e+01, 1.9212e+02, 1.1327e+02],
         [0.0000e+00, 9.9945e-04, 1.1181e+02, 1.6555e+01, 1.2800e+02]],

        [[0.0000e+00, 1.6908e+01, 5.8276e+01, 3.5177e+01, 7.5583e+01],
         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],

        [[0.0000e+00, 1.3272e+02, 8.7024e+01, 1.6045e+02, 1.1317e+02],
         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],

        [[0.0000e+00, 1.2285e+02, 7.5491e+00, 1.3671e+02, 1.9894e+01],
         [0.0000e+00, 1.0071e-03, 2.8989e+00, 4.4798e+00, 1.8559e+01],
         [0.0000e+00, 1.0697e+02, 6.7109e+01, 1.2118e+02, 8.0973e+01],
         [0.0000e+00, 5.0615e+01, 6.2927e+01, 6.4803e+01, 7.6837e+01]]],
       device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT labels shape: torch.Size([4, 4, 1])
[utils/util.py::ComputeLoss.__call__] GT bboxes shape: torch.Size([4, 4, 4])
[utils/util.py::ComputeLoss.__call__] GT mask shape: torch.Size([4, 4, 1])
[utils/util.py::ComputeLoss.__call__] Pred output dimensions - b: 4, a: 512, c: 64
[utils/util.py::ComputeLoss.__call__] Pred bboxes after softmax shape: torch.Size([4, 512, 4, 16])
[utils/util.py::ComputeLoss.__call__] Pred bboxes after matmul shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Final pred bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.__call__] ASSIGNMENT PHASE ---

--- [utils/util.py::ComputeLoss.assign] PYTORCH ASSIGNMENT DEBUG ---
[utils/util.py::ComputeLoss.assign] pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] true_labels shape: torch.Size([4, 4, 1])
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 4, 4])
[utils/util.py::ComputeLoss.assign] true_mask shape: torch.Size([4, 4, 1])
[utils/util.py::ComputeLoss.assign] anchors shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.assign] Batch size: 4, Max boxes: 4
[utils/util.py::ComputeLoss.assign] Created indices tensor with shape: torch.Size([2, 4, 4])

--- [utils/util.py::ComputeLoss.assign] IOUs DEBUG ---
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 4, 4])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([4, 4, 1, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([4, 1, 512, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([4, 4, 1, 1]), h: torch.Size([4, 4, 1, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([4, 1, 512, 1]), h: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([4, 4, 512, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([4, 4, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([4, 4, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.000000, max: 0.757759
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([4, 4, 512, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([4, 4, 512, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([4, 4, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([4, 4, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: -0.973568, max: 0.756539
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.assign] overlaps shape: torch.Size([4, 4, 512])
[utils/util.py::ComputeLoss.assign] overlaps min: 0.0, max: 0.7565386295318604
[utils/util.py::ComputeLoss.assign] align_metric shape: torch.Size([4, 4, 512])
[utils/util.py::ComputeLoss.assign] align_metric min: 0.0, max: 0.012290540151298046
[utils/util.py::ComputeLoss.assign] mask_in_gts shape: torch.Size([4, 4, 512])
[utils/util.py::ComputeLoss.assign] mask_in_gts sum: 39.0
[utils/util.py::ComputeLoss.assign] metrics shape: torch.Size([4, 4, 512])
[utils/util.py::ComputeLoss.assign] top_k_mask shape: torch.Size([4, 4, 10])
[utils/util.py::ComputeLoss.assign] top_k_metrics shape: torch.Size([4, 4, 10])
[utils/util.py::ComputeLoss.assign] top_k_indices shape: torch.Size([4, 4, 10])
[utils/util.py::ComputeLoss.assign] is_in_top_k shape: torch.Size([4, 4, 512])
[utils/util.py::ComputeLoss.assign] mask_top_k shape: torch.Size([4, 4, 512])
[utils/util.py::ComputeLoss.assign] mask_pos shape: torch.Size([4, 4, 512])
[utils/util.py::ComputeLoss.assign] fg_mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] fg_mask sum: 39.0
[utils/util.py::ComputeLoss.assign] target_gt_idx shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_labels shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] Normalized target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] target_scores sum: 5.164046287536621
--- [utils/util.py::ComputeLoss.assign] END PYTORCH ASSIGNMENT DEBUG ---

[utils/util.py::ComputeLoss.__call__] Target bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Target scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] FG mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.__call__] Target scores sum: 5.164046
[utils/util.py::ComputeLoss.__call__] Classification loss computed: 6.287463
[utils/util.py::ComputeLoss.__call__] Foreground count: 39
[utils/util.py::ComputeLoss.__call__] Weight shape: torch.Size([39, 1])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([39, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([39, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([39, 1]), h: torch.Size([39, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([39, 1]), h: torch.Size([39, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([39, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([39, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([39, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.087135, max: 0.757531
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([39, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([39, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([39, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([39, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: 0.046391, max: 0.756310
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.__call__] IoU values shape: torch.Size([39, 1])
[utils/util.py::ComputeLoss.__call__] Box loss computed: 0.600869
[utils/util.py::ComputeLoss.__call__] Target LT-RB shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.df_loss] PYTORCH DFL LOSS DEBUG ---
[utils/util.py::ComputeLoss.df_loss] pred_dist shape: torch.Size([156, 16])
[utils/util.py::ComputeLoss.df_loss] target shape: torch.Size([39, 4])
[utils/util.py::ComputeLoss.df_loss] DFL loss shape: torch.Size([39, 1])
[utils/util.py::ComputeLoss.df_loss] DFL loss mean: 1.551559
--- [utils/util.py::ComputeLoss.df_loss] END PYTORCH DFL LOSS DEBUG ---

[utils/util.py::ComputeLoss.__call__] DFL loss before weighting: 1.551559
[utils/util.py::ComputeLoss.__call__] DFL loss computed: 1.249990

--- [utils/util.py::ComputeLoss.__call__] LOSS COMPONENTS DEBUG ---
[utils/util.py::ComputeLoss.__call__] Raw loss_cls: 6.287463
[utils/util.py::ComputeLoss.__call__] Raw loss_box: 0.600869
[utils/util.py::ComputeLoss.__call__] Raw loss_dfl: 1.249990
[utils/util.py::ComputeLoss.__call__] Loss weights - cls: 0.5, box: 7.5, dfl: 1.5
[utils/util.py::ComputeLoss.__call__] target_scores_sum: 5.164046
[utils/util.py::ComputeLoss.__call__] fg_mask sum: 39
[utils/util.py::ComputeLoss.__call__] Weighted loss_cls: 3.143732
[utils/util.py::ComputeLoss.__call__] Weighted loss_box: 4.506519
[utils/util.py::ComputeLoss.__call__] Weighted loss_dfl: 1.874985
[utils/util.py::ComputeLoss.__call__] Total loss: 9.525236
--- [utils/util.py::ComputeLoss.__call__] END PYTORCH LOSS COMPUTATION DEBUG ---


--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([4, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: True
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([4, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - box shape: torch.Size([4, 64, 16, 32]), cls shape: torch.Size([4, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - final concat shape: torch.Size([4, 65, 16, 32])

--- [utils/util.py::ComputeLoss.__call__] PYTORCH LOSS COMPUTATION DEBUG ---
[utils/util.py::ComputeLoss.__call__] Outputs type: <class 'list'>
[utils/util.py::ComputeLoss.__call__] x type: <class 'list'>, len: 1
[utils/util.py::ComputeLoss.__call__] x[0] shape: torch.Size([4, 65, 16, 32])
[utils/util.py::ComputeLoss.__call__] Concatenated output shape: torch.Size([4, 65, 512])
[utils/util.py::ComputeLoss.__call__] self.no: 65, self.dfl_ch: 16, self.nc: 1
[utils/util.py::ComputeLoss.__call__] pred_output shape: torch.Size([4, 64, 512])
[utils/util.py::ComputeLoss.__call__] pred_scores shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.__call__] After permute - pred_output shape: torch.Size([4, 512, 64])
[utils/util.py::ComputeLoss.__call__] After permute - pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Size tensor: tensor([128., 256.], device='cuda:0', dtype=torch.float16)
[utils/util.py::ComputeLoss.__call__] Stride: tensor([8.])
[utils/util.py::ComputeLoss.__call__] Anchor points shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.__call__] Stride tensor shape: torch.Size([512, 1])

--- [utils/util.py::ComputeLoss.__call__] TARGET PROCESSING ---
[utils/util.py::ComputeLoss.__call__] Targets shape: torch.Size([3, 6])
[utils/util.py::ComputeLoss.__call__] Targets dtype: torch.float32
[utils/util.py::ComputeLoss.__call__] First few targets: tensor([[1.0000, 0.0000, 0.7111, 0.3624, 0.1052, 0.2095],
        [3.0000, 0.0000, 0.8242, 0.1891, 0.0868, 0.1846],
        [3.0000, 0.0000, 0.8220, 0.9727, 0.0900, 0.0545]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Image indices: tensor([1., 3., 3.], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Counts per image: tensor([1, 2], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT tensor shape: torch.Size([4, 2, 5])
[utils/util.py::ComputeLoss.__call__] Image 1: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 3: 2 targets assigned
[utils/util.py::ComputeLoss.__call__] GT before coordinate conversion: tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.7111, 0.3624, 0.1052, 0.2095],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.8242, 0.1891, 0.0868, 0.1846],
         [0.0000, 0.8220, 0.9727, 0.0900, 0.0545]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT after coordinate conversion: tensor([[[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000, 168.5760,  32.9766, 195.5198,  59.7890],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000, 199.8746,  12.3915, 222.0925,  36.0175],
         [  0.0000, 198.9201, 121.0192, 221.9507, 127.9990]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT labels shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.__call__] GT bboxes shape: torch.Size([4, 2, 4])
[utils/util.py::ComputeLoss.__call__] GT mask shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.__call__] Pred output dimensions - b: 4, a: 512, c: 64
[utils/util.py::ComputeLoss.__call__] Pred bboxes after softmax shape: torch.Size([4, 512, 4, 16])
[utils/util.py::ComputeLoss.__call__] Pred bboxes after matmul shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Final pred bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.__call__] ASSIGNMENT PHASE ---

--- [utils/util.py::ComputeLoss.assign] PYTORCH ASSIGNMENT DEBUG ---
[utils/util.py::ComputeLoss.assign] pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] true_labels shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 2, 4])
[utils/util.py::ComputeLoss.assign] true_mask shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.assign] anchors shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.assign] Batch size: 4, Max boxes: 2
[utils/util.py::ComputeLoss.assign] Created indices tensor with shape: torch.Size([2, 4, 2])

--- [utils/util.py::ComputeLoss.assign] IOUs DEBUG ---
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 2, 4])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([4, 2, 1, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([4, 1, 512, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([4, 2, 1, 1]), h: torch.Size([4, 2, 1, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([4, 1, 512, 1]), h: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.000000, max: 0.725800
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: -0.999329, max: 0.717701
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.assign] overlaps shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] overlaps min: 0.0, max: 0.7177014350891113
[utils/util.py::ComputeLoss.assign] align_metric shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] align_metric min: 0.0, max: 0.008099574595689774
[utils/util.py::ComputeLoss.assign] mask_in_gts shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] mask_in_gts sum: 21.0
[utils/util.py::ComputeLoss.assign] metrics shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] top_k_mask shape: torch.Size([4, 2, 10])
[utils/util.py::ComputeLoss.assign] top_k_metrics shape: torch.Size([4, 2, 10])
[utils/util.py::ComputeLoss.assign] top_k_indices shape: torch.Size([4, 2, 10])
[utils/util.py::ComputeLoss.assign] is_in_top_k shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] mask_top_k shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] mask_pos shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] fg_mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] fg_mask sum: 21.0
[utils/util.py::ComputeLoss.assign] target_gt_idx shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_labels shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] Normalized target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] target_scores sum: 2.693892002105713
--- [utils/util.py::ComputeLoss.assign] END PYTORCH ASSIGNMENT DEBUG ---

[utils/util.py::ComputeLoss.__call__] Target bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Target scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] FG mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.__call__] Target scores sum: 2.693892
[utils/util.py::ComputeLoss.__call__] Classification loss computed: 6.699183
[utils/util.py::ComputeLoss.__call__] Foreground count: 21
[utils/util.py::ComputeLoss.__call__] Weight shape: torch.Size([21, 1])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([21, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([21, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([21, 1]), h: torch.Size([21, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([21, 1]), h: torch.Size([21, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([21, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([21, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([21, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.157789, max: 0.725764
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([21, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([21, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([21, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([21, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: 0.087467, max: 0.717666
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.__call__] IoU values shape: torch.Size([21, 1])
[utils/util.py::ComputeLoss.__call__] Box loss computed: 0.378271
[utils/util.py::ComputeLoss.__call__] Target LT-RB shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.df_loss] PYTORCH DFL LOSS DEBUG ---
[utils/util.py::ComputeLoss.df_loss] pred_dist shape: torch.Size([84, 16])
[utils/util.py::ComputeLoss.df_loss] target shape: torch.Size([21, 4])
[utils/util.py::ComputeLoss.df_loss] DFL loss shape: torch.Size([21, 1])
[utils/util.py::ComputeLoss.df_loss] DFL loss mean: 1.880181
--- [utils/util.py::ComputeLoss.df_loss] END PYTORCH DFL LOSS DEBUG ---

[utils/util.py::ComputeLoss.__call__] DFL loss before weighting: 1.880181
[utils/util.py::ComputeLoss.__call__] DFL loss computed: 1.195994

--- [utils/util.py::ComputeLoss.__call__] LOSS COMPONENTS DEBUG ---
[utils/util.py::ComputeLoss.__call__] Raw loss_cls: 6.699183
[utils/util.py::ComputeLoss.__call__] Raw loss_box: 0.378271
[utils/util.py::ComputeLoss.__call__] Raw loss_dfl: 1.195994
[utils/util.py::ComputeLoss.__call__] Loss weights - cls: 0.5, box: 7.5, dfl: 1.5
[utils/util.py::ComputeLoss.__call__] target_scores_sum: 2.693892
[utils/util.py::ComputeLoss.__call__] fg_mask sum: 21
[utils/util.py::ComputeLoss.__call__] Weighted loss_cls: 3.349591
[utils/util.py::ComputeLoss.__call__] Weighted loss_box: 2.837030
[utils/util.py::ComputeLoss.__call__] Weighted loss_dfl: 1.793991
[utils/util.py::ComputeLoss.__call__] Total loss: 7.980613
--- [utils/util.py::ComputeLoss.__call__] END PYTORCH LOSS COMPUTATION DEBUG ---


--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([4, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: True
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([4, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - box shape: torch.Size([4, 64, 16, 32]), cls shape: torch.Size([4, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - final concat shape: torch.Size([4, 65, 16, 32])

--- [utils/util.py::ComputeLoss.__call__] PYTORCH LOSS COMPUTATION DEBUG ---
[utils/util.py::ComputeLoss.__call__] Outputs type: <class 'list'>
[utils/util.py::ComputeLoss.__call__] x type: <class 'list'>, len: 1
[utils/util.py::ComputeLoss.__call__] x[0] shape: torch.Size([4, 65, 16, 32])
[utils/util.py::ComputeLoss.__call__] Concatenated output shape: torch.Size([4, 65, 512])
[utils/util.py::ComputeLoss.__call__] self.no: 65, self.dfl_ch: 16, self.nc: 1
[utils/util.py::ComputeLoss.__call__] pred_output shape: torch.Size([4, 64, 512])
[utils/util.py::ComputeLoss.__call__] pred_scores shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.__call__] After permute - pred_output shape: torch.Size([4, 512, 64])
[utils/util.py::ComputeLoss.__call__] After permute - pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Size tensor: tensor([128., 256.], device='cuda:0', dtype=torch.float16)
[utils/util.py::ComputeLoss.__call__] Stride: tensor([8.])
[utils/util.py::ComputeLoss.__call__] Anchor points shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.__call__] Stride tensor shape: torch.Size([512, 1])

--- [utils/util.py::ComputeLoss.__call__] TARGET PROCESSING ---
[utils/util.py::ComputeLoss.__call__] Targets shape: torch.Size([9, 6])
[utils/util.py::ComputeLoss.__call__] Targets dtype: torch.float32
[utils/util.py::ComputeLoss.__call__] First few targets: tensor([[0.0000, 0.0000, 0.9040, 0.8608, 0.1483, 0.2784],
        [1.0000, 0.0000, 0.9609, 0.1767, 0.0550, 0.1082],
        [1.0000, 0.0000, 0.3801, 0.1152, 0.0590, 0.0738],
        [1.0000, 0.0000, 0.5283, 0.9243, 0.0654, 0.1377],
        [2.0000, 0.0000, 0.4117, 0.3931, 0.0800, 0.1561]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Image indices: tensor([0., 1., 1., 1., 2., 2., 3., 3., 3.], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Counts per image: tensor([1, 3, 2, 3], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT tensor shape: torch.Size([4, 3, 5])
[utils/util.py::ComputeLoss.__call__] Image 0: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 1: 3 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 2: 2 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 3: 3 targets assigned
[utils/util.py::ComputeLoss.__call__] GT before coordinate conversion: tensor([[[0.0000, 0.9040, 0.8608, 0.1483, 0.2784],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.9609, 0.1767, 0.0550, 0.1082],
         [0.0000, 0.3801, 0.1152, 0.0590, 0.0738],
         [0.0000, 0.5283, 0.9243, 0.0654, 0.1377]],

        [[0.0000, 0.4117, 0.3931, 0.0800, 0.1561],
         [0.0000, 0.1354, 0.1749, 0.0899, 0.1762],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.4963, 0.2206, 0.0503, 0.1032],
         [0.0000, 0.0152, 0.8996, 0.0304, 0.1225],
         [0.0000, 0.2338, 0.8078, 0.0547, 0.1050]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT after coordinate conversion: tensor([[[  0.0000, 212.4432,  92.3615, 250.4181, 127.9990],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000, 238.9413,  15.6945, 253.0180,  29.5445],
         [  0.0000,  89.7384,  10.0286, 104.8475,  19.4718],
         [  0.0000, 126.8849, 109.4971, 143.6246, 127.1245]],

        [[  0.0000,  95.1665,  40.3201, 115.6447,  60.3019],
         [  0.0000,  23.1647,  11.1063,  46.1723,  33.6642],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000, 120.6247,  21.6365, 133.5049,  34.8415],
         [  0.0000,   0.0000, 107.3150,   7.7830, 122.9897],
         [  0.0000,  52.8637,  96.6721,  66.8639, 110.1123]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT labels shape: torch.Size([4, 3, 1])
[utils/util.py::ComputeLoss.__call__] GT bboxes shape: torch.Size([4, 3, 4])
[utils/util.py::ComputeLoss.__call__] GT mask shape: torch.Size([4, 3, 1])
[utils/util.py::ComputeLoss.__call__] Pred output dimensions - b: 4, a: 512, c: 64
[utils/util.py::ComputeLoss.__call__] Pred bboxes after softmax shape: torch.Size([4, 512, 4, 16])
[utils/util.py::ComputeLoss.__call__] Pred bboxes after matmul shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Final pred bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.__call__] ASSIGNMENT PHASE ---

--- [utils/util.py::ComputeLoss.assign] PYTORCH ASSIGNMENT DEBUG ---
[utils/util.py::ComputeLoss.assign] pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] true_labels shape: torch.Size([4, 3, 1])
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 3, 4])
[utils/util.py::ComputeLoss.assign] true_mask shape: torch.Size([4, 3, 1])
[utils/util.py::ComputeLoss.assign] anchors shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.assign] Batch size: 4, Max boxes: 3
[utils/util.py::ComputeLoss.assign] Created indices tensor with shape: torch.Size([2, 4, 3])

--- [utils/util.py::ComputeLoss.assign] IOUs DEBUG ---
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 3, 4])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([4, 3, 1, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([4, 1, 512, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([4, 3, 1, 1]), h: torch.Size([4, 3, 1, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([4, 1, 512, 1]), h: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.000000, max: 0.803537
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: -0.966728, max: 0.801074
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.assign] overlaps shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] overlaps min: 0.0, max: 0.8010737299919128
[utils/util.py::ComputeLoss.assign] align_metric shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] align_metric min: 0.0, max: 0.018048664554953575
[utils/util.py::ComputeLoss.assign] mask_in_gts shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] mask_in_gts sum: 47.0
[utils/util.py::ComputeLoss.assign] metrics shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] top_k_mask shape: torch.Size([4, 3, 10])
[utils/util.py::ComputeLoss.assign] top_k_metrics shape: torch.Size([4, 3, 10])
[utils/util.py::ComputeLoss.assign] top_k_indices shape: torch.Size([4, 3, 10])
[utils/util.py::ComputeLoss.assign] is_in_top_k shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] mask_top_k shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] mask_pos shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] fg_mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] fg_mask sum: 41.0
[utils/util.py::ComputeLoss.assign] target_gt_idx shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_labels shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] Normalized target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] target_scores sum: 5.753955841064453
--- [utils/util.py::ComputeLoss.assign] END PYTORCH ASSIGNMENT DEBUG ---

[utils/util.py::ComputeLoss.__call__] Target bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Target scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] FG mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.__call__] Target scores sum: 5.753956
[utils/util.py::ComputeLoss.__call__] Classification loss computed: 6.153375
[utils/util.py::ComputeLoss.__call__] Foreground count: 41
[utils/util.py::ComputeLoss.__call__] Weight shape: torch.Size([41, 1])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([41, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([41, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([41, 1]), h: torch.Size([41, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([41, 1]), h: torch.Size([41, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([41, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([41, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([41, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.150758, max: 0.803777
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([41, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([41, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([41, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([41, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: 0.116617, max: 0.801313
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.__call__] IoU values shape: torch.Size([41, 1])
[utils/util.py::ComputeLoss.__call__] Box loss computed: 0.555266
[utils/util.py::ComputeLoss.__call__] Target LT-RB shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.df_loss] PYTORCH DFL LOSS DEBUG ---
[utils/util.py::ComputeLoss.df_loss] pred_dist shape: torch.Size([164, 16])
[utils/util.py::ComputeLoss.df_loss] target shape: torch.Size([41, 4])
[utils/util.py::ComputeLoss.df_loss] DFL loss shape: torch.Size([41, 1])
[utils/util.py::ComputeLoss.df_loss] DFL loss mean: 1.771438
--- [utils/util.py::ComputeLoss.df_loss] END PYTORCH DFL LOSS DEBUG ---

[utils/util.py::ComputeLoss.__call__] DFL loss before weighting: 1.771438
[utils/util.py::ComputeLoss.__call__] DFL loss computed: 1.422140

--- [utils/util.py::ComputeLoss.__call__] LOSS COMPONENTS DEBUG ---
[utils/util.py::ComputeLoss.__call__] Raw loss_cls: 6.153375
[utils/util.py::ComputeLoss.__call__] Raw loss_box: 0.555266
[utils/util.py::ComputeLoss.__call__] Raw loss_dfl: 1.422140
[utils/util.py::ComputeLoss.__call__] Loss weights - cls: 0.5, box: 7.5, dfl: 1.5
[utils/util.py::ComputeLoss.__call__] target_scores_sum: 5.753956
[utils/util.py::ComputeLoss.__call__] fg_mask sum: 41
[utils/util.py::ComputeLoss.__call__] Weighted loss_cls: 3.076688
[utils/util.py::ComputeLoss.__call__] Weighted loss_box: 4.164496
[utils/util.py::ComputeLoss.__call__] Weighted loss_dfl: 2.133210
[utils/util.py::ComputeLoss.__call__] Total loss: 9.374393
--- [utils/util.py::ComputeLoss.__call__] END PYTORCH LOSS COMPUTATION DEBUG ---


--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([4, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: True
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([4, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - box shape: torch.Size([4, 64, 16, 32]), cls shape: torch.Size([4, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - final concat shape: torch.Size([4, 65, 16, 32])

--- [utils/util.py::ComputeLoss.__call__] PYTORCH LOSS COMPUTATION DEBUG ---
[utils/util.py::ComputeLoss.__call__] Outputs type: <class 'list'>
[utils/util.py::ComputeLoss.__call__] x type: <class 'list'>, len: 1
[utils/util.py::ComputeLoss.__call__] x[0] shape: torch.Size([4, 65, 16, 32])
[utils/util.py::ComputeLoss.__call__] Concatenated output shape: torch.Size([4, 65, 512])
[utils/util.py::ComputeLoss.__call__] self.no: 65, self.dfl_ch: 16, self.nc: 1
[utils/util.py::ComputeLoss.__call__] pred_output shape: torch.Size([4, 64, 512])
[utils/util.py::ComputeLoss.__call__] pred_scores shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.__call__] After permute - pred_output shape: torch.Size([4, 512, 64])
[utils/util.py::ComputeLoss.__call__] After permute - pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Size tensor: tensor([128., 256.], device='cuda:0', dtype=torch.float16)
[utils/util.py::ComputeLoss.__call__] Stride: tensor([8.])
[utils/util.py::ComputeLoss.__call__] Anchor points shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.__call__] Stride tensor shape: torch.Size([512, 1])

--- [utils/util.py::ComputeLoss.__call__] TARGET PROCESSING ---
[utils/util.py::ComputeLoss.__call__] Targets shape: torch.Size([6, 6])
[utils/util.py::ComputeLoss.__call__] Targets dtype: torch.float32
[utils/util.py::ComputeLoss.__call__] First few targets: tensor([[0.0000, 0.0000, 0.5913, 0.4851, 0.0501, 0.1037],
        [1.0000, 0.0000, 0.7098, 0.3981, 0.0446, 0.0923],
        [2.0000, 0.0000, 0.0265, 0.2111, 0.0530, 0.1569],
        [2.0000, 0.0000, 0.8622, 0.0826, 0.0647, 0.1327],
        [2.0000, 0.0000, 0.8157, 0.8366, 0.0670, 0.1327]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Image indices: tensor([0., 1., 2., 2., 2., 3.], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Counts per image: tensor([1, 1, 3, 1], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT tensor shape: torch.Size([4, 3, 5])
[utils/util.py::ComputeLoss.__call__] Image 0: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 1: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 2: 3 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 3: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] GT before coordinate conversion: tensor([[[0.0000, 0.5913, 0.4851, 0.0501, 0.1037],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.7098, 0.3981, 0.0446, 0.0923],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.0265, 0.2111, 0.0530, 0.1569],
         [0.0000, 0.8622, 0.0826, 0.0647, 0.1327],
         [0.0000, 0.8157, 0.8366, 0.0670, 0.1327]],

        [[0.0000, 0.8049, 0.0406, 0.1363, 0.0812],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT after coordinate conversion: tensor([[[  0.0000, 144.9613,  55.4541, 157.7773,  68.7224],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000, 175.9928,  45.0541, 187.4094,  56.8714],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000,   0.0000,  16.9728,  13.5727,  37.0624],
         [  0.0000, 212.4303,   2.0794, 228.9915,  19.0652],
         [  0.0000, 200.2508,  98.5897, 217.4064, 115.5755]],

        [[  0.0000, 188.6102,   0.0000, 223.5013,  10.3929],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT labels shape: torch.Size([4, 3, 1])
[utils/util.py::ComputeLoss.__call__] GT bboxes shape: torch.Size([4, 3, 4])
[utils/util.py::ComputeLoss.__call__] GT mask shape: torch.Size([4, 3, 1])
[utils/util.py::ComputeLoss.__call__] Pred output dimensions - b: 4, a: 512, c: 64
[utils/util.py::ComputeLoss.__call__] Pred bboxes after softmax shape: torch.Size([4, 512, 4, 16])
[utils/util.py::ComputeLoss.__call__] Pred bboxes after matmul shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Final pred bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.__call__] ASSIGNMENT PHASE ---

--- [utils/util.py::ComputeLoss.assign] PYTORCH ASSIGNMENT DEBUG ---
[utils/util.py::ComputeLoss.assign] pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] true_labels shape: torch.Size([4, 3, 1])
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 3, 4])
[utils/util.py::ComputeLoss.assign] true_mask shape: torch.Size([4, 3, 1])
[utils/util.py::ComputeLoss.assign] anchors shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.assign] Batch size: 4, Max boxes: 3
[utils/util.py::ComputeLoss.assign] Created indices tensor with shape: torch.Size([2, 4, 3])

--- [utils/util.py::ComputeLoss.assign] IOUs DEBUG ---
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 3, 4])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([4, 3, 1, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([4, 1, 512, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([4, 3, 1, 1]), h: torch.Size([4, 3, 1, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([4, 1, 512, 1]), h: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.000000, max: 0.468202
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: -0.987813, max: 0.455039
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.assign] overlaps shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] overlaps min: 0.0, max: 0.4550391435623169
[utils/util.py::ComputeLoss.assign] align_metric shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] align_metric min: 0.0, max: 0.0008615286787971854
[utils/util.py::ComputeLoss.assign] mask_in_gts shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] mask_in_gts sum: 23.0
[utils/util.py::ComputeLoss.assign] metrics shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] top_k_mask shape: torch.Size([4, 3, 10])
[utils/util.py::ComputeLoss.assign] top_k_metrics shape: torch.Size([4, 3, 10])
[utils/util.py::ComputeLoss.assign] top_k_indices shape: torch.Size([4, 3, 10])
[utils/util.py::ComputeLoss.assign] is_in_top_k shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] mask_top_k shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] mask_pos shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] fg_mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] fg_mask sum: 23.0
[utils/util.py::ComputeLoss.assign] target_gt_idx shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_labels shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] Normalized target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] target_scores sum: 3.266552209854126
--- [utils/util.py::ComputeLoss.assign] END PYTORCH ASSIGNMENT DEBUG ---

[utils/util.py::ComputeLoss.__call__] Target bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Target scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] FG mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.__call__] Target scores sum: 3.266552
[utils/util.py::ComputeLoss.__call__] Classification loss computed: 6.677530
[utils/util.py::ComputeLoss.__call__] Foreground count: 23
[utils/util.py::ComputeLoss.__call__] Weight shape: torch.Size([23, 1])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([23, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([23, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([23, 1]), h: torch.Size([23, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([23, 1]), h: torch.Size([23, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([23, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([23, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([23, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.182811, max: 0.468334
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([23, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([23, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([23, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([23, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: 0.143559, max: 0.455170
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.__call__] IoU values shape: torch.Size([23, 1])
[utils/util.py::ComputeLoss.__call__] Box loss computed: 0.659197
[utils/util.py::ComputeLoss.__call__] Target LT-RB shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.df_loss] PYTORCH DFL LOSS DEBUG ---
[utils/util.py::ComputeLoss.df_loss] pred_dist shape: torch.Size([92, 16])
[utils/util.py::ComputeLoss.df_loss] target shape: torch.Size([23, 4])
[utils/util.py::ComputeLoss.df_loss] DFL loss shape: torch.Size([23, 1])
[utils/util.py::ComputeLoss.df_loss] DFL loss mean: 1.586917
--- [utils/util.py::ComputeLoss.df_loss] END PYTORCH DFL LOSS DEBUG ---

[utils/util.py::ComputeLoss.__call__] DFL loss before weighting: 1.586917
[utils/util.py::ComputeLoss.__call__] DFL loss computed: 1.291332

--- [utils/util.py::ComputeLoss.__call__] LOSS COMPONENTS DEBUG ---
[utils/util.py::ComputeLoss.__call__] Raw loss_cls: 6.677530
[utils/util.py::ComputeLoss.__call__] Raw loss_box: 0.659197
[utils/util.py::ComputeLoss.__call__] Raw loss_dfl: 1.291332
[utils/util.py::ComputeLoss.__call__] Loss weights - cls: 0.5, box: 7.5, dfl: 1.5
[utils/util.py::ComputeLoss.__call__] target_scores_sum: 3.266552
[utils/util.py::ComputeLoss.__call__] fg_mask sum: 23
[utils/util.py::ComputeLoss.__call__] Weighted loss_cls: 3.338765
[utils/util.py::ComputeLoss.__call__] Weighted loss_box: 4.943974
[utils/util.py::ComputeLoss.__call__] Weighted loss_dfl: 1.936998
[utils/util.py::ComputeLoss.__call__] Total loss: 10.219736
--- [utils/util.py::ComputeLoss.__call__] END PYTORCH LOSS COMPUTATION DEBUG ---


--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([4, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: True
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([4, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - box shape: torch.Size([4, 64, 16, 32]), cls shape: torch.Size([4, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - final concat shape: torch.Size([4, 65, 16, 32])

--- [utils/util.py::ComputeLoss.__call__] PYTORCH LOSS COMPUTATION DEBUG ---
[utils/util.py::ComputeLoss.__call__] Outputs type: <class 'list'>
[utils/util.py::ComputeLoss.__call__] x type: <class 'list'>, len: 1
[utils/util.py::ComputeLoss.__call__] x[0] shape: torch.Size([4, 65, 16, 32])
[utils/util.py::ComputeLoss.__call__] Concatenated output shape: torch.Size([4, 65, 512])
[utils/util.py::ComputeLoss.__call__] self.no: 65, self.dfl_ch: 16, self.nc: 1
[utils/util.py::ComputeLoss.__call__] pred_output shape: torch.Size([4, 64, 512])
[utils/util.py::ComputeLoss.__call__] pred_scores shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.__call__] After permute - pred_output shape: torch.Size([4, 512, 64])
[utils/util.py::ComputeLoss.__call__] After permute - pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Size tensor: tensor([128., 256.], device='cuda:0', dtype=torch.float16)
[utils/util.py::ComputeLoss.__call__] Stride: tensor([8.])
[utils/util.py::ComputeLoss.__call__] Anchor points shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.__call__] Stride tensor shape: torch.Size([512, 1])

--- [utils/util.py::ComputeLoss.__call__] TARGET PROCESSING ---
[utils/util.py::ComputeLoss.__call__] Targets shape: torch.Size([7, 6])
[utils/util.py::ComputeLoss.__call__] Targets dtype: torch.float32
[utils/util.py::ComputeLoss.__call__] First few targets: tensor([[0.0000, 0.0000, 0.0335, 0.6947, 0.0670, 0.2404],
        [0.0000, 0.0000, 0.8895, 0.5970, 0.1190, 0.2331],
        [1.0000, 0.0000, 0.6823, 0.6876, 0.1132, 0.2242],
        [2.0000, 0.0000, 0.6370, 0.4709, 0.1177, 0.2441],
        [3.0000, 0.0000, 0.8750, 0.0898, 0.0952, 0.1795]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Image indices: tensor([0., 0., 1., 2., 3., 3., 3.], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Counts per image: tensor([2, 1, 1, 3], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT tensor shape: torch.Size([4, 3, 5])
[utils/util.py::ComputeLoss.__call__] Image 0: 2 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 1: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 2: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 3: 3 targets assigned
[utils/util.py::ComputeLoss.__call__] GT before coordinate conversion: tensor([[[0.0000, 0.0335, 0.6947, 0.0670, 0.2404],
         [0.0000, 0.8895, 0.5970, 0.1190, 0.2331],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.6823, 0.6876, 0.1132, 0.2242],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.6370, 0.4709, 0.1177, 0.2441],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.8750, 0.0898, 0.0952, 0.1795],
         [0.0000, 0.3874, 0.0242, 0.0797, 0.0483],
         [0.0000, 0.4025, 0.8529, 0.0824, 0.1726]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT after coordinate conversion: tensor([[[  0.0000,   0.0000,  73.5392,  17.1533, 104.3086],
         [  0.0000, 212.4722,  61.4990, 242.9339,  91.3319],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000, 160.1715,  73.6690, 189.1509, 102.3615],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000, 148.0146,  44.6556, 178.1453,  75.8992],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000, 211.8260,   0.0000, 236.1962,  22.9808],
         [  0.0000,  88.9583,   0.0000, 109.3685,   6.1860],
         [  0.0000,  92.4941,  98.1157, 113.5937, 120.2142]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT labels shape: torch.Size([4, 3, 1])
[utils/util.py::ComputeLoss.__call__] GT bboxes shape: torch.Size([4, 3, 4])
[utils/util.py::ComputeLoss.__call__] GT mask shape: torch.Size([4, 3, 1])
[utils/util.py::ComputeLoss.__call__] Pred output dimensions - b: 4, a: 512, c: 64
[utils/util.py::ComputeLoss.__call__] Pred bboxes after softmax shape: torch.Size([4, 512, 4, 16])
[utils/util.py::ComputeLoss.__call__] Pred bboxes after matmul shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Final pred bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.__call__] ASSIGNMENT PHASE ---

--- [utils/util.py::ComputeLoss.assign] PYTORCH ASSIGNMENT DEBUG ---
[utils/util.py::ComputeLoss.assign] pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] true_labels shape: torch.Size([4, 3, 1])
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 3, 4])
[utils/util.py::ComputeLoss.assign] true_mask shape: torch.Size([4, 3, 1])
[utils/util.py::ComputeLoss.assign] anchors shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.assign] Batch size: 4, Max boxes: 3
[utils/util.py::ComputeLoss.assign] Created indices tensor with shape: torch.Size([2, 4, 3])

--- [utils/util.py::ComputeLoss.assign] IOUs DEBUG ---
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 3, 4])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([4, 3, 1, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([4, 1, 512, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([4, 3, 1, 1]), h: torch.Size([4, 3, 1, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([4, 1, 512, 1]), h: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.000000, max: 0.743017
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: -0.980074, max: 0.736444
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.assign] overlaps shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] overlaps min: 0.0, max: 0.7364444136619568
[utils/util.py::ComputeLoss.assign] align_metric shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] align_metric min: 0.0, max: 0.007603469304740429
[utils/util.py::ComputeLoss.assign] mask_in_gts shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] mask_in_gts sum: 63.0
[utils/util.py::ComputeLoss.assign] metrics shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] top_k_mask shape: torch.Size([4, 3, 10])
[utils/util.py::ComputeLoss.assign] top_k_metrics shape: torch.Size([4, 3, 10])
[utils/util.py::ComputeLoss.assign] top_k_indices shape: torch.Size([4, 3, 10])
[utils/util.py::ComputeLoss.assign] is_in_top_k shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] mask_top_k shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] mask_pos shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] fg_mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] fg_mask sum: 55.0
[utils/util.py::ComputeLoss.assign] target_gt_idx shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_labels shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] Normalized target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] target_scores sum: 7.148970603942871
--- [utils/util.py::ComputeLoss.assign] END PYTORCH ASSIGNMENT DEBUG ---

[utils/util.py::ComputeLoss.__call__] Target bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Target scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] FG mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.__call__] Target scores sum: 7.148971
[utils/util.py::ComputeLoss.__call__] Classification loss computed: 5.966768
[utils/util.py::ComputeLoss.__call__] Foreground count: 55
[utils/util.py::ComputeLoss.__call__] Weight shape: torch.Size([55, 1])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([55, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([55, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([55, 1]), h: torch.Size([55, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([55, 1]), h: torch.Size([55, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([55, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([55, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([55, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.119839, max: 0.742858
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([55, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([55, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([55, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([55, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: 0.063890, max: 0.736285
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.__call__] IoU values shape: torch.Size([55, 1])
[utils/util.py::ComputeLoss.__call__] Box loss computed: 0.403583
[utils/util.py::ComputeLoss.__call__] Target LT-RB shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.df_loss] PYTORCH DFL LOSS DEBUG ---
[utils/util.py::ComputeLoss.df_loss] pred_dist shape: torch.Size([220, 16])
[utils/util.py::ComputeLoss.df_loss] target shape: torch.Size([55, 4])
[utils/util.py::ComputeLoss.df_loss] DFL loss shape: torch.Size([55, 1])
[utils/util.py::ComputeLoss.df_loss] DFL loss mean: 1.889346
--- [utils/util.py::ComputeLoss.df_loss] END PYTORCH DFL LOSS DEBUG ---

[utils/util.py::ComputeLoss.__call__] DFL loss before weighting: 1.889346
[utils/util.py::ComputeLoss.__call__] DFL loss computed: 1.448658

--- [utils/util.py::ComputeLoss.__call__] LOSS COMPONENTS DEBUG ---
[utils/util.py::ComputeLoss.__call__] Raw loss_cls: 5.966768
[utils/util.py::ComputeLoss.__call__] Raw loss_box: 0.403583
[utils/util.py::ComputeLoss.__call__] Raw loss_dfl: 1.448658
[utils/util.py::ComputeLoss.__call__] Loss weights - cls: 0.5, box: 7.5, dfl: 1.5
[utils/util.py::ComputeLoss.__call__] target_scores_sum: 7.148971
[utils/util.py::ComputeLoss.__call__] fg_mask sum: 55
[utils/util.py::ComputeLoss.__call__] Weighted loss_cls: 2.983384
[utils/util.py::ComputeLoss.__call__] Weighted loss_box: 3.026870
[utils/util.py::ComputeLoss.__call__] Weighted loss_dfl: 2.172987
[utils/util.py::ComputeLoss.__call__] Total loss: 8.183242
--- [utils/util.py::ComputeLoss.__call__] END PYTORCH LOSS COMPUTATION DEBUG ---


--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([4, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: True
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([4, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - box shape: torch.Size([4, 64, 16, 32]), cls shape: torch.Size([4, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - final concat shape: torch.Size([4, 65, 16, 32])

--- [utils/util.py::ComputeLoss.__call__] PYTORCH LOSS COMPUTATION DEBUG ---
[utils/util.py::ComputeLoss.__call__] Outputs type: <class 'list'>
[utils/util.py::ComputeLoss.__call__] x type: <class 'list'>, len: 1
[utils/util.py::ComputeLoss.__call__] x[0] shape: torch.Size([4, 65, 16, 32])
[utils/util.py::ComputeLoss.__call__] Concatenated output shape: torch.Size([4, 65, 512])
[utils/util.py::ComputeLoss.__call__] self.no: 65, self.dfl_ch: 16, self.nc: 1
[utils/util.py::ComputeLoss.__call__] pred_output shape: torch.Size([4, 64, 512])
[utils/util.py::ComputeLoss.__call__] pred_scores shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.__call__] After permute - pred_output shape: torch.Size([4, 512, 64])
[utils/util.py::ComputeLoss.__call__] After permute - pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Size tensor: tensor([128., 256.], device='cuda:0', dtype=torch.float16)
[utils/util.py::ComputeLoss.__call__] Stride: tensor([8.])
[utils/util.py::ComputeLoss.__call__] Anchor points shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.__call__] Stride tensor shape: torch.Size([512, 1])

--- [utils/util.py::ComputeLoss.__call__] TARGET PROCESSING ---
[utils/util.py::ComputeLoss.__call__] Targets shape: torch.Size([8, 6])
[utils/util.py::ComputeLoss.__call__] Targets dtype: torch.float32
[utils/util.py::ComputeLoss.__call__] First few targets: tensor([[0.0000, 0.0000, 0.9467, 0.9390, 0.1066, 0.1220],
        [1.0000, 0.0000, 0.9291, 0.3273, 0.0264, 0.0892],
        [1.0000, 0.0000, 0.2222, 0.3516, 0.0561, 0.1135],
        [2.0000, 0.0000, 0.6820, 0.7231, 0.0929, 0.1771],
        [3.0000, 0.0000, 0.5252, 0.4351, 0.0641, 0.1251]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Image indices: tensor([0., 1., 1., 2., 3., 3., 3., 3.], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Counts per image: tensor([1, 2, 1, 4], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT tensor shape: torch.Size([4, 4, 5])
[utils/util.py::ComputeLoss.__call__] Image 0: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 1: 2 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 2: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 3: 4 targets assigned
[utils/util.py::ComputeLoss.__call__] GT before coordinate conversion: tensor([[[0.0000, 0.9467, 0.9390, 0.1066, 0.1220],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.9291, 0.3273, 0.0264, 0.0892],
         [0.0000, 0.2222, 0.3516, 0.0561, 0.1135],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.6820, 0.7231, 0.0929, 0.1771],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.5252, 0.4351, 0.0641, 0.1251],
         [0.0000, 0.4306, 0.2463, 0.0598, 0.1125],
         [0.0000, 0.6670, 0.9438, 0.0587, 0.1123],
         [0.0000, 0.4282, 0.9599, 0.0749, 0.0802]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT after coordinate conversion: tensor([[[  0.0000, 228.7203, 112.3820, 255.9990, 127.9990],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000, 234.4826,  36.1860, 241.2328,  47.6051],
         [  0.0000,  49.7057,  37.7431,  64.0678,  52.2766],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000, 162.6988,  81.2184, 186.4819, 103.8886],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000, 126.2449,  47.6810, 142.6529,  63.6975],
         [  0.0000, 102.5944,  24.3293, 117.8966,  38.7249],
         [  0.0000, 163.2299, 113.6187, 178.2643, 127.9990],
         [  0.0000, 100.0360, 117.7362, 119.2188, 127.9990]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT labels shape: torch.Size([4, 4, 1])
[utils/util.py::ComputeLoss.__call__] GT bboxes shape: torch.Size([4, 4, 4])
[utils/util.py::ComputeLoss.__call__] GT mask shape: torch.Size([4, 4, 1])
[utils/util.py::ComputeLoss.__call__] Pred output dimensions - b: 4, a: 512, c: 64
[utils/util.py::ComputeLoss.__call__] Pred bboxes after softmax shape: torch.Size([4, 512, 4, 16])
[utils/util.py::ComputeLoss.__call__] Pred bboxes after matmul shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Final pred bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.__call__] ASSIGNMENT PHASE ---

--- [utils/util.py::ComputeLoss.assign] PYTORCH ASSIGNMENT DEBUG ---
[utils/util.py::ComputeLoss.assign] pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] true_labels shape: torch.Size([4, 4, 1])
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 4, 4])
[utils/util.py::ComputeLoss.assign] true_mask shape: torch.Size([4, 4, 1])
[utils/util.py::ComputeLoss.assign] anchors shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.assign] Batch size: 4, Max boxes: 4
[utils/util.py::ComputeLoss.assign] Created indices tensor with shape: torch.Size([2, 4, 4])

--- [utils/util.py::ComputeLoss.assign] IOUs DEBUG ---
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 4, 4])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([4, 4, 1, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([4, 1, 512, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([4, 4, 1, 1]), h: torch.Size([4, 4, 1, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([4, 1, 512, 1]), h: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([4, 4, 512, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([4, 4, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([4, 4, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.000000, max: 0.690017
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([4, 4, 512, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([4, 4, 512, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([4, 4, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([4, 4, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: -1.006866, max: 0.681658
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.assign] overlaps shape: torch.Size([4, 4, 512])
[utils/util.py::ComputeLoss.assign] overlaps min: 0.0, max: 0.6816578507423401
[utils/util.py::ComputeLoss.assign] align_metric shape: torch.Size([4, 4, 512])
[utils/util.py::ComputeLoss.assign] align_metric min: 0.0, max: 0.0045250472612679005
[utils/util.py::ComputeLoss.assign] mask_in_gts shape: torch.Size([4, 4, 512])
[utils/util.py::ComputeLoss.assign] mask_in_gts sum: 34.0
[utils/util.py::ComputeLoss.assign] metrics shape: torch.Size([4, 4, 512])
[utils/util.py::ComputeLoss.assign] top_k_mask shape: torch.Size([4, 4, 10])
[utils/util.py::ComputeLoss.assign] top_k_metrics shape: torch.Size([4, 4, 10])
[utils/util.py::ComputeLoss.assign] top_k_indices shape: torch.Size([4, 4, 10])
[utils/util.py::ComputeLoss.assign] is_in_top_k shape: torch.Size([4, 4, 512])
[utils/util.py::ComputeLoss.assign] mask_top_k shape: torch.Size([4, 4, 512])
[utils/util.py::ComputeLoss.assign] mask_pos shape: torch.Size([4, 4, 512])
[utils/util.py::ComputeLoss.assign] fg_mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] fg_mask sum: 34.0
[utils/util.py::ComputeLoss.assign] target_gt_idx shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_labels shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] Normalized target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] target_scores sum: 5.830697536468506
--- [utils/util.py::ComputeLoss.assign] END PYTORCH ASSIGNMENT DEBUG ---

[utils/util.py::ComputeLoss.__call__] Target bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Target scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] FG mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.__call__] Target scores sum: 5.830698
[utils/util.py::ComputeLoss.__call__] Classification loss computed: 6.511871
[utils/util.py::ComputeLoss.__call__] Foreground count: 34
[utils/util.py::ComputeLoss.__call__] Weight shape: torch.Size([34, 1])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([34, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([34, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([34, 1]), h: torch.Size([34, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([34, 1]), h: torch.Size([34, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([34, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([34, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([34, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.117324, max: 0.690212
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([34, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([34, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([34, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([34, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: 0.102344, max: 0.681853
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.__call__] IoU values shape: torch.Size([34, 1])
[utils/util.py::ComputeLoss.__call__] Box loss computed: 0.588354
[utils/util.py::ComputeLoss.__call__] Target LT-RB shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.df_loss] PYTORCH DFL LOSS DEBUG ---
[utils/util.py::ComputeLoss.df_loss] pred_dist shape: torch.Size([136, 16])
[utils/util.py::ComputeLoss.df_loss] target shape: torch.Size([34, 4])
[utils/util.py::ComputeLoss.df_loss] DFL loss shape: torch.Size([34, 1])
[utils/util.py::ComputeLoss.df_loss] DFL loss mean: 1.617072
--- [utils/util.py::ComputeLoss.df_loss] END PYTORCH DFL LOSS DEBUG ---

[utils/util.py::ComputeLoss.__call__] DFL loss before weighting: 1.617072
[utils/util.py::ComputeLoss.__call__] DFL loss computed: 1.306151

--- [utils/util.py::ComputeLoss.__call__] LOSS COMPONENTS DEBUG ---
[utils/util.py::ComputeLoss.__call__] Raw loss_cls: 6.511871
[utils/util.py::ComputeLoss.__call__] Raw loss_box: 0.588354
[utils/util.py::ComputeLoss.__call__] Raw loss_dfl: 1.306151
[utils/util.py::ComputeLoss.__call__] Loss weights - cls: 0.5, box: 7.5, dfl: 1.5
[utils/util.py::ComputeLoss.__call__] target_scores_sum: 5.830698
[utils/util.py::ComputeLoss.__call__] fg_mask sum: 34
[utils/util.py::ComputeLoss.__call__] Weighted loss_cls: 3.255935
[utils/util.py::ComputeLoss.__call__] Weighted loss_box: 4.412658
[utils/util.py::ComputeLoss.__call__] Weighted loss_dfl: 1.959226
[utils/util.py::ComputeLoss.__call__] Total loss: 9.627819
--- [utils/util.py::ComputeLoss.__call__] END PYTORCH LOSS COMPUTATION DEBUG ---


--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([4, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: True
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([4, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - box shape: torch.Size([4, 64, 16, 32]), cls shape: torch.Size([4, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - final concat shape: torch.Size([4, 65, 16, 32])

--- [utils/util.py::ComputeLoss.__call__] PYTORCH LOSS COMPUTATION DEBUG ---
[utils/util.py::ComputeLoss.__call__] Outputs type: <class 'list'>
[utils/util.py::ComputeLoss.__call__] x type: <class 'list'>, len: 1
[utils/util.py::ComputeLoss.__call__] x[0] shape: torch.Size([4, 65, 16, 32])
[utils/util.py::ComputeLoss.__call__] Concatenated output shape: torch.Size([4, 65, 512])
[utils/util.py::ComputeLoss.__call__] self.no: 65, self.dfl_ch: 16, self.nc: 1
[utils/util.py::ComputeLoss.__call__] pred_output shape: torch.Size([4, 64, 512])
[utils/util.py::ComputeLoss.__call__] pred_scores shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.__call__] After permute - pred_output shape: torch.Size([4, 512, 64])
[utils/util.py::ComputeLoss.__call__] After permute - pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Size tensor: tensor([128., 256.], device='cuda:0', dtype=torch.float16)
[utils/util.py::ComputeLoss.__call__] Stride: tensor([8.])
[utils/util.py::ComputeLoss.__call__] Anchor points shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.__call__] Stride tensor shape: torch.Size([512, 1])

--- [utils/util.py::ComputeLoss.__call__] TARGET PROCESSING ---
[utils/util.py::ComputeLoss.__call__] Targets shape: torch.Size([5, 6])
[utils/util.py::ComputeLoss.__call__] Targets dtype: torch.float32
[utils/util.py::ComputeLoss.__call__] First few targets: tensor([[1.0000, 0.0000, 0.1933, 0.4047, 0.1423, 0.2669],
        [2.0000, 0.0000, 0.2494, 0.3268, 0.0800, 0.1692],
        [3.0000, 0.0000, 0.0788, 0.2111, 0.0777, 0.2054],
        [3.0000, 0.0000, 0.7116, 0.2364, 0.1041, 0.2204],
        [3.0000, 0.0000, 0.0240, 0.9752, 0.0481, 0.0495]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Image indices: tensor([1., 2., 3., 3., 3.], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Counts per image: tensor([1, 1, 3], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT tensor shape: torch.Size([4, 3, 5])
[utils/util.py::ComputeLoss.__call__] Image 1: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 2: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 3: 3 targets assigned
[utils/util.py::ComputeLoss.__call__] GT before coordinate conversion: tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.1933, 0.4047, 0.1423, 0.2669],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.2494, 0.3268, 0.0800, 0.1692],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.0788, 0.2111, 0.0777, 0.2054],
         [0.0000, 0.7116, 0.2364, 0.1041, 0.2204],
         [0.0000, 0.0240, 0.9752, 0.0481, 0.0495]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT after coordinate conversion: tensor([[[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000,  31.2645,  34.7217,  67.6830,  68.8805],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000,  53.6031,  31.0047,  74.0858,  52.6575],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000,  10.2362,  13.8758,  30.1208,  40.1668],
         [  0.0000, 168.8517,  16.1570, 195.4944,  44.3680],
         [  0.0000,   0.0000, 121.6631,  12.3131, 127.9990]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT labels shape: torch.Size([4, 3, 1])
[utils/util.py::ComputeLoss.__call__] GT bboxes shape: torch.Size([4, 3, 4])
[utils/util.py::ComputeLoss.__call__] GT mask shape: torch.Size([4, 3, 1])
[utils/util.py::ComputeLoss.__call__] Pred output dimensions - b: 4, a: 512, c: 64
[utils/util.py::ComputeLoss.__call__] Pred bboxes after softmax shape: torch.Size([4, 512, 4, 16])
[utils/util.py::ComputeLoss.__call__] Pred bboxes after matmul shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Final pred bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.__call__] ASSIGNMENT PHASE ---

--- [utils/util.py::ComputeLoss.assign] PYTORCH ASSIGNMENT DEBUG ---
[utils/util.py::ComputeLoss.assign] pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] true_labels shape: torch.Size([4, 3, 1])
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 3, 4])
[utils/util.py::ComputeLoss.assign] true_mask shape: torch.Size([4, 3, 1])
[utils/util.py::ComputeLoss.assign] anchors shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.assign] Batch size: 4, Max boxes: 3
[utils/util.py::ComputeLoss.assign] Created indices tensor with shape: torch.Size([2, 4, 3])

--- [utils/util.py::ComputeLoss.assign] IOUs DEBUG ---
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 3, 4])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([4, 3, 1, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([4, 1, 512, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([4, 3, 1, 1]), h: torch.Size([4, 3, 1, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([4, 1, 512, 1]), h: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.000000, max: 0.668623
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: -0.981453, max: 0.661616
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.assign] overlaps shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] overlaps min: 0.0, max: 0.661615788936615
[utils/util.py::ComputeLoss.assign] align_metric shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] align_metric min: 0.0, max: 0.006106063723564148
[utils/util.py::ComputeLoss.assign] mask_in_gts shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] mask_in_gts sum: 49.0
[utils/util.py::ComputeLoss.assign] metrics shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] top_k_mask shape: torch.Size([4, 3, 10])
[utils/util.py::ComputeLoss.assign] top_k_metrics shape: torch.Size([4, 3, 10])
[utils/util.py::ComputeLoss.assign] top_k_indices shape: torch.Size([4, 3, 10])
[utils/util.py::ComputeLoss.assign] is_in_top_k shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] mask_top_k shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] mask_pos shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] fg_mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] fg_mask sum: 37.0
[utils/util.py::ComputeLoss.assign] target_gt_idx shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_labels shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] Normalized target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] target_scores sum: 4.6513824462890625
--- [utils/util.py::ComputeLoss.assign] END PYTORCH ASSIGNMENT DEBUG ---

[utils/util.py::ComputeLoss.__call__] Target bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Target scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] FG mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.__call__] Target scores sum: 4.651382
[utils/util.py::ComputeLoss.__call__] Classification loss computed: 5.992842
[utils/util.py::ComputeLoss.__call__] Foreground count: 37
[utils/util.py::ComputeLoss.__call__] Weight shape: torch.Size([37, 1])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([37, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([37, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([37, 1]), h: torch.Size([37, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([37, 1]), h: torch.Size([37, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([37, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([37, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([37, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.116353, max: 0.668509
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([37, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([37, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([37, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([37, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: 0.108742, max: 0.661504
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.__call__] IoU values shape: torch.Size([37, 1])
[utils/util.py::ComputeLoss.__call__] Box loss computed: 0.478513
[utils/util.py::ComputeLoss.__call__] Target LT-RB shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.df_loss] PYTORCH DFL LOSS DEBUG ---
[utils/util.py::ComputeLoss.df_loss] pred_dist shape: torch.Size([148, 16])
[utils/util.py::ComputeLoss.df_loss] target shape: torch.Size([37, 4])
[utils/util.py::ComputeLoss.df_loss] DFL loss shape: torch.Size([37, 1])
[utils/util.py::ComputeLoss.df_loss] DFL loss mean: 2.033520
--- [utils/util.py::ComputeLoss.df_loss] END PYTORCH DFL LOSS DEBUG ---

[utils/util.py::ComputeLoss.__call__] DFL loss before weighting: 2.033520
[utils/util.py::ComputeLoss.__call__] DFL loss computed: 1.668205

--- [utils/util.py::ComputeLoss.__call__] LOSS COMPONENTS DEBUG ---
[utils/util.py::ComputeLoss.__call__] Raw loss_cls: 5.992842
[utils/util.py::ComputeLoss.__call__] Raw loss_box: 0.478513
[utils/util.py::ComputeLoss.__call__] Raw loss_dfl: 1.668205
[utils/util.py::ComputeLoss.__call__] Loss weights - cls: 0.5, box: 7.5, dfl: 1.5
[utils/util.py::ComputeLoss.__call__] target_scores_sum: 4.651382
[utils/util.py::ComputeLoss.__call__] fg_mask sum: 37
[utils/util.py::ComputeLoss.__call__] Weighted loss_cls: 2.996421
[utils/util.py::ComputeLoss.__call__] Weighted loss_box: 3.588847
[utils/util.py::ComputeLoss.__call__] Weighted loss_dfl: 2.502308
[utils/util.py::ComputeLoss.__call__] Total loss: 9.087576
--- [utils/util.py::ComputeLoss.__call__] END PYTORCH LOSS COMPUTATION DEBUG ---


--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([4, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: True
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([4, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - box shape: torch.Size([4, 64, 16, 32]), cls shape: torch.Size([4, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - final concat shape: torch.Size([4, 65, 16, 32])

--- [utils/util.py::ComputeLoss.__call__] PYTORCH LOSS COMPUTATION DEBUG ---
[utils/util.py::ComputeLoss.__call__] Outputs type: <class 'list'>
[utils/util.py::ComputeLoss.__call__] x type: <class 'list'>, len: 1
[utils/util.py::ComputeLoss.__call__] x[0] shape: torch.Size([4, 65, 16, 32])
[utils/util.py::ComputeLoss.__call__] Concatenated output shape: torch.Size([4, 65, 512])
[utils/util.py::ComputeLoss.__call__] self.no: 65, self.dfl_ch: 16, self.nc: 1
[utils/util.py::ComputeLoss.__call__] pred_output shape: torch.Size([4, 64, 512])
[utils/util.py::ComputeLoss.__call__] pred_scores shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.__call__] After permute - pred_output shape: torch.Size([4, 512, 64])
[utils/util.py::ComputeLoss.__call__] After permute - pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Size tensor: tensor([128., 256.], device='cuda:0', dtype=torch.float16)
[utils/util.py::ComputeLoss.__call__] Stride: tensor([8.])
[utils/util.py::ComputeLoss.__call__] Anchor points shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.__call__] Stride tensor shape: torch.Size([512, 1])

--- [utils/util.py::ComputeLoss.__call__] TARGET PROCESSING ---
[utils/util.py::ComputeLoss.__call__] Targets shape: torch.Size([4, 6])
[utils/util.py::ComputeLoss.__call__] Targets dtype: torch.float32
[utils/util.py::ComputeLoss.__call__] First few targets: tensor([[0.0000, 0.0000, 0.1318, 0.7147, 0.1010, 0.2031],
        [1.0000, 0.0000, 0.5291, 0.4977, 0.0638, 0.1223],
        [2.0000, 0.0000, 0.0710, 0.8104, 0.1154, 0.2402],
        [3.0000, 0.0000, 0.8886, 0.9144, 0.1113, 0.1711]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Image indices: tensor([0., 1., 2., 3.], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Counts per image: tensor([1, 1, 1, 1], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT tensor shape: torch.Size([4, 1, 5])
[utils/util.py::ComputeLoss.__call__] Image 0: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 1: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 2: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 3: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] GT before coordinate conversion: tensor([[[0.0000, 0.1318, 0.7147, 0.1010, 0.2031]],

        [[0.0000, 0.5291, 0.4977, 0.0638, 0.1223]],

        [[0.0000, 0.0710, 0.8104, 0.1154, 0.2402]],

        [[0.0000, 0.8886, 0.9144, 0.1113, 0.1711]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT after coordinate conversion: tensor([[[  0.0000,  20.8166,  78.4910,  46.6737, 104.4829]],

        [[  0.0000, 127.2697,  55.8759, 143.6064,  71.5318]],

        [[  0.0000,   3.4023,  88.3613,  32.9557, 119.1075]],

        [[  0.0000, 213.2242, 106.0979, 241.7297, 127.9990]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT labels shape: torch.Size([4, 1, 1])
[utils/util.py::ComputeLoss.__call__] GT bboxes shape: torch.Size([4, 1, 4])
[utils/util.py::ComputeLoss.__call__] GT mask shape: torch.Size([4, 1, 1])
[utils/util.py::ComputeLoss.__call__] Pred output dimensions - b: 4, a: 512, c: 64
[utils/util.py::ComputeLoss.__call__] Pred bboxes after softmax shape: torch.Size([4, 512, 4, 16])
[utils/util.py::ComputeLoss.__call__] Pred bboxes after matmul shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Final pred bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.__call__] ASSIGNMENT PHASE ---

--- [utils/util.py::ComputeLoss.assign] PYTORCH ASSIGNMENT DEBUG ---
[utils/util.py::ComputeLoss.assign] pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] true_labels shape: torch.Size([4, 1, 1])
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 1, 4])
[utils/util.py::ComputeLoss.assign] true_mask shape: torch.Size([4, 1, 1])
[utils/util.py::ComputeLoss.assign] anchors shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.assign] Batch size: 4, Max boxes: 1
[utils/util.py::ComputeLoss.assign] Created indices tensor with shape: torch.Size([2, 4, 1])

--- [utils/util.py::ComputeLoss.assign] IOUs DEBUG ---
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 1, 4])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([4, 1, 1, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([4, 1, 512, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([4, 1, 1, 1]), h: torch.Size([4, 1, 1, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([4, 1, 512, 1]), h: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.000000, max: 0.828513
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: -0.787382, max: 0.826708
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.assign] overlaps shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.assign] overlaps min: 0.0, max: 0.8267084956169128
[utils/util.py::ComputeLoss.assign] align_metric shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.assign] align_metric min: 0.0, max: 0.02271920070052147
[utils/util.py::ComputeLoss.assign] mask_in_gts shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.assign] mask_in_gts sum: 38.0
[utils/util.py::ComputeLoss.assign] metrics shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.assign] top_k_mask shape: torch.Size([4, 1, 10])
[utils/util.py::ComputeLoss.assign] top_k_metrics shape: torch.Size([4, 1, 10])
[utils/util.py::ComputeLoss.assign] top_k_indices shape: torch.Size([4, 1, 10])
[utils/util.py::ComputeLoss.assign] is_in_top_k shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.assign] mask_top_k shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.assign] mask_pos shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.assign] fg_mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] fg_mask sum: 32.0
[utils/util.py::ComputeLoss.assign] target_gt_idx shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_labels shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] Normalized target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] target_scores sum: 3.8073105812072754
--- [utils/util.py::ComputeLoss.assign] END PYTORCH ASSIGNMENT DEBUG ---

[utils/util.py::ComputeLoss.__call__] Target bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Target scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] FG mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.__call__] Target scores sum: 3.807311
[utils/util.py::ComputeLoss.__call__] Classification loss computed: 5.950723
[utils/util.py::ComputeLoss.__call__] Foreground count: 32
[utils/util.py::ComputeLoss.__call__] Weight shape: torch.Size([32, 1])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([32, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([32, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([32, 1]), h: torch.Size([32, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([32, 1]), h: torch.Size([32, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([32, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([32, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([32, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.262764, max: 0.828532
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([32, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([32, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([32, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([32, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: 0.193216, max: 0.826728
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.__call__] IoU values shape: torch.Size([32, 1])
[utils/util.py::ComputeLoss.__call__] Box loss computed: 0.377592
[utils/util.py::ComputeLoss.__call__] Target LT-RB shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.df_loss] PYTORCH DFL LOSS DEBUG ---
[utils/util.py::ComputeLoss.df_loss] pred_dist shape: torch.Size([128, 16])
[utils/util.py::ComputeLoss.df_loss] target shape: torch.Size([32, 4])
[utils/util.py::ComputeLoss.df_loss] DFL loss shape: torch.Size([32, 1])
[utils/util.py::ComputeLoss.df_loss] DFL loss mean: 1.851723
--- [utils/util.py::ComputeLoss.df_loss] END PYTORCH DFL LOSS DEBUG ---

[utils/util.py::ComputeLoss.__call__] DFL loss before weighting: 1.851723
[utils/util.py::ComputeLoss.__call__] DFL loss computed: 1.439073

--- [utils/util.py::ComputeLoss.__call__] LOSS COMPONENTS DEBUG ---
[utils/util.py::ComputeLoss.__call__] Raw loss_cls: 5.950723
[utils/util.py::ComputeLoss.__call__] Raw loss_box: 0.377592
[utils/util.py::ComputeLoss.__call__] Raw loss_dfl: 1.439073
[utils/util.py::ComputeLoss.__call__] Loss weights - cls: 0.5, box: 7.5, dfl: 1.5
[utils/util.py::ComputeLoss.__call__] target_scores_sum: 3.807311
[utils/util.py::ComputeLoss.__call__] fg_mask sum: 32
[utils/util.py::ComputeLoss.__call__] Weighted loss_cls: 2.975361
[utils/util.py::ComputeLoss.__call__] Weighted loss_box: 2.831938
[utils/util.py::ComputeLoss.__call__] Weighted loss_dfl: 2.158610
[utils/util.py::ComputeLoss.__call__] Total loss: 7.965909
--- [utils/util.py::ComputeLoss.__call__] END PYTORCH LOSS COMPUTATION DEBUG ---


--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([4, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: True
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([4, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - box shape: torch.Size([4, 64, 16, 32]), cls shape: torch.Size([4, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - final concat shape: torch.Size([4, 65, 16, 32])

--- [utils/util.py::ComputeLoss.__call__] PYTORCH LOSS COMPUTATION DEBUG ---
[utils/util.py::ComputeLoss.__call__] Outputs type: <class 'list'>
[utils/util.py::ComputeLoss.__call__] x type: <class 'list'>, len: 1
[utils/util.py::ComputeLoss.__call__] x[0] shape: torch.Size([4, 65, 16, 32])
[utils/util.py::ComputeLoss.__call__] Concatenated output shape: torch.Size([4, 65, 512])
[utils/util.py::ComputeLoss.__call__] self.no: 65, self.dfl_ch: 16, self.nc: 1
[utils/util.py::ComputeLoss.__call__] pred_output shape: torch.Size([4, 64, 512])
[utils/util.py::ComputeLoss.__call__] pred_scores shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.__call__] After permute - pred_output shape: torch.Size([4, 512, 64])
[utils/util.py::ComputeLoss.__call__] After permute - pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Size tensor: tensor([128., 256.], device='cuda:0', dtype=torch.float16)
[utils/util.py::ComputeLoss.__call__] Stride: tensor([8.])
[utils/util.py::ComputeLoss.__call__] Anchor points shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.__call__] Stride tensor shape: torch.Size([512, 1])

--- [utils/util.py::ComputeLoss.__call__] TARGET PROCESSING ---
[utils/util.py::ComputeLoss.__call__] Targets shape: torch.Size([4, 6])
[utils/util.py::ComputeLoss.__call__] Targets dtype: torch.float32
[utils/util.py::ComputeLoss.__call__] First few targets: tensor([[0.0000, 0.0000, 0.2376, 0.4236, 0.0770, 0.1473],
        [2.0000, 0.0000, 0.9513, 0.2363, 0.0611, 0.1208],
        [2.0000, 0.0000, 0.1290, 0.8833, 0.0615, 0.1139],
        [2.0000, 0.0000, 0.7945, 0.8833, 0.0615, 0.1139]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Image indices: tensor([0., 2., 2., 2.], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Counts per image: tensor([1, 3], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT tensor shape: torch.Size([4, 3, 5])
[utils/util.py::ComputeLoss.__call__] Image 0: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 2: 3 targets assigned
[utils/util.py::ComputeLoss.__call__] GT before coordinate conversion: tensor([[[0.0000, 0.2376, 0.4236, 0.0770, 0.1473],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.9513, 0.2363, 0.0611, 0.1208],
         [0.0000, 0.1290, 0.8833, 0.0615, 0.1139],
         [0.0000, 0.7945, 0.8833, 0.0615, 0.1139]],

        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT after coordinate conversion: tensor([[[  0.0000,  50.9701,  44.7893,  70.6869,  63.6488],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000, 235.7151,  22.5140, 251.3558,  37.9816],
         [  0.0000,  25.1451, 105.7756,  40.8789, 120.3514],
         [  0.0000, 195.5285, 105.7756, 211.2624, 120.3514]],

        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT labels shape: torch.Size([4, 3, 1])
[utils/util.py::ComputeLoss.__call__] GT bboxes shape: torch.Size([4, 3, 4])
[utils/util.py::ComputeLoss.__call__] GT mask shape: torch.Size([4, 3, 1])
[utils/util.py::ComputeLoss.__call__] Pred output dimensions - b: 4, a: 512, c: 64
[utils/util.py::ComputeLoss.__call__] Pred bboxes after softmax shape: torch.Size([4, 512, 4, 16])
[utils/util.py::ComputeLoss.__call__] Pred bboxes after matmul shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Final pred bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.__call__] ASSIGNMENT PHASE ---

--- [utils/util.py::ComputeLoss.assign] PYTORCH ASSIGNMENT DEBUG ---
[utils/util.py::ComputeLoss.assign] pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] true_labels shape: torch.Size([4, 3, 1])
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 3, 4])
[utils/util.py::ComputeLoss.assign] true_mask shape: torch.Size([4, 3, 1])
[utils/util.py::ComputeLoss.assign] anchors shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.assign] Batch size: 4, Max boxes: 3
[utils/util.py::ComputeLoss.assign] Created indices tensor with shape: torch.Size([2, 4, 3])

--- [utils/util.py::ComputeLoss.assign] IOUs DEBUG ---
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 3, 4])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([4, 3, 1, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([4, 1, 512, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([4, 3, 1, 1]), h: torch.Size([4, 3, 1, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([4, 1, 512, 1]), h: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.000000, max: 0.634873
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: -1.009463, max: 0.626204
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.assign] overlaps shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] overlaps min: 0.0, max: 0.6262036561965942
[utils/util.py::ComputeLoss.assign] align_metric shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] align_metric min: 0.0, max: 0.002693920163437724
[utils/util.py::ComputeLoss.assign] mask_in_gts shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] mask_in_gts sum: 18.0
[utils/util.py::ComputeLoss.assign] metrics shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] top_k_mask shape: torch.Size([4, 3, 10])
[utils/util.py::ComputeLoss.assign] top_k_metrics shape: torch.Size([4, 3, 10])
[utils/util.py::ComputeLoss.assign] top_k_indices shape: torch.Size([4, 3, 10])
[utils/util.py::ComputeLoss.assign] is_in_top_k shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] mask_top_k shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] mask_pos shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] fg_mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] fg_mask sum: 18.0
[utils/util.py::ComputeLoss.assign] target_gt_idx shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_labels shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] Normalized target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] target_scores sum: 2.382497787475586
--- [utils/util.py::ComputeLoss.assign] END PYTORCH ASSIGNMENT DEBUG ---

[utils/util.py::ComputeLoss.__call__] Target bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Target scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] FG mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.__call__] Target scores sum: 2.382498
[utils/util.py::ComputeLoss.__call__] Classification loss computed: 6.814015
[utils/util.py::ComputeLoss.__call__] Foreground count: 18
[utils/util.py::ComputeLoss.__call__] Weight shape: torch.Size([18, 1])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([18, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([18, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([18, 1]), h: torch.Size([18, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([18, 1]), h: torch.Size([18, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([18, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([18, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([18, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.257540, max: 0.635093
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([18, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([18, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([18, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([18, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: 0.186559, max: 0.626424
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.__call__] IoU values shape: torch.Size([18, 1])
[utils/util.py::ComputeLoss.__call__] Box loss computed: 0.577527
[utils/util.py::ComputeLoss.__call__] Target LT-RB shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.df_loss] PYTORCH DFL LOSS DEBUG ---
[utils/util.py::ComputeLoss.df_loss] pred_dist shape: torch.Size([72, 16])
[utils/util.py::ComputeLoss.df_loss] target shape: torch.Size([18, 4])
[utils/util.py::ComputeLoss.df_loss] DFL loss shape: torch.Size([18, 1])
[utils/util.py::ComputeLoss.df_loss] DFL loss mean: 1.539724
--- [utils/util.py::ComputeLoss.df_loss] END PYTORCH DFL LOSS DEBUG ---

[utils/util.py::ComputeLoss.__call__] DFL loss before weighting: 1.539724
[utils/util.py::ComputeLoss.__call__] DFL loss computed: 1.074498

--- [utils/util.py::ComputeLoss.__call__] LOSS COMPONENTS DEBUG ---
[utils/util.py::ComputeLoss.__call__] Raw loss_cls: 6.814015
[utils/util.py::ComputeLoss.__call__] Raw loss_box: 0.577527
[utils/util.py::ComputeLoss.__call__] Raw loss_dfl: 1.074498
[utils/util.py::ComputeLoss.__call__] Loss weights - cls: 0.5, box: 7.5, dfl: 1.5
[utils/util.py::ComputeLoss.__call__] target_scores_sum: 2.382498
[utils/util.py::ComputeLoss.__call__] fg_mask sum: 18
[utils/util.py::ComputeLoss.__call__] Weighted loss_cls: 3.407007
[utils/util.py::ComputeLoss.__call__] Weighted loss_box: 4.331451
[utils/util.py::ComputeLoss.__call__] Weighted loss_dfl: 1.611747
[utils/util.py::ComputeLoss.__call__] Total loss: 9.350205
--- [utils/util.py::ComputeLoss.__call__] END PYTORCH LOSS COMPUTATION DEBUG ---


--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([4, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: True
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([4, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - box shape: torch.Size([4, 64, 16, 32]), cls shape: torch.Size([4, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - final concat shape: torch.Size([4, 65, 16, 32])

--- [utils/util.py::ComputeLoss.__call__] PYTORCH LOSS COMPUTATION DEBUG ---
[utils/util.py::ComputeLoss.__call__] Outputs type: <class 'list'>
[utils/util.py::ComputeLoss.__call__] x type: <class 'list'>, len: 1
[utils/util.py::ComputeLoss.__call__] x[0] shape: torch.Size([4, 65, 16, 32])
[utils/util.py::ComputeLoss.__call__] Concatenated output shape: torch.Size([4, 65, 512])
[utils/util.py::ComputeLoss.__call__] self.no: 65, self.dfl_ch: 16, self.nc: 1
[utils/util.py::ComputeLoss.__call__] pred_output shape: torch.Size([4, 64, 512])
[utils/util.py::ComputeLoss.__call__] pred_scores shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.__call__] After permute - pred_output shape: torch.Size([4, 512, 64])
[utils/util.py::ComputeLoss.__call__] After permute - pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Size tensor: tensor([128., 256.], device='cuda:0', dtype=torch.float16)
[utils/util.py::ComputeLoss.__call__] Stride: tensor([8.])
[utils/util.py::ComputeLoss.__call__] Anchor points shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.__call__] Stride tensor shape: torch.Size([512, 1])

--- [utils/util.py::ComputeLoss.__call__] TARGET PROCESSING ---
[utils/util.py::ComputeLoss.__call__] Targets shape: torch.Size([6, 6])
[utils/util.py::ComputeLoss.__call__] Targets dtype: torch.float32
[utils/util.py::ComputeLoss.__call__] First few targets: tensor([[0.0000, 0.0000, 0.8056, 0.6834, 0.0889, 0.1794],
        [1.0000, 0.0000, 0.8956, 0.2701, 0.0547, 0.1025],
        [1.0000, 0.0000, 0.4674, 0.2419, 0.0441, 0.0935],
        [1.0000, 0.0000, 0.7549, 0.7493, 0.0438, 0.0907],
        [1.0000, 0.0000, 0.4271, 0.7513, 0.0430, 0.0947]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Image indices: tensor([0., 1., 1., 1., 1., 3.], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Counts per image: tensor([1, 4, 1], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT tensor shape: torch.Size([4, 4, 5])
[utils/util.py::ComputeLoss.__call__] Image 0: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 1: 4 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 3: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] GT before coordinate conversion: tensor([[[0.0000, 0.8056, 0.6834, 0.0889, 0.1794],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.8956, 0.2701, 0.0547, 0.1025],
         [0.0000, 0.4674, 0.2419, 0.0441, 0.0935],
         [0.0000, 0.7549, 0.7493, 0.0438, 0.0907],
         [0.0000, 0.4271, 0.7513, 0.0430, 0.0947]],

        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.5646, 0.4342, 0.0646, 0.1264],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT after coordinate conversion: tensor([[[  0.0000, 194.8523,  75.9916, 217.6222,  98.9541],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000, 222.2750,  28.0076, 236.2690,  41.1333],
         [  0.0000, 114.0181,  24.9760, 125.3163,  36.9457],
         [  0.0000, 187.6433,  90.1023, 198.8607, 101.7135],
         [  0.0000, 103.8431,  90.1023, 114.8435, 102.2184]],

        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000, 136.2686,  47.4855, 152.7938,  63.6649],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT labels shape: torch.Size([4, 4, 1])
[utils/util.py::ComputeLoss.__call__] GT bboxes shape: torch.Size([4, 4, 4])
[utils/util.py::ComputeLoss.__call__] GT mask shape: torch.Size([4, 4, 1])
[utils/util.py::ComputeLoss.__call__] Pred output dimensions - b: 4, a: 512, c: 64
[utils/util.py::ComputeLoss.__call__] Pred bboxes after softmax shape: torch.Size([4, 512, 4, 16])
[utils/util.py::ComputeLoss.__call__] Pred bboxes after matmul shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Final pred bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.__call__] ASSIGNMENT PHASE ---

--- [utils/util.py::ComputeLoss.assign] PYTORCH ASSIGNMENT DEBUG ---
[utils/util.py::ComputeLoss.assign] pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] true_labels shape: torch.Size([4, 4, 1])
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 4, 4])
[utils/util.py::ComputeLoss.assign] true_mask shape: torch.Size([4, 4, 1])
[utils/util.py::ComputeLoss.assign] anchors shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.assign] Batch size: 4, Max boxes: 4
[utils/util.py::ComputeLoss.assign] Created indices tensor with shape: torch.Size([2, 4, 4])

--- [utils/util.py::ComputeLoss.assign] IOUs DEBUG ---
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 4, 4])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([4, 4, 1, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([4, 1, 512, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([4, 4, 1, 1]), h: torch.Size([4, 4, 1, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([4, 1, 512, 1]), h: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([4, 4, 512, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([4, 4, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([4, 4, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.000000, max: 0.674160
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([4, 4, 512, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([4, 4, 512, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([4, 4, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([4, 4, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: -1.019838, max: 0.664489
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.assign] overlaps shape: torch.Size([4, 4, 512])
[utils/util.py::ComputeLoss.assign] overlaps min: 0.0, max: 0.6644892692565918
[utils/util.py::ComputeLoss.assign] align_metric shape: torch.Size([4, 4, 512])
[utils/util.py::ComputeLoss.assign] align_metric min: 0.0, max: 0.004773454740643501
[utils/util.py::ComputeLoss.assign] mask_in_gts shape: torch.Size([4, 4, 512])
[utils/util.py::ComputeLoss.assign] mask_in_gts sum: 25.0
[utils/util.py::ComputeLoss.assign] metrics shape: torch.Size([4, 4, 512])
[utils/util.py::ComputeLoss.assign] top_k_mask shape: torch.Size([4, 4, 10])
[utils/util.py::ComputeLoss.assign] top_k_metrics shape: torch.Size([4, 4, 10])
[utils/util.py::ComputeLoss.assign] top_k_indices shape: torch.Size([4, 4, 10])
[utils/util.py::ComputeLoss.assign] is_in_top_k shape: torch.Size([4, 4, 512])
[utils/util.py::ComputeLoss.assign] mask_top_k shape: torch.Size([4, 4, 512])
[utils/util.py::ComputeLoss.assign] mask_pos shape: torch.Size([4, 4, 512])
[utils/util.py::ComputeLoss.assign] fg_mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] fg_mask sum: 25.0
[utils/util.py::ComputeLoss.assign] target_gt_idx shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_labels shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] Normalized target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] target_scores sum: 3.8346335887908936
--- [utils/util.py::ComputeLoss.assign] END PYTORCH ASSIGNMENT DEBUG ---

[utils/util.py::ComputeLoss.__call__] Target bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Target scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] FG mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.__call__] Target scores sum: 3.834634
[utils/util.py::ComputeLoss.__call__] Classification loss computed: 6.352465
[utils/util.py::ComputeLoss.__call__] Foreground count: 25
[utils/util.py::ComputeLoss.__call__] Weight shape: torch.Size([25, 1])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([25, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([25, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([25, 1]), h: torch.Size([25, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([25, 1]), h: torch.Size([25, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([25, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([25, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([25, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.181152, max: 0.674006
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([25, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([25, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([25, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([25, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: 0.092790, max: 0.664335
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.__call__] IoU values shape: torch.Size([25, 1])
[utils/util.py::ComputeLoss.__call__] Box loss computed: 0.624906
[utils/util.py::ComputeLoss.__call__] Target LT-RB shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.df_loss] PYTORCH DFL LOSS DEBUG ---
[utils/util.py::ComputeLoss.df_loss] pred_dist shape: torch.Size([100, 16])
[utils/util.py::ComputeLoss.df_loss] target shape: torch.Size([25, 4])
[utils/util.py::ComputeLoss.df_loss] DFL loss shape: torch.Size([25, 1])
[utils/util.py::ComputeLoss.df_loss] DFL loss mean: 1.687457
--- [utils/util.py::ComputeLoss.df_loss] END PYTORCH DFL LOSS DEBUG ---

[utils/util.py::ComputeLoss.__call__] DFL loss before weighting: 1.687457
[utils/util.py::ComputeLoss.__call__] DFL loss computed: 1.368540

--- [utils/util.py::ComputeLoss.__call__] LOSS COMPONENTS DEBUG ---
[utils/util.py::ComputeLoss.__call__] Raw loss_cls: 6.352465
[utils/util.py::ComputeLoss.__call__] Raw loss_box: 0.624906
[utils/util.py::ComputeLoss.__call__] Raw loss_dfl: 1.368540
[utils/util.py::ComputeLoss.__call__] Loss weights - cls: 0.5, box: 7.5, dfl: 1.5
[utils/util.py::ComputeLoss.__call__] target_scores_sum: 3.834634
[utils/util.py::ComputeLoss.__call__] fg_mask sum: 25
[utils/util.py::ComputeLoss.__call__] Weighted loss_cls: 3.176232
[utils/util.py::ComputeLoss.__call__] Weighted loss_box: 4.686795
[utils/util.py::ComputeLoss.__call__] Weighted loss_dfl: 2.052810
[utils/util.py::ComputeLoss.__call__] Total loss: 9.915838
--- [utils/util.py::ComputeLoss.__call__] END PYTORCH LOSS COMPUTATION DEBUG ---


--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([4, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: True
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([4, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - box shape: torch.Size([4, 64, 16, 32]), cls shape: torch.Size([4, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - final concat shape: torch.Size([4, 65, 16, 32])

--- [utils/util.py::ComputeLoss.__call__] PYTORCH LOSS COMPUTATION DEBUG ---
[utils/util.py::ComputeLoss.__call__] Outputs type: <class 'list'>
[utils/util.py::ComputeLoss.__call__] x type: <class 'list'>, len: 1
[utils/util.py::ComputeLoss.__call__] x[0] shape: torch.Size([4, 65, 16, 32])
[utils/util.py::ComputeLoss.__call__] Concatenated output shape: torch.Size([4, 65, 512])
[utils/util.py::ComputeLoss.__call__] self.no: 65, self.dfl_ch: 16, self.nc: 1
[utils/util.py::ComputeLoss.__call__] pred_output shape: torch.Size([4, 64, 512])
[utils/util.py::ComputeLoss.__call__] pred_scores shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.__call__] After permute - pred_output shape: torch.Size([4, 512, 64])
[utils/util.py::ComputeLoss.__call__] After permute - pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Size tensor: tensor([128., 256.], device='cuda:0', dtype=torch.float16)
[utils/util.py::ComputeLoss.__call__] Stride: tensor([8.])
[utils/util.py::ComputeLoss.__call__] Anchor points shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.__call__] Stride tensor shape: torch.Size([512, 1])

--- [utils/util.py::ComputeLoss.__call__] TARGET PROCESSING ---
[utils/util.py::ComputeLoss.__call__] Targets shape: torch.Size([3, 6])
[utils/util.py::ComputeLoss.__call__] Targets dtype: torch.float32
[utils/util.py::ComputeLoss.__call__] First few targets: tensor([[0.0000, 0.0000, 0.5990, 0.8941, 0.1580, 0.2119],
        [2.0000, 0.0000, 0.5939, 0.3199, 0.0665, 0.1406],
        [3.0000, 0.0000, 0.4881, 0.7139, 0.1254, 0.2622]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Image indices: tensor([0., 2., 3.], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Counts per image: tensor([1, 1, 1], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT tensor shape: torch.Size([4, 1, 5])
[utils/util.py::ComputeLoss.__call__] Image 0: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 2: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 3: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] GT before coordinate conversion: tensor([[[0.0000, 0.5990, 0.8941, 0.1580, 0.2119]],

        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.5939, 0.3199, 0.0665, 0.1406]],

        [[0.0000, 0.4881, 0.7139, 0.1254, 0.2622]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT after coordinate conversion: tensor([[[  0.0000, 133.1231, 100.8801, 173.5676, 127.9990]],

        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000, 143.5208,  31.9431, 160.5573,  49.9422]],

        [[  0.0000, 108.8966,  74.5937, 140.9870, 108.1528]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT labels shape: torch.Size([4, 1, 1])
[utils/util.py::ComputeLoss.__call__] GT bboxes shape: torch.Size([4, 1, 4])
[utils/util.py::ComputeLoss.__call__] GT mask shape: torch.Size([4, 1, 1])
[utils/util.py::ComputeLoss.__call__] Pred output dimensions - b: 4, a: 512, c: 64
[utils/util.py::ComputeLoss.__call__] Pred bboxes after softmax shape: torch.Size([4, 512, 4, 16])
[utils/util.py::ComputeLoss.__call__] Pred bboxes after matmul shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Final pred bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.__call__] ASSIGNMENT PHASE ---

--- [utils/util.py::ComputeLoss.assign] PYTORCH ASSIGNMENT DEBUG ---
[utils/util.py::ComputeLoss.assign] pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] true_labels shape: torch.Size([4, 1, 1])
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 1, 4])
[utils/util.py::ComputeLoss.assign] true_mask shape: torch.Size([4, 1, 1])
[utils/util.py::ComputeLoss.assign] anchors shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.assign] Batch size: 4, Max boxes: 1
[utils/util.py::ComputeLoss.assign] Created indices tensor with shape: torch.Size([2, 4, 1])

--- [utils/util.py::ComputeLoss.assign] IOUs DEBUG ---
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 1, 4])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([4, 1, 1, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([4, 1, 512, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([4, 1, 1, 1]), h: torch.Size([4, 1, 1, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([4, 1, 512, 1]), h: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.000000, max: 0.594049
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: -0.948812, max: 0.592299
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.assign] overlaps shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.assign] overlaps min: 0.0, max: 0.592299222946167
[utils/util.py::ComputeLoss.assign] align_metric shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.assign] align_metric min: 0.0, max: 0.002844814443960786
[utils/util.py::ComputeLoss.assign] mask_in_gts shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.assign] mask_in_gts sum: 39.0
[utils/util.py::ComputeLoss.assign] metrics shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.assign] top_k_mask shape: torch.Size([4, 1, 10])
[utils/util.py::ComputeLoss.assign] top_k_metrics shape: torch.Size([4, 1, 10])
[utils/util.py::ComputeLoss.assign] top_k_indices shape: torch.Size([4, 1, 10])
[utils/util.py::ComputeLoss.assign] is_in_top_k shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.assign] mask_top_k shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.assign] mask_pos shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.assign] fg_mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] fg_mask sum: 24.0
[utils/util.py::ComputeLoss.assign] target_gt_idx shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_labels shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] Normalized target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] target_scores sum: 3.5346899032592773
--- [utils/util.py::ComputeLoss.assign] END PYTORCH ASSIGNMENT DEBUG ---

[utils/util.py::ComputeLoss.__call__] Target bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Target scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] FG mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.__call__] Target scores sum: 3.534690
[utils/util.py::ComputeLoss.__call__] Classification loss computed: 6.219605
[utils/util.py::ComputeLoss.__call__] Foreground count: 24
[utils/util.py::ComputeLoss.__call__] Weight shape: torch.Size([24, 1])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([24, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([24, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([24, 1]), h: torch.Size([24, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([24, 1]), h: torch.Size([24, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([24, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([24, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([24, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.289499, max: 0.594082
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([24, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([24, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([24, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([24, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: 0.230655, max: 0.592329
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.__call__] IoU values shape: torch.Size([24, 1])
[utils/util.py::ComputeLoss.__call__] Box loss computed: 0.505353
[utils/util.py::ComputeLoss.__call__] Target LT-RB shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.df_loss] PYTORCH DFL LOSS DEBUG ---
[utils/util.py::ComputeLoss.df_loss] pred_dist shape: torch.Size([96, 16])
[utils/util.py::ComputeLoss.df_loss] target shape: torch.Size([24, 4])
[utils/util.py::ComputeLoss.df_loss] DFL loss shape: torch.Size([24, 1])
[utils/util.py::ComputeLoss.df_loss] DFL loss mean: 2.042994
--- [utils/util.py::ComputeLoss.df_loss] END PYTORCH DFL LOSS DEBUG ---

[utils/util.py::ComputeLoss.__call__] DFL loss before weighting: 2.042994
[utils/util.py::ComputeLoss.__call__] DFL loss computed: 1.794293

--- [utils/util.py::ComputeLoss.__call__] LOSS COMPONENTS DEBUG ---
[utils/util.py::ComputeLoss.__call__] Raw loss_cls: 6.219605
[utils/util.py::ComputeLoss.__call__] Raw loss_box: 0.505353
[utils/util.py::ComputeLoss.__call__] Raw loss_dfl: 1.794293
[utils/util.py::ComputeLoss.__call__] Loss weights - cls: 0.5, box: 7.5, dfl: 1.5
[utils/util.py::ComputeLoss.__call__] target_scores_sum: 3.534690
[utils/util.py::ComputeLoss.__call__] fg_mask sum: 24
[utils/util.py::ComputeLoss.__call__] Weighted loss_cls: 3.109802
[utils/util.py::ComputeLoss.__call__] Weighted loss_box: 3.790145
[utils/util.py::ComputeLoss.__call__] Weighted loss_dfl: 2.691439
[utils/util.py::ComputeLoss.__call__] Total loss: 9.591387
--- [utils/util.py::ComputeLoss.__call__] END PYTORCH LOSS COMPUTATION DEBUG ---


--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([4, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: True
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([4, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - box shape: torch.Size([4, 64, 16, 32]), cls shape: torch.Size([4, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - final concat shape: torch.Size([4, 65, 16, 32])

--- [utils/util.py::ComputeLoss.__call__] PYTORCH LOSS COMPUTATION DEBUG ---
[utils/util.py::ComputeLoss.__call__] Outputs type: <class 'list'>
[utils/util.py::ComputeLoss.__call__] x type: <class 'list'>, len: 1
[utils/util.py::ComputeLoss.__call__] x[0] shape: torch.Size([4, 65, 16, 32])
[utils/util.py::ComputeLoss.__call__] Concatenated output shape: torch.Size([4, 65, 512])
[utils/util.py::ComputeLoss.__call__] self.no: 65, self.dfl_ch: 16, self.nc: 1
[utils/util.py::ComputeLoss.__call__] pred_output shape: torch.Size([4, 64, 512])
[utils/util.py::ComputeLoss.__call__] pred_scores shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.__call__] After permute - pred_output shape: torch.Size([4, 512, 64])
[utils/util.py::ComputeLoss.__call__] After permute - pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Size tensor: tensor([128., 256.], device='cuda:0', dtype=torch.float16)
[utils/util.py::ComputeLoss.__call__] Stride: tensor([8.])
[utils/util.py::ComputeLoss.__call__] Anchor points shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.__call__] Stride tensor shape: torch.Size([512, 1])

--- [utils/util.py::ComputeLoss.__call__] TARGET PROCESSING ---
[utils/util.py::ComputeLoss.__call__] Targets shape: torch.Size([3, 6])
[utils/util.py::ComputeLoss.__call__] Targets dtype: torch.float32
[utils/util.py::ComputeLoss.__call__] First few targets: tensor([[0.0000, 0.0000, 0.3662, 0.2017, 0.0692, 0.1399],
        [1.0000, 0.0000, 0.2494, 0.4519, 0.0465, 0.0965],
        [3.0000, 0.0000, 0.6056, 0.7316, 0.0821, 0.1556]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Image indices: tensor([0., 1., 3.], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Counts per image: tensor([1, 1, 1], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT tensor shape: torch.Size([4, 1, 5])
[utils/util.py::ComputeLoss.__call__] Image 0: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 1: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 3: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] GT before coordinate conversion: tensor([[[0.0000, 0.3662, 0.2017, 0.0692, 0.1399]],

        [[0.0000, 0.2494, 0.4519, 0.0465, 0.0965]],

        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.6056, 0.7316, 0.0821, 0.1556]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT after coordinate conversion: tensor([[[  0.0000,  84.8963,  16.8566, 102.6197,  34.7683]],

        [[  0.0000,  57.8982,  51.6640,  69.8076,  64.0182]],

        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000, 144.5194,  83.6845, 165.5335, 103.5989]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT labels shape: torch.Size([4, 1, 1])
[utils/util.py::ComputeLoss.__call__] GT bboxes shape: torch.Size([4, 1, 4])
[utils/util.py::ComputeLoss.__call__] GT mask shape: torch.Size([4, 1, 1])
[utils/util.py::ComputeLoss.__call__] Pred output dimensions - b: 4, a: 512, c: 64
[utils/util.py::ComputeLoss.__call__] Pred bboxes after softmax shape: torch.Size([4, 512, 4, 16])
[utils/util.py::ComputeLoss.__call__] Pred bboxes after matmul shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Final pred bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.__call__] ASSIGNMENT PHASE ---

--- [utils/util.py::ComputeLoss.assign] PYTORCH ASSIGNMENT DEBUG ---
[utils/util.py::ComputeLoss.assign] pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] true_labels shape: torch.Size([4, 1, 1])
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 1, 4])
[utils/util.py::ComputeLoss.assign] true_mask shape: torch.Size([4, 1, 1])
[utils/util.py::ComputeLoss.assign] anchors shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.assign] Batch size: 4, Max boxes: 1
[utils/util.py::ComputeLoss.assign] Created indices tensor with shape: torch.Size([2, 4, 1])

--- [utils/util.py::ComputeLoss.assign] IOUs DEBUG ---
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 1, 4])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([4, 1, 1, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([4, 1, 512, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([4, 1, 1, 1]), h: torch.Size([4, 1, 1, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([4, 1, 512, 1]), h: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.000000, max: 0.710843
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: -0.965635, max: 0.709152
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.assign] overlaps shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.assign] overlaps min: 0.0, max: 0.709151566028595
[utils/util.py::ComputeLoss.assign] align_metric shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.assign] align_metric min: 0.0, max: 0.011054126545786858
[utils/util.py::ComputeLoss.assign] mask_in_gts shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.assign] mask_in_gts sum: 17.0
[utils/util.py::ComputeLoss.assign] metrics shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.assign] top_k_mask shape: torch.Size([4, 1, 10])
[utils/util.py::ComputeLoss.assign] top_k_metrics shape: torch.Size([4, 1, 10])
[utils/util.py::ComputeLoss.assign] top_k_indices shape: torch.Size([4, 1, 10])
[utils/util.py::ComputeLoss.assign] is_in_top_k shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.assign] mask_top_k shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.assign] mask_pos shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.assign] fg_mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] fg_mask sum: 17.0
[utils/util.py::ComputeLoss.assign] target_gt_idx shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_labels shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] Normalized target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] target_scores sum: 1.8892079591751099
--- [utils/util.py::ComputeLoss.assign] END PYTORCH ASSIGNMENT DEBUG ---

[utils/util.py::ComputeLoss.__call__] Target bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Target scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] FG mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.__call__] Target scores sum: 1.889208
[utils/util.py::ComputeLoss.__call__] Classification loss computed: 6.575176
[utils/util.py::ComputeLoss.__call__] Foreground count: 17
[utils/util.py::ComputeLoss.__call__] Weight shape: torch.Size([17, 1])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([17, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([17, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([17, 1]), h: torch.Size([17, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([17, 1]), h: torch.Size([17, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([17, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([17, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([17, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.199096, max: 0.711076
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([17, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([17, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([17, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([17, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: 0.145487, max: 0.709385
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.__call__] IoU values shape: torch.Size([17, 1])
[utils/util.py::ComputeLoss.__call__] Box loss computed: 0.479078
[utils/util.py::ComputeLoss.__call__] Target LT-RB shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.df_loss] PYTORCH DFL LOSS DEBUG ---
[utils/util.py::ComputeLoss.df_loss] pred_dist shape: torch.Size([68, 16])
[utils/util.py::ComputeLoss.df_loss] target shape: torch.Size([17, 4])
[utils/util.py::ComputeLoss.df_loss] DFL loss shape: torch.Size([17, 1])
[utils/util.py::ComputeLoss.df_loss] DFL loss mean: 1.593379
--- [utils/util.py::ComputeLoss.df_loss] END PYTORCH DFL LOSS DEBUG ---

[utils/util.py::ComputeLoss.__call__] DFL loss before weighting: 1.593379
[utils/util.py::ComputeLoss.__call__] DFL loss computed: 1.001857

--- [utils/util.py::ComputeLoss.__call__] LOSS COMPONENTS DEBUG ---
[utils/util.py::ComputeLoss.__call__] Raw loss_cls: 6.575176
[utils/util.py::ComputeLoss.__call__] Raw loss_box: 0.479078
[utils/util.py::ComputeLoss.__call__] Raw loss_dfl: 1.001857
[utils/util.py::ComputeLoss.__call__] Loss weights - cls: 0.5, box: 7.5, dfl: 1.5
[utils/util.py::ComputeLoss.__call__] target_scores_sum: 1.889208
[utils/util.py::ComputeLoss.__call__] fg_mask sum: 17
[utils/util.py::ComputeLoss.__call__] Weighted loss_cls: 3.287588
[utils/util.py::ComputeLoss.__call__] Weighted loss_box: 3.593084
[utils/util.py::ComputeLoss.__call__] Weighted loss_dfl: 1.502785
[utils/util.py::ComputeLoss.__call__] Total loss: 8.383457
--- [utils/util.py::ComputeLoss.__call__] END PYTORCH LOSS COMPUTATION DEBUG ---


--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([4, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: True
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([4, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - box shape: torch.Size([4, 64, 16, 32]), cls shape: torch.Size([4, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - final concat shape: torch.Size([4, 65, 16, 32])

--- [utils/util.py::ComputeLoss.__call__] PYTORCH LOSS COMPUTATION DEBUG ---
[utils/util.py::ComputeLoss.__call__] Outputs type: <class 'list'>
[utils/util.py::ComputeLoss.__call__] x type: <class 'list'>, len: 1
[utils/util.py::ComputeLoss.__call__] x[0] shape: torch.Size([4, 65, 16, 32])
[utils/util.py::ComputeLoss.__call__] Concatenated output shape: torch.Size([4, 65, 512])
[utils/util.py::ComputeLoss.__call__] self.no: 65, self.dfl_ch: 16, self.nc: 1
[utils/util.py::ComputeLoss.__call__] pred_output shape: torch.Size([4, 64, 512])
[utils/util.py::ComputeLoss.__call__] pred_scores shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.__call__] After permute - pred_output shape: torch.Size([4, 512, 64])
[utils/util.py::ComputeLoss.__call__] After permute - pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Size tensor: tensor([128., 256.], device='cuda:0', dtype=torch.float16)
[utils/util.py::ComputeLoss.__call__] Stride: tensor([8.])
[utils/util.py::ComputeLoss.__call__] Anchor points shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.__call__] Stride tensor shape: torch.Size([512, 1])

--- [utils/util.py::ComputeLoss.__call__] TARGET PROCESSING ---
[utils/util.py::ComputeLoss.__call__] Targets shape: torch.Size([7, 6])
[utils/util.py::ComputeLoss.__call__] Targets dtype: torch.float32
[utils/util.py::ComputeLoss.__call__] First few targets: tensor([[0.0000, 0.0000, 0.4040, 0.4696, 0.0801, 0.1418],
        [0.0000, 0.0000, 0.0205, 0.9763, 0.0409, 0.0474],
        [1.0000, 0.0000, 0.6052, 0.9490, 0.1078, 0.1020],
        [2.0000, 0.0000, 0.9655, 0.0977, 0.0689, 0.1954],
        [2.0000, 0.0000, 0.0998, 0.9813, 0.1001, 0.0373]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Image indices: tensor([0., 0., 1., 2., 2., 2., 3.], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Counts per image: tensor([2, 1, 3, 1], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT tensor shape: torch.Size([4, 3, 5])
[utils/util.py::ComputeLoss.__call__] Image 0: 2 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 1: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 2: 3 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 3: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] GT before coordinate conversion: tensor([[[0.0000, 0.4040, 0.4696, 0.0801, 0.1418],
         [0.0000, 0.0205, 0.9763, 0.0409, 0.0474],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.6052, 0.9490, 0.1078, 0.1020],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.9655, 0.0977, 0.0689, 0.1954],
         [0.0000, 0.0998, 0.9813, 0.1001, 0.0373],
         [0.0000, 0.6368, 0.9612, 0.1125, 0.0776]],

        [[0.0000, 0.8385, 0.7970, 0.0844, 0.1697],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT after coordinate conversion: tensor([[[  0.0000,  93.1644,  51.0327, 113.6616,  69.1877],
         [  0.0000,   0.0000, 121.9291,  10.4725, 127.9990],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000, 141.1363, 114.9429, 168.7265, 127.9990],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000, 238.3513,   0.0000, 255.9990,  25.0048],
         [  0.0000,  12.7235, 123.2232,  38.3543, 127.9990],
         [  0.0000, 148.6140, 118.0678, 177.4238, 127.9990]],

        [[  0.0000, 203.8537,  91.1505, 225.4600, 112.8694],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT labels shape: torch.Size([4, 3, 1])
[utils/util.py::ComputeLoss.__call__] GT bboxes shape: torch.Size([4, 3, 4])
[utils/util.py::ComputeLoss.__call__] GT mask shape: torch.Size([4, 3, 1])
[utils/util.py::ComputeLoss.__call__] Pred output dimensions - b: 4, a: 512, c: 64
[utils/util.py::ComputeLoss.__call__] Pred bboxes after softmax shape: torch.Size([4, 512, 4, 16])
[utils/util.py::ComputeLoss.__call__] Pred bboxes after matmul shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Final pred bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.__call__] ASSIGNMENT PHASE ---

--- [utils/util.py::ComputeLoss.assign] PYTORCH ASSIGNMENT DEBUG ---
[utils/util.py::ComputeLoss.assign] pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] true_labels shape: torch.Size([4, 3, 1])
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 3, 4])
[utils/util.py::ComputeLoss.assign] true_mask shape: torch.Size([4, 3, 1])
[utils/util.py::ComputeLoss.assign] anchors shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.assign] Batch size: 4, Max boxes: 3
[utils/util.py::ComputeLoss.assign] Created indices tensor with shape: torch.Size([2, 4, 3])

--- [utils/util.py::ComputeLoss.assign] IOUs DEBUG ---
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 3, 4])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([4, 3, 1, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([4, 1, 512, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([4, 3, 1, 1]), h: torch.Size([4, 3, 1, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([4, 1, 512, 1]), h: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.000000, max: 0.695345
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: -0.963533, max: 0.688015
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.assign] overlaps shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] overlaps min: 0.0, max: 0.688014566898346
[utils/util.py::ComputeLoss.assign] align_metric shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] align_metric min: 0.0, max: 0.007483826018869877
[utils/util.py::ComputeLoss.assign] mask_in_gts shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] mask_in_gts sum: 34.0
[utils/util.py::ComputeLoss.assign] metrics shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] top_k_mask shape: torch.Size([4, 3, 10])
[utils/util.py::ComputeLoss.assign] top_k_metrics shape: torch.Size([4, 3, 10])
[utils/util.py::ComputeLoss.assign] top_k_indices shape: torch.Size([4, 3, 10])
[utils/util.py::ComputeLoss.assign] is_in_top_k shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] mask_top_k shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] mask_pos shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] fg_mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] fg_mask sum: 34.0
[utils/util.py::ComputeLoss.assign] target_gt_idx shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_labels shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] Normalized target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] target_scores sum: 4.6137285232543945
--- [utils/util.py::ComputeLoss.assign] END PYTORCH ASSIGNMENT DEBUG ---

[utils/util.py::ComputeLoss.__call__] Target bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Target scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] FG mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.__call__] Target scores sum: 4.613729
[utils/util.py::ComputeLoss.__call__] Classification loss computed: 6.119644
[utils/util.py::ComputeLoss.__call__] Foreground count: 34
[utils/util.py::ComputeLoss.__call__] Weight shape: torch.Size([34, 1])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([34, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([34, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([34, 1]), h: torch.Size([34, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([34, 1]), h: torch.Size([34, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([34, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([34, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([34, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.098565, max: 0.695424
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([34, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([34, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([34, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([34, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: 0.024535, max: 0.688093
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.__call__] IoU values shape: torch.Size([34, 1])
[utils/util.py::ComputeLoss.__call__] Box loss computed: 0.476814
[utils/util.py::ComputeLoss.__call__] Target LT-RB shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.df_loss] PYTORCH DFL LOSS DEBUG ---
[utils/util.py::ComputeLoss.df_loss] pred_dist shape: torch.Size([136, 16])
[utils/util.py::ComputeLoss.df_loss] target shape: torch.Size([34, 4])
[utils/util.py::ComputeLoss.df_loss] DFL loss shape: torch.Size([34, 1])
[utils/util.py::ComputeLoss.df_loss] DFL loss mean: 1.728379
--- [utils/util.py::ComputeLoss.df_loss] END PYTORCH DFL LOSS DEBUG ---

[utils/util.py::ComputeLoss.__call__] DFL loss before weighting: 1.728379
[utils/util.py::ComputeLoss.__call__] DFL loss computed: 1.187653

--- [utils/util.py::ComputeLoss.__call__] LOSS COMPONENTS DEBUG ---
[utils/util.py::ComputeLoss.__call__] Raw loss_cls: 6.119644
[utils/util.py::ComputeLoss.__call__] Raw loss_box: 0.476814
[utils/util.py::ComputeLoss.__call__] Raw loss_dfl: 1.187653
[utils/util.py::ComputeLoss.__call__] Loss weights - cls: 0.5, box: 7.5, dfl: 1.5
[utils/util.py::ComputeLoss.__call__] target_scores_sum: 4.613729
[utils/util.py::ComputeLoss.__call__] fg_mask sum: 34
[utils/util.py::ComputeLoss.__call__] Weighted loss_cls: 3.059822
[utils/util.py::ComputeLoss.__call__] Weighted loss_box: 3.576105
[utils/util.py::ComputeLoss.__call__] Weighted loss_dfl: 1.781480
[utils/util.py::ComputeLoss.__call__] Total loss: 8.417407
--- [utils/util.py::ComputeLoss.__call__] END PYTORCH LOSS COMPUTATION DEBUG ---


--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([4, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: True
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([4, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - box shape: torch.Size([4, 64, 16, 32]), cls shape: torch.Size([4, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - final concat shape: torch.Size([4, 65, 16, 32])

--- [utils/util.py::ComputeLoss.__call__] PYTORCH LOSS COMPUTATION DEBUG ---
[utils/util.py::ComputeLoss.__call__] Outputs type: <class 'list'>
[utils/util.py::ComputeLoss.__call__] x type: <class 'list'>, len: 1
[utils/util.py::ComputeLoss.__call__] x[0] shape: torch.Size([4, 65, 16, 32])
[utils/util.py::ComputeLoss.__call__] Concatenated output shape: torch.Size([4, 65, 512])
[utils/util.py::ComputeLoss.__call__] self.no: 65, self.dfl_ch: 16, self.nc: 1
[utils/util.py::ComputeLoss.__call__] pred_output shape: torch.Size([4, 64, 512])
[utils/util.py::ComputeLoss.__call__] pred_scores shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.__call__] After permute - pred_output shape: torch.Size([4, 512, 64])
[utils/util.py::ComputeLoss.__call__] After permute - pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Size tensor: tensor([128., 256.], device='cuda:0', dtype=torch.float16)
[utils/util.py::ComputeLoss.__call__] Stride: tensor([8.])
[utils/util.py::ComputeLoss.__call__] Anchor points shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.__call__] Stride tensor shape: torch.Size([512, 1])

--- [utils/util.py::ComputeLoss.__call__] TARGET PROCESSING ---
[utils/util.py::ComputeLoss.__call__] Targets shape: torch.Size([5, 6])
[utils/util.py::ComputeLoss.__call__] Targets dtype: torch.float32
[utils/util.py::ComputeLoss.__call__] First few targets: tensor([[1.0000, 0.0000, 0.3941, 0.2725, 0.0879, 0.1705],
        [1.0000, 0.0000, 0.0244, 0.8594, 0.0487, 0.1478],
        [2.0000, 0.0000, 0.5897, 0.7887, 0.0912, 0.1780],
        [3.0000, 0.0000, 0.3884, 0.2771, 0.0542, 0.1185],
        [3.0000, 0.0000, 0.8671, 0.3647, 0.0606, 0.1289]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Image indices: tensor([1., 1., 2., 3., 3.], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Counts per image: tensor([2, 1, 2], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT tensor shape: torch.Size([4, 2, 5])
[utils/util.py::ComputeLoss.__call__] Image 1: 2 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 2: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 3: 2 targets assigned
[utils/util.py::ComputeLoss.__call__] GT before coordinate conversion: tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.3941, 0.2725, 0.0879, 0.1705],
         [0.0000, 0.0244, 0.8594, 0.0487, 0.1478]],

        [[0.0000, 0.5897, 0.7887, 0.0912, 0.1780],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.3884, 0.2771, 0.0542, 0.1185],
         [0.0000, 0.8671, 0.3647, 0.0606, 0.1289]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT after coordinate conversion: tensor([[[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000,  89.6495,  23.9756, 112.1432,  45.7935],
         [  0.0000,   0.0000, 100.5453,  12.4674, 119.4576]],

        [[  0.0000, 139.2856,  89.5613, 162.6340, 112.3402],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000,  92.5030,  27.8785, 106.3768,  43.0519],
         [  0.0000, 214.2336,  38.4339, 229.7435,  54.9268]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT labels shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.__call__] GT bboxes shape: torch.Size([4, 2, 4])
[utils/util.py::ComputeLoss.__call__] GT mask shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.__call__] Pred output dimensions - b: 4, a: 512, c: 64
[utils/util.py::ComputeLoss.__call__] Pred bboxes after softmax shape: torch.Size([4, 512, 4, 16])
[utils/util.py::ComputeLoss.__call__] Pred bboxes after matmul shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Final pred bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.__call__] ASSIGNMENT PHASE ---

--- [utils/util.py::ComputeLoss.assign] PYTORCH ASSIGNMENT DEBUG ---
[utils/util.py::ComputeLoss.assign] pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] true_labels shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 2, 4])
[utils/util.py::ComputeLoss.assign] true_mask shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.assign] anchors shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.assign] Batch size: 4, Max boxes: 2
[utils/util.py::ComputeLoss.assign] Created indices tensor with shape: torch.Size([2, 4, 2])

--- [utils/util.py::ComputeLoss.assign] IOUs DEBUG ---
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 2, 4])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([4, 2, 1, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([4, 1, 512, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([4, 2, 1, 1]), h: torch.Size([4, 2, 1, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([4, 1, 512, 1]), h: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.000000, max: 0.841006
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: -0.978317, max: 0.838055
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.assign] overlaps shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] overlaps min: 0.0, max: 0.8380547165870667
[utils/util.py::ComputeLoss.assign] align_metric shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] align_metric min: 0.0, max: 0.028905656188726425
[utils/util.py::ComputeLoss.assign] mask_in_gts shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] mask_in_gts sum: 28.0
[utils/util.py::ComputeLoss.assign] metrics shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] top_k_mask shape: torch.Size([4, 2, 10])
[utils/util.py::ComputeLoss.assign] top_k_metrics shape: torch.Size([4, 2, 10])
[utils/util.py::ComputeLoss.assign] top_k_indices shape: torch.Size([4, 2, 10])
[utils/util.py::ComputeLoss.assign] is_in_top_k shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] mask_top_k shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] mask_pos shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] fg_mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] fg_mask sum: 28.0
[utils/util.py::ComputeLoss.assign] target_gt_idx shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_labels shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] Normalized target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] target_scores sum: 3.6575140953063965
--- [utils/util.py::ComputeLoss.assign] END PYTORCH ASSIGNMENT DEBUG ---

[utils/util.py::ComputeLoss.__call__] Target bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Target scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] FG mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.__call__] Target scores sum: 3.657514
[utils/util.py::ComputeLoss.__call__] Classification loss computed: 6.126087
[utils/util.py::ComputeLoss.__call__] Foreground count: 28
[utils/util.py::ComputeLoss.__call__] Weight shape: torch.Size([28, 1])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([28, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([28, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([28, 1]), h: torch.Size([28, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([28, 1]), h: torch.Size([28, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([28, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([28, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([28, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.213021, max: 0.841030
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([28, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([28, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([28, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([28, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: 0.127704, max: 0.838079
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.__call__] IoU values shape: torch.Size([28, 1])
[utils/util.py::ComputeLoss.__call__] Box loss computed: 0.424509
[utils/util.py::ComputeLoss.__call__] Target LT-RB shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.df_loss] PYTORCH DFL LOSS DEBUG ---
[utils/util.py::ComputeLoss.df_loss] pred_dist shape: torch.Size([112, 16])
[utils/util.py::ComputeLoss.df_loss] target shape: torch.Size([28, 4])
[utils/util.py::ComputeLoss.df_loss] DFL loss shape: torch.Size([28, 1])
[utils/util.py::ComputeLoss.df_loss] DFL loss mean: 1.627541
--- [utils/util.py::ComputeLoss.df_loss] END PYTORCH DFL LOSS DEBUG ---

[utils/util.py::ComputeLoss.__call__] DFL loss before weighting: 1.627541
[utils/util.py::ComputeLoss.__call__] DFL loss computed: 1.031424

--- [utils/util.py::ComputeLoss.__call__] LOSS COMPONENTS DEBUG ---
[utils/util.py::ComputeLoss.__call__] Raw loss_cls: 6.126087
[utils/util.py::ComputeLoss.__call__] Raw loss_box: 0.424509
[utils/util.py::ComputeLoss.__call__] Raw loss_dfl: 1.031424
[utils/util.py::ComputeLoss.__call__] Loss weights - cls: 0.5, box: 7.5, dfl: 1.5
[utils/util.py::ComputeLoss.__call__] target_scores_sum: 3.657514
[utils/util.py::ComputeLoss.__call__] fg_mask sum: 28
[utils/util.py::ComputeLoss.__call__] Weighted loss_cls: 3.063044
[utils/util.py::ComputeLoss.__call__] Weighted loss_box: 3.183818
[utils/util.py::ComputeLoss.__call__] Weighted loss_dfl: 1.547136
[utils/util.py::ComputeLoss.__call__] Total loss: 7.793997
--- [utils/util.py::ComputeLoss.__call__] END PYTORCH LOSS COMPUTATION DEBUG ---


--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([4, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: True
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([4, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - box shape: torch.Size([4, 64, 16, 32]), cls shape: torch.Size([4, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - final concat shape: torch.Size([4, 65, 16, 32])

--- [utils/util.py::ComputeLoss.__call__] PYTORCH LOSS COMPUTATION DEBUG ---
[utils/util.py::ComputeLoss.__call__] Outputs type: <class 'list'>
[utils/util.py::ComputeLoss.__call__] x type: <class 'list'>, len: 1
[utils/util.py::ComputeLoss.__call__] x[0] shape: torch.Size([4, 65, 16, 32])
[utils/util.py::ComputeLoss.__call__] Concatenated output shape: torch.Size([4, 65, 512])
[utils/util.py::ComputeLoss.__call__] self.no: 65, self.dfl_ch: 16, self.nc: 1
[utils/util.py::ComputeLoss.__call__] pred_output shape: torch.Size([4, 64, 512])
[utils/util.py::ComputeLoss.__call__] pred_scores shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.__call__] After permute - pred_output shape: torch.Size([4, 512, 64])
[utils/util.py::ComputeLoss.__call__] After permute - pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Size tensor: tensor([128., 256.], device='cuda:0', dtype=torch.float16)
[utils/util.py::ComputeLoss.__call__] Stride: tensor([8.])
[utils/util.py::ComputeLoss.__call__] Anchor points shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.__call__] Stride tensor shape: torch.Size([512, 1])

--- [utils/util.py::ComputeLoss.__call__] TARGET PROCESSING ---
[utils/util.py::ComputeLoss.__call__] Targets shape: torch.Size([6, 6])
[utils/util.py::ComputeLoss.__call__] Targets dtype: torch.float32
[utils/util.py::ComputeLoss.__call__] First few targets: tensor([[0.0000, 0.0000, 0.9212, 0.0615, 0.0679, 0.1230],
        [0.0000, 0.0000, 0.7704, 0.9549, 0.0677, 0.0902],
        [0.0000, 0.0000, 0.0667, 0.7655, 0.0629, 0.1302],
        [1.0000, 0.0000, 0.3457, 0.8806, 0.0709, 0.1875],
        [2.0000, 0.0000, 0.3871, 0.2238, 0.0795, 0.1589]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Image indices: tensor([0., 0., 0., 1., 2., 3.], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Counts per image: tensor([3, 1, 1, 1], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT tensor shape: torch.Size([4, 3, 5])
[utils/util.py::ComputeLoss.__call__] Image 0: 3 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 1: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 2: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 3: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] GT before coordinate conversion: tensor([[[0.0000, 0.9212, 0.0615, 0.0679, 0.1230],
         [0.0000, 0.7704, 0.9549, 0.0677, 0.0902],
         [0.0000, 0.0667, 0.7655, 0.0629, 0.1302]],

        [[0.0000, 0.3457, 0.8806, 0.0709, 0.1875],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.3871, 0.2238, 0.0795, 0.1589],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.2200, 0.6575, 0.0824, 0.1607],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT after coordinate conversion: tensor([[[  0.0000, 227.1223,   0.0000, 244.5114,  15.7426],
         [  0.0000, 188.5437, 116.4585, 205.8821, 127.9990],
         [  0.0000,   9.0330,  89.6465,  25.1325, 106.3112]],

        [[  0.0000,  79.4156, 100.7223,  97.5657, 124.7200],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000,  88.9296,  18.4681, 109.2741,  38.8125],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000,  45.7597,  73.8664,  66.8570,  94.4409],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT labels shape: torch.Size([4, 3, 1])
[utils/util.py::ComputeLoss.__call__] GT bboxes shape: torch.Size([4, 3, 4])
[utils/util.py::ComputeLoss.__call__] GT mask shape: torch.Size([4, 3, 1])
[utils/util.py::ComputeLoss.__call__] Pred output dimensions - b: 4, a: 512, c: 64
[utils/util.py::ComputeLoss.__call__] Pred bboxes after softmax shape: torch.Size([4, 512, 4, 16])
[utils/util.py::ComputeLoss.__call__] Pred bboxes after matmul shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Final pred bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.__call__] ASSIGNMENT PHASE ---

--- [utils/util.py::ComputeLoss.assign] PYTORCH ASSIGNMENT DEBUG ---
[utils/util.py::ComputeLoss.assign] pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] true_labels shape: torch.Size([4, 3, 1])
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 3, 4])
[utils/util.py::ComputeLoss.assign] true_mask shape: torch.Size([4, 3, 1])
[utils/util.py::ComputeLoss.assign] anchors shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.assign] Batch size: 4, Max boxes: 3
[utils/util.py::ComputeLoss.assign] Created indices tensor with shape: torch.Size([2, 4, 3])

--- [utils/util.py::ComputeLoss.assign] IOUs DEBUG ---
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 3, 4])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([4, 3, 1, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([4, 1, 512, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([4, 3, 1, 1]), h: torch.Size([4, 3, 1, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([4, 1, 512, 1]), h: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.000000, max: 0.669541
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: -0.973733, max: 0.667500
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.assign] overlaps shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] overlaps min: 0.0, max: 0.6675000190734863
[utils/util.py::ComputeLoss.assign] align_metric shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] align_metric min: 0.0, max: 0.00866465549916029
[utils/util.py::ComputeLoss.assign] mask_in_gts shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] mask_in_gts sum: 33.0
[utils/util.py::ComputeLoss.assign] metrics shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] top_k_mask shape: torch.Size([4, 3, 10])
[utils/util.py::ComputeLoss.assign] top_k_metrics shape: torch.Size([4, 3, 10])
[utils/util.py::ComputeLoss.assign] top_k_indices shape: torch.Size([4, 3, 10])
[utils/util.py::ComputeLoss.assign] is_in_top_k shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] mask_top_k shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] mask_pos shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] fg_mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] fg_mask sum: 33.0
[utils/util.py::ComputeLoss.assign] target_gt_idx shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_labels shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] Normalized target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] target_scores sum: 4.195517539978027
--- [utils/util.py::ComputeLoss.assign] END PYTORCH ASSIGNMENT DEBUG ---

[utils/util.py::ComputeLoss.__call__] Target bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Target scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] FG mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.__call__] Target scores sum: 4.195518
[utils/util.py::ComputeLoss.__call__] Classification loss computed: 5.720391
[utils/util.py::ComputeLoss.__call__] Foreground count: 33
[utils/util.py::ComputeLoss.__call__] Weight shape: torch.Size([33, 1])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([33, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([33, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([33, 1]), h: torch.Size([33, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([33, 1]), h: torch.Size([33, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([33, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([33, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([33, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.226719, max: 0.669339
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([33, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([33, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([33, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([33, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: 0.147628, max: 0.667298
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.__call__] IoU values shape: torch.Size([33, 1])
[utils/util.py::ComputeLoss.__call__] Box loss computed: 0.470722
[utils/util.py::ComputeLoss.__call__] Target LT-RB shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.df_loss] PYTORCH DFL LOSS DEBUG ---
[utils/util.py::ComputeLoss.df_loss] pred_dist shape: torch.Size([132, 16])
[utils/util.py::ComputeLoss.df_loss] target shape: torch.Size([33, 4])
[utils/util.py::ComputeLoss.df_loss] DFL loss shape: torch.Size([33, 1])
[utils/util.py::ComputeLoss.df_loss] DFL loss mean: 1.598388
--- [utils/util.py::ComputeLoss.df_loss] END PYTORCH DFL LOSS DEBUG ---

[utils/util.py::ComputeLoss.__call__] DFL loss before weighting: 1.598388
[utils/util.py::ComputeLoss.__call__] DFL loss computed: 1.109465

--- [utils/util.py::ComputeLoss.__call__] LOSS COMPONENTS DEBUG ---
[utils/util.py::ComputeLoss.__call__] Raw loss_cls: 5.720391
[utils/util.py::ComputeLoss.__call__] Raw loss_box: 0.470722
[utils/util.py::ComputeLoss.__call__] Raw loss_dfl: 1.109465
[utils/util.py::ComputeLoss.__call__] Loss weights - cls: 0.5, box: 7.5, dfl: 1.5
[utils/util.py::ComputeLoss.__call__] target_scores_sum: 4.195518
[utils/util.py::ComputeLoss.__call__] fg_mask sum: 33
[utils/util.py::ComputeLoss.__call__] Weighted loss_cls: 2.860195
[utils/util.py::ComputeLoss.__call__] Weighted loss_box: 3.530416
[utils/util.py::ComputeLoss.__call__] Weighted loss_dfl: 1.664197
[utils/util.py::ComputeLoss.__call__] Total loss: 8.054809
--- [utils/util.py::ComputeLoss.__call__] END PYTORCH LOSS COMPUTATION DEBUG ---


--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([4, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: True
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([4, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - box shape: torch.Size([4, 64, 16, 32]), cls shape: torch.Size([4, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - final concat shape: torch.Size([4, 65, 16, 32])

--- [utils/util.py::ComputeLoss.__call__] PYTORCH LOSS COMPUTATION DEBUG ---
[utils/util.py::ComputeLoss.__call__] Outputs type: <class 'list'>
[utils/util.py::ComputeLoss.__call__] x type: <class 'list'>, len: 1
[utils/util.py::ComputeLoss.__call__] x[0] shape: torch.Size([4, 65, 16, 32])
[utils/util.py::ComputeLoss.__call__] Concatenated output shape: torch.Size([4, 65, 512])
[utils/util.py::ComputeLoss.__call__] self.no: 65, self.dfl_ch: 16, self.nc: 1
[utils/util.py::ComputeLoss.__call__] pred_output shape: torch.Size([4, 64, 512])
[utils/util.py::ComputeLoss.__call__] pred_scores shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.__call__] After permute - pred_output shape: torch.Size([4, 512, 64])
[utils/util.py::ComputeLoss.__call__] After permute - pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Size tensor: tensor([128., 256.], device='cuda:0', dtype=torch.float16)
[utils/util.py::ComputeLoss.__call__] Stride: tensor([8.])
[utils/util.py::ComputeLoss.__call__] Anchor points shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.__call__] Stride tensor shape: torch.Size([512, 1])

--- [utils/util.py::ComputeLoss.__call__] TARGET PROCESSING ---
[utils/util.py::ComputeLoss.__call__] Targets shape: torch.Size([6, 6])
[utils/util.py::ComputeLoss.__call__] Targets dtype: torch.float32
[utils/util.py::ComputeLoss.__call__] First few targets: tensor([[0.0000, 0.0000, 0.4878, 0.2168, 0.1526, 0.2928],
        [1.0000, 0.0000, 0.2180, 0.6428, 0.1088, 0.2090],
        [1.0000, 0.0000, 0.8072, 0.6474, 0.0840, 0.1800],
        [2.0000, 0.0000, 0.0133, 0.2443, 0.0267, 0.1322],
        [2.0000, 0.0000, 0.6502, 0.1045, 0.0642, 0.1356]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Image indices: tensor([0., 1., 1., 2., 2., 2.], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Counts per image: tensor([1, 2, 3], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT tensor shape: torch.Size([4, 3, 5])
[utils/util.py::ComputeLoss.__call__] Image 0: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 1: 2 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 2: 3 targets assigned
[utils/util.py::ComputeLoss.__call__] GT before coordinate conversion: tensor([[[0.0000, 0.4878, 0.2168, 0.1526, 0.2928],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.2180, 0.6428, 0.1088, 0.2090],
         [0.0000, 0.8072, 0.6474, 0.0840, 0.1800],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.0133, 0.2443, 0.0267, 0.1322],
         [0.0000, 0.6502, 0.1045, 0.0642, 0.1356],
         [0.0000, 0.8113, 0.8591, 0.0636, 0.1356]],

        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT after coordinate conversion: tensor([[[  0.0000, 105.3514,   9.0065, 144.4232,  46.4903],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000,  41.8835,  68.9003,  69.7363,  95.6507],
         [  0.0000, 195.8836,  71.3393, 217.3854,  94.3825],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000,   0.0000,  22.8021,   6.8302,  39.7277],
         [  0.0000, 158.2435,   4.6956, 174.6711,  22.0513],
         [  0.0000, 199.5538, 101.2838, 215.8229, 118.6395]],

        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT labels shape: torch.Size([4, 3, 1])
[utils/util.py::ComputeLoss.__call__] GT bboxes shape: torch.Size([4, 3, 4])
[utils/util.py::ComputeLoss.__call__] GT mask shape: torch.Size([4, 3, 1])
[utils/util.py::ComputeLoss.__call__] Pred output dimensions - b: 4, a: 512, c: 64
[utils/util.py::ComputeLoss.__call__] Pred bboxes after softmax shape: torch.Size([4, 512, 4, 16])
[utils/util.py::ComputeLoss.__call__] Pred bboxes after matmul shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Final pred bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.__call__] ASSIGNMENT PHASE ---

--- [utils/util.py::ComputeLoss.assign] PYTORCH ASSIGNMENT DEBUG ---
[utils/util.py::ComputeLoss.assign] pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] true_labels shape: torch.Size([4, 3, 1])
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 3, 4])
[utils/util.py::ComputeLoss.assign] true_mask shape: torch.Size([4, 3, 1])
[utils/util.py::ComputeLoss.assign] anchors shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.assign] Batch size: 4, Max boxes: 3
[utils/util.py::ComputeLoss.assign] Created indices tensor with shape: torch.Size([2, 4, 3])

--- [utils/util.py::ComputeLoss.assign] IOUs DEBUG ---
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 3, 4])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([4, 3, 1, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([4, 1, 512, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([4, 3, 1, 1]), h: torch.Size([4, 3, 1, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([4, 1, 512, 1]), h: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.000000, max: 0.781437
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: -0.982643, max: 0.777814
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.assign] overlaps shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] overlaps min: 0.0, max: 0.7778137922286987
[utils/util.py::ComputeLoss.assign] align_metric shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] align_metric min: 0.0, max: 0.0325184240937233
[utils/util.py::ComputeLoss.assign] mask_in_gts shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] mask_in_gts sum: 56.0
[utils/util.py::ComputeLoss.assign] metrics shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] top_k_mask shape: torch.Size([4, 3, 10])
[utils/util.py::ComputeLoss.assign] top_k_metrics shape: torch.Size([4, 3, 10])
[utils/util.py::ComputeLoss.assign] top_k_indices shape: torch.Size([4, 3, 10])
[utils/util.py::ComputeLoss.assign] is_in_top_k shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] mask_top_k shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] mask_pos shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] fg_mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] fg_mask sum: 39.0
[utils/util.py::ComputeLoss.assign] target_gt_idx shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_labels shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] Normalized target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] target_scores sum: 5.800975799560547
--- [utils/util.py::ComputeLoss.assign] END PYTORCH ASSIGNMENT DEBUG ---

[utils/util.py::ComputeLoss.__call__] Target bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Target scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] FG mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.__call__] Target scores sum: 5.800976
[utils/util.py::ComputeLoss.__call__] Classification loss computed: 5.791051
[utils/util.py::ComputeLoss.__call__] Foreground count: 39
[utils/util.py::ComputeLoss.__call__] Weight shape: torch.Size([39, 1])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([39, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([39, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([39, 1]), h: torch.Size([39, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([39, 1]), h: torch.Size([39, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([39, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([39, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([39, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.146322, max: 0.781630
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([39, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([39, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([39, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([39, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: 0.067948, max: 0.778007
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.__call__] IoU values shape: torch.Size([39, 1])
[utils/util.py::ComputeLoss.__call__] Box loss computed: 0.492082
[utils/util.py::ComputeLoss.__call__] Target LT-RB shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.df_loss] PYTORCH DFL LOSS DEBUG ---
[utils/util.py::ComputeLoss.df_loss] pred_dist shape: torch.Size([156, 16])
[utils/util.py::ComputeLoss.df_loss] target shape: torch.Size([39, 4])
[utils/util.py::ComputeLoss.df_loss] DFL loss shape: torch.Size([39, 1])
[utils/util.py::ComputeLoss.df_loss] DFL loss mean: 1.979222
--- [utils/util.py::ComputeLoss.df_loss] END PYTORCH DFL LOSS DEBUG ---

[utils/util.py::ComputeLoss.__call__] DFL loss before weighting: 1.979222
[utils/util.py::ComputeLoss.__call__] DFL loss computed: 1.608087

--- [utils/util.py::ComputeLoss.__call__] LOSS COMPONENTS DEBUG ---
[utils/util.py::ComputeLoss.__call__] Raw loss_cls: 5.791051
[utils/util.py::ComputeLoss.__call__] Raw loss_box: 0.492082
[utils/util.py::ComputeLoss.__call__] Raw loss_dfl: 1.608087
[utils/util.py::ComputeLoss.__call__] Loss weights - cls: 0.5, box: 7.5, dfl: 1.5
[utils/util.py::ComputeLoss.__call__] target_scores_sum: 5.800976
[utils/util.py::ComputeLoss.__call__] fg_mask sum: 39
[utils/util.py::ComputeLoss.__call__] Weighted loss_cls: 2.895526
[utils/util.py::ComputeLoss.__call__] Weighted loss_box: 3.690612
[utils/util.py::ComputeLoss.__call__] Weighted loss_dfl: 2.412130
[utils/util.py::ComputeLoss.__call__] Total loss: 8.998267
--- [utils/util.py::ComputeLoss.__call__] END PYTORCH LOSS COMPUTATION DEBUG ---


--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([4, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: True
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([4, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - box shape: torch.Size([4, 64, 16, 32]), cls shape: torch.Size([4, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - final concat shape: torch.Size([4, 65, 16, 32])

--- [utils/util.py::ComputeLoss.__call__] PYTORCH LOSS COMPUTATION DEBUG ---
[utils/util.py::ComputeLoss.__call__] Outputs type: <class 'list'>
[utils/util.py::ComputeLoss.__call__] x type: <class 'list'>, len: 1
[utils/util.py::ComputeLoss.__call__] x[0] shape: torch.Size([4, 65, 16, 32])
[utils/util.py::ComputeLoss.__call__] Concatenated output shape: torch.Size([4, 65, 512])
[utils/util.py::ComputeLoss.__call__] self.no: 65, self.dfl_ch: 16, self.nc: 1
[utils/util.py::ComputeLoss.__call__] pred_output shape: torch.Size([4, 64, 512])
[utils/util.py::ComputeLoss.__call__] pred_scores shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.__call__] After permute - pred_output shape: torch.Size([4, 512, 64])
[utils/util.py::ComputeLoss.__call__] After permute - pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Size tensor: tensor([128., 256.], device='cuda:0', dtype=torch.float16)
[utils/util.py::ComputeLoss.__call__] Stride: tensor([8.])
[utils/util.py::ComputeLoss.__call__] Anchor points shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.__call__] Stride tensor shape: torch.Size([512, 1])

--- [utils/util.py::ComputeLoss.__call__] TARGET PROCESSING ---
[utils/util.py::ComputeLoss.__call__] Targets shape: torch.Size([4, 6])
[utils/util.py::ComputeLoss.__call__] Targets dtype: torch.float32
[utils/util.py::ComputeLoss.__call__] First few targets: tensor([[0.0000, 0.0000, 0.8472, 0.1353, 0.1136, 0.2093],
        [1.0000, 0.0000, 0.7384, 0.0821, 0.0897, 0.1642],
        [2.0000, 0.0000, 0.8906, 0.8098, 0.0512, 0.1041],
        [2.0000, 0.0000, 0.3912, 0.7261, 0.0552, 0.1103]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Image indices: tensor([0., 1., 2., 2.], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Counts per image: tensor([1, 1, 2], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT tensor shape: torch.Size([4, 2, 5])
[utils/util.py::ComputeLoss.__call__] Image 0: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 1: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 2: 2 targets assigned
[utils/util.py::ComputeLoss.__call__] GT before coordinate conversion: tensor([[[0.0000, 0.8472, 0.1353, 0.1136, 0.2093],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.7384, 0.0821, 0.0897, 0.1642],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.8906, 0.8098, 0.0512, 0.1041],
         [0.0000, 0.3912, 0.7261, 0.0552, 0.1103]],

        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT after coordinate conversion: tensor([[[  0.0000, 202.3523,   3.9161, 231.4393,  30.7084],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000, 177.5405,   0.0000, 200.5041,  21.0224],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000, 221.4291,  96.9859, 234.5343, 110.3121],
         [  0.0000,  93.0800,  85.8828, 107.2045, 100.0073]],

        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT labels shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.__call__] GT bboxes shape: torch.Size([4, 2, 4])
[utils/util.py::ComputeLoss.__call__] GT mask shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.__call__] Pred output dimensions - b: 4, a: 512, c: 64
[utils/util.py::ComputeLoss.__call__] Pred bboxes after softmax shape: torch.Size([4, 512, 4, 16])
[utils/util.py::ComputeLoss.__call__] Pred bboxes after matmul shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Final pred bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.__call__] ASSIGNMENT PHASE ---

--- [utils/util.py::ComputeLoss.assign] PYTORCH ASSIGNMENT DEBUG ---
[utils/util.py::ComputeLoss.assign] pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] true_labels shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 2, 4])
[utils/util.py::ComputeLoss.assign] true_mask shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.assign] anchors shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.assign] Batch size: 4, Max boxes: 2
[utils/util.py::ComputeLoss.assign] Created indices tensor with shape: torch.Size([2, 4, 2])

--- [utils/util.py::ComputeLoss.assign] IOUs DEBUG ---
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 2, 4])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([4, 2, 1, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([4, 1, 512, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([4, 2, 1, 1]), h: torch.Size([4, 2, 1, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([4, 1, 512, 1]), h: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.000000, max: 0.755101
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: -0.968532, max: 0.749556
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.assign] overlaps shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] overlaps min: 0.0, max: 0.7495561838150024
[utils/util.py::ComputeLoss.assign] align_metric shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] align_metric min: 0.0, max: 0.018087629228830338
[utils/util.py::ComputeLoss.assign] mask_in_gts shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] mask_in_gts sum: 29.0
[utils/util.py::ComputeLoss.assign] metrics shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] top_k_mask shape: torch.Size([4, 2, 10])
[utils/util.py::ComputeLoss.assign] top_k_metrics shape: torch.Size([4, 2, 10])
[utils/util.py::ComputeLoss.assign] top_k_indices shape: torch.Size([4, 2, 10])
[utils/util.py::ComputeLoss.assign] is_in_top_k shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] mask_top_k shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] mask_pos shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] fg_mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] fg_mask sum: 23.0
[utils/util.py::ComputeLoss.assign] target_gt_idx shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_labels shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] Normalized target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] target_scores sum: 3.2828545570373535
--- [utils/util.py::ComputeLoss.assign] END PYTORCH ASSIGNMENT DEBUG ---

[utils/util.py::ComputeLoss.__call__] Target bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Target scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] FG mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.__call__] Target scores sum: 3.282855
[utils/util.py::ComputeLoss.__call__] Classification loss computed: 6.177931
[utils/util.py::ComputeLoss.__call__] Foreground count: 23
[utils/util.py::ComputeLoss.__call__] Weight shape: torch.Size([23, 1])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([23, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([23, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([23, 1]), h: torch.Size([23, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([23, 1]), h: torch.Size([23, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([23, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([23, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([23, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.212641, max: 0.755182
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([23, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([23, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([23, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([23, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: 0.130012, max: 0.749638
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.__call__] IoU values shape: torch.Size([23, 1])
[utils/util.py::ComputeLoss.__call__] Box loss computed: 0.435350
[utils/util.py::ComputeLoss.__call__] Target LT-RB shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.df_loss] PYTORCH DFL LOSS DEBUG ---
[utils/util.py::ComputeLoss.df_loss] pred_dist shape: torch.Size([92, 16])
[utils/util.py::ComputeLoss.df_loss] target shape: torch.Size([23, 4])
[utils/util.py::ComputeLoss.df_loss] DFL loss shape: torch.Size([23, 1])
[utils/util.py::ComputeLoss.df_loss] DFL loss mean: 1.740474
--- [utils/util.py::ComputeLoss.df_loss] END PYTORCH DFL LOSS DEBUG ---

[utils/util.py::ComputeLoss.__call__] DFL loss before weighting: 1.740474
[utils/util.py::ComputeLoss.__call__] DFL loss computed: 1.208969

--- [utils/util.py::ComputeLoss.__call__] LOSS COMPONENTS DEBUG ---
[utils/util.py::ComputeLoss.__call__] Raw loss_cls: 6.177931
[utils/util.py::ComputeLoss.__call__] Raw loss_box: 0.435350
[utils/util.py::ComputeLoss.__call__] Raw loss_dfl: 1.208969
[utils/util.py::ComputeLoss.__call__] Loss weights - cls: 0.5, box: 7.5, dfl: 1.5
[utils/util.py::ComputeLoss.__call__] target_scores_sum: 3.282855
[utils/util.py::ComputeLoss.__call__] fg_mask sum: 23
[utils/util.py::ComputeLoss.__call__] Weighted loss_cls: 3.088966
[utils/util.py::ComputeLoss.__call__] Weighted loss_box: 3.265124
[utils/util.py::ComputeLoss.__call__] Weighted loss_dfl: 1.813454
[utils/util.py::ComputeLoss.__call__] Total loss: 8.167543
--- [utils/util.py::ComputeLoss.__call__] END PYTORCH LOSS COMPUTATION DEBUG ---


--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([4, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: True
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([4, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - box shape: torch.Size([4, 64, 16, 32]), cls shape: torch.Size([4, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - final concat shape: torch.Size([4, 65, 16, 32])

--- [utils/util.py::ComputeLoss.__call__] PYTORCH LOSS COMPUTATION DEBUG ---
[utils/util.py::ComputeLoss.__call__] Outputs type: <class 'list'>
[utils/util.py::ComputeLoss.__call__] x type: <class 'list'>, len: 1
[utils/util.py::ComputeLoss.__call__] x[0] shape: torch.Size([4, 65, 16, 32])
[utils/util.py::ComputeLoss.__call__] Concatenated output shape: torch.Size([4, 65, 512])
[utils/util.py::ComputeLoss.__call__] self.no: 65, self.dfl_ch: 16, self.nc: 1
[utils/util.py::ComputeLoss.__call__] pred_output shape: torch.Size([4, 64, 512])
[utils/util.py::ComputeLoss.__call__] pred_scores shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.__call__] After permute - pred_output shape: torch.Size([4, 512, 64])
[utils/util.py::ComputeLoss.__call__] After permute - pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Size tensor: tensor([128., 256.], device='cuda:0', dtype=torch.float16)
[utils/util.py::ComputeLoss.__call__] Stride: tensor([8.])
[utils/util.py::ComputeLoss.__call__] Anchor points shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.__call__] Stride tensor shape: torch.Size([512, 1])

--- [utils/util.py::ComputeLoss.__call__] TARGET PROCESSING ---
[utils/util.py::ComputeLoss.__call__] Targets shape: torch.Size([4, 6])
[utils/util.py::ComputeLoss.__call__] Targets dtype: torch.float32
[utils/util.py::ComputeLoss.__call__] First few targets: tensor([[0.0000, 0.0000, 0.1111, 0.6619, 0.1306, 0.2490],
        [1.0000, 0.0000, 0.1836, 0.8855, 0.1080, 0.2176],
        [2.0000, 0.0000, 0.2935, 0.0274, 0.1030, 0.0549],
        [3.0000, 0.0000, 0.3824, 0.4246, 0.0853, 0.1844]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Image indices: tensor([0., 1., 2., 3.], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Counts per image: tensor([1, 1, 1, 1], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT tensor shape: torch.Size([4, 1, 5])
[utils/util.py::ComputeLoss.__call__] Image 0: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 1: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 2: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 3: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] GT before coordinate conversion: tensor([[[0.0000, 0.1111, 0.6619, 0.1306, 0.2490]],

        [[0.0000, 0.1836, 0.8855, 0.1080, 0.2176]],

        [[0.0000, 0.2935, 0.0274, 0.1030, 0.0549]],

        [[0.0000, 0.3824, 0.4246, 0.0853, 0.1844]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT after coordinate conversion: tensor([[[  0.0000,  11.7243,  68.7902,  45.1685, 100.6571]],

        [[  0.0000,  33.1775,  99.4090,  60.8230, 127.2678]],

        [[  0.0000,  61.9583,   0.0000,  88.3166,   7.0236]],

        [[  0.0000,  86.9686,  42.5439, 108.8133,  66.1432]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT labels shape: torch.Size([4, 1, 1])
[utils/util.py::ComputeLoss.__call__] GT bboxes shape: torch.Size([4, 1, 4])
[utils/util.py::ComputeLoss.__call__] GT mask shape: torch.Size([4, 1, 1])
[utils/util.py::ComputeLoss.__call__] Pred output dimensions - b: 4, a: 512, c: 64
[utils/util.py::ComputeLoss.__call__] Pred bboxes after softmax shape: torch.Size([4, 512, 4, 16])
[utils/util.py::ComputeLoss.__call__] Pred bboxes after matmul shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Final pred bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.__call__] ASSIGNMENT PHASE ---

--- [utils/util.py::ComputeLoss.assign] PYTORCH ASSIGNMENT DEBUG ---
[utils/util.py::ComputeLoss.assign] pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] true_labels shape: torch.Size([4, 1, 1])
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 1, 4])
[utils/util.py::ComputeLoss.assign] true_mask shape: torch.Size([4, 1, 1])
[utils/util.py::ComputeLoss.assign] anchors shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.assign] Batch size: 4, Max boxes: 1
[utils/util.py::ComputeLoss.assign] Created indices tensor with shape: torch.Size([2, 4, 1])

--- [utils/util.py::ComputeLoss.assign] IOUs DEBUG ---
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 1, 4])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([4, 1, 1, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([4, 1, 512, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([4, 1, 1, 1]), h: torch.Size([4, 1, 1, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([4, 1, 512, 1]), h: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.000000, max: 0.700303
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: -0.782066, max: 0.696271
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.assign] overlaps shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.assign] overlaps min: 0.0, max: 0.6962708830833435
[utils/util.py::ComputeLoss.assign] align_metric shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.assign] align_metric min: 0.0, max: 0.008111798204481602
[utils/util.py::ComputeLoss.assign] mask_in_gts shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.assign] mask_in_gts sum: 48.0
[utils/util.py::ComputeLoss.assign] metrics shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.assign] top_k_mask shape: torch.Size([4, 1, 10])
[utils/util.py::ComputeLoss.assign] top_k_metrics shape: torch.Size([4, 1, 10])
[utils/util.py::ComputeLoss.assign] top_k_indices shape: torch.Size([4, 1, 10])
[utils/util.py::ComputeLoss.assign] is_in_top_k shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.assign] mask_top_k shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.assign] mask_pos shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.assign] fg_mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] fg_mask sum: 32.0
[utils/util.py::ComputeLoss.assign] target_gt_idx shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_labels shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] Normalized target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] target_scores sum: 3.2430830001831055
--- [utils/util.py::ComputeLoss.assign] END PYTORCH ASSIGNMENT DEBUG ---

[utils/util.py::ComputeLoss.__call__] Target bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Target scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] FG mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.__call__] Target scores sum: 3.243083
[utils/util.py::ComputeLoss.__call__] Classification loss computed: 6.562043
[utils/util.py::ComputeLoss.__call__] Foreground count: 32
[utils/util.py::ComputeLoss.__call__] Weight shape: torch.Size([32, 1])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([32, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([32, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([32, 1]), h: torch.Size([32, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([32, 1]), h: torch.Size([32, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([32, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([32, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([32, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.163338, max: 0.700171
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([32, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([32, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([32, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([32, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: 0.107134, max: 0.696139
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.__call__] IoU values shape: torch.Size([32, 1])
[utils/util.py::ComputeLoss.__call__] Box loss computed: 0.424330
[utils/util.py::ComputeLoss.__call__] Target LT-RB shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.df_loss] PYTORCH DFL LOSS DEBUG ---
[utils/util.py::ComputeLoss.df_loss] pred_dist shape: torch.Size([128, 16])
[utils/util.py::ComputeLoss.df_loss] target shape: torch.Size([32, 4])
[utils/util.py::ComputeLoss.df_loss] DFL loss shape: torch.Size([32, 1])
[utils/util.py::ComputeLoss.df_loss] DFL loss mean: 1.914866
--- [utils/util.py::ComputeLoss.df_loss] END PYTORCH DFL LOSS DEBUG ---

[utils/util.py::ComputeLoss.__call__] DFL loss before weighting: 1.914866
[utils/util.py::ComputeLoss.__call__] DFL loss computed: 1.499752

--- [utils/util.py::ComputeLoss.__call__] LOSS COMPONENTS DEBUG ---
[utils/util.py::ComputeLoss.__call__] Raw loss_cls: 6.562043
[utils/util.py::ComputeLoss.__call__] Raw loss_box: 0.424330
[utils/util.py::ComputeLoss.__call__] Raw loss_dfl: 1.499752
[utils/util.py::ComputeLoss.__call__] Loss weights - cls: 0.5, box: 7.5, dfl: 1.5
[utils/util.py::ComputeLoss.__call__] target_scores_sum: 3.243083
[utils/util.py::ComputeLoss.__call__] fg_mask sum: 32
[utils/util.py::ComputeLoss.__call__] Weighted loss_cls: 3.281022
[utils/util.py::ComputeLoss.__call__] Weighted loss_box: 3.182473
[utils/util.py::ComputeLoss.__call__] Weighted loss_dfl: 2.249628
[utils/util.py::ComputeLoss.__call__] Total loss: 8.713122
--- [utils/util.py::ComputeLoss.__call__] END PYTORCH LOSS COMPUTATION DEBUG ---


--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([4, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: True
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([4, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - box shape: torch.Size([4, 64, 16, 32]), cls shape: torch.Size([4, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - final concat shape: torch.Size([4, 65, 16, 32])

--- [utils/util.py::ComputeLoss.__call__] PYTORCH LOSS COMPUTATION DEBUG ---
[utils/util.py::ComputeLoss.__call__] Outputs type: <class 'list'>
[utils/util.py::ComputeLoss.__call__] x type: <class 'list'>, len: 1
[utils/util.py::ComputeLoss.__call__] x[0] shape: torch.Size([4, 65, 16, 32])
[utils/util.py::ComputeLoss.__call__] Concatenated output shape: torch.Size([4, 65, 512])
[utils/util.py::ComputeLoss.__call__] self.no: 65, self.dfl_ch: 16, self.nc: 1
[utils/util.py::ComputeLoss.__call__] pred_output shape: torch.Size([4, 64, 512])
[utils/util.py::ComputeLoss.__call__] pred_scores shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.__call__] After permute - pred_output shape: torch.Size([4, 512, 64])
[utils/util.py::ComputeLoss.__call__] After permute - pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Size tensor: tensor([128., 256.], device='cuda:0', dtype=torch.float16)
[utils/util.py::ComputeLoss.__call__] Stride: tensor([8.])
[utils/util.py::ComputeLoss.__call__] Anchor points shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.__call__] Stride tensor shape: torch.Size([512, 1])

--- [utils/util.py::ComputeLoss.__call__] TARGET PROCESSING ---
[utils/util.py::ComputeLoss.__call__] Targets shape: torch.Size([4, 6])
[utils/util.py::ComputeLoss.__call__] Targets dtype: torch.float32
[utils/util.py::ComputeLoss.__call__] First few targets: tensor([[0.0000, 0.0000, 0.3091, 0.6344, 0.1387, 0.2659],
        [1.0000, 0.0000, 0.8649, 0.3663, 0.0589, 0.1158],
        [2.0000, 0.0000, 0.2170, 0.9808, 0.1543, 0.0383],
        [2.0000, 0.0000, 0.5081, 0.9307, 0.1269, 0.1386]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Image indices: tensor([0., 1., 2., 2.], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Counts per image: tensor([1, 1, 2], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT tensor shape: torch.Size([4, 2, 5])
[utils/util.py::ComputeLoss.__call__] Image 0: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 1: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 2: 2 targets assigned
[utils/util.py::ComputeLoss.__call__] GT before coordinate conversion: tensor([[[0.0000, 0.3091, 0.6344, 0.1387, 0.2659],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.8649, 0.3663, 0.0589, 0.1158],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.2170, 0.9808, 0.1543, 0.0383],
         [0.0000, 0.5081, 0.9307, 0.1269, 0.1386]],

        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT after coordinate conversion: tensor([[[  0.0000,  61.3718,  64.1863,  96.8912,  98.2257],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000, 213.8866,  39.4740, 228.9545,  54.2946],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000,  35.8009, 123.0969,  75.2916, 127.9990],
         [  0.0000, 113.8261, 110.2520, 146.3235, 127.9990]],

        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT labels shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.__call__] GT bboxes shape: torch.Size([4, 2, 4])
[utils/util.py::ComputeLoss.__call__] GT mask shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.__call__] Pred output dimensions - b: 4, a: 512, c: 64
[utils/util.py::ComputeLoss.__call__] Pred bboxes after softmax shape: torch.Size([4, 512, 4, 16])
[utils/util.py::ComputeLoss.__call__] Pred bboxes after matmul shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Final pred bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.__call__] ASSIGNMENT PHASE ---

--- [utils/util.py::ComputeLoss.assign] PYTORCH ASSIGNMENT DEBUG ---
[utils/util.py::ComputeLoss.assign] pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] true_labels shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 2, 4])
[utils/util.py::ComputeLoss.assign] true_mask shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.assign] anchors shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.assign] Batch size: 4, Max boxes: 2
[utils/util.py::ComputeLoss.assign] Created indices tensor with shape: torch.Size([2, 4, 2])

--- [utils/util.py::ComputeLoss.assign] IOUs DEBUG ---
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 2, 4])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([4, 2, 1, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([4, 1, 512, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([4, 2, 1, 1]), h: torch.Size([4, 2, 1, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([4, 1, 512, 1]), h: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.000000, max: 0.574507
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: -1.003608, max: 0.565993
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.assign] overlaps shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] overlaps min: 0.0, max: 0.5659934878349304
[utils/util.py::ComputeLoss.assign] align_metric shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] align_metric min: 0.0, max: 0.0024560096208006144
[utils/util.py::ComputeLoss.assign] mask_in_gts shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] mask_in_gts sum: 33.0
[utils/util.py::ComputeLoss.assign] metrics shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] top_k_mask shape: torch.Size([4, 2, 10])
[utils/util.py::ComputeLoss.assign] top_k_metrics shape: torch.Size([4, 2, 10])
[utils/util.py::ComputeLoss.assign] top_k_indices shape: torch.Size([4, 2, 10])
[utils/util.py::ComputeLoss.assign] is_in_top_k shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] mask_top_k shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] mask_pos shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] fg_mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] fg_mask sum: 26.0
[utils/util.py::ComputeLoss.assign] target_gt_idx shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_labels shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] Normalized target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] target_scores sum: 3.912792205810547
--- [utils/util.py::ComputeLoss.assign] END PYTORCH ASSIGNMENT DEBUG ---

[utils/util.py::ComputeLoss.__call__] Target bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Target scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] FG mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.__call__] Target scores sum: 3.912792
[utils/util.py::ComputeLoss.__call__] Classification loss computed: 5.938055
[utils/util.py::ComputeLoss.__call__] Foreground count: 26
[utils/util.py::ComputeLoss.__call__] Weight shape: torch.Size([26, 1])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([26, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([26, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([26, 1]), h: torch.Size([26, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([26, 1]), h: torch.Size([26, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([26, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([26, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([26, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.123794, max: 0.574456
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([26, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([26, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([26, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([26, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: 0.040324, max: 0.565948
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.__call__] IoU values shape: torch.Size([26, 1])
[utils/util.py::ComputeLoss.__call__] Box loss computed: 0.548329
[utils/util.py::ComputeLoss.__call__] Target LT-RB shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.df_loss] PYTORCH DFL LOSS DEBUG ---
[utils/util.py::ComputeLoss.df_loss] pred_dist shape: torch.Size([104, 16])
[utils/util.py::ComputeLoss.df_loss] target shape: torch.Size([26, 4])
[utils/util.py::ComputeLoss.df_loss] DFL loss shape: torch.Size([26, 1])
[utils/util.py::ComputeLoss.df_loss] DFL loss mean: 2.074765
--- [utils/util.py::ComputeLoss.df_loss] END PYTORCH DFL LOSS DEBUG ---

[utils/util.py::ComputeLoss.__call__] DFL loss before weighting: 2.074765
[utils/util.py::ComputeLoss.__call__] DFL loss computed: 1.803619

--- [utils/util.py::ComputeLoss.__call__] LOSS COMPONENTS DEBUG ---
[utils/util.py::ComputeLoss.__call__] Raw loss_cls: 5.938055
[utils/util.py::ComputeLoss.__call__] Raw loss_box: 0.548329
[utils/util.py::ComputeLoss.__call__] Raw loss_dfl: 1.803619
[utils/util.py::ComputeLoss.__call__] Loss weights - cls: 0.5, box: 7.5, dfl: 1.5
[utils/util.py::ComputeLoss.__call__] target_scores_sum: 3.912792
[utils/util.py::ComputeLoss.__call__] fg_mask sum: 26
[utils/util.py::ComputeLoss.__call__] Weighted loss_cls: 2.969028
[utils/util.py::ComputeLoss.__call__] Weighted loss_box: 4.112467
[utils/util.py::ComputeLoss.__call__] Weighted loss_dfl: 2.705429
[utils/util.py::ComputeLoss.__call__] Total loss: 9.786923
--- [utils/util.py::ComputeLoss.__call__] END PYTORCH LOSS COMPUTATION DEBUG ---


--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([4, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: True
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([4, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - box shape: torch.Size([4, 64, 16, 32]), cls shape: torch.Size([4, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - final concat shape: torch.Size([4, 65, 16, 32])

--- [utils/util.py::ComputeLoss.__call__] PYTORCH LOSS COMPUTATION DEBUG ---
[utils/util.py::ComputeLoss.__call__] Outputs type: <class 'list'>
[utils/util.py::ComputeLoss.__call__] x type: <class 'list'>, len: 1
[utils/util.py::ComputeLoss.__call__] x[0] shape: torch.Size([4, 65, 16, 32])
[utils/util.py::ComputeLoss.__call__] Concatenated output shape: torch.Size([4, 65, 512])
[utils/util.py::ComputeLoss.__call__] self.no: 65, self.dfl_ch: 16, self.nc: 1
[utils/util.py::ComputeLoss.__call__] pred_output shape: torch.Size([4, 64, 512])
[utils/util.py::ComputeLoss.__call__] pred_scores shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.__call__] After permute - pred_output shape: torch.Size([4, 512, 64])
[utils/util.py::ComputeLoss.__call__] After permute - pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Size tensor: tensor([128., 256.], device='cuda:0', dtype=torch.float16)
[utils/util.py::ComputeLoss.__call__] Stride: tensor([8.])
[utils/util.py::ComputeLoss.__call__] Anchor points shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.__call__] Stride tensor shape: torch.Size([512, 1])

--- [utils/util.py::ComputeLoss.__call__] TARGET PROCESSING ---
[utils/util.py::ComputeLoss.__call__] Targets shape: torch.Size([6, 6])
[utils/util.py::ComputeLoss.__call__] Targets dtype: torch.float32
[utils/util.py::ComputeLoss.__call__] First few targets: tensor([[0.0000, 0.0000, 0.3816, 0.0588, 0.1372, 0.1176],
        [1.0000, 0.0000, 0.8123, 0.3524, 0.0758, 0.1670],
        [2.0000, 0.0000, 0.6252, 0.1647, 0.0913, 0.1827],
        [2.0000, 0.0000, 0.1972, 0.3572, 0.1034, 0.2181],
        [3.0000, 0.0000, 0.4627, 0.3688, 0.0520, 0.1035]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Image indices: tensor([0., 1., 2., 2., 3., 3.], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Counts per image: tensor([1, 1, 2, 2], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT tensor shape: torch.Size([4, 2, 5])
[utils/util.py::ComputeLoss.__call__] Image 0: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 1: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 2: 2 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 3: 2 targets assigned
[utils/util.py::ComputeLoss.__call__] GT before coordinate conversion: tensor([[[0.0000, 0.3816, 0.0588, 0.1372, 0.1176],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.8123, 0.3524, 0.0758, 0.1670],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.6252, 0.1647, 0.0913, 0.1827],
         [0.0000, 0.1972, 0.3572, 0.1034, 0.2181]],

        [[0.0000, 0.4627, 0.3688, 0.0520, 0.1035],
         [0.0000, 0.3392, 0.9801, 0.0506, 0.0398]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT after coordinate conversion: tensor([[[  0.0000,  80.1409,   0.0000, 115.2585,  15.0470],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000, 198.2348,  34.4242, 217.6383,  55.7957],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000, 148.3547,   9.3907, 171.7388,  32.7749],
         [  0.0000,  37.2391,  31.7582,  63.7141,  59.6768]],

        [[  0.0000, 111.7952,  40.5857, 125.1017,  53.8273],
         [  0.0000,  80.3500, 122.9075,  93.2965, 127.9990]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT labels shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.__call__] GT bboxes shape: torch.Size([4, 2, 4])
[utils/util.py::ComputeLoss.__call__] GT mask shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.__call__] Pred output dimensions - b: 4, a: 512, c: 64
[utils/util.py::ComputeLoss.__call__] Pred bboxes after softmax shape: torch.Size([4, 512, 4, 16])
[utils/util.py::ComputeLoss.__call__] Pred bboxes after matmul shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Final pred bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.__call__] ASSIGNMENT PHASE ---

--- [utils/util.py::ComputeLoss.assign] PYTORCH ASSIGNMENT DEBUG ---
[utils/util.py::ComputeLoss.assign] pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] true_labels shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 2, 4])
[utils/util.py::ComputeLoss.assign] true_mask shape: torch.Size([4, 2, 1])
[utils/util.py::ComputeLoss.assign] anchors shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.assign] Batch size: 4, Max boxes: 2
[utils/util.py::ComputeLoss.assign] Created indices tensor with shape: torch.Size([2, 4, 2])

--- [utils/util.py::ComputeLoss.assign] IOUs DEBUG ---
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 2, 4])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([4, 2, 1, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([4, 1, 512, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([4, 2, 1, 1]), h: torch.Size([4, 2, 1, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([4, 1, 512, 1]), h: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.000000, max: 0.811614
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([4, 2, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: -0.968575, max: 0.811121
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.assign] overlaps shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] overlaps min: 0.0, max: 0.8111207485198975
[utils/util.py::ComputeLoss.assign] align_metric shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] align_metric min: 0.0, max: 0.01960659772157669
[utils/util.py::ComputeLoss.assign] mask_in_gts shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] mask_in_gts sum: 35.0
[utils/util.py::ComputeLoss.assign] metrics shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] top_k_mask shape: torch.Size([4, 2, 10])
[utils/util.py::ComputeLoss.assign] top_k_metrics shape: torch.Size([4, 2, 10])
[utils/util.py::ComputeLoss.assign] top_k_indices shape: torch.Size([4, 2, 10])
[utils/util.py::ComputeLoss.assign] is_in_top_k shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] mask_top_k shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] mask_pos shape: torch.Size([4, 2, 512])
[utils/util.py::ComputeLoss.assign] fg_mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] fg_mask sum: 35.0
[utils/util.py::ComputeLoss.assign] target_gt_idx shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_labels shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] Normalized target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] target_scores sum: 5.007537364959717
--- [utils/util.py::ComputeLoss.assign] END PYTORCH ASSIGNMENT DEBUG ---

[utils/util.py::ComputeLoss.__call__] Target bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Target scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] FG mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.__call__] Target scores sum: 5.007537
[utils/util.py::ComputeLoss.__call__] Classification loss computed: 6.334201
[utils/util.py::ComputeLoss.__call__] Foreground count: 35
[utils/util.py::ComputeLoss.__call__] Weight shape: torch.Size([35, 1])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([35, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([35, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([35, 1]), h: torch.Size([35, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([35, 1]), h: torch.Size([35, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([35, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([35, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([35, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.093301, max: 0.811496
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([35, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([35, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([35, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([35, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: 0.074289, max: 0.811003
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.__call__] IoU values shape: torch.Size([35, 1])
[utils/util.py::ComputeLoss.__call__] Box loss computed: 0.458670
[utils/util.py::ComputeLoss.__call__] Target LT-RB shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.df_loss] PYTORCH DFL LOSS DEBUG ---
[utils/util.py::ComputeLoss.df_loss] pred_dist shape: torch.Size([140, 16])
[utils/util.py::ComputeLoss.df_loss] target shape: torch.Size([35, 4])
[utils/util.py::ComputeLoss.df_loss] DFL loss shape: torch.Size([35, 1])
[utils/util.py::ComputeLoss.df_loss] DFL loss mean: 1.690005
--- [utils/util.py::ComputeLoss.df_loss] END PYTORCH DFL LOSS DEBUG ---

[utils/util.py::ComputeLoss.__call__] DFL loss before weighting: 1.690005
[utils/util.py::ComputeLoss.__call__] DFL loss computed: 1.295993

--- [utils/util.py::ComputeLoss.__call__] LOSS COMPONENTS DEBUG ---
[utils/util.py::ComputeLoss.__call__] Raw loss_cls: 6.334201
[utils/util.py::ComputeLoss.__call__] Raw loss_box: 0.458670
[utils/util.py::ComputeLoss.__call__] Raw loss_dfl: 1.295993
[utils/util.py::ComputeLoss.__call__] Loss weights - cls: 0.5, box: 7.5, dfl: 1.5
[utils/util.py::ComputeLoss.__call__] target_scores_sum: 5.007537
[utils/util.py::ComputeLoss.__call__] fg_mask sum: 35
[utils/util.py::ComputeLoss.__call__] Weighted loss_cls: 3.167101
[utils/util.py::ComputeLoss.__call__] Weighted loss_box: 3.440027
[utils/util.py::ComputeLoss.__call__] Weighted loss_dfl: 1.943989
[utils/util.py::ComputeLoss.__call__] Total loss: 8.551117
--- [utils/util.py::ComputeLoss.__call__] END PYTORCH LOSS COMPUTATION DEBUG ---


--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([4, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: True
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([4, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - box shape: torch.Size([4, 64, 16, 32]), cls shape: torch.Size([4, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - final concat shape: torch.Size([4, 65, 16, 32])

--- [utils/util.py::ComputeLoss.__call__] PYTORCH LOSS COMPUTATION DEBUG ---
[utils/util.py::ComputeLoss.__call__] Outputs type: <class 'list'>
[utils/util.py::ComputeLoss.__call__] x type: <class 'list'>, len: 1
[utils/util.py::ComputeLoss.__call__] x[0] shape: torch.Size([4, 65, 16, 32])
[utils/util.py::ComputeLoss.__call__] Concatenated output shape: torch.Size([4, 65, 512])
[utils/util.py::ComputeLoss.__call__] self.no: 65, self.dfl_ch: 16, self.nc: 1
[utils/util.py::ComputeLoss.__call__] pred_output shape: torch.Size([4, 64, 512])
[utils/util.py::ComputeLoss.__call__] pred_scores shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.__call__] After permute - pred_output shape: torch.Size([4, 512, 64])
[utils/util.py::ComputeLoss.__call__] After permute - pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Size tensor: tensor([128., 256.], device='cuda:0', dtype=torch.float16)
[utils/util.py::ComputeLoss.__call__] Stride: tensor([8.])
[utils/util.py::ComputeLoss.__call__] Anchor points shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.__call__] Stride tensor shape: torch.Size([512, 1])

--- [utils/util.py::ComputeLoss.__call__] TARGET PROCESSING ---
[utils/util.py::ComputeLoss.__call__] Targets shape: torch.Size([5, 6])
[utils/util.py::ComputeLoss.__call__] Targets dtype: torch.float32
[utils/util.py::ComputeLoss.__call__] First few targets: tensor([[0.0000, 0.0000, 0.6697, 0.2026, 0.1012, 0.2132],
        [1.0000, 0.0000, 0.9847, 0.3059, 0.0305, 0.1338],
        [1.0000, 0.0000, 0.3424, 0.3795, 0.0654, 0.1268],
        [1.0000, 0.0000, 0.1048, 0.8343, 0.0614, 0.1227],
        [3.0000, 0.0000, 0.3768, 0.8629, 0.0765, 0.1513]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Image indices: tensor([0., 1., 1., 1., 3.], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Counts per image: tensor([1, 3, 1], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT tensor shape: torch.Size([4, 3, 5])
[utils/util.py::ComputeLoss.__call__] Image 0: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 1: 3 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 3: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] GT before coordinate conversion: tensor([[[0.0000, 0.6697, 0.2026, 0.1012, 0.2132],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.9847, 0.3059, 0.0305, 0.1338],
         [0.0000, 0.3424, 0.3795, 0.0654, 0.1268],
         [0.0000, 0.1048, 0.8343, 0.0614, 0.1227]],

        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.3768, 0.8629, 0.0765, 0.1513],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT after coordinate conversion: tensor([[[  0.0000, 158.5014,  12.2818, 184.4044,  39.5730],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000, 248.1864,  30.5892, 256.0000,  47.7136],
         [  0.0000,  79.2952,  40.4617,  96.0300,  56.6938],
         [  0.0000,  18.9699,  98.9331,  34.6804, 114.6436]],

        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000,  86.6670, 100.7676, 106.2442, 120.1281],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT labels shape: torch.Size([4, 3, 1])
[utils/util.py::ComputeLoss.__call__] GT bboxes shape: torch.Size([4, 3, 4])
[utils/util.py::ComputeLoss.__call__] GT mask shape: torch.Size([4, 3, 1])
[utils/util.py::ComputeLoss.__call__] Pred output dimensions - b: 4, a: 512, c: 64
[utils/util.py::ComputeLoss.__call__] Pred bboxes after softmax shape: torch.Size([4, 512, 4, 16])
[utils/util.py::ComputeLoss.__call__] Pred bboxes after matmul shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Final pred bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.__call__] ASSIGNMENT PHASE ---

--- [utils/util.py::ComputeLoss.assign] PYTORCH ASSIGNMENT DEBUG ---
[utils/util.py::ComputeLoss.assign] pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] true_labels shape: torch.Size([4, 3, 1])
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 3, 4])
[utils/util.py::ComputeLoss.assign] true_mask shape: torch.Size([4, 3, 1])
[utils/util.py::ComputeLoss.assign] anchors shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.assign] Batch size: 4, Max boxes: 3
[utils/util.py::ComputeLoss.assign] Created indices tensor with shape: torch.Size([2, 4, 3])

--- [utils/util.py::ComputeLoss.assign] IOUs DEBUG ---
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 3, 4])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([4, 3, 1, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([4, 1, 512, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([4, 3, 1, 1]), h: torch.Size([4, 3, 1, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([4, 1, 512, 1]), h: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.000000, max: 0.869083
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([4, 3, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: -0.965728, max: 0.867665
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.assign] overlaps shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] overlaps min: 0.0, max: 0.8676649332046509
[utils/util.py::ComputeLoss.assign] align_metric shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] align_metric min: 0.0, max: 0.028803644701838493
[utils/util.py::ComputeLoss.assign] mask_in_gts shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] mask_in_gts sum: 23.0
[utils/util.py::ComputeLoss.assign] metrics shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] top_k_mask shape: torch.Size([4, 3, 10])
[utils/util.py::ComputeLoss.assign] top_k_metrics shape: torch.Size([4, 3, 10])
[utils/util.py::ComputeLoss.assign] top_k_indices shape: torch.Size([4, 3, 10])
[utils/util.py::ComputeLoss.assign] is_in_top_k shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] mask_top_k shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] mask_pos shape: torch.Size([4, 3, 512])
[utils/util.py::ComputeLoss.assign] fg_mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] fg_mask sum: 23.0
[utils/util.py::ComputeLoss.assign] target_gt_idx shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_labels shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] Normalized target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] target_scores sum: 3.9911489486694336
--- [utils/util.py::ComputeLoss.assign] END PYTORCH ASSIGNMENT DEBUG ---

[utils/util.py::ComputeLoss.__call__] Target bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Target scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] FG mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.__call__] Target scores sum: 3.991149
[utils/util.py::ComputeLoss.__call__] Classification loss computed: 6.682756
[utils/util.py::ComputeLoss.__call__] Foreground count: 23
[utils/util.py::ComputeLoss.__call__] Weight shape: torch.Size([23, 1])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([23, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([23, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([23, 1]), h: torch.Size([23, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([23, 1]), h: torch.Size([23, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([23, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([23, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([23, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.181922, max: 0.868814
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([23, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([23, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([23, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([23, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: 0.168966, max: 0.867396
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.__call__] IoU values shape: torch.Size([23, 1])
[utils/util.py::ComputeLoss.__call__] Box loss computed: 0.486291
[utils/util.py::ComputeLoss.__call__] Target LT-RB shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.df_loss] PYTORCH DFL LOSS DEBUG ---
[utils/util.py::ComputeLoss.df_loss] pred_dist shape: torch.Size([92, 16])
[utils/util.py::ComputeLoss.df_loss] target shape: torch.Size([23, 4])
[utils/util.py::ComputeLoss.df_loss] DFL loss shape: torch.Size([23, 1])
[utils/util.py::ComputeLoss.df_loss] DFL loss mean: 1.521061
--- [utils/util.py::ComputeLoss.df_loss] END PYTORCH DFL LOSS DEBUG ---

[utils/util.py::ComputeLoss.__call__] DFL loss before weighting: 1.521061
[utils/util.py::ComputeLoss.__call__] DFL loss computed: 1.188117

--- [utils/util.py::ComputeLoss.__call__] LOSS COMPONENTS DEBUG ---
[utils/util.py::ComputeLoss.__call__] Raw loss_cls: 6.682756
[utils/util.py::ComputeLoss.__call__] Raw loss_box: 0.486291
[utils/util.py::ComputeLoss.__call__] Raw loss_dfl: 1.188117
[utils/util.py::ComputeLoss.__call__] Loss weights - cls: 0.5, box: 7.5, dfl: 1.5
[utils/util.py::ComputeLoss.__call__] target_scores_sum: 3.991149
[utils/util.py::ComputeLoss.__call__] fg_mask sum: 23
[utils/util.py::ComputeLoss.__call__] Weighted loss_cls: 3.341378
[utils/util.py::ComputeLoss.__call__] Weighted loss_box: 3.647183
[utils/util.py::ComputeLoss.__call__] Weighted loss_dfl: 1.782175
[utils/util.py::ComputeLoss.__call__] Total loss: 8.770737
--- [utils/util.py::ComputeLoss.__call__] END PYTORCH LOSS COMPUTATION DEBUG ---


--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([4, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: True
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([4, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - box shape: torch.Size([4, 64, 16, 32]), cls shape: torch.Size([4, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Training - final concat shape: torch.Size([4, 65, 16, 32])

--- [utils/util.py::ComputeLoss.__call__] PYTORCH LOSS COMPUTATION DEBUG ---
[utils/util.py::ComputeLoss.__call__] Outputs type: <class 'list'>
[utils/util.py::ComputeLoss.__call__] x type: <class 'list'>, len: 1
[utils/util.py::ComputeLoss.__call__] x[0] shape: torch.Size([4, 65, 16, 32])
[utils/util.py::ComputeLoss.__call__] Concatenated output shape: torch.Size([4, 65, 512])
[utils/util.py::ComputeLoss.__call__] self.no: 65, self.dfl_ch: 16, self.nc: 1
[utils/util.py::ComputeLoss.__call__] pred_output shape: torch.Size([4, 64, 512])
[utils/util.py::ComputeLoss.__call__] pred_scores shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.__call__] After permute - pred_output shape: torch.Size([4, 512, 64])
[utils/util.py::ComputeLoss.__call__] After permute - pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Size tensor: tensor([128., 256.], device='cuda:0', dtype=torch.float16)
[utils/util.py::ComputeLoss.__call__] Stride: tensor([8.])
[utils/util.py::ComputeLoss.__call__] Anchor points shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.__call__] Stride tensor shape: torch.Size([512, 1])

--- [utils/util.py::ComputeLoss.__call__] TARGET PROCESSING ---
[utils/util.py::ComputeLoss.__call__] Targets shape: torch.Size([2, 6])
[utils/util.py::ComputeLoss.__call__] Targets dtype: torch.float32
[utils/util.py::ComputeLoss.__call__] First few targets: tensor([[0.0000, 0.0000, 0.2772, 0.3308, 0.0722, 0.1415],
        [2.0000, 0.0000, 0.9590, 0.0668, 0.0821, 0.1336]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Image indices: tensor([0., 2.], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] Counts per image: tensor([1, 1], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT tensor shape: torch.Size([4, 1, 5])
[utils/util.py::ComputeLoss.__call__] Image 0: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] Image 2: 1 targets assigned
[utils/util.py::ComputeLoss.__call__] GT before coordinate conversion: tensor([[[0.0000, 0.2772, 0.3308, 0.0722, 0.1415]],

        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.9590, 0.0668, 0.0821, 0.1336]],

        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT after coordinate conversion: tensor([[[  0.0000,  61.7218,  33.2884,  80.1944,  51.4028]],

        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[  0.0000, 234.9908,   0.0000, 256.0000,  17.1061]],

        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]], device='cuda:0')
[utils/util.py::ComputeLoss.__call__] GT labels shape: torch.Size([4, 1, 1])
[utils/util.py::ComputeLoss.__call__] GT bboxes shape: torch.Size([4, 1, 4])
[utils/util.py::ComputeLoss.__call__] GT mask shape: torch.Size([4, 1, 1])
[utils/util.py::ComputeLoss.__call__] Pred output dimensions - b: 4, a: 512, c: 64
[utils/util.py::ComputeLoss.__call__] Pred bboxes after softmax shape: torch.Size([4, 512, 4, 16])
[utils/util.py::ComputeLoss.__call__] Pred bboxes after matmul shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Final pred bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] Bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.__call__] ASSIGNMENT PHASE ---

--- [utils/util.py::ComputeLoss.assign] PYTORCH ASSIGNMENT DEBUG ---
[utils/util.py::ComputeLoss.assign] pred_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] true_labels shape: torch.Size([4, 1, 1])
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 1, 4])
[utils/util.py::ComputeLoss.assign] true_mask shape: torch.Size([4, 1, 1])
[utils/util.py::ComputeLoss.assign] anchors shape: torch.Size([512, 2])
[utils/util.py::ComputeLoss.assign] Batch size: 4, Max boxes: 1
[utils/util.py::ComputeLoss.assign] Created indices tensor with shape: torch.Size([2, 4, 1])

--- [utils/util.py::ComputeLoss.assign] IOUs DEBUG ---
[utils/util.py::ComputeLoss.assign] true_bboxes shape: torch.Size([4, 1, 4])
[utils/util.py::ComputeLoss.assign] pred_bboxes shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([4, 1, 1, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([4, 1, 512, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([4, 1, 1, 1]), h: torch.Size([4, 1, 1, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([4, 1, 512, 1]), h: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.000000, max: 0.597600
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([4, 1, 512, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: -0.996702, max: 0.579870
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.assign] overlaps shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.assign] overlaps min: 0.0, max: 0.5798696279525757
[utils/util.py::ComputeLoss.assign] align_metric shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.assign] align_metric min: 0.0, max: 0.0036662265192717314
[utils/util.py::ComputeLoss.assign] mask_in_gts shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.assign] mask_in_gts sum: 10.0
[utils/util.py::ComputeLoss.assign] metrics shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.assign] top_k_mask shape: torch.Size([4, 1, 10])
[utils/util.py::ComputeLoss.assign] top_k_metrics shape: torch.Size([4, 1, 10])
[utils/util.py::ComputeLoss.assign] top_k_indices shape: torch.Size([4, 1, 10])
[utils/util.py::ComputeLoss.assign] is_in_top_k shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.assign] mask_top_k shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.assign] mask_pos shape: torch.Size([4, 1, 512])
[utils/util.py::ComputeLoss.assign] fg_mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] fg_mask sum: 10.0
[utils/util.py::ComputeLoss.assign] target_gt_idx shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_labels shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.assign] target_bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.assign] target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] Normalized target_scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.assign] target_scores sum: 1.6561540365219116
--- [utils/util.py::ComputeLoss.assign] END PYTORCH ASSIGNMENT DEBUG ---

[utils/util.py::ComputeLoss.__call__] Target bboxes shape: torch.Size([4, 512, 4])
[utils/util.py::ComputeLoss.__call__] Target scores shape: torch.Size([4, 512, 1])
[utils/util.py::ComputeLoss.__call__] FG mask shape: torch.Size([4, 512])
[utils/util.py::ComputeLoss.__call__] Target scores sum: 1.656154
[utils/util.py::ComputeLoss.__call__] Classification loss computed: 6.915495
[utils/util.py::ComputeLoss.__call__] Foreground count: 10
[utils/util.py::ComputeLoss.__call__] Weight shape: torch.Size([10, 1])

--- [utils/util.py::ComputeLoss.iou] PYTORCH IOU DEBUG ---
[utils/util.py::ComputeLoss.iou] box1 shape: torch.Size([10, 4])
[utils/util.py::ComputeLoss.iou] box2 shape: torch.Size([10, 4])
[utils/util.py::ComputeLoss.iou] Box1 dimensions - w: torch.Size([10, 1]), h: torch.Size([10, 1])
[utils/util.py::ComputeLoss.iou] Box2 dimensions - w: torch.Size([10, 1]), h: torch.Size([10, 1])
[utils/util.py::ComputeLoss.iou] Intersection shape: torch.Size([10, 1])
[utils/util.py::ComputeLoss.iou] Union shape: torch.Size([10, 1])
[utils/util.py::ComputeLoss.iou] IoU shape: torch.Size([10, 1])
[utils/util.py::ComputeLoss.iou] IoU min: 0.285802, max: 0.597735
[utils/util.py::ComputeLoss.iou] Convex diagonal squared shape: torch.Size([10, 1])
[utils/util.py::ComputeLoss.iou] Center distance squared shape: torch.Size([10, 1])
[utils/util.py::ComputeLoss.iou] Aspect ratio term shape: torch.Size([10, 1])
[utils/util.py::ComputeLoss.iou] CIoU shape: torch.Size([10, 1])
[utils/util.py::ComputeLoss.iou] CIoU min: 0.217480, max: 0.580004
--- [utils/util.py::ComputeLoss.iou] END PYTORCH IOU DEBUG ---

[utils/util.py::ComputeLoss.__call__] IoU values shape: torch.Size([10, 1])
[utils/util.py::ComputeLoss.__call__] Box loss computed: 0.495816
[utils/util.py::ComputeLoss.__call__] Target LT-RB shape: torch.Size([4, 512, 4])

--- [utils/util.py::ComputeLoss.df_loss] PYTORCH DFL LOSS DEBUG ---
[utils/util.py::ComputeLoss.df_loss] pred_dist shape: torch.Size([40, 16])
[utils/util.py::ComputeLoss.df_loss] target shape: torch.Size([10, 4])
[utils/util.py::ComputeLoss.df_loss] DFL loss shape: torch.Size([10, 1])
[utils/util.py::ComputeLoss.df_loss] DFL loss mean: 1.452858
--- [utils/util.py::ComputeLoss.df_loss] END PYTORCH DFL LOSS DEBUG ---

[utils/util.py::ComputeLoss.__call__] DFL loss before weighting: 1.452858
[utils/util.py::ComputeLoss.__call__] DFL loss computed: 1.196412

--- [utils/util.py::ComputeLoss.__call__] LOSS COMPONENTS DEBUG ---
[utils/util.py::ComputeLoss.__call__] Raw loss_cls: 6.915495
[utils/util.py::ComputeLoss.__call__] Raw loss_box: 0.495816
[utils/util.py::ComputeLoss.__call__] Raw loss_dfl: 1.196412
[utils/util.py::ComputeLoss.__call__] Loss weights - cls: 0.5, box: 7.5, dfl: 1.5
[utils/util.py::ComputeLoss.__call__] target_scores_sum: 1.656154
[utils/util.py::ComputeLoss.__call__] fg_mask sum: 10
[utils/util.py::ComputeLoss.__call__] Weighted loss_cls: 3.457747
[utils/util.py::ComputeLoss.__call__] Weighted loss_box: 3.718624
[utils/util.py::ComputeLoss.__call__] Weighted loss_dfl: 1.794618
[utils/util.py::ComputeLoss.__call__] Total loss: 8.970989
--- [utils/util.py::ComputeLoss.__call__] END PYTORCH LOSS COMPUTATION DEBUG ---

Evaluating on training data...

--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([8, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: False
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([8, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Inference mode - processing...
[nets/tinysimov35.py::Head.forward] Box feature shape: torch.Size([8, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Cls feature shape: torch.Size([8, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Anchors shape: torch.Size([2, 512])
[nets/tinysimov35.py::Head.forward] Strides shape: torch.Size([1, 512])
[nets/tinysimov35.py::Head.forward] Combined features shape: torch.Size([8, 65, 16, 32])
[nets/tinysimov35.py::Head.forward] Combined flat shape: torch.Size([8, 65, 512])
[nets/tinysimov35.py::Head.forward] Expected self.no: 65
[nets/tinysimov35.py::Head.forward] Split - box shape: torch.Size([8, 64, 512]), cls shape: torch.Size([8, 1, 512])

--- [nets/tinysimov35.py::DFL.forward] PYTORCH DFL DEBUG ---
[nets/tinysimov35.py::DFL.forward] Input shape: torch.Size([8, 64, 512])
[nets/tinysimov35.py::DFL.forward] DFL channels (self.ch): 16
[nets/tinysimov35.py::DFL.forward] Parsed dimensions - batch: 8, channels: 64, anchors: 512
[nets/tinysimov35.py::DFL.forward] After view(b, 4, ch, a): torch.Size([8, 4, 16, 512])
[nets/tinysimov35.py::DFL.forward] After transpose(2, 1): torch.Size([8, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After softmax(1): torch.Size([8, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After conv: torch.Size([8, 1, 4, 512])
[nets/tinysimov35.py::DFL.forward] Final output shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL output shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL split - a shape: torch.Size([8, 2, 512]), b shape: torch.Size([8, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchors expanded shape: torch.Size([1, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchor adjusted - a: torch.Size([8, 2, 512]), b: torch.Size([8, 2, 512])
[nets/tinysimov35.py::Head.forward] Box coordinates shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] Scaled boxes shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] Sigmoid classes shape: torch.Size([8, 1, 512])
[nets/tinysimov35.py::Head.forward] Final output shape: torch.Size([8, 5, 512])
[main.py::test] Model outputs shape: torch.Size([8, 5, 512])

--- [utils/util.py::non_max_suppression] PYTORCH NMS DEBUG ---
[utils/util.py::non_max_suppression] Prediction shape: torch.Size([8, 5, 512])
[utils/util.py::non_max_suppression] Conf threshold: 0.25, IoU threshold: 0.45
[utils/util.py::non_max_suppression] Number of classes: 1
[utils/util.py::non_max_suppression] Candidates per image: [0, 0, 0, 0, 0, 0, 0, 0]

--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([8, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: False
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([8, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Inference mode - processing...
[nets/tinysimov35.py::Head.forward] Box feature shape: torch.Size([8, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Cls feature shape: torch.Size([8, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Anchors shape: torch.Size([2, 512])
[nets/tinysimov35.py::Head.forward] Strides shape: torch.Size([1, 512])
[nets/tinysimov35.py::Head.forward] Combined features shape: torch.Size([8, 65, 16, 32])
[nets/tinysimov35.py::Head.forward] Combined flat shape: torch.Size([8, 65, 512])
[nets/tinysimov35.py::Head.forward] Expected self.no: 65
[nets/tinysimov35.py::Head.forward] Split - box shape: torch.Size([8, 64, 512]), cls shape: torch.Size([8, 1, 512])

--- [nets/tinysimov35.py::DFL.forward] PYTORCH DFL DEBUG ---
[nets/tinysimov35.py::DFL.forward] Input shape: torch.Size([8, 64, 512])
[nets/tinysimov35.py::DFL.forward] DFL channels (self.ch): 16
[nets/tinysimov35.py::DFL.forward] Parsed dimensions - batch: 8, channels: 64, anchors: 512
[nets/tinysimov35.py::DFL.forward] After view(b, 4, ch, a): torch.Size([8, 4, 16, 512])
[nets/tinysimov35.py::DFL.forward] After transpose(2, 1): torch.Size([8, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After softmax(1): torch.Size([8, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After conv: torch.Size([8, 1, 4, 512])
[nets/tinysimov35.py::DFL.forward] Final output shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL output shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL split - a shape: torch.Size([8, 2, 512]), b shape: torch.Size([8, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchors expanded shape: torch.Size([1, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchor adjusted - a: torch.Size([8, 2, 512]), b: torch.Size([8, 2, 512])
[nets/tinysimov35.py::Head.forward] Box coordinates shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] Scaled boxes shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] Sigmoid classes shape: torch.Size([8, 1, 512])
[nets/tinysimov35.py::Head.forward] Final output shape: torch.Size([8, 5, 512])
[main.py::test] Model outputs shape: torch.Size([8, 5, 512])

--- [utils/util.py::non_max_suppression] PYTORCH NMS DEBUG ---
[utils/util.py::non_max_suppression] Prediction shape: torch.Size([8, 5, 512])
[utils/util.py::non_max_suppression] Conf threshold: 0.25, IoU threshold: 0.45
[utils/util.py::non_max_suppression] Number of classes: 1
[utils/util.py::non_max_suppression] Candidates per image: [0, 0, 0, 0, 0, 0, 0, 0]

--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([8, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: False
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([8, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Inference mode - processing...
[nets/tinysimov35.py::Head.forward] Box feature shape: torch.Size([8, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Cls feature shape: torch.Size([8, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Anchors shape: torch.Size([2, 512])
[nets/tinysimov35.py::Head.forward] Strides shape: torch.Size([1, 512])
[nets/tinysimov35.py::Head.forward] Combined features shape: torch.Size([8, 65, 16, 32])
[nets/tinysimov35.py::Head.forward] Combined flat shape: torch.Size([8, 65, 512])
[nets/tinysimov35.py::Head.forward] Expected self.no: 65
[nets/tinysimov35.py::Head.forward] Split - box shape: torch.Size([8, 64, 512]), cls shape: torch.Size([8, 1, 512])

--- [nets/tinysimov35.py::DFL.forward] PYTORCH DFL DEBUG ---
[nets/tinysimov35.py::DFL.forward] Input shape: torch.Size([8, 64, 512])
[nets/tinysimov35.py::DFL.forward] DFL channels (self.ch): 16
[nets/tinysimov35.py::DFL.forward] Parsed dimensions - batch: 8, channels: 64, anchors: 512
[nets/tinysimov35.py::DFL.forward] After view(b, 4, ch, a): torch.Size([8, 4, 16, 512])
[nets/tinysimov35.py::DFL.forward] After transpose(2, 1): torch.Size([8, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After softmax(1): torch.Size([8, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After conv: torch.Size([8, 1, 4, 512])
[nets/tinysimov35.py::DFL.forward] Final output shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL output shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL split - a shape: torch.Size([8, 2, 512]), b shape: torch.Size([8, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchors expanded shape: torch.Size([1, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchor adjusted - a: torch.Size([8, 2, 512]), b: torch.Size([8, 2, 512])
[nets/tinysimov35.py::Head.forward] Box coordinates shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] Scaled boxes shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] Sigmoid classes shape: torch.Size([8, 1, 512])
[nets/tinysimov35.py::Head.forward] Final output shape: torch.Size([8, 5, 512])
[main.py::test] Model outputs shape: torch.Size([8, 5, 512])

--- [utils/util.py::non_max_suppression] PYTORCH NMS DEBUG ---
[utils/util.py::non_max_suppression] Prediction shape: torch.Size([8, 5, 512])
[utils/util.py::non_max_suppression] Conf threshold: 0.25, IoU threshold: 0.45
[utils/util.py::non_max_suppression] Number of classes: 1
[utils/util.py::non_max_suppression] Candidates per image: [0, 0, 0, 0, 0, 0, 0, 0]

--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([8, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: False
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([8, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Inference mode - processing...
[nets/tinysimov35.py::Head.forward] Box feature shape: torch.Size([8, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Cls feature shape: torch.Size([8, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Anchors shape: torch.Size([2, 512])
[nets/tinysimov35.py::Head.forward] Strides shape: torch.Size([1, 512])
[nets/tinysimov35.py::Head.forward] Combined features shape: torch.Size([8, 65, 16, 32])
[nets/tinysimov35.py::Head.forward] Combined flat shape: torch.Size([8, 65, 512])
[nets/tinysimov35.py::Head.forward] Expected self.no: 65
[nets/tinysimov35.py::Head.forward] Split - box shape: torch.Size([8, 64, 512]), cls shape: torch.Size([8, 1, 512])

--- [nets/tinysimov35.py::DFL.forward] PYTORCH DFL DEBUG ---
[nets/tinysimov35.py::DFL.forward] Input shape: torch.Size([8, 64, 512])
[nets/tinysimov35.py::DFL.forward] DFL channels (self.ch): 16
[nets/tinysimov35.py::DFL.forward] Parsed dimensions - batch: 8, channels: 64, anchors: 512
[nets/tinysimov35.py::DFL.forward] After view(b, 4, ch, a): torch.Size([8, 4, 16, 512])
[nets/tinysimov35.py::DFL.forward] After transpose(2, 1): torch.Size([8, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After softmax(1): torch.Size([8, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After conv: torch.Size([8, 1, 4, 512])
[nets/tinysimov35.py::DFL.forward] Final output shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL output shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL split - a shape: torch.Size([8, 2, 512]), b shape: torch.Size([8, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchors expanded shape: torch.Size([1, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchor adjusted - a: torch.Size([8, 2, 512]), b: torch.Size([8, 2, 512])
[nets/tinysimov35.py::Head.forward] Box coordinates shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] Scaled boxes shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] Sigmoid classes shape: torch.Size([8, 1, 512])
[nets/tinysimov35.py::Head.forward] Final output shape: torch.Size([8, 5, 512])
[main.py::test] Model outputs shape: torch.Size([8, 5, 512])

--- [utils/util.py::non_max_suppression] PYTORCH NMS DEBUG ---
[utils/util.py::non_max_suppression] Prediction shape: torch.Size([8, 5, 512])
[utils/util.py::non_max_suppression] Conf threshold: 0.25, IoU threshold: 0.45
[utils/util.py::non_max_suppression] Number of classes: 1
[utils/util.py::non_max_suppression] Candidates per image: [0, 0, 0, 0, 0, 0, 0, 0]

--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([8, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: False
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([8, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Inference mode - processing...
[nets/tinysimov35.py::Head.forward] Box feature shape: torch.Size([8, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Cls feature shape: torch.Size([8, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Anchors shape: torch.Size([2, 512])
[nets/tinysimov35.py::Head.forward] Strides shape: torch.Size([1, 512])
[nets/tinysimov35.py::Head.forward] Combined features shape: torch.Size([8, 65, 16, 32])
[nets/tinysimov35.py::Head.forward] Combined flat shape: torch.Size([8, 65, 512])
[nets/tinysimov35.py::Head.forward] Expected self.no: 65
[nets/tinysimov35.py::Head.forward] Split - box shape: torch.Size([8, 64, 512]), cls shape: torch.Size([8, 1, 512])

--- [nets/tinysimov35.py::DFL.forward] PYTORCH DFL DEBUG ---
[nets/tinysimov35.py::DFL.forward] Input shape: torch.Size([8, 64, 512])
[nets/tinysimov35.py::DFL.forward] DFL channels (self.ch): 16
[nets/tinysimov35.py::DFL.forward] Parsed dimensions - batch: 8, channels: 64, anchors: 512
[nets/tinysimov35.py::DFL.forward] After view(b, 4, ch, a): torch.Size([8, 4, 16, 512])
[nets/tinysimov35.py::DFL.forward] After transpose(2, 1): torch.Size([8, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After softmax(1): torch.Size([8, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After conv: torch.Size([8, 1, 4, 512])
[nets/tinysimov35.py::DFL.forward] Final output shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL output shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL split - a shape: torch.Size([8, 2, 512]), b shape: torch.Size([8, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchors expanded shape: torch.Size([1, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchor adjusted - a: torch.Size([8, 2, 512]), b: torch.Size([8, 2, 512])
[nets/tinysimov35.py::Head.forward] Box coordinates shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] Scaled boxes shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] Sigmoid classes shape: torch.Size([8, 1, 512])
[nets/tinysimov35.py::Head.forward] Final output shape: torch.Size([8, 5, 512])
[main.py::test] Model outputs shape: torch.Size([8, 5, 512])

--- [utils/util.py::non_max_suppression] PYTORCH NMS DEBUG ---
[utils/util.py::non_max_suppression] Prediction shape: torch.Size([8, 5, 512])
[utils/util.py::non_max_suppression] Conf threshold: 0.25, IoU threshold: 0.45
[utils/util.py::non_max_suppression] Number of classes: 1
[utils/util.py::non_max_suppression] Candidates per image: [0, 0, 0, 0, 0, 0, 0, 0]

--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([8, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: False
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([8, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Inference mode - processing...
[nets/tinysimov35.py::Head.forward] Box feature shape: torch.Size([8, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Cls feature shape: torch.Size([8, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Anchors shape: torch.Size([2, 512])
[nets/tinysimov35.py::Head.forward] Strides shape: torch.Size([1, 512])
[nets/tinysimov35.py::Head.forward] Combined features shape: torch.Size([8, 65, 16, 32])
[nets/tinysimov35.py::Head.forward] Combined flat shape: torch.Size([8, 65, 512])
[nets/tinysimov35.py::Head.forward] Expected self.no: 65
[nets/tinysimov35.py::Head.forward] Split - box shape: torch.Size([8, 64, 512]), cls shape: torch.Size([8, 1, 512])

--- [nets/tinysimov35.py::DFL.forward] PYTORCH DFL DEBUG ---
[nets/tinysimov35.py::DFL.forward] Input shape: torch.Size([8, 64, 512])
[nets/tinysimov35.py::DFL.forward] DFL channels (self.ch): 16
[nets/tinysimov35.py::DFL.forward] Parsed dimensions - batch: 8, channels: 64, anchors: 512
[nets/tinysimov35.py::DFL.forward] After view(b, 4, ch, a): torch.Size([8, 4, 16, 512])
[nets/tinysimov35.py::DFL.forward] After transpose(2, 1): torch.Size([8, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After softmax(1): torch.Size([8, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After conv: torch.Size([8, 1, 4, 512])
[nets/tinysimov35.py::DFL.forward] Final output shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL output shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL split - a shape: torch.Size([8, 2, 512]), b shape: torch.Size([8, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchors expanded shape: torch.Size([1, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchor adjusted - a: torch.Size([8, 2, 512]), b: torch.Size([8, 2, 512])
[nets/tinysimov35.py::Head.forward] Box coordinates shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] Scaled boxes shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] Sigmoid classes shape: torch.Size([8, 1, 512])
[nets/tinysimov35.py::Head.forward] Final output shape: torch.Size([8, 5, 512])
[main.py::test] Model outputs shape: torch.Size([8, 5, 512])

--- [utils/util.py::non_max_suppression] PYTORCH NMS DEBUG ---
[utils/util.py::non_max_suppression] Prediction shape: torch.Size([8, 5, 512])
[utils/util.py::non_max_suppression] Conf threshold: 0.25, IoU threshold: 0.45
[utils/util.py::non_max_suppression] Number of classes: 1
[utils/util.py::non_max_suppression] Candidates per image: [0, 0, 0, 0, 0, 0, 0, 0]

--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([8, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: False
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([8, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Inference mode - processing...
[nets/tinysimov35.py::Head.forward] Box feature shape: torch.Size([8, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Cls feature shape: torch.Size([8, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Anchors shape: torch.Size([2, 512])
[nets/tinysimov35.py::Head.forward] Strides shape: torch.Size([1, 512])
[nets/tinysimov35.py::Head.forward] Combined features shape: torch.Size([8, 65, 16, 32])
[nets/tinysimov35.py::Head.forward] Combined flat shape: torch.Size([8, 65, 512])
[nets/tinysimov35.py::Head.forward] Expected self.no: 65
[nets/tinysimov35.py::Head.forward] Split - box shape: torch.Size([8, 64, 512]), cls shape: torch.Size([8, 1, 512])

--- [nets/tinysimov35.py::DFL.forward] PYTORCH DFL DEBUG ---
[nets/tinysimov35.py::DFL.forward] Input shape: torch.Size([8, 64, 512])
[nets/tinysimov35.py::DFL.forward] DFL channels (self.ch): 16
[nets/tinysimov35.py::DFL.forward] Parsed dimensions - batch: 8, channels: 64, anchors: 512
[nets/tinysimov35.py::DFL.forward] After view(b, 4, ch, a): torch.Size([8, 4, 16, 512])
[nets/tinysimov35.py::DFL.forward] After transpose(2, 1): torch.Size([8, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After softmax(1): torch.Size([8, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After conv: torch.Size([8, 1, 4, 512])
[nets/tinysimov35.py::DFL.forward] Final output shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL output shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL split - a shape: torch.Size([8, 2, 512]), b shape: torch.Size([8, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchors expanded shape: torch.Size([1, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchor adjusted - a: torch.Size([8, 2, 512]), b: torch.Size([8, 2, 512])
[nets/tinysimov35.py::Head.forward] Box coordinates shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] Scaled boxes shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] Sigmoid classes shape: torch.Size([8, 1, 512])
[nets/tinysimov35.py::Head.forward] Final output shape: torch.Size([8, 5, 512])
[main.py::test] Model outputs shape: torch.Size([8, 5, 512])

--- [utils/util.py::non_max_suppression] PYTORCH NMS DEBUG ---
[utils/util.py::non_max_suppression] Prediction shape: torch.Size([8, 5, 512])
[utils/util.py::non_max_suppression] Conf threshold: 0.25, IoU threshold: 0.45
[utils/util.py::non_max_suppression] Number of classes: 1
[utils/util.py::non_max_suppression] Candidates per image: [0, 0, 0, 0, 0, 0, 0, 0]

--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([8, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: False
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([8, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Inference mode - processing...
[nets/tinysimov35.py::Head.forward] Box feature shape: torch.Size([8, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Cls feature shape: torch.Size([8, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Anchors shape: torch.Size([2, 512])
[nets/tinysimov35.py::Head.forward] Strides shape: torch.Size([1, 512])
[nets/tinysimov35.py::Head.forward] Combined features shape: torch.Size([8, 65, 16, 32])
[nets/tinysimov35.py::Head.forward] Combined flat shape: torch.Size([8, 65, 512])
[nets/tinysimov35.py::Head.forward] Expected self.no: 65
[nets/tinysimov35.py::Head.forward] Split - box shape: torch.Size([8, 64, 512]), cls shape: torch.Size([8, 1, 512])

--- [nets/tinysimov35.py::DFL.forward] PYTORCH DFL DEBUG ---
[nets/tinysimov35.py::DFL.forward] Input shape: torch.Size([8, 64, 512])
[nets/tinysimov35.py::DFL.forward] DFL channels (self.ch): 16
[nets/tinysimov35.py::DFL.forward] Parsed dimensions - batch: 8, channels: 64, anchors: 512
[nets/tinysimov35.py::DFL.forward] After view(b, 4, ch, a): torch.Size([8, 4, 16, 512])
[nets/tinysimov35.py::DFL.forward] After transpose(2, 1): torch.Size([8, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After softmax(1): torch.Size([8, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After conv: torch.Size([8, 1, 4, 512])
[nets/tinysimov35.py::DFL.forward] Final output shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL output shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL split - a shape: torch.Size([8, 2, 512]), b shape: torch.Size([8, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchors expanded shape: torch.Size([1, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchor adjusted - a: torch.Size([8, 2, 512]), b: torch.Size([8, 2, 512])
[nets/tinysimov35.py::Head.forward] Box coordinates shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] Scaled boxes shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] Sigmoid classes shape: torch.Size([8, 1, 512])
[nets/tinysimov35.py::Head.forward] Final output shape: torch.Size([8, 5, 512])
[main.py::test] Model outputs shape: torch.Size([8, 5, 512])

--- [utils/util.py::non_max_suppression] PYTORCH NMS DEBUG ---
[utils/util.py::non_max_suppression] Prediction shape: torch.Size([8, 5, 512])
[utils/util.py::non_max_suppression] Conf threshold: 0.25, IoU threshold: 0.45
[utils/util.py::non_max_suppression] Number of classes: 1
[utils/util.py::non_max_suppression] Candidates per image: [0, 0, 0, 0, 0, 0, 0, 0]

--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([8, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: False
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([8, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Inference mode - processing...
[nets/tinysimov35.py::Head.forward] Box feature shape: torch.Size([8, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Cls feature shape: torch.Size([8, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Anchors shape: torch.Size([2, 512])
[nets/tinysimov35.py::Head.forward] Strides shape: torch.Size([1, 512])
[nets/tinysimov35.py::Head.forward] Combined features shape: torch.Size([8, 65, 16, 32])
[nets/tinysimov35.py::Head.forward] Combined flat shape: torch.Size([8, 65, 512])
[nets/tinysimov35.py::Head.forward] Expected self.no: 65
[nets/tinysimov35.py::Head.forward] Split - box shape: torch.Size([8, 64, 512]), cls shape: torch.Size([8, 1, 512])

--- [nets/tinysimov35.py::DFL.forward] PYTORCH DFL DEBUG ---
[nets/tinysimov35.py::DFL.forward] Input shape: torch.Size([8, 64, 512])
[nets/tinysimov35.py::DFL.forward] DFL channels (self.ch): 16
[nets/tinysimov35.py::DFL.forward] Parsed dimensions - batch: 8, channels: 64, anchors: 512
[nets/tinysimov35.py::DFL.forward] After view(b, 4, ch, a): torch.Size([8, 4, 16, 512])
[nets/tinysimov35.py::DFL.forward] After transpose(2, 1): torch.Size([8, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After softmax(1): torch.Size([8, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After conv: torch.Size([8, 1, 4, 512])
[nets/tinysimov35.py::DFL.forward] Final output shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL output shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL split - a shape: torch.Size([8, 2, 512]), b shape: torch.Size([8, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchors expanded shape: torch.Size([1, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchor adjusted - a: torch.Size([8, 2, 512]), b: torch.Size([8, 2, 512])
[nets/tinysimov35.py::Head.forward] Box coordinates shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] Scaled boxes shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] Sigmoid classes shape: torch.Size([8, 1, 512])
[nets/tinysimov35.py::Head.forward] Final output shape: torch.Size([8, 5, 512])
[main.py::test] Model outputs shape: torch.Size([8, 5, 512])

--- [utils/util.py::non_max_suppression] PYTORCH NMS DEBUG ---
[utils/util.py::non_max_suppression] Prediction shape: torch.Size([8, 5, 512])
[utils/util.py::non_max_suppression] Conf threshold: 0.25, IoU threshold: 0.45
[utils/util.py::non_max_suppression] Number of classes: 1
[utils/util.py::non_max_suppression] Candidates per image: [0, 0, 0, 0, 0, 0, 0, 0]

--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([8, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: False
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([8, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Inference mode - processing...
[nets/tinysimov35.py::Head.forward] Box feature shape: torch.Size([8, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Cls feature shape: torch.Size([8, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Anchors shape: torch.Size([2, 512])
[nets/tinysimov35.py::Head.forward] Strides shape: torch.Size([1, 512])
[nets/tinysimov35.py::Head.forward] Combined features shape: torch.Size([8, 65, 16, 32])
[nets/tinysimov35.py::Head.forward] Combined flat shape: torch.Size([8, 65, 512])
[nets/tinysimov35.py::Head.forward] Expected self.no: 65
[nets/tinysimov35.py::Head.forward] Split - box shape: torch.Size([8, 64, 512]), cls shape: torch.Size([8, 1, 512])

--- [nets/tinysimov35.py::DFL.forward] PYTORCH DFL DEBUG ---
[nets/tinysimov35.py::DFL.forward] Input shape: torch.Size([8, 64, 512])
[nets/tinysimov35.py::DFL.forward] DFL channels (self.ch): 16
[nets/tinysimov35.py::DFL.forward] Parsed dimensions - batch: 8, channels: 64, anchors: 512
[nets/tinysimov35.py::DFL.forward] After view(b, 4, ch, a): torch.Size([8, 4, 16, 512])
[nets/tinysimov35.py::DFL.forward] After transpose(2, 1): torch.Size([8, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After softmax(1): torch.Size([8, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After conv: torch.Size([8, 1, 4, 512])
[nets/tinysimov35.py::DFL.forward] Final output shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL output shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL split - a shape: torch.Size([8, 2, 512]), b shape: torch.Size([8, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchors expanded shape: torch.Size([1, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchor adjusted - a: torch.Size([8, 2, 512]), b: torch.Size([8, 2, 512])
[nets/tinysimov35.py::Head.forward] Box coordinates shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] Scaled boxes shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] Sigmoid classes shape: torch.Size([8, 1, 512])
[nets/tinysimov35.py::Head.forward] Final output shape: torch.Size([8, 5, 512])
[main.py::test] Model outputs shape: torch.Size([8, 5, 512])

--- [utils/util.py::non_max_suppression] PYTORCH NMS DEBUG ---
[utils/util.py::non_max_suppression] Prediction shape: torch.Size([8, 5, 512])
[utils/util.py::non_max_suppression] Conf threshold: 0.25, IoU threshold: 0.45
[utils/util.py::non_max_suppression] Number of classes: 1
[utils/util.py::non_max_suppression] Candidates per image: [0, 0, 0, 0, 0, 0, 0, 0]

--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([8, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: False
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([8, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Inference mode - processing...
[nets/tinysimov35.py::Head.forward] Box feature shape: torch.Size([8, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Cls feature shape: torch.Size([8, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Anchors shape: torch.Size([2, 512])
[nets/tinysimov35.py::Head.forward] Strides shape: torch.Size([1, 512])
[nets/tinysimov35.py::Head.forward] Combined features shape: torch.Size([8, 65, 16, 32])
[nets/tinysimov35.py::Head.forward] Combined flat shape: torch.Size([8, 65, 512])
[nets/tinysimov35.py::Head.forward] Expected self.no: 65
[nets/tinysimov35.py::Head.forward] Split - box shape: torch.Size([8, 64, 512]), cls shape: torch.Size([8, 1, 512])

--- [nets/tinysimov35.py::DFL.forward] PYTORCH DFL DEBUG ---
[nets/tinysimov35.py::DFL.forward] Input shape: torch.Size([8, 64, 512])
[nets/tinysimov35.py::DFL.forward] DFL channels (self.ch): 16
[nets/tinysimov35.py::DFL.forward] Parsed dimensions - batch: 8, channels: 64, anchors: 512
[nets/tinysimov35.py::DFL.forward] After view(b, 4, ch, a): torch.Size([8, 4, 16, 512])
[nets/tinysimov35.py::DFL.forward] After transpose(2, 1): torch.Size([8, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After softmax(1): torch.Size([8, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After conv: torch.Size([8, 1, 4, 512])
[nets/tinysimov35.py::DFL.forward] Final output shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL output shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL split - a shape: torch.Size([8, 2, 512]), b shape: torch.Size([8, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchors expanded shape: torch.Size([1, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchor adjusted - a: torch.Size([8, 2, 512]), b: torch.Size([8, 2, 512])
[nets/tinysimov35.py::Head.forward] Box coordinates shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] Scaled boxes shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] Sigmoid classes shape: torch.Size([8, 1, 512])
[nets/tinysimov35.py::Head.forward] Final output shape: torch.Size([8, 5, 512])
[main.py::test] Model outputs shape: torch.Size([8, 5, 512])

--- [utils/util.py::non_max_suppression] PYTORCH NMS DEBUG ---
[utils/util.py::non_max_suppression] Prediction shape: torch.Size([8, 5, 512])
[utils/util.py::non_max_suppression] Conf threshold: 0.25, IoU threshold: 0.45
[utils/util.py::non_max_suppression] Number of classes: 1
[utils/util.py::non_max_suppression] Candidates per image: [0, 0, 0, 0, 0, 0, 0, 0]

--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([8, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: False
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([8, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Inference mode - processing...
[nets/tinysimov35.py::Head.forward] Box feature shape: torch.Size([8, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Cls feature shape: torch.Size([8, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Anchors shape: torch.Size([2, 512])
[nets/tinysimov35.py::Head.forward] Strides shape: torch.Size([1, 512])
[nets/tinysimov35.py::Head.forward] Combined features shape: torch.Size([8, 65, 16, 32])
[nets/tinysimov35.py::Head.forward] Combined flat shape: torch.Size([8, 65, 512])
[nets/tinysimov35.py::Head.forward] Expected self.no: 65
[nets/tinysimov35.py::Head.forward] Split - box shape: torch.Size([8, 64, 512]), cls shape: torch.Size([8, 1, 512])

--- [nets/tinysimov35.py::DFL.forward] PYTORCH DFL DEBUG ---
[nets/tinysimov35.py::DFL.forward] Input shape: torch.Size([8, 64, 512])
[nets/tinysimov35.py::DFL.forward] DFL channels (self.ch): 16
[nets/tinysimov35.py::DFL.forward] Parsed dimensions - batch: 8, channels: 64, anchors: 512
[nets/tinysimov35.py::DFL.forward] After view(b, 4, ch, a): torch.Size([8, 4, 16, 512])
[nets/tinysimov35.py::DFL.forward] After transpose(2, 1): torch.Size([8, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After softmax(1): torch.Size([8, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After conv: torch.Size([8, 1, 4, 512])
[nets/tinysimov35.py::DFL.forward] Final output shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL output shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL split - a shape: torch.Size([8, 2, 512]), b shape: torch.Size([8, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchors expanded shape: torch.Size([1, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchor adjusted - a: torch.Size([8, 2, 512]), b: torch.Size([8, 2, 512])
[nets/tinysimov35.py::Head.forward] Box coordinates shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] Scaled boxes shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] Sigmoid classes shape: torch.Size([8, 1, 512])
[nets/tinysimov35.py::Head.forward] Final output shape: torch.Size([8, 5, 512])
[main.py::test] Model outputs shape: torch.Size([8, 5, 512])

--- [utils/util.py::non_max_suppression] PYTORCH NMS DEBUG ---
[utils/util.py::non_max_suppression] Prediction shape: torch.Size([8, 5, 512])
[utils/util.py::non_max_suppression] Conf threshold: 0.25, IoU threshold: 0.45
[utils/util.py::non_max_suppression] Number of classes: 1
[utils/util.py::non_max_suppression] Candidates per image: [0, 0, 0, 0, 0, 0, 0, 0]

--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([8, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: False
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([8, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Inference mode - processing...
[nets/tinysimov35.py::Head.forward] Box feature shape: torch.Size([8, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Cls feature shape: torch.Size([8, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Anchors shape: torch.Size([2, 512])
[nets/tinysimov35.py::Head.forward] Strides shape: torch.Size([1, 512])
[nets/tinysimov35.py::Head.forward] Combined features shape: torch.Size([8, 65, 16, 32])
[nets/tinysimov35.py::Head.forward] Combined flat shape: torch.Size([8, 65, 512])
[nets/tinysimov35.py::Head.forward] Expected self.no: 65
[nets/tinysimov35.py::Head.forward] Split - box shape: torch.Size([8, 64, 512]), cls shape: torch.Size([8, 1, 512])

--- [nets/tinysimov35.py::DFL.forward] PYTORCH DFL DEBUG ---
[nets/tinysimov35.py::DFL.forward] Input shape: torch.Size([8, 64, 512])
[nets/tinysimov35.py::DFL.forward] DFL channels (self.ch): 16
[nets/tinysimov35.py::DFL.forward] Parsed dimensions - batch: 8, channels: 64, anchors: 512
[nets/tinysimov35.py::DFL.forward] After view(b, 4, ch, a): torch.Size([8, 4, 16, 512])
[nets/tinysimov35.py::DFL.forward] After transpose(2, 1): torch.Size([8, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After softmax(1): torch.Size([8, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After conv: torch.Size([8, 1, 4, 512])
[nets/tinysimov35.py::DFL.forward] Final output shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL output shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL split - a shape: torch.Size([8, 2, 512]), b shape: torch.Size([8, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchors expanded shape: torch.Size([1, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchor adjusted - a: torch.Size([8, 2, 512]), b: torch.Size([8, 2, 512])
[nets/tinysimov35.py::Head.forward] Box coordinates shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] Scaled boxes shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] Sigmoid classes shape: torch.Size([8, 1, 512])
[nets/tinysimov35.py::Head.forward] Final output shape: torch.Size([8, 5, 512])
[main.py::test] Model outputs shape: torch.Size([8, 5, 512])

--- [utils/util.py::non_max_suppression] PYTORCH NMS DEBUG ---
[utils/util.py::non_max_suppression] Prediction shape: torch.Size([8, 5, 512])
[utils/util.py::non_max_suppression] Conf threshold: 0.25, IoU threshold: 0.45
[utils/util.py::non_max_suppression] Number of classes: 1
[utils/util.py::non_max_suppression] Candidates per image: [0, 0, 0, 0, 0, 0, 0, 0]

--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([8, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: False
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([8, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Inference mode - processing...
[nets/tinysimov35.py::Head.forward] Box feature shape: torch.Size([8, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Cls feature shape: torch.Size([8, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Anchors shape: torch.Size([2, 512])
[nets/tinysimov35.py::Head.forward] Strides shape: torch.Size([1, 512])
[nets/tinysimov35.py::Head.forward] Combined features shape: torch.Size([8, 65, 16, 32])
[nets/tinysimov35.py::Head.forward] Combined flat shape: torch.Size([8, 65, 512])
[nets/tinysimov35.py::Head.forward] Expected self.no: 65
[nets/tinysimov35.py::Head.forward] Split - box shape: torch.Size([8, 64, 512]), cls shape: torch.Size([8, 1, 512])

--- [nets/tinysimov35.py::DFL.forward] PYTORCH DFL DEBUG ---
[nets/tinysimov35.py::DFL.forward] Input shape: torch.Size([8, 64, 512])
[nets/tinysimov35.py::DFL.forward] DFL channels (self.ch): 16
[nets/tinysimov35.py::DFL.forward] Parsed dimensions - batch: 8, channels: 64, anchors: 512
[nets/tinysimov35.py::DFL.forward] After view(b, 4, ch, a): torch.Size([8, 4, 16, 512])
[nets/tinysimov35.py::DFL.forward] After transpose(2, 1): torch.Size([8, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After softmax(1): torch.Size([8, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After conv: torch.Size([8, 1, 4, 512])
[nets/tinysimov35.py::DFL.forward] Final output shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL output shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL split - a shape: torch.Size([8, 2, 512]), b shape: torch.Size([8, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchors expanded shape: torch.Size([1, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchor adjusted - a: torch.Size([8, 2, 512]), b: torch.Size([8, 2, 512])
[nets/tinysimov35.py::Head.forward] Box coordinates shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] Scaled boxes shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] Sigmoid classes shape: torch.Size([8, 1, 512])
[nets/tinysimov35.py::Head.forward] Final output shape: torch.Size([8, 5, 512])
[main.py::test] Model outputs shape: torch.Size([8, 5, 512])

--- [utils/util.py::non_max_suppression] PYTORCH NMS DEBUG ---
[utils/util.py::non_max_suppression] Prediction shape: torch.Size([8, 5, 512])
[utils/util.py::non_max_suppression] Conf threshold: 0.25, IoU threshold: 0.45
[utils/util.py::non_max_suppression] Number of classes: 1
[utils/util.py::non_max_suppression] Candidates per image: [0, 0, 0, 0, 0, 0, 0, 0]

--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([8, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: False
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([8, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Inference mode - processing...
[nets/tinysimov35.py::Head.forward] Box feature shape: torch.Size([8, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Cls feature shape: torch.Size([8, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Anchors shape: torch.Size([2, 512])
[nets/tinysimov35.py::Head.forward] Strides shape: torch.Size([1, 512])
[nets/tinysimov35.py::Head.forward] Combined features shape: torch.Size([8, 65, 16, 32])
[nets/tinysimov35.py::Head.forward] Combined flat shape: torch.Size([8, 65, 512])
[nets/tinysimov35.py::Head.forward] Expected self.no: 65
[nets/tinysimov35.py::Head.forward] Split - box shape: torch.Size([8, 64, 512]), cls shape: torch.Size([8, 1, 512])

--- [nets/tinysimov35.py::DFL.forward] PYTORCH DFL DEBUG ---
[nets/tinysimov35.py::DFL.forward] Input shape: torch.Size([8, 64, 512])
[nets/tinysimov35.py::DFL.forward] DFL channels (self.ch): 16
[nets/tinysimov35.py::DFL.forward] Parsed dimensions - batch: 8, channels: 64, anchors: 512
[nets/tinysimov35.py::DFL.forward] After view(b, 4, ch, a): torch.Size([8, 4, 16, 512])
[nets/tinysimov35.py::DFL.forward] After transpose(2, 1): torch.Size([8, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After softmax(1): torch.Size([8, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After conv: torch.Size([8, 1, 4, 512])
[nets/tinysimov35.py::DFL.forward] Final output shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL output shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL split - a shape: torch.Size([8, 2, 512]), b shape: torch.Size([8, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchors expanded shape: torch.Size([1, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchor adjusted - a: torch.Size([8, 2, 512]), b: torch.Size([8, 2, 512])
[nets/tinysimov35.py::Head.forward] Box coordinates shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] Scaled boxes shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] Sigmoid classes shape: torch.Size([8, 1, 512])
[nets/tinysimov35.py::Head.forward] Final output shape: torch.Size([8, 5, 512])
[main.py::test] Model outputs shape: torch.Size([8, 5, 512])

--- [utils/util.py::non_max_suppression] PYTORCH NMS DEBUG ---
[utils/util.py::non_max_suppression] Prediction shape: torch.Size([8, 5, 512])
[utils/util.py::non_max_suppression] Conf threshold: 0.25, IoU threshold: 0.45
[utils/util.py::non_max_suppression] Number of classes: 1
[utils/util.py::non_max_suppression] Candidates per image: [0, 0, 0, 0, 0, 0, 0, 0]

--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([8, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: False
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([8, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Inference mode - processing...
[nets/tinysimov35.py::Head.forward] Box feature shape: torch.Size([8, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Cls feature shape: torch.Size([8, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Anchors shape: torch.Size([2, 512])
[nets/tinysimov35.py::Head.forward] Strides shape: torch.Size([1, 512])
[nets/tinysimov35.py::Head.forward] Combined features shape: torch.Size([8, 65, 16, 32])
[nets/tinysimov35.py::Head.forward] Combined flat shape: torch.Size([8, 65, 512])
[nets/tinysimov35.py::Head.forward] Expected self.no: 65
[nets/tinysimov35.py::Head.forward] Split - box shape: torch.Size([8, 64, 512]), cls shape: torch.Size([8, 1, 512])

--- [nets/tinysimov35.py::DFL.forward] PYTORCH DFL DEBUG ---
[nets/tinysimov35.py::DFL.forward] Input shape: torch.Size([8, 64, 512])
[nets/tinysimov35.py::DFL.forward] DFL channels (self.ch): 16
[nets/tinysimov35.py::DFL.forward] Parsed dimensions - batch: 8, channels: 64, anchors: 512
[nets/tinysimov35.py::DFL.forward] After view(b, 4, ch, a): torch.Size([8, 4, 16, 512])
[nets/tinysimov35.py::DFL.forward] After transpose(2, 1): torch.Size([8, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After softmax(1): torch.Size([8, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After conv: torch.Size([8, 1, 4, 512])
[nets/tinysimov35.py::DFL.forward] Final output shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL output shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL split - a shape: torch.Size([8, 2, 512]), b shape: torch.Size([8, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchors expanded shape: torch.Size([1, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchor adjusted - a: torch.Size([8, 2, 512]), b: torch.Size([8, 2, 512])
[nets/tinysimov35.py::Head.forward] Box coordinates shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] Scaled boxes shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] Sigmoid classes shape: torch.Size([8, 1, 512])
[nets/tinysimov35.py::Head.forward] Final output shape: torch.Size([8, 5, 512])
[main.py::test] Model outputs shape: torch.Size([8, 5, 512])

--- [utils/util.py::non_max_suppression] PYTORCH NMS DEBUG ---
[utils/util.py::non_max_suppression] Prediction shape: torch.Size([8, 5, 512])
[utils/util.py::non_max_suppression] Conf threshold: 0.25, IoU threshold: 0.45
[utils/util.py::non_max_suppression] Number of classes: 1
[utils/util.py::non_max_suppression] Candidates per image: [0, 0, 0, 0, 0, 0, 0, 0]

--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([8, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: False
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([8, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Inference mode - processing...
[nets/tinysimov35.py::Head.forward] Box feature shape: torch.Size([8, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Cls feature shape: torch.Size([8, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Anchors shape: torch.Size([2, 512])
[nets/tinysimov35.py::Head.forward] Strides shape: torch.Size([1, 512])
[nets/tinysimov35.py::Head.forward] Combined features shape: torch.Size([8, 65, 16, 32])
[nets/tinysimov35.py::Head.forward] Combined flat shape: torch.Size([8, 65, 512])
[nets/tinysimov35.py::Head.forward] Expected self.no: 65
[nets/tinysimov35.py::Head.forward] Split - box shape: torch.Size([8, 64, 512]), cls shape: torch.Size([8, 1, 512])

--- [nets/tinysimov35.py::DFL.forward] PYTORCH DFL DEBUG ---
[nets/tinysimov35.py::DFL.forward] Input shape: torch.Size([8, 64, 512])
[nets/tinysimov35.py::DFL.forward] DFL channels (self.ch): 16
[nets/tinysimov35.py::DFL.forward] Parsed dimensions - batch: 8, channels: 64, anchors: 512
[nets/tinysimov35.py::DFL.forward] After view(b, 4, ch, a): torch.Size([8, 4, 16, 512])
[nets/tinysimov35.py::DFL.forward] After transpose(2, 1): torch.Size([8, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After softmax(1): torch.Size([8, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After conv: torch.Size([8, 1, 4, 512])
[nets/tinysimov35.py::DFL.forward] Final output shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL output shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL split - a shape: torch.Size([8, 2, 512]), b shape: torch.Size([8, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchors expanded shape: torch.Size([1, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchor adjusted - a: torch.Size([8, 2, 512]), b: torch.Size([8, 2, 512])
[nets/tinysimov35.py::Head.forward] Box coordinates shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] Scaled boxes shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] Sigmoid classes shape: torch.Size([8, 1, 512])
[nets/tinysimov35.py::Head.forward] Final output shape: torch.Size([8, 5, 512])
[main.py::test] Model outputs shape: torch.Size([8, 5, 512])

--- [utils/util.py::non_max_suppression] PYTORCH NMS DEBUG ---
[utils/util.py::non_max_suppression] Prediction shape: torch.Size([8, 5, 512])
[utils/util.py::non_max_suppression] Conf threshold: 0.25, IoU threshold: 0.45
[utils/util.py::non_max_suppression] Number of classes: 1
[utils/util.py::non_max_suppression] Candidates per image: [0, 0, 0, 0, 0, 0, 0, 0]

--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([8, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: False
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([8, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Inference mode - processing...
[nets/tinysimov35.py::Head.forward] Box feature shape: torch.Size([8, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Cls feature shape: torch.Size([8, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Anchors shape: torch.Size([2, 512])
[nets/tinysimov35.py::Head.forward] Strides shape: torch.Size([1, 512])
[nets/tinysimov35.py::Head.forward] Combined features shape: torch.Size([8, 65, 16, 32])
[nets/tinysimov35.py::Head.forward] Combined flat shape: torch.Size([8, 65, 512])
[nets/tinysimov35.py::Head.forward] Expected self.no: 65
[nets/tinysimov35.py::Head.forward] Split - box shape: torch.Size([8, 64, 512]), cls shape: torch.Size([8, 1, 512])

--- [nets/tinysimov35.py::DFL.forward] PYTORCH DFL DEBUG ---
[nets/tinysimov35.py::DFL.forward] Input shape: torch.Size([8, 64, 512])
[nets/tinysimov35.py::DFL.forward] DFL channels (self.ch): 16
[nets/tinysimov35.py::DFL.forward] Parsed dimensions - batch: 8, channels: 64, anchors: 512
[nets/tinysimov35.py::DFL.forward] After view(b, 4, ch, a): torch.Size([8, 4, 16, 512])
[nets/tinysimov35.py::DFL.forward] After transpose(2, 1): torch.Size([8, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After softmax(1): torch.Size([8, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After conv: torch.Size([8, 1, 4, 512])
[nets/tinysimov35.py::DFL.forward] Final output shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL output shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL split - a shape: torch.Size([8, 2, 512]), b shape: torch.Size([8, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchors expanded shape: torch.Size([1, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchor adjusted - a: torch.Size([8, 2, 512]), b: torch.Size([8, 2, 512])
[nets/tinysimov35.py::Head.forward] Box coordinates shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] Scaled boxes shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] Sigmoid classes shape: torch.Size([8, 1, 512])
[nets/tinysimov35.py::Head.forward] Final output shape: torch.Size([8, 5, 512])
[main.py::test] Model outputs shape: torch.Size([8, 5, 512])

--- [utils/util.py::non_max_suppression] PYTORCH NMS DEBUG ---
[utils/util.py::non_max_suppression] Prediction shape: torch.Size([8, 5, 512])
[utils/util.py::non_max_suppression] Conf threshold: 0.25, IoU threshold: 0.45
[utils/util.py::non_max_suppression] Number of classes: 1
[utils/util.py::non_max_suppression] Candidates per image: [0, 0, 0, 0, 0, 0, 0, 0]

--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([8, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: False
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([8, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Inference mode - processing...
[nets/tinysimov35.py::Head.forward] Box feature shape: torch.Size([8, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Cls feature shape: torch.Size([8, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Anchors shape: torch.Size([2, 512])
[nets/tinysimov35.py::Head.forward] Strides shape: torch.Size([1, 512])
[nets/tinysimov35.py::Head.forward] Combined features shape: torch.Size([8, 65, 16, 32])
[nets/tinysimov35.py::Head.forward] Combined flat shape: torch.Size([8, 65, 512])
[nets/tinysimov35.py::Head.forward] Expected self.no: 65
[nets/tinysimov35.py::Head.forward] Split - box shape: torch.Size([8, 64, 512]), cls shape: torch.Size([8, 1, 512])

--- [nets/tinysimov35.py::DFL.forward] PYTORCH DFL DEBUG ---
[nets/tinysimov35.py::DFL.forward] Input shape: torch.Size([8, 64, 512])
[nets/tinysimov35.py::DFL.forward] DFL channels (self.ch): 16
[nets/tinysimov35.py::DFL.forward] Parsed dimensions - batch: 8, channels: 64, anchors: 512
[nets/tinysimov35.py::DFL.forward] After view(b, 4, ch, a): torch.Size([8, 4, 16, 512])
[nets/tinysimov35.py::DFL.forward] After transpose(2, 1): torch.Size([8, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After softmax(1): torch.Size([8, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After conv: torch.Size([8, 1, 4, 512])
[nets/tinysimov35.py::DFL.forward] Final output shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL output shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL split - a shape: torch.Size([8, 2, 512]), b shape: torch.Size([8, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchors expanded shape: torch.Size([1, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchor adjusted - a: torch.Size([8, 2, 512]), b: torch.Size([8, 2, 512])
[nets/tinysimov35.py::Head.forward] Box coordinates shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] Scaled boxes shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] Sigmoid classes shape: torch.Size([8, 1, 512])
[nets/tinysimov35.py::Head.forward] Final output shape: torch.Size([8, 5, 512])
[main.py::test] Model outputs shape: torch.Size([8, 5, 512])

--- [utils/util.py::non_max_suppression] PYTORCH NMS DEBUG ---
[utils/util.py::non_max_suppression] Prediction shape: torch.Size([8, 5, 512])
[utils/util.py::non_max_suppression] Conf threshold: 0.25, IoU threshold: 0.45
[utils/util.py::non_max_suppression] Number of classes: 1
[utils/util.py::non_max_suppression] Candidates per image: [0, 0, 0, 0, 0, 0, 0, 0]

--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([8, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: False
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([8, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Inference mode - processing...
[nets/tinysimov35.py::Head.forward] Box feature shape: torch.Size([8, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Cls feature shape: torch.Size([8, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Anchors shape: torch.Size([2, 512])
[nets/tinysimov35.py::Head.forward] Strides shape: torch.Size([1, 512])
[nets/tinysimov35.py::Head.forward] Combined features shape: torch.Size([8, 65, 16, 32])
[nets/tinysimov35.py::Head.forward] Combined flat shape: torch.Size([8, 65, 512])
[nets/tinysimov35.py::Head.forward] Expected self.no: 65
[nets/tinysimov35.py::Head.forward] Split - box shape: torch.Size([8, 64, 512]), cls shape: torch.Size([8, 1, 512])

--- [nets/tinysimov35.py::DFL.forward] PYTORCH DFL DEBUG ---
[nets/tinysimov35.py::DFL.forward] Input shape: torch.Size([8, 64, 512])
[nets/tinysimov35.py::DFL.forward] DFL channels (self.ch): 16
[nets/tinysimov35.py::DFL.forward] Parsed dimensions - batch: 8, channels: 64, anchors: 512
[nets/tinysimov35.py::DFL.forward] After view(b, 4, ch, a): torch.Size([8, 4, 16, 512])
[nets/tinysimov35.py::DFL.forward] After transpose(2, 1): torch.Size([8, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After softmax(1): torch.Size([8, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After conv: torch.Size([8, 1, 4, 512])
[nets/tinysimov35.py::DFL.forward] Final output shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL output shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL split - a shape: torch.Size([8, 2, 512]), b shape: torch.Size([8, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchors expanded shape: torch.Size([1, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchor adjusted - a: torch.Size([8, 2, 512]), b: torch.Size([8, 2, 512])
[nets/tinysimov35.py::Head.forward] Box coordinates shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] Scaled boxes shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] Sigmoid classes shape: torch.Size([8, 1, 512])
[nets/tinysimov35.py::Head.forward] Final output shape: torch.Size([8, 5, 512])
[main.py::test] Model outputs shape: torch.Size([8, 5, 512])

--- [utils/util.py::non_max_suppression] PYTORCH NMS DEBUG ---
[utils/util.py::non_max_suppression] Prediction shape: torch.Size([8, 5, 512])
[utils/util.py::non_max_suppression] Conf threshold: 0.25, IoU threshold: 0.45
[utils/util.py::non_max_suppression] Number of classes: 1
[utils/util.py::non_max_suppression] Candidates per image: [0, 0, 0, 0, 0, 0, 0, 0]

--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([8, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: False
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([8, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Inference mode - processing...
[nets/tinysimov35.py::Head.forward] Box feature shape: torch.Size([8, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Cls feature shape: torch.Size([8, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Anchors shape: torch.Size([2, 512])
[nets/tinysimov35.py::Head.forward] Strides shape: torch.Size([1, 512])
[nets/tinysimov35.py::Head.forward] Combined features shape: torch.Size([8, 65, 16, 32])
[nets/tinysimov35.py::Head.forward] Combined flat shape: torch.Size([8, 65, 512])
[nets/tinysimov35.py::Head.forward] Expected self.no: 65
[nets/tinysimov35.py::Head.forward] Split - box shape: torch.Size([8, 64, 512]), cls shape: torch.Size([8, 1, 512])

--- [nets/tinysimov35.py::DFL.forward] PYTORCH DFL DEBUG ---
[nets/tinysimov35.py::DFL.forward] Input shape: torch.Size([8, 64, 512])
[nets/tinysimov35.py::DFL.forward] DFL channels (self.ch): 16
[nets/tinysimov35.py::DFL.forward] Parsed dimensions - batch: 8, channels: 64, anchors: 512
[nets/tinysimov35.py::DFL.forward] After view(b, 4, ch, a): torch.Size([8, 4, 16, 512])
[nets/tinysimov35.py::DFL.forward] After transpose(2, 1): torch.Size([8, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After softmax(1): torch.Size([8, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After conv: torch.Size([8, 1, 4, 512])
[nets/tinysimov35.py::DFL.forward] Final output shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL output shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL split - a shape: torch.Size([8, 2, 512]), b shape: torch.Size([8, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchors expanded shape: torch.Size([1, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchor adjusted - a: torch.Size([8, 2, 512]), b: torch.Size([8, 2, 512])
[nets/tinysimov35.py::Head.forward] Box coordinates shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] Scaled boxes shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] Sigmoid classes shape: torch.Size([8, 1, 512])
[nets/tinysimov35.py::Head.forward] Final output shape: torch.Size([8, 5, 512])
[main.py::test] Model outputs shape: torch.Size([8, 5, 512])

--- [utils/util.py::non_max_suppression] PYTORCH NMS DEBUG ---
[utils/util.py::non_max_suppression] Prediction shape: torch.Size([8, 5, 512])
[utils/util.py::non_max_suppression] Conf threshold: 0.25, IoU threshold: 0.45
[utils/util.py::non_max_suppression] Number of classes: 1
[utils/util.py::non_max_suppression] Candidates per image: [0, 0, 0, 0, 0, 0, 0, 0]

--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([4, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: False
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([4, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Inference mode - processing...
[nets/tinysimov35.py::Head.forward] Box feature shape: torch.Size([4, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Cls feature shape: torch.Size([4, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Anchors shape: torch.Size([2, 512])
[nets/tinysimov35.py::Head.forward] Strides shape: torch.Size([1, 512])
[nets/tinysimov35.py::Head.forward] Combined features shape: torch.Size([4, 65, 16, 32])
[nets/tinysimov35.py::Head.forward] Combined flat shape: torch.Size([4, 65, 512])
[nets/tinysimov35.py::Head.forward] Expected self.no: 65
[nets/tinysimov35.py::Head.forward] Split - box shape: torch.Size([4, 64, 512]), cls shape: torch.Size([4, 1, 512])

--- [nets/tinysimov35.py::DFL.forward] PYTORCH DFL DEBUG ---
[nets/tinysimov35.py::DFL.forward] Input shape: torch.Size([4, 64, 512])
[nets/tinysimov35.py::DFL.forward] DFL channels (self.ch): 16
[nets/tinysimov35.py::DFL.forward] Parsed dimensions - batch: 4, channels: 64, anchors: 512
[nets/tinysimov35.py::DFL.forward] After view(b, 4, ch, a): torch.Size([4, 4, 16, 512])
[nets/tinysimov35.py::DFL.forward] After transpose(2, 1): torch.Size([4, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After softmax(1): torch.Size([4, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After conv: torch.Size([4, 1, 4, 512])
[nets/tinysimov35.py::DFL.forward] Final output shape: torch.Size([4, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL output shape: torch.Size([4, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL split - a shape: torch.Size([4, 2, 512]), b shape: torch.Size([4, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchors expanded shape: torch.Size([1, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchor adjusted - a: torch.Size([4, 2, 512]), b: torch.Size([4, 2, 512])
[nets/tinysimov35.py::Head.forward] Box coordinates shape: torch.Size([4, 4, 512])
[nets/tinysimov35.py::Head.forward] Scaled boxes shape: torch.Size([4, 4, 512])
[nets/tinysimov35.py::Head.forward] Sigmoid classes shape: torch.Size([4, 1, 512])
[nets/tinysimov35.py::Head.forward] Final output shape: torch.Size([4, 5, 512])
[main.py::test] Model outputs shape: torch.Size([4, 5, 512])

--- [utils/util.py::non_max_suppression] PYTORCH NMS DEBUG ---
[utils/util.py::non_max_suppression] Prediction shape: torch.Size([4, 5, 512])
[utils/util.py::non_max_suppression] Conf threshold: 0.25, IoU threshold: 0.45
[utils/util.py::non_max_suppression] Number of classes: 1
[utils/util.py::non_max_suppression] Candidates per image: [0, 0, 0, 0]

--- [utils/util.py::compute_ap] PYTORCH COMPUTE_AP DEBUG ---
[utils/util.py::compute_ap] TP shape: (0, 10), dtype: bool
[utils/util.py::compute_ap] Conf shape: (0,), dtype: float32
[utils/util.py::compute_ap] Pred_cls shape: (0,), dtype: float32
[utils/util.py::compute_ap] Target_cls shape: (0,), dtype: float32
[utils/util.py::compute_ap] Conf array is empty - no predictions to evaluate
After sorting - first 5 conf: []
Unique classes: []
Class counts: []
Number of classes: 0
Precision: nan, Recall: nan, mAP50: nan, mAP: nan
Evaluating on validation data...

--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([8, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: False
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([8, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Inference mode - processing...
[nets/tinysimov35.py::Head.forward] Box feature shape: torch.Size([8, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Cls feature shape: torch.Size([8, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Anchors shape: torch.Size([2, 512])
[nets/tinysimov35.py::Head.forward] Strides shape: torch.Size([1, 512])
[nets/tinysimov35.py::Head.forward] Combined features shape: torch.Size([8, 65, 16, 32])
[nets/tinysimov35.py::Head.forward] Combined flat shape: torch.Size([8, 65, 512])
[nets/tinysimov35.py::Head.forward] Expected self.no: 65
[nets/tinysimov35.py::Head.forward] Split - box shape: torch.Size([8, 64, 512]), cls shape: torch.Size([8, 1, 512])

--- [nets/tinysimov35.py::DFL.forward] PYTORCH DFL DEBUG ---
[nets/tinysimov35.py::DFL.forward] Input shape: torch.Size([8, 64, 512])
[nets/tinysimov35.py::DFL.forward] DFL channels (self.ch): 16
[nets/tinysimov35.py::DFL.forward] Parsed dimensions - batch: 8, channels: 64, anchors: 512
[nets/tinysimov35.py::DFL.forward] After view(b, 4, ch, a): torch.Size([8, 4, 16, 512])
[nets/tinysimov35.py::DFL.forward] After transpose(2, 1): torch.Size([8, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After softmax(1): torch.Size([8, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After conv: torch.Size([8, 1, 4, 512])
[nets/tinysimov35.py::DFL.forward] Final output shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL output shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL split - a shape: torch.Size([8, 2, 512]), b shape: torch.Size([8, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchors expanded shape: torch.Size([1, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchor adjusted - a: torch.Size([8, 2, 512]), b: torch.Size([8, 2, 512])
[nets/tinysimov35.py::Head.forward] Box coordinates shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] Scaled boxes shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] Sigmoid classes shape: torch.Size([8, 1, 512])
[nets/tinysimov35.py::Head.forward] Final output shape: torch.Size([8, 5, 512])
[main.py::test] Model outputs shape: torch.Size([8, 5, 512])

--- [utils/util.py::non_max_suppression] PYTORCH NMS DEBUG ---
[utils/util.py::non_max_suppression] Prediction shape: torch.Size([8, 5, 512])
[utils/util.py::non_max_suppression] Conf threshold: 0.25, IoU threshold: 0.45
[utils/util.py::non_max_suppression] Number of classes: 1
[utils/util.py::non_max_suppression] Candidates per image: [0, 0, 0, 0, 0, 0, 0, 0]

=== DEBUG: visualize_predictions input shapes (vis_count=0) ===
single_sample shape: torch.Size([1, 3, 128, 256])
single_sample dtype: torch.float16
single_sample min/max: 0.322/0.749
single_out type: <class 'list'>
single_out length: 1
single_out[0] shape: torch.Size([0, 6])
single_out[0] dtype: torch.float32
single_out[0]: empty tensor
single_gt shape: torch.Size([1, 6])
single_gt dtype: torch.float32
single_gt content (first few):
tensor([[ 0.0000,  0.0000, 18.0000, 17.3100, 24.0000, 23.3800]])
single_shapes: [([128, 256], [[1.0, 1.0], [0, 0]])]
single_shapes type: <class 'list'>
single_shapes[0]: ([128, 256], [[1.0, 1.0], [0, 0]])
=== END DEBUG ===

=== DEBUG: visualize_predictions input shapes (vis_count=1) ===
single_sample shape: torch.Size([1, 3, 128, 256])
single_sample dtype: torch.float16
single_sample min/max: 0.341/0.761
single_out type: <class 'list'>
single_out length: 1
single_out[0] shape: torch.Size([0, 6])
single_out[0] dtype: torch.float32
single_out[0]: empty tensor
single_gt shape: torch.Size([1, 6])
single_gt dtype: torch.float32
single_gt content (first few):
tensor([[  0.0000,   0.0000, 245.3500,  19.5000,  21.2900,  23.0000]])
single_shapes: [([128, 256], [[1.0, 1.0], [0, 0]])]
single_shapes type: <class 'list'>
single_shapes[0]: ([128, 256], [[1.0, 1.0], [0, 0]])
=== END DEBUG ===

=== DEBUG: visualize_predictions input shapes (vis_count=2) ===
single_sample shape: torch.Size([1, 3, 128, 256])
single_sample dtype: torch.float16
single_sample min/max: 0.396/0.792
single_out type: <class 'list'>
single_out length: 1
single_out[0] shape: torch.Size([0, 6])
single_out[0] dtype: torch.float32
single_out[0]: empty tensor
single_gt shape: torch.Size([1, 6])
single_gt dtype: torch.float32
single_gt content (first few):
tensor([[  0.0000,   0.0000, 127.9700,  43.3800,  26.0700,  27.5400]])
single_shapes: [([128, 256], [[1.0, 1.0], [0, 0]])]
single_shapes type: <class 'list'>
single_shapes[0]: ([128, 256], [[1.0, 1.0], [0, 0]])
=== END DEBUG ===

=== DEBUG: visualize_predictions input shapes (vis_count=3) ===
single_sample shape: torch.Size([1, 3, 128, 256])
single_sample dtype: torch.float16
single_sample min/max: 0.227/0.800
single_out type: <class 'list'>
single_out length: 1
single_out[0] shape: torch.Size([0, 6])
single_out[0] dtype: torch.float32
single_out[0]: empty tensor
single_gt shape: torch.Size([1, 6])
single_gt dtype: torch.float32
single_gt content (first few):
tensor([[  0.0000,   0.0000, 243.6200,  25.5000,  22.4400,  23.0000]])
single_shapes: [([128, 256], [[1.0, 1.0], [0, 0]])]
single_shapes type: <class 'list'>
single_shapes[0]: ([128, 256], [[1.0, 1.0], [0, 0]])
=== END DEBUG ===

=== DEBUG: visualize_predictions input shapes (vis_count=4) ===
single_sample shape: torch.Size([1, 3, 128, 256])
single_sample dtype: torch.float16
single_sample min/max: 0.027/0.749
single_out type: <class 'list'>
single_out length: 1
single_out[0] shape: torch.Size([0, 6])
single_out[0] dtype: torch.float32
single_out[0]: empty tensor
single_gt shape: torch.Size([1, 6])
single_gt dtype: torch.float32
single_gt content (first few):
tensor([[  0.0000,   0.0000, 235.0000,  44.6700,  20.6700,  21.3300]])
single_shapes: [([128, 256], [[1.0, 1.0], [0, 0]])]
single_shapes type: <class 'list'>
single_shapes[0]: ([128, 256], [[1.0, 1.0], [0, 0]])
=== END DEBUG ===

--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([8, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: False
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([8, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Inference mode - processing...
[nets/tinysimov35.py::Head.forward] Box feature shape: torch.Size([8, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Cls feature shape: torch.Size([8, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Anchors shape: torch.Size([2, 512])
[nets/tinysimov35.py::Head.forward] Strides shape: torch.Size([1, 512])
[nets/tinysimov35.py::Head.forward] Combined features shape: torch.Size([8, 65, 16, 32])
[nets/tinysimov35.py::Head.forward] Combined flat shape: torch.Size([8, 65, 512])
[nets/tinysimov35.py::Head.forward] Expected self.no: 65
[nets/tinysimov35.py::Head.forward] Split - box shape: torch.Size([8, 64, 512]), cls shape: torch.Size([8, 1, 512])

--- [nets/tinysimov35.py::DFL.forward] PYTORCH DFL DEBUG ---
[nets/tinysimov35.py::DFL.forward] Input shape: torch.Size([8, 64, 512])
[nets/tinysimov35.py::DFL.forward] DFL channels (self.ch): 16
[nets/tinysimov35.py::DFL.forward] Parsed dimensions - batch: 8, channels: 64, anchors: 512
[nets/tinysimov35.py::DFL.forward] After view(b, 4, ch, a): torch.Size([8, 4, 16, 512])
[nets/tinysimov35.py::DFL.forward] After transpose(2, 1): torch.Size([8, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After softmax(1): torch.Size([8, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After conv: torch.Size([8, 1, 4, 512])
[nets/tinysimov35.py::DFL.forward] Final output shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL output shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL split - a shape: torch.Size([8, 2, 512]), b shape: torch.Size([8, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchors expanded shape: torch.Size([1, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchor adjusted - a: torch.Size([8, 2, 512]), b: torch.Size([8, 2, 512])
[nets/tinysimov35.py::Head.forward] Box coordinates shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] Scaled boxes shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] Sigmoid classes shape: torch.Size([8, 1, 512])
[nets/tinysimov35.py::Head.forward] Final output shape: torch.Size([8, 5, 512])
[main.py::test] Model outputs shape: torch.Size([8, 5, 512])

--- [utils/util.py::non_max_suppression] PYTORCH NMS DEBUG ---
[utils/util.py::non_max_suppression] Prediction shape: torch.Size([8, 5, 512])
[utils/util.py::non_max_suppression] Conf threshold: 0.25, IoU threshold: 0.45
[utils/util.py::non_max_suppression] Number of classes: 1
[utils/util.py::non_max_suppression] Candidates per image: [0, 0, 0, 0, 0, 0, 0, 0]

--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([8, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: False
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([8, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Inference mode - processing...
[nets/tinysimov35.py::Head.forward] Box feature shape: torch.Size([8, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Cls feature shape: torch.Size([8, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Anchors shape: torch.Size([2, 512])
[nets/tinysimov35.py::Head.forward] Strides shape: torch.Size([1, 512])
[nets/tinysimov35.py::Head.forward] Combined features shape: torch.Size([8, 65, 16, 32])
[nets/tinysimov35.py::Head.forward] Combined flat shape: torch.Size([8, 65, 512])
[nets/tinysimov35.py::Head.forward] Expected self.no: 65
[nets/tinysimov35.py::Head.forward] Split - box shape: torch.Size([8, 64, 512]), cls shape: torch.Size([8, 1, 512])

--- [nets/tinysimov35.py::DFL.forward] PYTORCH DFL DEBUG ---
[nets/tinysimov35.py::DFL.forward] Input shape: torch.Size([8, 64, 512])
[nets/tinysimov35.py::DFL.forward] DFL channels (self.ch): 16
[nets/tinysimov35.py::DFL.forward] Parsed dimensions - batch: 8, channels: 64, anchors: 512
[nets/tinysimov35.py::DFL.forward] After view(b, 4, ch, a): torch.Size([8, 4, 16, 512])
[nets/tinysimov35.py::DFL.forward] After transpose(2, 1): torch.Size([8, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After softmax(1): torch.Size([8, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After conv: torch.Size([8, 1, 4, 512])
[nets/tinysimov35.py::DFL.forward] Final output shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL output shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL split - a shape: torch.Size([8, 2, 512]), b shape: torch.Size([8, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchors expanded shape: torch.Size([1, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchor adjusted - a: torch.Size([8, 2, 512]), b: torch.Size([8, 2, 512])
[nets/tinysimov35.py::Head.forward] Box coordinates shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] Scaled boxes shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] Sigmoid classes shape: torch.Size([8, 1, 512])
[nets/tinysimov35.py::Head.forward] Final output shape: torch.Size([8, 5, 512])
[main.py::test] Model outputs shape: torch.Size([8, 5, 512])

--- [utils/util.py::non_max_suppression] PYTORCH NMS DEBUG ---
[utils/util.py::non_max_suppression] Prediction shape: torch.Size([8, 5, 512])
[utils/util.py::non_max_suppression] Conf threshold: 0.25, IoU threshold: 0.45
[utils/util.py::non_max_suppression] Number of classes: 1
[utils/util.py::non_max_suppression] Candidates per image: [0, 0, 0, 0, 0, 0, 0, 0]

--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([8, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: False
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([8, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Inference mode - processing...
[nets/tinysimov35.py::Head.forward] Box feature shape: torch.Size([8, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Cls feature shape: torch.Size([8, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Anchors shape: torch.Size([2, 512])
[nets/tinysimov35.py::Head.forward] Strides shape: torch.Size([1, 512])
[nets/tinysimov35.py::Head.forward] Combined features shape: torch.Size([8, 65, 16, 32])
[nets/tinysimov35.py::Head.forward] Combined flat shape: torch.Size([8, 65, 512])
[nets/tinysimov35.py::Head.forward] Expected self.no: 65
[nets/tinysimov35.py::Head.forward] Split - box shape: torch.Size([8, 64, 512]), cls shape: torch.Size([8, 1, 512])

--- [nets/tinysimov35.py::DFL.forward] PYTORCH DFL DEBUG ---
[nets/tinysimov35.py::DFL.forward] Input shape: torch.Size([8, 64, 512])
[nets/tinysimov35.py::DFL.forward] DFL channels (self.ch): 16
[nets/tinysimov35.py::DFL.forward] Parsed dimensions - batch: 8, channels: 64, anchors: 512
[nets/tinysimov35.py::DFL.forward] After view(b, 4, ch, a): torch.Size([8, 4, 16, 512])
[nets/tinysimov35.py::DFL.forward] After transpose(2, 1): torch.Size([8, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After softmax(1): torch.Size([8, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After conv: torch.Size([8, 1, 4, 512])
[nets/tinysimov35.py::DFL.forward] Final output shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL output shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL split - a shape: torch.Size([8, 2, 512]), b shape: torch.Size([8, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchors expanded shape: torch.Size([1, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchor adjusted - a: torch.Size([8, 2, 512]), b: torch.Size([8, 2, 512])
[nets/tinysimov35.py::Head.forward] Box coordinates shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] Scaled boxes shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] Sigmoid classes shape: torch.Size([8, 1, 512])
[nets/tinysimov35.py::Head.forward] Final output shape: torch.Size([8, 5, 512])
[main.py::test] Model outputs shape: torch.Size([8, 5, 512])

--- [utils/util.py::non_max_suppression] PYTORCH NMS DEBUG ---
[utils/util.py::non_max_suppression] Prediction shape: torch.Size([8, 5, 512])
[utils/util.py::non_max_suppression] Conf threshold: 0.25, IoU threshold: 0.45
[utils/util.py::non_max_suppression] Number of classes: 1
[utils/util.py::non_max_suppression] Candidates per image: [0, 0, 0, 0, 0, 0, 0, 0]

--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([8, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: False
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([8, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Inference mode - processing...
[nets/tinysimov35.py::Head.forward] Box feature shape: torch.Size([8, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Cls feature shape: torch.Size([8, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Anchors shape: torch.Size([2, 512])
[nets/tinysimov35.py::Head.forward] Strides shape: torch.Size([1, 512])
[nets/tinysimov35.py::Head.forward] Combined features shape: torch.Size([8, 65, 16, 32])
[nets/tinysimov35.py::Head.forward] Combined flat shape: torch.Size([8, 65, 512])
[nets/tinysimov35.py::Head.forward] Expected self.no: 65
[nets/tinysimov35.py::Head.forward] Split - box shape: torch.Size([8, 64, 512]), cls shape: torch.Size([8, 1, 512])

--- [nets/tinysimov35.py::DFL.forward] PYTORCH DFL DEBUG ---
[nets/tinysimov35.py::DFL.forward] Input shape: torch.Size([8, 64, 512])
[nets/tinysimov35.py::DFL.forward] DFL channels (self.ch): 16
[nets/tinysimov35.py::DFL.forward] Parsed dimensions - batch: 8, channels: 64, anchors: 512
[nets/tinysimov35.py::DFL.forward] After view(b, 4, ch, a): torch.Size([8, 4, 16, 512])
[nets/tinysimov35.py::DFL.forward] After transpose(2, 1): torch.Size([8, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After softmax(1): torch.Size([8, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After conv: torch.Size([8, 1, 4, 512])
[nets/tinysimov35.py::DFL.forward] Final output shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL output shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL split - a shape: torch.Size([8, 2, 512]), b shape: torch.Size([8, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchors expanded shape: torch.Size([1, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchor adjusted - a: torch.Size([8, 2, 512]), b: torch.Size([8, 2, 512])
[nets/tinysimov35.py::Head.forward] Box coordinates shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] Scaled boxes shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] Sigmoid classes shape: torch.Size([8, 1, 512])
[nets/tinysimov35.py::Head.forward] Final output shape: torch.Size([8, 5, 512])
[main.py::test] Model outputs shape: torch.Size([8, 5, 512])

--- [utils/util.py::non_max_suppression] PYTORCH NMS DEBUG ---
[utils/util.py::non_max_suppression] Prediction shape: torch.Size([8, 5, 512])
[utils/util.py::non_max_suppression] Conf threshold: 0.25, IoU threshold: 0.45
[utils/util.py::non_max_suppression] Number of classes: 1
[utils/util.py::non_max_suppression] Candidates per image: [0, 0, 0, 0, 0, 0, 0, 0]

--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([8, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: False
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([8, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Inference mode - processing...
[nets/tinysimov35.py::Head.forward] Box feature shape: torch.Size([8, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Cls feature shape: torch.Size([8, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Anchors shape: torch.Size([2, 512])
[nets/tinysimov35.py::Head.forward] Strides shape: torch.Size([1, 512])
[nets/tinysimov35.py::Head.forward] Combined features shape: torch.Size([8, 65, 16, 32])
[nets/tinysimov35.py::Head.forward] Combined flat shape: torch.Size([8, 65, 512])
[nets/tinysimov35.py::Head.forward] Expected self.no: 65
[nets/tinysimov35.py::Head.forward] Split - box shape: torch.Size([8, 64, 512]), cls shape: torch.Size([8, 1, 512])

--- [nets/tinysimov35.py::DFL.forward] PYTORCH DFL DEBUG ---
[nets/tinysimov35.py::DFL.forward] Input shape: torch.Size([8, 64, 512])
[nets/tinysimov35.py::DFL.forward] DFL channels (self.ch): 16
[nets/tinysimov35.py::DFL.forward] Parsed dimensions - batch: 8, channels: 64, anchors: 512
[nets/tinysimov35.py::DFL.forward] After view(b, 4, ch, a): torch.Size([8, 4, 16, 512])
[nets/tinysimov35.py::DFL.forward] After transpose(2, 1): torch.Size([8, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After softmax(1): torch.Size([8, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After conv: torch.Size([8, 1, 4, 512])
[nets/tinysimov35.py::DFL.forward] Final output shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL output shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL split - a shape: torch.Size([8, 2, 512]), b shape: torch.Size([8, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchors expanded shape: torch.Size([1, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchor adjusted - a: torch.Size([8, 2, 512]), b: torch.Size([8, 2, 512])
[nets/tinysimov35.py::Head.forward] Box coordinates shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] Scaled boxes shape: torch.Size([8, 4, 512])
[nets/tinysimov35.py::Head.forward] Sigmoid classes shape: torch.Size([8, 1, 512])
[nets/tinysimov35.py::Head.forward] Final output shape: torch.Size([8, 5, 512])
[main.py::test] Model outputs shape: torch.Size([8, 5, 512])

--- [utils/util.py::non_max_suppression] PYTORCH NMS DEBUG ---
[utils/util.py::non_max_suppression] Prediction shape: torch.Size([8, 5, 512])
[utils/util.py::non_max_suppression] Conf threshold: 0.25, IoU threshold: 0.45
[utils/util.py::non_max_suppression] Number of classes: 1
[utils/util.py::non_max_suppression] Candidates per image: [0, 0, 0, 0, 0, 0, 0, 0]

--- [nets/tinysimov35.py::Head.forward] PYTORCH HEAD DEBUG ---
[nets/tinysimov35.py::Head.forward] Input shape: torch.Size([1, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Training mode: False
[nets/tinysimov35.py::Head.forward] After conv shape: torch.Size([1, 24, 16, 32])
[nets/tinysimov35.py::Head.forward] Inference mode - processing...
[nets/tinysimov35.py::Head.forward] Box feature shape: torch.Size([1, 64, 16, 32])
[nets/tinysimov35.py::Head.forward] Cls feature shape: torch.Size([1, 1, 16, 32])
[nets/tinysimov35.py::Head.forward] Anchors shape: torch.Size([2, 512])
[nets/tinysimov35.py::Head.forward] Strides shape: torch.Size([1, 512])
[nets/tinysimov35.py::Head.forward] Combined features shape: torch.Size([1, 65, 16, 32])
[nets/tinysimov35.py::Head.forward] Combined flat shape: torch.Size([1, 65, 512])
[nets/tinysimov35.py::Head.forward] Expected self.no: 65
[nets/tinysimov35.py::Head.forward] Split - box shape: torch.Size([1, 64, 512]), cls shape: torch.Size([1, 1, 512])

--- [nets/tinysimov35.py::DFL.forward] PYTORCH DFL DEBUG ---
[nets/tinysimov35.py::DFL.forward] Input shape: torch.Size([1, 64, 512])
[nets/tinysimov35.py::DFL.forward] DFL channels (self.ch): 16
[nets/tinysimov35.py::DFL.forward] Parsed dimensions - batch: 1, channels: 64, anchors: 512
[nets/tinysimov35.py::DFL.forward] After view(b, 4, ch, a): torch.Size([1, 4, 16, 512])
[nets/tinysimov35.py::DFL.forward] After transpose(2, 1): torch.Size([1, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After softmax(1): torch.Size([1, 16, 4, 512])
[nets/tinysimov35.py::DFL.forward] After conv: torch.Size([1, 1, 4, 512])
[nets/tinysimov35.py::DFL.forward] Final output shape: torch.Size([1, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL output shape: torch.Size([1, 4, 512])
[nets/tinysimov35.py::Head.forward] DFL split - a shape: torch.Size([1, 2, 512]), b shape: torch.Size([1, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchors expanded shape: torch.Size([1, 2, 512])
[nets/tinysimov35.py::Head.forward] Anchor adjusted - a: torch.Size([1, 2, 512]), b: torch.Size([1, 2, 512])
[nets/tinysimov35.py::Head.forward] Box coordinates shape: torch.Size([1, 4, 512])
[nets/tinysimov35.py::Head.forward] Scaled boxes shape: torch.Size([1, 4, 512])
[nets/tinysimov35.py::Head.forward] Sigmoid classes shape: torch.Size([1, 1, 512])
[nets/tinysimov35.py::Head.forward] Final output shape: torch.Size([1, 5, 512])
[main.py::test] Model outputs shape: torch.Size([1, 5, 512])

--- [utils/util.py::non_max_suppression] PYTORCH NMS DEBUG ---
[utils/util.py::non_max_suppression] Prediction shape: torch.Size([1, 5, 512])
[utils/util.py::non_max_suppression] Conf threshold: 0.25, IoU threshold: 0.45
[utils/util.py::non_max_suppression] Number of classes: 1
[utils/util.py::non_max_suppression] Candidates per image: [0]

--- [utils/util.py::compute_ap] PYTORCH COMPUTE_AP DEBUG ---
[utils/util.py::compute_ap] TP shape: (0, 10), dtype: bool
[utils/util.py::compute_ap] Conf shape: (0,), dtype: float32
[utils/util.py::compute_ap] Pred_cls shape: (0,), dtype: float32
[utils/util.py::compute_ap] Target_cls shape: (0,), dtype: float32
[utils/util.py::compute_ap] Conf array is empty - no predictions to evaluate
After sorting - first 5 conf: []
Unique classes: []
Class counts: []
Number of classes: 0
Precision: nan, Recall: nan, mAP50: nan, mAP: nan
